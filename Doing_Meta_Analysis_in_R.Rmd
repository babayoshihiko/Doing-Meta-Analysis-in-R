--- 
title: "Doing Meta-Analysis in R"
subtitle: "A Hands-on Guide"
author: 
- Mathias Harrer 
- Pim Cuijpers
- Toshi A. Furukawa
- David D. Ebert
github-repo: "MathiasHarrer/Doing-Meta-Analysis-in-R"
site: bookdown::bookdown_site
output: 
  bookdown::gitbook:
    config: 
      toc:
       collapse: section
      search: yes
      fontsettings:
        size: 2
    split_by: section
    includes:
      after_body: banner.html
    df_print: paged
    theme: !expr bslib::bs_theme()
documentclass: book
bibliography: [book.bib, packages.bib]
biblio-style: apalike
link-citations: yes
twitter-handle: MathiasHarrer
description: "This is a guide on how to conduct Meta-Analyses in R. (Japanese version)"
favicon: "favicon.ico"
---



# ようこそ！ {- #index}

---

<a href="https://www.routledge.com/Doing-Meta-Analysis-with-R-A-Hands-On-Guide/Harrer-Cuijpers-Furukawa-Ebert/p/book/9780367610074" target="_blank"><img src="images/cover.png" width="250" align="right" alt="" class="cover" /></a> オンライン版の **R によるメタ分析：**. 

本書は、 _R_ でメタ分析を行う方法について、わかりやすく紹介するものである。メタ分析の基本的な手順として、アウトカム指標のプール、フォレストプロット、異質性診断、サブグループ解析、メタ回帰、出版バイアスの制御方法、バイアスリスク評価、プロットツールなどを網羅している。

また、ネットワークメタ分析、マルチレベル（３レベル）メタ分析、ベイズメタ分析アプローチ、SEMメタ分析など、高度でありながら関連性の高いトピックも取り上げる。

本書で扱うプログラミングや統計的背景は、**非専門家レベル**にとどめている。本書の**印刷版**は、[Chapman & Hall/CRC Press](https://www.routledge.com/Doing-Meta-Analysis-with-R-A-Hands-On-Guide/Harrer-Cuijpers-Furukawa-Ebert/p/book/9780367610074) (Taylor & Francis) から出版されている。


<br></br>

## ソースレポジトリ {-}

---

本書は、[**{rmarkdown}**](https://rmarkdown.rstudio.com/docs/) および [**{bookdown}**](https://bookdown.org/) を使用して構築した。数式は [MathJax](http://docs.mathjax.org/en/latest/index.html) を使ってレンダリングしている。このガイドの編集に使用したすべての資料とソースコードは **GitHub** で見ることができる。フォーク、共有、再利用は自由である。ただし、このリポジトリは主に「読むだけ」を想定しており、基本的に PR は考慮されていない（連絡方法については、以下のセクションと前書きを参照）。  

[![GitHub followers](https://img.shields.io/badge/View Repository-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/MathiasHarrer/Doing-Meta-Analysis-in-R)



<br></br>

## Contributing {-}

---

本ガイドはオープンソースプロジェクトであり、本ガイドのいくつかのセクションで追加コンテンツを提供してくれた専門家の貢献者に特別な感謝を捧げる。

* [**Luke A. McGuinness**](https://twitter.com/mcguinlu), University of Bristol: Chapter 15, Risk of Bias Plots.

本書に貢献したい方は、**Mathias** (mathias.harrer@fau.de) にメールを送り、提案する追加事項を伝えていただきたい。

<br></br>

## 本書を引用 {-}

---

本書の原著を引用する際には、以下のようにされたい。

```{block, type='boxempty'}
Harrer, M., Cuijpers, P., Furukawa, T.A., & Ebert, D.D. (2021). _Doing Meta-Analysis with R: A Hands-On Guide_. Boca Raton, FL and London: Chapman & Hall/CRC Press. ISBN 978-0-367-61007-4.
```

引用は [BibTeX](https://www.protectlab.org/meta-analysis-in-r/data/citation.bib) または [.ris](https://www.protectlab.org/meta-analysis-in-r/data/citation.ris) でもダウンロード可能。


<br></br>


## パッケージを引用 {-}

---

このガイドでは、様々な _R_ パッケージを紹介し、使用していく。こうしたパッケージが誰でも無料で使えるのは、世界中の専門家が膨大な時間と労力を費やして、通常は無報酬で開発してきたからに他ならない。本書で紹介されているパッケージを使ってメタ分析する場合は、レポートの中で引用することも強く推奨する。

このガイドでは、新しいパッケージが紹介されるたびに、それを引用するためのリファレンスも提供していく。また、`citation("package")` を実行することで、適切な引用方法を取得することが可能である。感謝！


<br></br>

```{r include=FALSE}
# automatically create a bib database for R packages
knitr::write_bib(c(
  .packages(), 'bookdown', 'knitr', 'rmarkdown'
), 'packages.bib')
```

<!--chapter:end:index-ja.Rmd-->

# 序章 {- #preface}

---



> "The problems are solved, not by giving new information,
> but by arranging what we have known since long."
> 
> -- **Ludwig Wittgenstein**, [**Philosophical Investigations**](https://plato.stanford.edu/entries/wittgenstein/#PhilInve)



<span class="firstcharacter">こ</span>
の世界を観察していて複雑であると気づくのは、ごく当たり前のことである。科学研究も例外ではなく、多くの研究分野において、一見すると乗り越えられないような先行研究群に直面することがある。また、異なる研究からの証拠は矛盾していることがあり、様々な情報源から意味を見出すことが困難な場合もある。

そのため、社会科学、医学、生物学、計量経済学など、多くの分野で**エビデンス合成**の手法が重要な役割を担っている。**メタ分析**は、様々な研究や分析の結果を組み合わせるために用いられる統計的手法であり、多くの研究分野において不可欠なツールとなっている。メタ分析は、特に実用的な意思決定や将来の研究努力の指針となる場合、非常に重要な意味を持つことがある。そのため、多くの応用研究者はメタ分析のスキルを「統計のツールボックス」の中に入れているが、一方で、自分の研究分野でメタ分析を行う方法を学びたいと考えている研究者もいる。メタ分析は非常に一般的なものとなっており、多くの大学院生や学部生がすでにカリキュラムの一部としてメタ分析の実行方法を学んでいる（その熱心さは様々であるが）。

メタ分析の実行方法は、統計計算全体と同様に、この数十年で大きな変化を遂げた。これは、主に _R_ Statistical Programming Language and Environmentという形で、オープンソースで共同開発された統計ソフトウェアの台頭と大いに関係がある。 _R_ のエコシステムにより、世界中の研究者や統計学者が独自の**パッケージ**を構築し、誰でも無料で利用することができるようになった。このため、 _R_ 言語用の統計ソフトは目を見張るほど増えている。これを書いている間にも、[CRAN Task View](https://cran.r-project.org/web/views/MetaAnalysis.html) には、メタ分析専用パッケージだけでも130以上リストアップされている。

 _R_ では、文字通り何でも可能である。完全なプログラミング言語なので、必要な関数が見つからなければ、自分で簡単に書くことも可能である。しかし、メタ分析では、もうほとんどその必要はない。それほど多くない _R_ パッケージのコレクションで、現在の「最先端」のメタ解析プログラムに見られるすべての機能を無料で提供しているのである。さらに言えば、現在 _R_ でしか適用できない新しいメタ分析手法もたくさんある。要するに、 _R_ 環境は研究者に多くのメタ解析ツールを提供している。最良のケースでは、データからより確かな結論を導き出すことができ、その結果、意思決定により良い情報を提供することが可能である。

ここで、なぜ誰もがメタ分析に _R_ を使わないのかという疑問が湧いてくる。私たちは、主に2つの理由があると考えている。**利便性**と**不安**（そして時にはその両方が混在している）である。どちらの理由も非常に理解しやすいものである。メタ分析者の多くは応用研究者であり、統計学者やプログラマーではない。不明瞭で複雑に見えるプログラミング言語を学ぶことを考えると、それが抑止力として働くことがある。メタ分析の手法も同様で、特別な理論的背景、無数の分析的選択肢、正しく解釈する必要のあるさまざまな統計学がある。

このガイドでは、これらの懸念の多くが杞憂であること、そして _R_ でのメタ分析の方法を学ぶことは努力に値することを示したい。このガイドが、 _R_ でのメタ分析プロジェクトをマスターするために必要なスキルの習得の一助となれば幸いである。また、このガイドによって、いつ**どのような**メタ分析手法を適用するかだけでなく、**なぜ**その手法を適用するかも簡単に理解できるようになることを期待している。最後になるが、このガイドは、メタ分析手法と _R_ プログラミングが単なる不便なものではなく、魅力的なトピックであることを示す試みであると考えている。

<br></br>

## 対象者は普通の人 {-}

---

このガイドは、メタ分析の専門家や統計学者向けに書かれたものではない。また、メタ分析手法に関する特別な背景知識を持っていることを前提としていない。必要なのは、基本的な数学的・統計的概念に関する基礎知識だけである。例えば、「平均」「標準偏差」「相関」「回帰」「$p$値」「正規分布」などは聞いたことがあるだろう。これらの用語にピンとくるのであればもう大丈夫。本当にゼロから始めるのであれば、まず Robert Stinerock の統計学ビギナーズガイド [@stinerock2018statistics] を読み、 _R_ での実践例を含む徹底的な紹介を受けると良いだろう -- あるいは他の統計学入門書でも構わない。

数式や統計表記を使うことがあるが、なるべく最小限にとどめるようにした。しかし、慌てないように。数式やギリシャ文字は一見するとわかりにくいが、メタ分析手法の背後にある考え方を的確に表現するための非常に優れた方法であることが多いのである。これらの数式を見て、それが何を表しているのかを知ることで、この先読みすすめるより高度な文章を理解することも容易になる。もちろん、ある記号や文字が何を表しているのか、特定の数式が何を伝えようとしているのか、常に詳しく説明するように努める。この本の付録には、記号のリストと、それが何を表しているのかが書かれている。この後の章、特に上級者向けの手法の章では、応用技術の背後にある考え方を説明するために、少し専門的になる必要がある。それでも、これらの章で使用される数学的、統計的概念に関する背景情報を常に含めるようにする。

 _R_ （または一般的なプログラミング）の予備知識は必要ない。このガイドでは、独自のメタ分析をコーディングするために必要な _R_ の基本的なスキルを優しく紹介するように努めている。また、学習を継続するための適切なリソースへの参照も提供する。さらに、PC や Mac で _R_ を便利に使用できる無料のコンピュータプログラムをセットアップする方法を紹介する。

タイトルにあるように、本書はメタ分析を「行う」部分に焦点をあてている。本書は、 _R_ を使った分析を始めたいと考えている応用研究者、学生、データサイエンティストのニーズを満たす、アクセス可能なリソースとなることを目的としている。しかし、メタ分析は広大で多面的なトピックであるため、このガイドですべてをカバーできないのは当然である。本書では、特に3つの領域について制限を設けている。

- 各トピックについて簡単な入門を提供するが、研究課題を定義する方法、系統的に研究を検索してメタ分析に含める方法、そして研究の質を評価する方法については**詳細には**説明しない。トピック一つ一つはそれぞれ独自の書籍に値するものであり、幸いにも多くの有用なリソースが少なくとも英語では既に存在している。そこで、メタ分析用のデータを収集する際の重要な検討事項や落とし穴について概要を説明し、詳細については適切なリソースを紹介する。

- このガイドの第二の限界は、技術的なレベルに関するものである。この本は、明らかに「人間」向けに書かれている。本書の目的は、特定のメタ分析技術をいつ、どのように、そしてなぜ適用するのか、その落とし穴も含めて紹介することである。また、本書で扱う技術について、簡単にアクセスでき、概念的な理解を得られるように努め、このミッションに役立つ場合のみ、より技術的な詳細に言及する。当然ながら、専門家レベルのメタ分析や統計学者が望むような技術的な内容を深く掘り下げることは、このガイドの一部には含まれないことになる。それでも、各章にはより高度なリソースや出版物への参照を設け、関心のある読者のために配慮している。

- 書籍の内容は、常に著者の経歴や経験をある程度反映している。本書で取り上げる手法は、幅広い研究領域や専門分野に適用でき、関連性があると確信している。しかし、本書の著者4名は、主に心理学、精神医学、医学、介入研究の最新の研究に精通している。そのため、本書で取り上げる「実世界」での使用例や事例も、私たちが熟知しているトピックに集中している。メタ分析の手法は、（これから説明するいくつかの前提条件を満たせば）データがどのような研究分野に由来しているかにはほとんど関係なく、さまざまな種類の結果指標に使用できることは良いニュースである。しかし、このガイドをできるだけ多くの応用研究分野に広く適用しようと最善を尽くしているが、本書で取り上げる方法が特定の分野に強く関連する可能性もある。



## 本書で扱うトピック {-}

---

このガイドでは、特に以下のトピックについて説明する。

* メタ分析とは何か、そしてなぜメタ分析が**発明された**のか。

* メタ分析の**利点**と**一般的な問題点**。

* メタ分析の**リサーチクエスチョン**をどのように設定し、どのように**研究のための検索**を行うことができるのか。

* _R_ の設定方法と、 _R_ を便利に使うための**コンピュータ・プログラム**である。

* メタ分析のデータを _R_ に**インポート**する方法と、コードで**操作**する方法。

* **効果量**とは何か、どのように算出するのか。

* 固定効果メタ解析とランダム効果メタ解析における**効果量**のプール方法。

* メタ分析における**異質性**の分析方法、および**サブグループ解析**と**メタ回帰**を用いた探索方法。

* **選択的成果報告**の問題点、およびその取り組み方。

* マルチレベルメタ解析、メタ解析的構造方程式モデリング、ネットワークメタ解析、ベイズメタ解析などの**高度なメタ解析手法**の実行方法。

* メタ分析の結果をどのように**報告**し、**再現性**を持たせるか。




## 本書の使い方 {-}

---

### 作業の流れ {-}

---

本書は「直線的」に読み進めることを意図している。メタ分析と _R_ の基本に関する最初の章から始めて、1章ずつ読み進めていくことを勧める。すぐに実践的な章に飛びつくのは魅力的かもしれないが、一般的には勧めない。学生や研究者に初めてメタ分析を行う方法を教える場合、この手法や R Studio 環境に関する基本的な知識は、後々挫折しないための必要悪であることがわかるようにする。特に、メタ分析と _R_ プログラミングの経験がない場合には、このことが当てはまる。 _R_ の経験者は、 _R_ と R Studio を紹介する章を読み飛ばしても構わないが、復習のために読んでおいても損はないだろう。

すべての章はほぼ自己完結しているが、前の章で扱ったトピックを参照することがある。特に高度なメタ解析手法の章では、以前に扱った理論的な概念に慣れていることを前提としている。

本書の最後のセクションで、メタ分析に役立つツールを紹介している。しかし、これらのツールはメタ分析を行う際に考慮すべき最後の事柄であるということではない。主にメタ分析プロジェクトのための参考文献として役立つものとしてこれらの章を最後に置いただけである。本書では、テーマごとに関連するセクションで、これらのツールにリンクしている。





### コンパニオン _R_ パッケージ {-}

---

本書には **{dmetar}** というコンパニオン _R_ パッケージが付属している。このパッケージは主に2つの機能を提供する。まず、快適に _R_ に親しむことを目的としている。 _R_ には、メタ解析のための素晴らしい パッケージがすでにあり、その機能は多岐にわたるが、少なくとも初心者が _R_ で使うのは現状では簡単ではない落とし穴もある。

**{dmetar}** パッケージは、問題解決を容易にする関数を提供することによって、この落とし穴を埋めることを目的としている。さらに、このパッケージには、本書で紹介する実践的な例で使用するすべてのデータセットも含まれている。Chapter \@ref(dmetar) では、**{dmetar}** パッケージを詳しく紹介し、パッケージのインストール方法を順を追って説明する。大きな変更はないが、**{dmetar}** は現在も活発に開発されているので、時々[package website](https://dmetar.protectlab.org) を見て、メタ解析に使える新機能や改良がないか確認しておくとよいだろう。

**{dmetar}** パッケージのインストールを推奨するが、必須ではない。本書で **{dmetar}** を使用する場合、その関数の生のコード、または使用するデータセットのダウンロードリンクも提供する。




### テキストボックス {-}

---

本書全体を通して、テキストボックスのセットを使用している。

```{block, type='boxinfo'}
**一般的な注意事項**

一般的なメモには、関連する背景情報、洞察、逸話、考察、または主題に関連するテイクホームメッセージが含まれている。
```

```{block, type='boximportant'}
**重要なお知らせ**

このボックスには、注意点、問題点、欠点、落とし穴などの情報が記載されている。
```

```{block, type='boxquestion'}
**質問**

各章の終わりには、このボックスの中にいくつかの質問があり、あなたの知識を試すことが可能である。これらの質問の答えは、巻末の[付録A](#qanda)に掲載されている。
```

```{block, type='boxdmetar'}
**{dmetar}** 注意事項

付属の _R_ パッケージに含まれる関数やデータセットが使用された場合、**{dmetar}** のノートボックスが表示される。これらのボックスには、パッケージがインストールされていない読者のために、関数コードやデータセットのダウンロードリンクへのURLも含まれている。
```

```{block, type='boxreport'}
**どのように報告すればよいのだろうか？**

このボックスには、論文や研究記事で _R_ 出力を報告する方法についての推奨事項が記載されている。
```




## 凡例 {-}

---

この本では、いくつかの表記法を使っている。

$$~$$

**{package}**

すべての _R_ パッケージは太字で書かれ、中括弧（波括弧）でくくられる。これは _R_ のコミュニティでは一般的なパッケージ名の書き方である。

$$~$$

`R code`

_R_ のコードや _R_ で定義するオブジェクトは、すべてこの等幅フォントで書かれている。

$$~$$

`## R出力`

_R_ のコードを実行した後に受け取る出力にも同じ等幅フォントが使用されている。ただし、 _R_ の入力と区別するために2つの番号記号（シャープ記号）を使っている。

$$~$$

$Formula$

セリフフォントは、数式や統計など、数学的な表記をするときに使う。




## 行き詰まったら {-}

---

_R_ でメタ分析を行うための道は、時に険しい道であることは否めない。これは時に誇張されていると思うこともあるが、 _R_ の学習曲線は**険しい**。統計学は難しいものである。本書では、 _R_ を使ったメタ分析の実行方法を学ぶ際に、できるだけ苦痛を感じないようにするために最善を尽くす。しかし、それでも、時には挫折することがある。これは当然といえば当然なのである。私たちは皆、どこかでゼロから始めなければならないのである。私たちの経験から、 _R_ やメタ分析のやり方を学べなかった人に会ったことがないと断言できる。必要なのは練習と、いつまでも「学び続ける」ことなのである。私たちはあなたを信じている。

このモチベーションメッセージよりももう少し実用的なものとして、このガイドでは答えられないようなことにつまずいたときにできることをいくつか紹介する。

<br></br>

### パニックにならない {-}

---

_R_ の最初の一歩を踏み出すとき、多くの人は最初の赤いエラーメッセージが出始めると恐怖を感じるが、恐れる必要はない。**誰でも**エラーメッセージは**頻繁に**出ている。パニックになったり、コンピュータを窓から投げ捨てたりするのではなく、深呼吸をしてエラーメッセージをよく読もう。少し手を加えるだけで、エラーメッセージが消えることはよくある。コードのスペルを間違えていないか？括弧を閉じたり、引用符で囲んだりするのを忘れていないか？

また、出力が実際に エラー**である**ことを確認する（訳注:訳者は初心者に _R_ の使い方を教えることがあるが、  _R_ のメッセージは赤字かつ英語であるため、初学者はエラーでないものも「エラーが出た」と勘違いすることが多い。）。 _R_  は「エラー (Error)」、「警告 (Warning)」、「メッセージ」を区別している。エラーは、コードが実行されなかったことを意味する。警告は、コードは実行されたが、何か問題が発生した可能性があることを意味する。メッセージは、コードが完全に実行されたことを意味し、通常、関数が内部で行ったことに注意を向けさせたいときに表示される。このため、これは **診断メッセージ**とも呼ばれている。


<br></br>

### Google {-}

---

あるソフトウェア開発者の友人が、ソフトウェア開発者についてこんなジョークを言ったことがある。「プログラマーとは、一般人よりもグーグル操作がうまい人のことだ」。この言葉は、 _R_ プログラミングにも当てはまる。もし、エラーや警告のメッセージの意味が分からない状況に陥ったら、迷わずコピー＆ペーストして、Googleで検索する。その際、「R」をつけると検索結果が良くなることがある。インターネット上のほとんどのコンテンツは英語で書かれているので、 _R_ のエラーメッセージが他の言語で書かれている場合は、 `Sys.setenv(LANGUAGE = "en")` を実行してから、もう一度コードを実行してみよう。

世の中には大きな _R_ コミュニティがあり、以前同じ問題に直面した人がいる可能性は非常に高い。また、データに対して何か特別なことをしたいが、そのためにどのような _R_ コマンドを使用できるかがわからない場合にも、Google は役に立つ。専門家であっても、 _R_ のコードを書くときに Google を**数十回**使うことはよくある。あなたも困ったときは、迷わず Google を使おう。



### _StackOverflow_ と _CrossValidated_ {-}

---

Google で _R_ 関連の質問を検索すると、最初にヒットするリンクが [StackOverflow](https://stackoverflow.com/) というサイトが多いことがすぐに分かる。StackOverflow は、プログラミングに関連する一般的な質問のための大規模なコミュニティベースのフォーラムである。StackOverflow では、（あなたを含む）すべての人が質問をしたり回答したりすることが可能である。

インターネット上の他の多くのフォーラムとは対照的に、StackOverflow で得られる回答は、通常、目標指向で役に立つものである。Google で検索しても問題が解決しない場合は、そこで対処するのが良い解決策になるかもしれない。ただし、いくつか注意しなければならないことがある。まず、質問をするときは、どのプログラミング言語について話しているのかがわかるように、常に `[R]` というタグを付けてみよう。また、 _R_ で `sessionInfo()` を実行し、得られた出力を質問に添付する。これにより、あなたが使っている _R_ とパッケージのバージョンを知ることができ、問題の所在を突き止めるのに役立つこともある。

最後に、圧倒的な優しさを期待しないことである。StackOverflow のユーザーの多くは経験豊富なプログラマーで、特定の解決策を教えてくれるかもしれないが、誰かがあなたの代わりに問題を解決してくれると思うべきではない。また、誰かがこのトピックはすでに他の場所で扱われていることを伝え、リンクを送り、次に進むこともあり得る。とはいえ、StackOverflow を使用することは、通常、あなたが対処している特定の問題に対する質の高いサポートを得るための最良の方法である。

ちなみに StackOverflow は、主にプログラミングに関する質問をするところである。統計学的な背景もある質問であれば、代わりに [CrossValidated](https://stats.stackexchange.com/) を利用するとよいだろう。CrossValidated は StackOverflow と同じように機能しているが、主に統計学や機械学習の専門家が使用する。




### 問い合わせ {-}

---

もし、疑問がこのガイド自体と関係があるように感じられるのであれば、私たちに連絡することも可能である。特に、このガイドの付属の _R_ パッケージである **{dmetar}** の問題に関係している場合がそうである。パッケージのインストールや機能の使用に問題がある場合、私たちの[ウェブサイト](https://www.protectlab.org/meta-analysis-in-r)で問題を報告する方法を見つけることができる。特定の問題が頻繁に発生する場合、私たちは通常その問題を調査し、解決策を探している。既知の問題は、オンライン版ガイドの「修正・備考」セクションにも表示される（**ワークフロー**セクションを参照）。ご質問に対する回答がない場合や、回答までに時間がかかる場合もあるが、ご容赦いただきたい。メタ分析やパッケージに関する質問は毎日多数寄せられており、ひとつひとつに直接お答えすることができない場合もある。（訳注：日本語訳に関することは、[日本語版の github](https://github.com/babayoshihiko/Doing-Meta-Analysis-in-R)に報告していただきたい。）

<br></br>

## 謝辞 {-}

---

David Grubbs と Chapmann & Hall/CRC Press には、私たちのオンラインガイドを印刷された書籍にするという素晴らしいアイデアをいただき、また編集面で貴重なご支援をいただいたことに感謝する。

2018年末にオンライン版の予備的な執筆を始めて以来、多くの研究者や学生が本書で作業した感想や経験を私たちと共有してくた。このフィードバックは非常に貴重であり、本書を読むもののニーズに合わせてさらに調整するのにかなり役立っている。皆さまに感謝する。

このガイドで紹介する _R_ メタ分析基盤の開発に携わったすべての研究者に感謝する。しかし、何よりもまず、**{meta}** と **{metafor}** パッケージのメンテナである Guido Schwarzer と Wolfgang Viechtbauer に、それぞれお礼を申し上げる。このガイドは、 _R_ メタ解析コミュニティ全体と同様に、彼らの努力と献身なしには存在し得なかった。

さらに、本書のコンパニオンサイトにある バイアスリスクの可視化に関する追加章を執筆してくれた、豪華な **{robvis}** パッケージの著者である Luke McGuinness に特に感謝を捧げたい。Luke、私たちはこのプロジェクトに対するあなたの継続的なサポートにとても感謝している。

最後になるが、本書の作成と編集をサポートしてくれた Lea Schuurmans と Paula Kuper に感謝する。


<br></br>

エアランゲン、アムステルダム、京都、ミュンヘン

<p style="text-align:right;"><strong>Mathias, Pim, Toshi & David</strong></p>

<br></br>


<!--chapter:end:01-preface-ja.Rmd-->

# 著者について  {- #about-the-authors}

---

<br></br>

<img src="images/harrer.png" width="130" align="right" alt="" class="cover" /> [**Mathias Harrer**](https://www.protectlab.org/en/author/mathias-harrer-msc/) は、 ミュンヘン工科大学およびフリードリヒ・アレクサンダー大学エアランゲン-ニュルンベルク校の研究者。マティアスの研究は、心理療法研究における統計的・技術的手法、臨床研究統合のための手法、統計ソフトの開発に重点を置いている。

[![Twitter URL](https://img.shields.io/badge/@MathiasHarrer-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/MathiasHarrer)
[![GitHub followers](https://img.shields.io/badge/MathiasHarrer-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/MathiasHarrer)

---

<img src="images/cuijpers.jpg" width="130" align="right" alt="" class="cover" /> [**Pim Cuijpers**](https://www.pimcuijpers.com/blog/) は、アムステルダム自由大学の臨床心理学教授。一般的な精神疾患の予防と治療を中心に、無作為化比較試験とメタアナリシスの実施を専門としている。国際的な査読付き科学雑誌に800以上の論文を発表しており、その多くは臨床試験のメタアナリシスである。

[![Twitter URL](https://img.shields.io/badge/@pimcuijpers-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/pimcuijpers)

---

<img src="images/furukawa.jpg" width="130" align="right" alt="" class="cover" /> [**Toshi A. Furukawa**](http://ebmh.med.kyoto-u.ac.jp/professor.html) （古川壽亮）は、京都大学公衆衛生大学院健康増進・行動学の教授。研究統合とメタアナリシスの理論的側面と、エビデンスに基づく医療への応用の両方に焦点を当てた精力的な研究を行っている。

[![Twitter URL](https://img.shields.io/badge/@Toshi_FRKW-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/Toshi_FRKW)

---

<img src="images/ebert.jpg" width="130" align="right" alt="" class="cover" /> [**David D. Ebert**](https://www.protectlab.org/en/author/prof.-dr.-david-daniel-ebert/) は、ミュンヘン工科大学心理学・行動健康工学部教授。インターネットを利用した介入、臨床疫学、およびこの分野における応用研究の統合を中心に研究している。

[![Twitter URL](https://img.shields.io/badge/@DDEbert-1DA1F2?style=for-the-badge&logo=twitter&logoColor=white)](https://twitter.com/DDEbert)

---

翻訳者：馬場美彦は、有限会社アウトソー、杏林大学医学部非常勤講師。博士（医学）。専門は地域包括ケア、まちづくり。高齢者介護の実践と研究を行なっている。


<br></br>

<!--chapter:end:02-author-ja.Rmd-->

# (PART) はじめに {-}

# はじめに {#intro}

---

<img src="_figs/balloon.jpg" alt="balloons" />


<br></br>

<span class="firstcharacter">科</span>
学は一般に、蓄積されたプロセスであると考えられている。研究者は、何世代も前の科学者が積み上げてきた証拠を基に、科学的な努力を積み重ねている。アイザック・ニュートンの有名な言葉に「巨人の肩の上に立つことで、より遠くを見ることができる」というのがある。多くの人が科学に魅了されるのは、科学が進歩的であり、世界への理解を深めたり、より良い決断を下すのに役立つからである。

これは直感的な考えであるが、少なくとも数字上は正当化される。歴史上、今日ほど研究論文の発表という形で多くの証拠にアクセスできる時代はなかった。ペタバイト級の研究成果が、世界中で毎日生み出されているのである。生物医学だけでも、毎年100万件以上の査読付き論文が出版されている [@bjork2008global]。

発表される研究成果の量は、ほぼ指数関数的に増加している。最大の書誌データベースの一つである [**PubMed**](pubmed.ncbi.nlm.nih.gov/) の各年度の索引論文数は、このことを模範的に象徴しているといえるだろう。20世紀の半ばまで、各年度の研究論文は数百件しか掲載されていなかった。それが、その後の数十年で大幅に増え、21世紀に入ってから急増している（Figure \@ref(fig:pubmed) 参照）。

```{r pubmed, fig.cap='PubMed にインデックスされた論文数（年別）、1781年～2019年', echo=F, message=F, warning = FALSE, fig.align='center', fig.width=4.5, fig.height=3}
library(ggplot2)
options(scipen = 999)

read.csv("data/pubmed.csv", skip = 1)[-1,] -> pubmed

ggplot(pubmed, aes(x = Year, y = Count)) +
  geom_line() +
  geom_area(fill = "lightgrey") +
  theme_minimal() +
  scale_y_continuous(breaks = seq(0, 125e+4, by = 25e+4)) +
  xlab("") + ylab("") +
  theme(panel.background = element_rect(fill = "#FFFEFA",
                                        size = 0),
        plot.background = element_rect(fill = "#FFFEFA",
                                       size = 0))

```

原理的には、科学の発展により、科学の将来性について熱狂的になるはずである。科学が蓄積されるものであるならば、より多くの研究が発表され、より多くの証拠が得られる。そうすれば、より強力な理論を構築し、過去の誤謬を取り除くことができるはずである。

しかし、もちろん、そう簡単にはいかない。スタンフォード大学の John Ioannidis は、非常に影響力のある論文の中で、科学は自動的に蓄積され、常に改善されるという考え方を批判した。彼の論文には、「科学は、なぜ必ずしも自己修正しないのか」 ("Why Science Is Not Necessarily Self-Correcting") という分かりやすいタイトルがつけられている [@ioannidis2012science]。彼は、研究分野では、特定のトピックや理論について膨大な研究成果が生み出される一方、根本的な誤謬に対しては検証されずに永続する状態が存在することもよくあると主張している。

1970年代にさかのぼるが、優れた心理学者である Paul Meehl は、ある研究分野において、理論とファッションのトレンドが酷似していることを既に観察していた。Meehl は、多くの理論は継続的に改良されたり反論されたりするのではなく、人々が興味を失い始めると、単に「消えていく」のだと主張した [@meehl1978theoretical]。

科学的なプロセスだけでは、自動的に最善の世界へと導かれることはない。これは、不都合な真実である。日々、前例のない量の研究結果が生み出される中、証拠となるものを**全体として**捉え、批判的に評価することがより一層重要になっている。メタ分析は、メタ分析自体の限界とバイアスを認識する限り、最善の世界に達するために非常に役立つものである。


<br></br>

## メタ分析とは？ {#what-are-mas}

---

\index{Review, Systematic}\index{レビュー, システマティック}
\index{Review, Narrative}\index{レビュー, ナラティブ}

メタ分析の創始者の一人である Gene V. Glass は、メタ分析を「分析の分析」[@glass1976primary] と表現した。この単純な定義が、すでに多くのことを物語っている。従来の研究では、分析の単位は、多数の人、標本、国、または物である。メタ分析では、**一次研究**そのものが分析の要素になるのである。

メタ分析の目的は、明確に定義された研究分野や研究課題に関連する利用可能なすべての証拠を組み合わせ、要約し、解釈することである [@lipsey2001practical, chapter 1]。しかし、メタ分析はこれを行うための1つの手法に過ぎない。複数の研究からのエビデンスを合成する方法には、少なくとも3つの異なる方法がある [@cuijpers2016meta]。

* **伝統的/ナラティブレビュー**. 1980年代に入るまで、研究分野を要約する方法としては、**ナラティブレビュー** (narrative review) が最も一般的であった。ナラティブ（訳注：「物語り」の意）レビューは、その分野の専門家や権威によって書かれることが多い。ナラティブレビューに含まれる研究をどのように選択しなければならないか、またレビューの範囲をどのように定義するかについて、厳密なルールはない。また、レビューされたエビデンスからどのように結論を出すかについても、決まったルールはない。全体として、これは著者の意見に有利なバイアスにつながる可能性がある。しかしながら、ナラティブレビューは、バランスの取れた方法で書かれていれば、読者が関連するリサーチクエスチョンや分野のエビデンスベースについて全体的な印象を得るのに役立つ方法となり得る。

* **システマティックレビュー**. システマティックレビューは、明確に定義された透明性の高いルールでエビデンスをまとめようとするものである。システマティックレビューでは、研究課題を事前に決定し、研究を選択し、レビューするための明確で再現可能な方法論が存在する。その目的は、利用可能なすべてのエビデンスを網羅することである。また、あらかじめ定義された基準でエビデンスの妥当性を評価し、結果の統合を系統的に提示する。

* **メタ分析**. メタ分析の多くは、システマティックレビューの発展型といえるだろう。メタ分析の範囲は事前に明確に定義され、一次研究も体系的かつ再現可能な方法で選択され、エビデンスの妥当性を評価する基準も明確になっている。そのため、「システマティックレビュー**と**メタ分析」と名付けられた研究がよく見られるのである。メタ分析の目的は、先行研究の結果を**定量的**に組み合わせることで、この点がメタ分析を特別なものにしている。メタ分析の目的は、選択された研究で報告された定量的アウトカムを1つの数値的な推定値に統合することである。そしてこの推定値は、個々の結果をすべて要約したものである。メタ分析は、例えば、薬の効果、病気の流行、2つの性質の相関などを、**すべての研究にわたって**定量化する^[この記述はもちろん、メタ分析技術が適切に適用され、メタ分析の結果がそのような一般化を可能にする場合にのみ当てはまる] 。したがって、定量的な結果を報告している研究にのみ適用することが可能である。システマティックレビューと比較して、メタ分析は、要約される証拠の種類に関してより限定的でなければならないことが多い。メタ分析を行うには、通常、同じデザイン、同じタイプの測定、同じ介入を行った研究が必要である (Chapter \@ref(pitfalls) 参照)。


```{block, type='boxinfo'}
**個別被験者データメタ分析** (Individual Participant Data Meta-Analysis)

定義によっては、第4のタイプのエビデンス合成法、いわゆる**個別被験者データ** (Individual Participant Data, IPD) **メタ分析**も存在する [@riley2010meta]。従来、メタ分析は、発表された文献にある研究の**集計された**結果（例えば、平均と標準偏差、または割合）に基づいている。IPD メタ分析では、代わりにすべての研究の**オリジナル**データを収集し、1つの大きなデータセットにまとめる。

IPD メタ分析にはいくつかの利点がある。例えば、欠損データをインプットしたり、全ての研究に対して全く同じ方法で統計手法を適用することが可能である。さらに、関心のある結果に影響を与える変数の探索を容易にすることが可能である。従来のメタ分析では、いわゆる**研究レベル**の変数（例えば、発表年や研究で使用された集団など）のみを使用して、このようなことを行うことができることとする。しかし、結果の重要なモデレータとしての役割を果たすのは、しばしば**参加者レベル**の情報（例えば、個々の人の年齢や性別）である。このような変数は、IPD メタ分析を使ってのみ探索することが可能である。


IPD メタ解析は比較的新しい手法であり、現在行われているメタ解析の圧倒的多数は「従来の」メタ解析のままである。このことも、本ガイドで IPD メタ分析手法を取り上げない理由の一つである。

これは、従来のメタ分析が優れているということとは全く関係がなく、その逆である。これは単に、すべての研究データがオープンに利用可能であるという事実が、残念ながら最近までほとんどの分野で非常に稀であったためである。発表された研究報告から要約された結果を抽出することは比較的容易であるが、関連するすべての研究のオリジナルデータを入手することは、はるかに困難である。例えば、生物医学研究では、参加者個人のデータは、対象となる研究の約64％からしか得られない [@riley2007evidence]。

```


<br></br>

## "Exercises in Mega-Silliness" 歴史的な逸話 {#history}

---

メタ分析は一人の人間によって発明されたのではなく、多くの創始者と父親によって発明されたのである。別々の、しかし類似した研究の効果を統計的に要約する最初の試みは約100年前にさかのぼり、史上最も重要な統計学者である Karl Pearson と Ronald A. Fisher の2人に結びつけることが可能である。

Pearson は20世紀初頭に、大英帝国全体での腸チフス接種の効果に関する知見を組み合わせて、プール推定値を計算した [@shannon2016statistical]。Fisher は、1935年の実験計画法の代表的な著書で、農業研究における複数の研究のデータを分析するアプローチを取り上げ、場所や時間によって研究結果が異なるという問題を既に認めている [@fisher19351he; @o2007historical].

\index{Standardized Mean Difference}\index{標準化平均差}
\index{Random-Effects Model}\index{ランダム効果モデル}
\index{History of Meta-Analysis}

しかし、「メタ分析」という名称とその隆盛のきっかけは、20世紀半ばに起こったある学問的論争にさかのぼることが可能である。1952年、イギリスの著名な心理学者 Hans Jürgen Eysenck (Figure \@ref(fig:eysenck))  が、心理療法（当時はフロイトの精神分析を指すことが多かった）は効果がないと主張する論文を発表したのである。もし患者が治療中に良くなったとしても、それは治療とは関係のない要因によるものであって、治療がなくとも状況が改善されたからである。さらに悪いことに、Eysenck は、心理療法は患者の回復を妨げることもよくあると主張した。

心理療法は大きな打撃を受け、1970年代後半までその評判は回復しなかった。この間、Gene V. Glass は「メタ分析」と呼ぶ技法を開発し、研究間で**標準化平均差** (Standardized Mean Differences)^[介入群と対照群など2群間の平均値の差を、両群の標準偏差をプールした単位で表したもの（Chapter \@ref(s-md) 参照）]をプールできるようにした。この手法が初めて広範囲に適用されたのは、Mary L. Smith と Glass 自身 [@smith1977meta] が書いた **American Psychologist** 誌に掲載された論文であった。この大規模な研究では、4000人以上が参加した375の研究の結果がメタ分析で統合された。

その結果、心理療法は 0.68 のプール効果を示し、これは非常に大きいと考えられる。Glass の研究は、Eysenck の評決が誤りであることを定量的に証明するものであり、そのインパクトは絶大であった。しかし、Eysenck 自身は納得しておらず、メタ分析を "Exercises in Mega-Silliness" と呼んでいる [@eysenck1978exercise] 。

(ref:eysenck) Hans Jürgen Eysenck ([_Sirswindon/CC BY-SA 3.0_](#attr))


```{r eysenck, fig.cap='(ref:eysenck)', fig.scap="Hans Jürgen Eysenck.",  out.width='35%', message = F, echo = F, fig.align='right'}
library(OpenImageR)
knitr::include_graphics('images/eysenck_col.jpg')
```


今日、私たちは、Smith and Glass の研究が、対象研究のバイアスを制御しなかったために、心理療法の効果を過大評価した可能性があることを知っている [@cuijpers2019eysenck]。しかし、いくつかの心理療法が有効であるという主要な発見は、その後の数十年間で、他の無数のメタ分析によって裏付けらた。Eysenck の厳しい反応も、メタ分析がやがて様々な研究分野でよく使われる手法となったことを変えることはできなかった。

メタ分析の方法論は、当時から絶えず改良されてきた。Glass がメタ分析の手法を開発したのとほぼ同時期に、Hunter and Schmidt は、測定誤差の補正に重点を置いた独自のメタ分析手法を作り始めた [@schmidt1977development; @hunter2004methods]。

メタ分析が初めて医学の世界に登場したのは、Peter Elwood や Archie Cochrane らがメタ分析を用いた画期的な業績からである。このメタ分析で、アスピリンには、わずかではあるが心臓発作の再発を防ぐ効果が統計的にも臨床的にもあることを示した [@peto1980aspirin; @elwood2006first; @o2007historical]。

80年代半ば、Rebecca DerSimonian and Nan Laird がランダム効果メタ分析を計算するアプローチを紹介し（Chapter \@ref(rem) 参照）、今日まで使用されている [@dersimonian1986meta]。その他にも数え切れないほどの技術革新があり、過去40年間にメタ分析手法の適用性、頑健性、汎用性を高めることに貢献してきた。  


\index{Cochrane}\index{コクラン}
\index{Cochrane, Risk of Bias Tool}
\index{Cochrane, Handbook}
\index{Campbell Collaboration}


```{block2, type='boxinfo'}
**Cochrane と Campbellの共同研究**

1993 年に設立され、Archie Cochrane にちなんで名付けられた [**コクラン共同計画**](https://www.cochrane.org/) （Cochrane Collaboration, または単に **Cochrane**） は、応用メタ分析の発展において重要な役割を担っている。コクラン共同計画は、研究者、専門家、患者、その他関係者の国際的なネットワークで、「商業的なスポンサーシップやその他の利益相反のない、信頼性が高くアクセスしやすい健康情報を生み出すために協力し合う」ものである。

コクラン共同計画は、生物医学分野におけるエビデンスを統合するために、厳格な基準を用いている。ロンドンに本部を置くほか、世界数カ国に現地支部を置いている。

コクラン共同計画では、定期的に更新される [**Handbook for Systematic Reviews of Interventions**](https://training.cochrane.org/handbook) [@higgins2019cochrane] と [**Cochrane Risk of Bias Tool**](https://methods.cochrane.org/bias/resources/rob-2-revised-cochrane-risk-bias-tool-randomized-trials) [@sterni2019rob]  を発行している。どちらもシステマティックレビューやメタ分析に関するあらゆる技術的な詳細について、標準的な参考書として広く知られている（Chapter \@ref(spec-search-coding) 参照）。

コクランに似た組織として、オスロに拠点を置く[**Campbell Collaboration**](https://campbellcollaboration.org/) があり、主に社会科学分野の研究に力を入れている。

```

<br></br>

## りんごとオレンジ: メタ分析の落とし穴のクイックツアー {#pitfalls}

---

この数十年で、メタ分析は普遍的に受け入れられる研究ツールとなった。しかし、これにはそれなりのコストがかかる。質の高い一次研究を行うには多くの場合非常にコストがかかり、その結果を最終的に分析できるようになるまで何年もかかることがある。それに比べてメタ分析は、あまり多くのリソースを必要とせず、比較的短期間で作成することが可能である。それにもかかわらず、メタ分析はしばしば高い影響力を持ち、頻繁に引用されている [@patsopoulos2005relative]。

すなわち、科学雑誌はメタ分析を掲載する傾向が強く、たとえその品質や科学的メリットが限られていたとしても、掲載する傾向があるのである。残念ながら、このことは研究者に多くのメタ分析を作成する動機を与え、科学的動機は時として従属的になっている。

Ioannidis [-@ioannidis2016mass] は、毎年膨大な量の冗長で誤解を招くメタ分析が生産されていると批判している。いくつかの「ホット」なトピックでは、最近のメタ分析が20以上ある。また、薬物療法研究などでは、企業の利益に大きく偏ったメタ分析もある[@ebrahim2016meta; @kirsch2002emperor]。前にも述べたように、再現性は優れた科学の特徴である。しかし現実には、重要な情報が報告されないために、多くのメタ分析の再現性が制限されていることがあまりにも多い [@lakens2017examining]。

また、同じテーマ、あるいは重複するテーマについて、異なるメタ分析で異なる結論に至ることもよくある問題である。例えば、心理療法の研究では、すべてのタイプの心理療法が同等の結果をもたらすかどうかという問題に関連する議論が続いている。数え切れないほどのレビューが、どちらかの結論を支持する形で発表されている [@wampold2013great; @cuijpers2019role] 。

こうした問題は、科学的プロセスの体系的な問題と関連しているかもしれないし、メタ分析自体の欠陥にさかのぼることが可能である。そこで、メタ分析の落とし穴を簡単に紹介する [@borenstein2011introduction, chapter 40; @greco2013meta; @sharpe1997apples]。

\index{"Apples and Oranges" Problem}\index{「りんごとオレンジ」問題}
\index{"Garbage In, Garbage Out" Problem}
\index{"File Drawer" Problem}
\index{"Researcher Agenda" Problem}

<br></br>


### 「りんごとオレンジ」問題

---

メタ分析とは、りんごとオレンジを混ぜることだ、と主張する人もいる。対象基準を最大限に厳格にしても、メタ分析における研究が完全に同一であることはない。含まれるサンプル、介入の実施方法、研究デザイン、研究で使用された測定の種類などには、常に大小の差が存在する。

これは問題になることもある。メタ分析とは、すべての研究の結果を表す数値的な推定値を計算することである。このような推定値は、統計学的な観点からは常に計算することが可能であるが、特定の研究課題に答えるために重要な特性を共有する研究がない場合には、意味がなくなる。

明らかにばかげたシナリオとして、仕事のパフォーマンスに対する仕事満足度の効果に関する研究と糖尿病患者の HbA<sub>1c</sub> 値に対する投薬の効果に関する利用可能なすべてのエビデンスを、1つのメタ分析にプールすることを決定した、と想像してみよう。その結果は、組織心理学者にとっても、糖尿病学者にとっても、無意味なものだろう。

さて、この無能なメタ分析者が、過去の失敗から学び過剰な補償をして、1990年から1999年の間に発表された、中程度の抑うつ症状を持つ60代のカナダ人男性に Fluoxetine を1日 40 mg、正確に6週間投与した研究のみを含むメタ分析を実施したとする。メタ分析は、研究の肯定的な結果を誇らしげに精神科医に報告することが可能である。しかし、精神科医は、「私の患者が45歳のフランス人だったらどうすればいいのか」と聞くだけだろう。

ここで重要なポイントがある。メタ分析の目的は、組み合わせられるものは何でも無造作に放り込むことではない。メタ分析は、個々の研究の特殊性を超えた、関連する研究課題に答えるために用いることが可能である [@borenstein2011introduction, chapter 40]。したがって、メタ分析の範囲と特異性は、答えたい研究課題に基づくべきであり、この課題は実用的な関連性を持つものであるべきである（Chapter \@ref(spec-search-coding) 参照）。

例えば、ある種のトレーニングプログラムが、様々な年齢層、文化的地域、環境において有効であるかどうかに関心がある場合、研究の対象者や出身国に制限を設けないことは非常に理にかなっている。しかし、その場合、評価する研修プログラムを限定し、一定の長さの研修や類似のトピックを扱った研修のみを対象とすることが望ましいと考えられる。

このようなメタ分析の結果は、トレーニングのプール効果を推定するだけでなく、この効果がどの程度変動しているのかを定量化することが可能である。メタ分析は、このような**異質性**に対応し、意味を持たせることができるのである。Chapter \@ref(heterogeneity) では、この重要な概念について詳しく見ていく。

要約すると、「りんごとオレンジ」問題が実際に問題であるかどうかは、メタ分析が答えたい問題に大きく依存するということである。研究間のばらつきは、メタ分析の目的と問題の特定に正しく組み入れられれば、多くの場合問題にはならず、洞察的でさえある。


<br></br>

### 「Garbage In, Garbage Out」問題

---

メタ分析が生み出すエビデンスの質は、それが要約した研究の質に大きく依存する。もし、含まれる知見で報告された結果が偏っていたり、全く間違っていたりすれば、メタ分析の結果も同様に欠陥があることになりる。これが「Garbage In, Garbage Out」問題の指すところである（訳注: 入力が無意味なら出力も無意味であることを指す。略して GIGO と書くこともある。）。これは、含まれる研究の質や**バイアスのリスク**（Chapter \@ref(spec-search-coding) と Chapter \@ref(risk-of-bias-plots)) 参照）を評価することである程度軽減することが可能である。

しかし、結果の多くまたは大部分が最適な品質ではなく、バイアスがある可能性が高い場合、最も厳密なメタ分析でもバランスを取ることはできない。このような場合、導き出される唯一の結論は、レビューしたテーマについて信頼できる証拠は存在せず、今後さらに質の高い研究を実施しなければならないということである。しかし、このような残念な結果であっても、将来の研究の指針として参考になることがある。

<br></br>

### 「ファイルの引き出し」問題

---

ファイルの引き出し問題とは、関連する研究結果がすべて発表されているわけではないため、メタ分析に欠落してしまうという問題である。メタ分析ですべてのエビデンスを統合できないことは望ましくないが、少なくとも、研究成果が発表された文献の中でランダムに欠落していると安全に仮定できるのであれば、許容範囲であろう。

しかし、残念ながら、そうではない。ポジティブで「革新的」な発見は、失敗した複製やネガティブで結論の出ない研究よりも話題を呼ぶことが多い。これに伴い、ここ数十年、多くの分野、特に社会科学や生物医学の分野で、否定的な知見が発表されることが少なくなっていることが調査で明らかになっている [@fanelli2012negative]。

否定的な結果や「期待はずれ」の結果を出した研究は、発表された文献の中で体系的に過小評価されており、いわゆる**発表バイアス**があると考える十分な根拠がある。このバイアスの正確な性質と程度は、メタ分析ではせいぜい「未知の知」(known unknown) である。

しかし、出版バイアスを最小化する方法はいくつかある。一つは、研究の検索・抽出の方法に関連する（Chapter \@ref(spec-search-coding) 参照）。もう1つは、メタ分析において出版バイアスが存在するかどうか、またその影響がどの程度あるのかを推定しようとする統計的な方法である。これらの手法については、Chapter \@ref(pub-bias) でいくつか紹介する。


<br></br>

### 「研究者のアジェンダ」問題

---

メタ分析の範囲を定義し、研究を検索・選択し、最終的にアウトカム指標をプールする際、研究者は無数の選択を迫られる。メタ分析には多くの「研究者の自由度」[@wicherts2016degrees] があり、時には恣意的であったり、公表されていない個人の好みの結果などの決定の余地が多く残されている。

メタ分析の**運用法** (modus operandi) の自由度は、研究者が意識的または無意識的に自身のアジェンダに突き動かされている場合に特に問題となる。メタ分析は通常、応用研究者によって行われるが、レビュートピックに関する広範な主題固有の専門知識を持つことは諸刃の剣である。一方では、特定の分野における有意義なリサーチクエスチョンを導き出し、それに答えるのに役立つこともある。

また他方では、そのような専門家は、自分が調査している研究分野に深く関与していることも事実である。つまり、多くのメタ分析者は特定のテーマについて強い意見を持っており、意図的または無意識に自分の信念に合う方向に結果に影響を与える可能性がある。

同じデータセットが与えられると、最高の意図を持った経験豊富な分析者間でも、結論が大きく異なることがあるというエビデンスがある [@silberzahn2018many] 。この問題は介入研究においてさらに深刻で、メタ分析者の中には、研究中の介入手法の開発に貢献したことがあるため、堅固な**研究者としての忠誠心**を持っている人もいる。そのような研究者はもちろん、メタ分析の結果を証拠によって示されるよりも肯定的に解釈する傾向が強いかもしれない。

研究者のアジェンダ問題を軽減する一つの方法として、メタ分析のデータ収集を開始する前に、事前登録を行い、詳細な解析計画を公開することが挙げられる（Chapter \@ref(spec-search-coding) と \@ref(pre-registration)を参照）。

<br></br>

## 問題の特定、スタディ検索、コーディング {#spec-search-coding}

---

\index{Study Search}

前章では、メタ分析の一般的な問題や限界について時間をかけて議論した。「りんごとオレンジ」問題、「ファイルの引き出し」問題、「研究者のアジェンダ」問題など、これらの問題の多くは、すべてのメタ分析者が取り組むことができ、また取り組むべきものである。

これは、最初の結果を計算し始めるずっと前から始まっている。メタ分析はデータがなければ実施できないため、当然ながらこのデータをどこからか持ってこなければならない。まず、計画中のメタ分析の**研究課題**と**適格基準**を特定し、研究を検索して関連するものを選び、計算に必要なデータを抽出し、後で報告したい重要な情報をコーディングする。

各ステップにおいて、従うことができる、または従うべき規則、基準、推奨事項がいくつかあり、高品質なメタ分析を作成するのに役立つ。このような高品質のメタ分析には、すべての適切なエビデンスが包括的に選択されており、その対象に関してバイアスがなく公平であり、その結果から有効かつ正当で、実際的に適切な結論が導き出されている。

しかし、「すべてのルールに従う」といっても、実際には具体的にどのような判断が最適なのか、必ずしも明らかでない場合もある。あなたが行った方法に対して、人々が反対することもあり得る。これは普通のことで、方法論の決定が**透明**かつ**再現可能**である限り、問題はない [@pigott2020methodological]。

この章では、計算を始めるより前の段階で必要となる重要な構成要素を順番に説明する。この章は長いが、データ取得のプロセスが現実に要する時間を表すものではない。経験上、統計解析はメタ分析に費やす時間の最大15％を占めるに過ぎず、その前に行われるすべての作業と比較するとはるかに少ないものである。しかし、研究課題を特定し、系統的に研究を検索し、抽出されたデータを確実にコーディングすることは不可欠である。これが、優れたメタ分析の基礎となるのである。

<br></br>

### リサーチクエスチョンの定義 {#research-question}

---


\index{Research Question}

研究をデザインするとき、最初にすることはリサーチクエスチョンの定義である。メタ分析も例外ではない。リサーチクエスチョンを**問題指定**の一形態として捉えると、適切に定義することができる。適切でインパクトのあるメタ分析を行うためには、問題を解決する必要がある。そのような問題を特定するためには、対象分野に特化した知識が必要である。

メタ分析のための良いリサーチクエスチョンを見つけるには、ある程度背景知識のある研究分野を選び、まずいくつかの基本的な質問を自分自身に問いかけることが有効だろう。この分野では、現在どのようなことが問題になっているのか？特定のテーマについて、現在の知識には欠如がないか？未解決の議論が残っていないか？また、対象となる読者について考えてみるのもよいだろう。他の研究者に関連する問題は何か？他の人々、例えば医療関係者、国家機関、学校、人事部などが直面しそうな問題は何か。

メタ分析は先行研究に依存する。研究課題の大まかな方向性が決まったら、現在の文献を見るのが効果的である。このテーマに関する先行研究は存在し、どのように問題に対処していたのか？どのような方法とアウトカム尺度を使用したのか？論文の背景や考察のセクションで、どのような制限に言及しているか？過去のレビューやメタ分析でこのテーマを扱ったことがあるか、またどのような問題が残されているか？

Cummings ら [-@cummings2013conceiving] は、メタ分析の対象となる問題を特定するために使用できるいくつかの基準、FINERフレームワークを提案している。それは、リサーチクエスチョンが、実行可能 (**F**easible）で、興味深く（**I**nteresting）、新規性があり（**N**ovel）、倫理的である（ **E**thical）、関連性がある（**R**elevant）べきである。

これらの質問を自分に投げかけることで、メタ分析で何を達成したいのかが、少しずつ明らかになってくるはずである。また、メタ分析が自分の問題に適していないことが明らかになる場合もある。例えば、そのテーマを扱った関連する研究がない、あるいは、その問題を十分に扱った質の高いメタ分析が既に文献に残っている、などである。

しかし、自分の問題が1つまたは複数のグループの人々に関連し、先行研究がこの問題に関連するデータを提供し、先行するレビューやメタ分析が十分にまたは適切に対処していないと感じた場合、それを**リサーチクエスチョン**に変えるために進むことが可能である。

どのようなことができるのか、例を挙げてみよう。医学研究においてジェンダーバイアスが存在することを示唆する証拠がある [@hamberg2008gender; @nielsen2017one]。以前は、多くの臨床試験で男性の参加者のみであるか、または大部分が男性であっタにもかかわらず、単純にアウトカムが女性にも一般化されると仮定されていた。このため、心臓疾患など一部の疾患では、女性の健康状態が悪くなることにつながったと考えられている [@kim2009status; @mosca2013fifteen]  ^[なお、ジェンダーバイアスは女性だけでなく男性にも悪影響を及ぼすことがあり、例として骨粗しょう症 [@adler2014osteoporosis] などの病気がある]。

あなたが医学研究者であると仮定しよう。よく使われる薬である **Chauvicepine** には、これまでほとんど認識されていなかった女性への深刻な副作用があるのではないかという噂を耳にしたとする。これは、安全でない可能性のある薬が多くの女性に処方されていることになるので、もし噂が本当であれば非常に重要な問題であると判断した。

文献を見ると、Chauvicepine を調査した研究のほとんどが無作為化プラセボ対照試験であることがわかった。初期の試験では、男性のみ、あるいは男性が大半を占める集団で実施された。しかし、最近の試験では、性別の構成がよりバランスの取れたものもいくつか見受けられる。これらの試験の多くは、試験中に発生した否定的な副作用の数を、男女別に報告していた。また医学雑誌の最近の論評で、ある医師が、自分のクリニックでは、この薬で治療したときに多くの女性がネガティブな副作用を経験したと報告しているのも見つかった。

この問題をメタ分析で解決するのは面白いかもしれないと考えついた。そこで、今発見した問題をリサーチクエスチョンに変換した。「プラセボと比較して、Chauvicepine が女性における負の副作用を有意に増加させることを示す無作為化プラセボ対照試験からのエビデンスはあるだろうか？」。

\index{PICO}

リサーチクエスチョンの最初の定式化は、最初のステップに過ぎない。次に、それを具体的な**適格性基準**に変換する必要がある。これらの適格基準は、どの研究がメタ分析に含まれ、どの研究が含まれないかを決定する指針となりうる。したがって、この基準は非常に重要であり、絶対的に透明で再現可能でなければならない。

適格基準を指定し始める良い方法は、PICO フレームワークを使用することである [@mattos2015systematic]。このフレームワークは主に介入研究を対象としているが、他のタイプのリサーチクエスチョンにも役に立ちる。PICO の文字は、母集団（**P**opulation）、介入（ **I**ntervention）、対照群（**C**ontrol group）または比較（Comparison）、アウトカム（**O**utcome）の頭文字をとったものである（訳注: P は、Patients, Problems とも）。

* **母集団** (P): どのような人々や研究対象者が含まれていれば、研究の対象となるのか。繰り返しになりますが、この質問にはできるだけ正確に答え、それぞれの定義が持つ意味を考えることが重要であることを覚えておいてください。若年成人を対象とした研究のみを対象とするのであれば、「若年成人」とは何を意味するのだろうか。18歳から30歳までの人だけが対象なのだろうか？それは発表された論文から簡単に判断できることなのだろうか？それとも、大学や **Cardi B** のコンサートのような、若者がよく訪れる場所で募集されたことだけが重要なのだろうか？特定の病状を持つ患者に関する研究のみを対象とするのであれば、その病状はどのように診断されたのだろうか？訓練を受けた医療専門家によるものなのか、それとも自己報告式のアンケートで十分なのか？こうした質問は、FINER フレームワークの F と R の部分に頼ることによって答えられることが多い。発表された研究にこのような制限を加えることは可能なのか？また、それは適切な差別化なのだろうか。

* **介入** (I): どのような介入（または**曝露**）を研究する必要があるのか。介入の効果を研究したいのであれば、対象となる治療の種類を明確にすることが重要である。介入はどのくらいの期間でなければならないか？誰が介入を行うことが可能であるか？介入はどのような内容を含まなければならないか？介入に焦点を当てない場合、**独立変数**はどのように運用されなければならないか？変数は特定の測定機器や質問紙によって測定されなければならないか？例えば、仕事に対する満足度を研究する場合、この構成要素は研究においてどのように運用されなければならないか？

* **対照群**または**比較対象** (C): 試験結果は何と比較されたのか？情報提供プラセボ (Attention placebo) か、または錠剤のプラセボを受けた対照群か？待機者？別の治療法？それとも全く何もしないのか？例えば、異なる研究間での病気の有病率推定を研究したい場合や、異なる生息地にどれだけの種の標本があるのかを研究したい場合など、比較群や対照群が全くないこともあり得る。

* **アウトカム** (O): 研究では、どのような成果や従属変数を測定しなければならないのだろうか？そして、その変数はどのように測定しなければならないのだろうか？質問票の点数の平均や標準偏差だろうか？それとも、死亡した患者や病気になった患者の数か？結果はいつ測定されなければならないのだろうか？治療期間には関係なく、単純に治療直後でよいのか？それとも1〜2年後か？


\index{PRISMA Statement}\index{PRISMA 声明}
\index{MARS Statement}\index{MARS 声明}
\index{Cochrane, Handbook}

```{block2, type='boxinfo'}
**システマティックレビューとメタ分析のためのガイドライン**

メタ分析の質が低いことが多いことから、メタ分析の実施方法について、いくつかのガイドラインや基準が設けられている。

生物医学研究または介入の効果に関するエビデンスをメタ分析する場合、**Preferred Reporting Items for Systematic Reviews and Meta-Analyses** (PRISMA) [@moher2009preferred] に従うよう強く推奨する。PRISMA 声明には、メタ分析過程のほぼすべての側面についてどのように報告すべきかという推奨事項が含まれている。また、この声明は[オンライン](http://www.prisma-statement.org/)で見ることが可能である^[最近、2009年の古いバージョンが更新され、**PRISMA 2020** 声明[@page2021prisma]が発表された。アブストラクト報告チェックリスト、検索の更新に関する情報も盛り込んだフロー図の改訂、競合利益の宣言とデータ共有の重視などが目新しい点である。]。

心理・行動研究のメタ分析については、**米国心理学会**の**メタ分析報告基準** (American Psychological Association’s Meta-Analysis Reporting Standards, MARS) [@appelbaum2018journal] に従うことが可能である。

これらの基準は、メタ分析がどのように**報告**されるべきかについて主にコメントしているが、メタ分析を行う際のベストプラクティスにも影響を及ぼしている。PRISMA とMARS はコアな要素を多数共有しており、本章で取り上げる多くの事柄は、両ガイドラインでも言及されている。

さらに詳細な資料として、**Cochrane Handbook for Systematic Reviews of Interventions** (Chapter \@ref(history)) があり、システマティックレビューとメタ分析のほぼすべての側面に関する正確な推奨事項が記載されている。社会科学におけるメタ分析の方法論的基準の概要は、Pigott and Polanin [-@pigott2020methodological] で見ることが可能である。

```


PICO フレームワークはメタ分析の適格基準を指定する優れた方法であるが、関連する可能性のある情報すべてを網羅しているわけではない。他にも考慮すべき点がいくつかある [@lipsey2001practical]。

関連する詳細の1つは、対象となる**研究デザイン**である。エビデンスに基づく医療では、無作為化化比較試験（参加者が偶然に治療群または対照群に割り付けられた研究を意味する）からのエビデンスのみを含めることが一般的であるが、これは必ずしも必要ではない [@borenstein2011introduction、Chapter 40]。

\index{WEIRD Populations}

また、対象となる研究の**文化的**および**言語的範囲**を指定することも有用だろう。ほとんどの研究は WEIRD 集団、つまり西洋（Western）、教育（Educated）、工業化（Industrialized）、豊か（Ric）、 民主主義国（Democratic societies）に基づいている [@henrich2010most] 。特に社会科学の分野では、ある効果や現象が他の社会規範を持つ国にはうまく一般化されない可能性が非常に高い。しかし、多くの研究者は、他の言語の論文を翻訳する手間を省くために、英語の論文のみをメタ分析の対象としている。

これは、異なる言語圏からのエビデンスが考慮されないことを意味する。英語はほとんどの分野で科学的発表の最も一般的な言語であるが、少なくともこの制限が存在することは適格基準において明らかにされるべきである。しかし、メタ分析の目的の一つが異文化間の差異を調べることであるならば、他のすべての基準を満たす限り、一般的に適格基準を他の言語にも拡大することが望ましい。

\index{"File Drawer" Problem}

もう一つの重要な点は、メタ分析に許可される**出版物の種類**である。メタ分析には、査読付き科学雑誌に掲載された研究論文のみが含まれることがある。これは、その分野の専門家の厳しい目を通過した研究であるため、より高い基準を満たすという主張である。この正当化には欠点がないわけではない。Chapter \@ref(pitfalls) では、「ファイル引き出し」問題がメタ分析結果の妥当性を著しく制限する可能性があることをすでに取り上げた。

したがって、出版バイアスのリスクを軽減する方法として、**灰色文献**も含めることが挙げられる。灰色文献とは、従来の出版形式では入手できなかったあらゆるタイプの研究資料と定義することが可能である。これには、研究報告書、プレプリント、ワーキングペーパー、会議への投稿などが含まれる。学位論文も灰色文献に数えられることが多いが、その多くは今日、電子書誌データベースで索引付けされている [@schopfel2018electronic]。

学位論文については、少なくともメタ分析には含めることが望ましいと思われる。他の種類の未発表資料と比較して、学位論文で提供される情報に大きなバイアスがあったり、明らかに不正であったりすることは、むしろ少ないだろう。さらに、科学雑誌に掲載されたかどうかにかかわらず、特定の方法論的要件を満たす研究のみを含めるよう、他の適格基準を定義することも可能である。

適格基準を定義する最後のステップは、適用する**包含基準**と**除外基準**のリストとして書き留めることである。大学生における不眠症の介入に関するメタ分析から、このような方法があることを示す例を紹介する [@saruhanjan2020psychological]。


> _"We included: (a) RCTs [randomized controlled trials; authors' note] in which (b) individuals enrolled at a tertiary education facility (university, college or comparable postsecondary higher education facility) at the time of randomization, (c) received a sleep-focused psychological intervention, (d) that was compared with a passive control condition, defined as a control condition in which no active manipulation was induced as part of the study (wait-list, treatment as usual)._ 

> _For the purposes of this analysis, “sleep-focused” means that (e) effects on symptoms of sleep disturbances (global measures of sleep disturbances, sleep-onset latency [...], fatigue and daytime functionality, pre-sleep behaviour and experiences) were assessed as a (f) target outcome (by declaring a sleep outcome as the primary outcome or by stating the intervention was primarily aimed at this outcome) using (g) standardized symptom measures (objective sleep measures, standardized sleep or fatigue questionnaires, sleep diaries, items recording sleep quantity, quality or hygiene)._

> _Only studies (h) published in English or German were considered for inclusion."_



<br></br>

### 解析計画・事前登録 {#analysis-plan}

---

\index{Analysis Plan}\index{解析計画}
\index{Preregistration}

リサーチクエスチョンと適格基準を設定したら、**解析計画** [@pigott2020methodological; @tipton2019history] も書くのが賢明だろう。統計学では、**a priori** （先験的）と **post hoc** （事後）の分析に重要な区別がある。a priori 分析とは、**データを見る前に**指定される分析である。post hoc 分析あるいは探索的分析は、**データを見た後**、あるいはデータから示唆される結果に基づいて行われる。

a priori 分析の結果は、post hoc 分析よりもはるかに有効で信頼できると見なすことができる。post hoc 分析では、研究者の目標が達成されるまで、分析内容やデータそのものに手を加えることが容易になりる。そのため、「研究者アジェンダ」の問題が発生しやすい。

解析計画では、メタ解析で行いたい重要な計算をすべて a priori に指定する。これには2つの目的がある。まず、実行した分析が本当に計画されたものであり、望ましい結果が得られるまでデータを操作しただけの結果ではないことを、他の人が確認することが可能である。つまり、メタ分析の各ステップで何をしたかを理解し、それを再現しようとすることができるのである。

_R_ を使う場合は、分析の各ステップを他の人が再実行できるようなドキュメントを書くことができ、これによって解析の再現性を高めることが可能である（「各種ツール」の Chapter \@ref(reporting-reproducibility) 参照）。しかし、これは分析が完了した後の話である。解析計画では、データを収集する前に、何をする予定なのかを指定する。

\index{Random-Effects Model}\index{ランダム効果モデル}
\index{Power Analysis}\index{検出力分析}
\index{Subgroup Analysis}\index{サブグループ解析}
\index{Meta-Regression}\index{メタ回帰}\index{メタ回帰}

解析計画には、必ず明記すべきことが何点かある。どのような情報を抽出するのか、含まれる研究ごとにどのような効果量指標を算出するのかを明確にしておく必要がある（Chapter \@ref(effects)）。また、各研究の結果をプールする際に、研究間のばらつきの大きさを考慮して、**固定効果モデル**と**ランダム効果モデル**のどちらを使用するかをあらかじめ決めておくとよいだろう（Chapter \@ref(pooling-es)参照）。また、メタ分析で統計的に有意な効果を得るために必要な研究数を決定するために、先験的な**検出力分析**も役に立つ（「ツール」の Chapter \@ref(power) 参照）。

さらに、サブグループ解析（Chapter \@ref(subgroup)）やメタ回帰（Chapter \@ref(metareg)）を用いて、いくつかの変数が対象研究の結果の違いを説明しているかどうかを評価したいかを決定することが重要である。例えば、仮説として出版年が研究のアウトカムと関連している可能性があり、この関連をメタ分析で後で調べたい場合、解析計画にその旨を記載する。研究をサブグループに分類し、そのサブグループを別々に調査する予定であれば、特定のサブグループに属すると判断する正確な基準も報告する必要がある（Chapter \@ref(study-selection) 参照）。

本書の第II部（「 _R_ でメタ分析」）では、メタ分析の一部として適用すべき様々な統計的技法について取り上げる。ここで学び、メタ分析で適用する予定の技法は、すべて解析計画書に記載する必要がある。

\index{Open Science Framework (OSF)}
\index{Preprint}
\index{Protocol}\index{プロトコル}
\index{PRISMA Statement}\index{PRISMA 声明}

解析計画を書き終えたら、どこかに埋めてしまうのではなく、公開するようにしよう。研究者が自分の研究文書をオープンにするための優れた選択肢がいくつかある。例えば、**オープンサイエンス・フレームワーク**（OSF）のウェブサイトに新しいプロジェクトを作成し、そこに解析計画書をアップロードすることができる。また、研究内容によっては、**medrxiv.org**、**biorxiv.org**、**psyarxiv.com**などのプレプリントサーバーに解析計画をアップロードすることも可能である。

研究課題、適格基準、解析計画、検索戦略（次章参照）が決まったら、メタ分析も**登録**する必要がある。メタ分析が広く健康に関連するアウトカムである場合、前向きシステマティックレビューとメタ分析の最大級の登録機関である [PROSPERO](https://www.crd.york.ac.uk/prospero/) を利用することが望ましい。OSF の[事前登録サービス](https://osf.io/prereg/)も良い選択肢である。

さらに一歩進んで、メタ分析用の**プロトコル**全体を書くことも可能である [@quintana2015pre]。メタ分析プロトコルには、解析計画に加えて、研究の科学的背景の説明、より詳細な方法論、研究の潜在的な影響についての議論を含める。

また、PRISMA-P ステートメント [@moher2015preferred] など、プロトコルの書き方に関するガイドラインも存在する。メタ分析のプロトコルは、多くの査読誌で受け入れられている。Büscher, Torok and Sander [-@buscher2019effectiveness] や Valstad and colleagues [-@valstad2016relationship] などは良い例である。

a priori な解析計画と事前登録は、よくできた信頼できるメタ分析には欠かせない特徴である。そして、このことで不安になる必要はない。方法論の決定一つ一つについて、事前に完璧な選択をすることは、不可能ではないにせよ、困難である。最初の計画をある時点で変更するのは、ごく普通のことである。計画したアプローチの変更について正直かつ明確に説明すれば、ほとんどの研究者はこれを失敗の印ではなく、プロ意識と信頼性の証と受け止めてくれることは間違いない。

<br></br>

### 研究の検索 {#study-search}

---

\index{Study Search}

適格基準や解析計画を決定した次のステップは、研究の検索である。本章では、ほとんどのメタ分析がシステマティックレビューの発展型であることを説明してきた。偏りのない包括的な事実の見方を得るために、研究課題に関する利用可能なエビデンス**すべて**を見つけることを目的としている。つまり、研究の検索も可能な限り包括的でなければならない。研究の検索には、1つだけでなく、複数の情報源を使用する必要がある。ここでは、重要かつ一般的に使用されている情報源の概要を説明する。

* **レビュー記事**. 同じトピックや類似のトピックに関する過去のレビューを精査し、関連する文献を探すことは非常に役に立つ。ナラティブレビューやシステマティックレビューでは、通常、レビューに含まれるすべての研究の引用が提供される。こうした研究の中には、自分の研究目的にも関連しているものも多くある可能性がある。

* **研究中の参照文献**. メタ分析に関連する研究を見つけた場合、この研究が参照している論文もスクリーニングするのが賢明である。その研究が序論や考察のセクションで同じトピックに関する過去の文献を引用している可能性は非常に高く、これらの研究のいくつかもメタ分析に関連する可能性がある。

* **フォワードサーチ**. フォワードサーチは、先行する一次研究やレビューの文献をスクリーニングすることの逆と見ることができる。メタ分析に関連する研究をベースとして、その研究が発表されてから引用された他の論文を検索することを意味する。これはインターネット上で非常に簡単に行うことが可能である。通常、その研究が掲載された雑誌のウェブサイトにある、その研究のオンラインエントリーを見つければいいのである。今日、ほとんどの雑誌のウェブサイトには、ある研究を引用した論文を表示する機能がある。また、**Google Scholar**で検索することもできる（Table \@ref(tab:bibdatabases) を参照）。Google Scholarでは、引用されている研究を項目ごとに表示することが可能である。

* **関連する学術雑誌**. 多くの場合、あなたが注目している研究課題の種類に特化した科学雑誌がいくつもある。そのため、それらの雑誌に掲載されている研究を探すとよいだろう。現在では、ほぼすべての学術雑誌が検索機能を備えたウェブ サイトを持っており、それを使って対象となりそうな研究を選別することができ る。また、電子書誌データベースを利用し、1つまたは複数の雑誌からの結果のみが表示されるようにフィルタを使用することも可能である。

上で説明した方法は、かなり細かい戦略として見ることができる。この方法は、関連する論文がリストアップされる可能性が非常に高い場所を検索する方法である。欠点としては、本当にそこにあるすべての証拠を発見することができないことである。したがって、検索には**電子書誌データベース**も使用することが推奨される。重要なデータベースの概要は、Table \@ref(tab:bibdatabases) に記載している。  

1つのデータベースだけでなく、常に複数のデータベースで検索する必要がある。多くの書誌データベースには、膨大な数の項目が含まれている。それでも、データベースの検索結果の重複が予想以上に少ないということはよくあることである。検索するデータベースは、テーマ別の焦点に基づいて選択することができる。例えば、メタ分析が健康に関連する結果に焦点を当てている場合、少なくとも PubMed と CENTRAL を検索する必要がある。

書誌データベースを検索する際には、**検索文字列**を作成することが重要になる。検索文字列には、異なる単語や用語を含め、AND や OR などの演算子を使って連結する。検索文字列の作成には、ある程度の時間と実験が必要である。まずは、PICO や適格基準（Chapter \@ref(research-question)）をベースに、AND でつなげるのがよいだろう（簡単な例では、**"college student" AND  "psychotherapy" AND "randomized controlled trial" AND "depression"** など）。

ほとんどの書誌データベースでは、**切り捨て**と**ワイルドカード**も使用可能である。切り捨ては、語尾を記号で置き換えて、検索の一部として変化させることである。これは通常、アスタリスクを使用して行われる。たとえば、"_sociolog\*_" を検索用語として使用すると、データベースは "sociology"、"sociological"、"sociologist" を同時に検索する。

ワイルドカードは、単語の中の文字が変化してもよいことを意味している。これは、単語の綴りに違いがある場合に便利である（例えば、アメリカ英語とイギリス英語の違いなど）。例えば、"_randomized_" という検索語を考えてみよう。この場合、アメリカ英語のスペルを使った研究のみが検索される。ワイルドカード（しばしばクエスチョンマークで象徴される）を使用する場合、代わりに "_randomi?ed_" と書くと、イギリス英語のスペルが使用された結果 ("randomised") も得られる。

検索文字列を作成する際には、ヒット数にも注目する必要がある。検索文字列は、あまり特定しすぎて関連する記事が見落とされるようなことがあってはならない。例えば、検索文字列のヒット数が3000件程度であれば、後のステップで管理しやすく、重要な参考文献がすべて結果にリストアップされる可能性が高くなる。検索文字列が一般的に有効かどうかを確認するには、最初の数百件を検索して、少なくともいくつかの文献が研究課題と関係があるかどうかをチェックすると良いだろう。

選択したデータベースで使用する検索文字列の最終版を作成したら、どこかに保存する。検索文字列は、事前登録に含めておくのがベストプラクティスである。メタ分析のプロトコルを公開する場合や、メタ分析の最終結果を公開する場合は、検索文字列の報告（例えば、付録）が必要である。

結論として、書誌データベースの検索はそれ自体が技術であり、この段落では表面をわずかになぞった程度であることを強調しておきたい。このトピックに関しては、Cuijpers [-@cuijpers2016meta] と Bramer and colleagues [-@bramer2018systematic] が より詳細な議論している。

<br></br>

```{r bibdatabases, echo=F, message=F, fig.align='center', warning=F}
library(kableExtra)
library(stringr)

bibdb = read.csv("data/bib_databases-ja.csv")
bibdb$Type = NULL

bibdb$Database = with(bibdb, paste0("[**", Database, "**](https://www.", str_replace_all(bibdb$Website, " ", ""), ")"))
bibdb$Website = NULL

kableExtra::kable(bibdb,
                  longtable = T,
                  booktabs = T,
                  caption = "関連する書誌データベースの一部。",
                  font_size = 14) %>% 
  #kable_styling(latex_options = c("repeat_header"), font_size = 8) %>% 
  column_spec(1, width = "6cm") %>% 
  #column_spec(2, width = "5cm") %>% 
  #column_spec(3, width = "3cm") %>% 
  pack_rows("Core Database", 1, 6, latex_align = "c", latex_gap_space = "2em",
            hline_after = T, indent = F, background = "#f2f1ed") %>% 
  pack_rows("Citation Database", 7, 9, latex_align = "c", latex_gap_space = "2em",
            hline_after = T, indent = F, background = "#f2f1ed") %>% 
  pack_rows("Dissertations", 10, 10, latex_align = "c", latex_gap_space = "2em",
            hline_after = T, indent = F, background = "#f2f1ed") %>% 
  pack_rows("Study Registries", 11, 12, latex_align = "c", latex_gap_space = "2em",
            hline_after = T, indent = F, background = "#f2f1ed") %>% 
  row_spec(0, font_size = 17) %>% 
  kable_styling(bootstrap_options = c("hover"), font_size = 14)

```

<br></br>

### 研究の選択 {#study-selection}

---

研究調査を終えれば、さまざまな情報源から何千もの参考文献を集めることができるはずである。次のステップは、自分の適格基準を満たすものを選択することである。そのためには、以下のように3つのステップを踏むことを勧める。

ステップ 1 では、重複している文献を削除する必要がある。特に、複数の電子書誌データベースで検索した場合、1つの文献が2回以上表示される可能性がある。これを行う簡単な方法は、まず、すべての参考文献を**参考文献管理ソフトウェア**にインポートして、一箇所に集めることである。優れた参考文献管理ツールはいくつかある。[**Zotero**](https://www.zotero.org/) や [**Mendeley**](https://www.mendeley.com/) のようなものは、無料でダウンロードすることが可能である。また、[**EndNote**](https://endnote.com/) のようなプログラムは、より多くの機能を提供したが、通常、ライセンスが必要である。

レファレンスマネージャーは、重複する論文を自動的に削除できる機能を備えている。最初に研究検索で見つけた文献の数と、重複を除去した後に残った文献の数を書き留めておくことが重要である。除外の詳細は、後にメタ分析を公開する際に報告する必要がある。

重複を除去した後は、**タイトルとアブストラクト**に基づいて、目的に合わない文献を除外する必要がある。研究検索をすると、研究課題とは全く関係のない結果が何百件も出てくる可能性が非常に高い^[Lipsey and Wilson [-@lipsey2001practical] は、アルコール摂取と攻撃性の関係に関するメタ分析の論文を検索する際に、縄張り争い行動を調べるために魚にアルコールを与えるという驚くほど多くの研究を除外しなければならないという面白いエピソードを語っている] 。このような文献は、タイトルと要旨だけを見て、安全に削除することが可能である。このステップでも、レファレンスマネージャーが役に立つ。各参考文献を一つずつ調べていき、その論文が自分とは関係ないと確信したら、単に削除すればいい^[電子データベースから参考文献をエクスポートする場合、通常は抄録が参考文献ファイルに追加され、参考文献管理ツールで表示することが可能である。その参考文献に抄録がない場合は、通常、研究タイトルで Google 検索すればすぐに見つかる]。

タイトルとアブストラクトから、ある研究に興味深い情報が含まれているかもしれないと思った場合、たとえその研究が重要でないように思えても、削除しないほうがよい。せっかく時間と労力をかけて総合的な研究を検索したのに、次のステップで誤って関連する文献を削除してしまったら残念なことである。タイトルと抄録に基づく文献のスクリーニングでは、その研究を除外した具体的な理由を説明する必要はない。最終的には、次のステップのために、いくつの研究が残ったかを記録するだけでよいのである。

タイトルと抄録のスクリーニングに基づくと、最初の参考文献の90%以上が削除される可能性がある。次のステップでは、各文献の**全文**を取得する必要がある。論文で報告されたすべての内容に基づいて、その研究が適格基準を満たすかどうかを最終的に判断する。この作業は、メタ分析に研究を含めるかどうかを決定する最終ステップなので、特に念入りに行う必要がある。さらに、単に「目的に合わないから外した」というだけでは不十分である。ここで**理由**を述べなければならない。削除する各研究について、定義した基準に従って、なぜその研究が適格でなかったのかを文書化する必要がある。適格性の基準以外に、ある研究を含めることができない理由がもう一つある。

論文全体に目を通すと、その研究が適格かどうかを判断するのに十分な情報が提供されていないことがわかるかもしれない。研究デザインに関する十分な情報が提供されていないだけということもあり得る。また別のよくあるシナリオは、メタ分析に必要な効果量メトリックを計算できるような形で研究結果が報告されていないことである。このような場合は、少なくとも2回、研究の責任著者に連絡を取り、必要な情報を求めるようにする。著者が応答しない場合、そして発表論文に欠けている情報が不可欠な場合のみ、その研究を除外することが可能である。

\index{PRISMA Statement}\index{PRISMA 声明}
\index{Campbell Collaboration}

含めるべき研究の最終的な選択に到達したら、含めるプロセスのすべての詳細を**フロー図**に書き留める。フロー図のテンプレートとしてよく使われるのが、[PRISMAガイドライン](http://prisma-statement.org/PRISMAStatement/FlowDiagram)で提供されている^[Neal Haddaway and Luke McGuinness [-@prisma2020package] は最近 **{PRISMA2020}** というパッケージを開発し、PRISMA 2020 準拠フロー図を _R_ で直接生成できるようになっている。パッケージの機能は、インタラクティブな[ウェブアプリ](https://estech.shinyapps.io/prisma_flowdiagram/)を介してアクセスすることも可能である。]。このフローチャートは、上記で取り上げた必要な情報をすべて文書化したものである。

1. **電子データベース**を検索して、いくつの文献を特定できたか。

2. **他の情報源**から見つけた追加の参考資料の数。

3. **重複排除**後に残った参考文献の数。

4. **タイトルとアブストラクト**に基づいて削除した文献の数。

5. **フル論文**に基づいて削除した**論文**の数、**特定の理由**で除外した論文の数を含む。

6. **定性的統合**（つまりシステマティックレビュー）および**定量的統合**（つまりメタ分析）に含めた**研究**の数である。

なお、(5)で除外しなかった論文の数と(6)で含めた研究の数は通常同じであるが、必ずしも同じである必要はない。例えば、1つの論文が2つ以上の独立した研究の結果を報告し、そのすべてがメタ分析に適していることもあり得る。その場合、**研究**の数は、含まれる**論文**の数より多くなる。


```{block2, type='boximportant'}
**ダブルスクリーニング**

関連するほぼすべてのガイドラインやコンセンサスステートメントは、研究選択プロセスにおいて**ダブルスクリーニング**を用いるべきであると強調している [@dissemination2009systematic; @higgins2019cochrane; @methods2016methodological]。

つまり、誤りを避けるために、少なくとも2人が独立して各研究選択ステップを行う必要がある。タイトルとアブストラクトに基づく文献の削除は、2人以上の研究者が独立して行い、評価者が削除しなかったすべての記録の組み合わせを次のステップに転送する必要がある。

2人以上の評価者を使うことは、論文の全文をスクリーニングする最後のステップではさらに重要である。このステップでは、各人が独立して研究が適格であるかどうかを評価し、適格でない場合はその理由を述べなければならない。


その後、評価者同士でその結果を比較する必要がある。一部の研究の適格性に関して評価者が意見を異にすることはよくあることで、そのような意見の相違は通常、議論を通じて解決することが可能である。評価者が合意を見いだせない場合、そのような場合に最終決定を下すことができる上級研究者をあらかじめ決めておくと便利である。


2人以上の評価者を使用することは、研究の選択プロセスにおいてのみ望ましいわけではない。この方法は、データの抽出やコーディングの際にも有効である（Chapter \@ref(data-extraction) 参照）。


```

<br></br>

### データ抽出とコーディング {#data-extraction}

---

メタ分析に含める研究の選択が確定すると、データを抽出することができる。選択した論文から抽出すべき情報は、大きく分けて3種類ある [@cuijpers2016meta]。

1. 研究の特徴。
2. 効果量を算出するために必要なデータ。
3. 研究の質またはバイアスのリスクの特性。

質の高いメタ分析では、対象となった研究の特徴を報告する表が用意されるのが通例である。この表で報告される正確な内容は、研究分野や研究課題によって異なる可能性がある。しかし、研究の筆頭著者とその発表時期は必ず抽出して報告する必要がある。また、各研究のサンプルサイズも報告する必要がある。

これとは別に、メタ分析の PICO で指定された特性、例えば、対象国、平均年齢または中央値、女性と男性の参加者の割合、介入または曝露の種類、対照群または比較（該当する場合）、および各研究の評価結果についての情報を含めることが可能である。1つまたは複数の研究で特性の1つが評価されていない場合は、その詳細が表で指定されていないことを示す必要がある。

また、プールする予定の効果量や結果指標を計算するために必要なデータを抽出・収集することも必要である。章では、効果量データを表計算ソフトで構成し、 _R_ での計算に利用しやすくする方法について詳しく説明する。また、解析計画（Chapter \@ref(analysis-plan) 参照）にサブグループ解析やメタ回帰を計画している場合は、これらの分析に必要なデータも論文から抽出する必要がある。

\index{Risk of Bias}
\index{Cochrane, Risk of Bias Tool}

メタ分析では、一次研究の質も評価して報告することが一般的である。そのために各研究から抽出する必要のある情報は、使用する評価システムの種類に依存する。一次研究の質を評価するツールは、この数十年で数え切れないほど開発されている [@sanderson2007tools]。

ランダム化比較試験のみが対象である場合、研究の質をコード化する方法として、コクランが開発した [**Risk of Bias Tool**](https://methods.cochrane.org/bias/resources/rob-2-revised-cochrane-risk-bias-tool-randomized-trials) を用いるのが最適な方法の1つである [@higgins2011cochrane; @sterni2019rob] 。タイトルにあるように、このツールは研究の質**そのもの**を評価するのではなく、研究のバイアスのリスク\index{Risk of Bias}\index{バイアスリスク}を評価するものである。

研究の質とバイアスのリスクは関連しているが、同一の概念ではない。「バイアス」（あるいは「偏り」）とは、研究結果やその解釈における系統的な誤りを指す。バイアスのリスクとは、研究の実施方法やその結果が、そのような系統的な誤りを引き起こす可能性を高めるような側面である。たとえ、ある研究が「最先端」とされる方法のみを適用している場合でも、バイアスが存在する可能性はある。ある研究は、特定の研究分野で重要だと考えられている品質基準をすべて満たすことが可能であるが、時にはこれらのベストプラクティスでさえ、研究を歪みから守るには十分でない場合がある。このように、「バイアスのリスク」の概念は、研究の質の評価とは少し異なる焦点を持っている。それは主に介入研究のアウトプットが**信じられるか**という問題に関心があり、この目標に資する基準に焦点を当てている [@higgins2019cochrane].


\index{Cochrane, ROBINS-I Tool}

いくつかのドメインでは、バイアスリスクツールで研究のバイアスリスクを「高い」「低い」に分類できたり、「何らかの懸念がある」と判断できる。また、バイアスリスクをどのように視覚的にまとめるかについても慣例がある（Chapter \@ref(risk-of-bias-plots) で _R_ でどのようにできるかを説明している）。非無作為化研究のバイアスリスクを評価するための同様のリソースとして、**Risk of Bias in Non-randomized Studies of Interventions** または ROBINS-I, tool がある [[@sterne2016robins]](https://www.riskofbias.info/welcome/home)。

Cochrane Risk of Bias ツールは、（非）無作為化臨床試験におけるバイアスのリスクを評価するための標準的なアプローチとなっている [@jorgensen2016evaluation]。他の分野では、現在は残念ながらまだむしろ開拓時代である。例えば、心理学研究においては、研究の質の評価は一貫性がなく、不透明であるか、全く実施されていないことが多い [@hohn2019primary]。

臨床試験以外の研究のメタ分析を計画している場合、できることが2つある。まず、Risk of Bias または ROBINS-I ツールがまだ適用可能かどうかを確認しよう。例えば、健康に関連しない別の介入方法に焦点を当てている場合である。もう一つは、確かに最適とは言えないかもしれないが、類似のテーマに関する過去の高品質なメタ分析を検索し、これらの研究がどのように主要研究の品質を決定したかを確認することである。

これで、メタ分析の歴史、問題点、そしてデータを収集しエンコードする際にそれらをどのように回避するかについての考察を終えることとする。次の章は、このガイドの「ハンズオン」部分の始まりである。この章では、 _R_ の最初のステップを自分で実施してみる。

$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block2, type='boxquestion'}
**知識を試そう！**

  
\vspace{4mm}

1. メタ分析はどのように定義することができるか？メタ分析と他の文献レビューの違いは何か？

\vspace{-2mm}

2. メタ分析の生みの親、生みの親を一人挙げることができるか？その人物はどのような功績を残したか？

\vspace{-2mm}

3. メタ分析のよくある問題点を3つ挙げ、1～2文で説明しなさい。

\vspace{-2mm}

4. メタ分析のための良いリサーチクエスチョンを定義する資質を挙げなさい。

\vspace{-2mm}

5. 大学生の睡眠介入に関するメタ分析の適格基準をもう一度見てみよう（Chapter \@ref(research-question)章末)。この研究の適格基準、除外基準から PICO を抽出できるか。

\vspace{-2mm}

6. 研究を検索するために使用できるいくつかの重要なソースを挙げなさい。

\vspace{-2mm}

7. 「研究の質」と「バイアスのリスク」の違いを1～2文で説明しなさい。


\vspace{4mm}



**問題の解答は、本書の巻末 [Appendix A](#qanda1) にある。**
```

<br></br>

## 概要

* 毎年、より多くの科学的研究が発表され、利用可能な証拠を追跡することが難しくなっている。しかし、研究成果が多いからといって、自動的に科学が進歩するわけではない。

* メタ分析の目的は、過去の研究結果を定量的に組み合わせることである。ある研究課題に関する利用可能なすべての証拠を統合し、意思決定に利用することができる。

* メタ分析の手法は、20世紀初頭にまで遡る。しかし、現代的なメタ分析手法は20世紀後半に開発され、それ以降、メタ分析は一般的な研究ツールとなった。

* 各メタ分析には、「りんごとオレンジ」問題、「Garbage In, Garbage Out」問題、「ファイルの引き出し」問題、「研究者のアジェンダ」問題などが関連する。

* これらの問題の多くは、明確な研究課題と適格基準を定義し、解析計画を書き、メタ解析を事前に登録し、研究検索とデータ抽出を系統的かつ再現可能な方法で行うことによって軽減することが可能である。


<!--chapter:end:03-introduction-ja.Rmd-->

# R の発見 {#discovering-R}

---

<img src="_figs/discover.jpg" />

<br></br>

<span class="firstcharacter">こ</span>
の章では、 _R_ の世界への旅行を始める。プログラミングに触れるのが初めてであれば、少し不安かもしれない。その心はよく分かるが、心配する必要はない。この20年間、世界中の何千人もの知的な人々が、 _R_ をより簡単に、より便利に使えるようにするための方法を提供してきた。また、 _R_ のコードの記述と実行をより簡単にするために使用できる、非常に強力なコンピュータ プログラムについても紹介した。

とはいえ、これまで使ってきた他のデータ解析プログラムと比べると、 _R_ で作業するのはやはり難しいのも事実である。 _R_ コミュニティの最も重要な人物の一人である Hadley Wickham は、かつて _R_ は **GUI** (Graphical User Interface) ベースの統計用ソフトウェアとは根本的に異なることを強調した [@grolemund2014hands, Foreword]。GUI では、いくつかのボタンをクリックするだけでデータ分析を行うことが可能であるが、最終的には開発者が重要と判断した機能に限定されてしまう。

一方、 _R_ はこのような制限はない。しかし、より多くの背景知識を必要とする場合がある。他の言語と同様に、 _R_ も学習が必要であり、熟練したユーザーになるためには練習が必要である。この過程では、不満が生じることもあるが、それは当然のことである。序文では、行き詰まったときにできることをいくつか紹介している。

本書では、 _R_ を学ぶことは**価値がある**と断言したい。 _R_ は、最も汎用性が高く、包括的で、最も頻繁に使用されている統計プログラミング言語である。 _R_ のコミュニティは毎年急速に拡大しており、 _R_ の魅力は非常に大きいので、ニューヨークタイムズでさえもニュースとして報道する価値があると判断した [@vance2009data]。

大学や研究機関で働いていようが、一般企業で働いていようが、 _R_ でできることは、他人から見れば超能力に見えることが多いだろう。しかし、多少の時間と努力さえあれば、誰でも習得できる超能力なのである。では、そろそろ始めよう。

<br></br>

## Installing _R_ and R Studio {#install-R}

---

\index{R Studio}

その前に、統計解析のために _R_ を便利に使えるコンピュータ・プログラムをダウンロードし、用意しなければならない。現時点での最良の選択肢は、おそらく [**R Studio**](https://rstudio.com/) だろう。このプログラムは、データ、パッケージ、出力の取り扱いを容易にするユーザー・インタフェースを提供してくれる。R Studio は完全に無料で、インターネットからいつでもダウンロードできるのが最大の魅力である。最近では、R Studio のオンライン版もリリースされ (https://rstudio.cloud/)、ウェブブラウザを通してほぼ同じインターフェースと機能を利用できるようになった。しかし、本書では、コンピュータに直接インストールする R Studio のバージョンに焦点を当てる。

```{block, type='boxinfo'}
この章では、 _R_ と R Studio 各自のコンピュータに **インストール**する方法に焦点を当てている。すでに R Studio をコンピュータにインストールしており、 _R_ の経験豊富なユーザーであれば、**どれも目新しいものではないだろう**。その場合は、この章を読み飛ばしてよい。 _R_ を使ったことがない人は、しばらくお付き合い願いたい。
```



それでは、初めてのコーディングに向けて、 _R_ と R Studio の設定に必要なステップに進んでいこう。

\index{Comprehensive _R_ Archive Network (CRAN)}

1. R Studio は、 _R_ のコードを書き、それを簡単に実行できるようにするインターフェイスである。しかし、R Studioは _R_ と同一ではなく、 _R_ のソフトウェアがすでにコンピュータにインストールされている必要がある。したがって、まず、 _R_ の最新版をインストールする必要がある。R Studio と同様、 _R_ は完全に無料である。**Comprehensive R Archive Network** (CRAN)というウェブサイトからダウンロード可能である。[Windows PC](https://cran.r-project.org/bin/windows/base/) か [Mac](https://cran.r-project.org/bin/macosx/) かによって、ダウンロードする _R_ の種類は異なる。 _R_ の重要な点は、その **バージョン** である。 _R_ は定期的に更新され、新しいバージョンが利用できるようになる。 _R_ のバージョンが古くなりすぎると、一部の機能が動作しなくなることがある。そのため、 _R_ を再インストールして、定期的（だいたい1年ごと）に _R_ のバージョンを更新することが有効である。この本では 、 _R_ のバージョン 4.0.3 を使用している。 _R_ をインストールした時点で、すでに上位のバージョンがある可能性もあるので、常に最新のバージョンをインストールすることを勧める。

2. _R_ をダウンロードしてインストールした後、[R Studioのウェブサイト](https://rstudio.com/products/rstudio/download/)から "R Studio Desktop" をダウンロードする。R Studio にはライセンスを購入しなければならないバージョンもあるが、今回の目的では必要ではない。R Studio Desktop の無料版をダウンロードしてインストールするだけである。

3. R Studio を初めて開くと、Figure \@ref(fig:rstudio-1) のような画面になると思われる。R Studio には、3 つのペインがある。右上には **Environment** ペインがあり、 _R_ で内部的に定義した（＝保存した）オブジェクトが表示される。右下には、**Files, Plots, Packages,Help** ペインがある。このペインにはいくつかの機能があり、例えば、コンピュータ上のファイルを表示したり、プロットやインストールされたパッケージを表示したり、ヘルプページにアクセスするために使用される。しかし、R Studio の中心は左側の **Console** である。Console は、 _R_ コードを入力し、実行する場所である。

```{r rstudio-1, fig.cap='R Studio のペイン', out.width='100%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rstudio_1_col_sep.png')
```

4. R Studioには、通常はじめに表示されない4番目のペインとして、**Source** ペインがある。メニューの **File** > **New File** > **R Script** をクリックすると、Source ペインを開くことが可能である（訳注: R Script よりも R Markdown をお勧めする）。すると、左上に空の _R_ **スクリプト**を含む新しいペインが開く。 _R_ スクリプトは、コードを1つの場所に集めるのに最適な方法である。また、拡張子が ".R" のファイル (例: **myscript.R**) として、コンピュータに保存することも可能である。 _R_ スクリプトのコードを実行するには、関連するすべての行にカーソルをドラッグして選択し、右側にある "Run" ボタンをクリックする。これにより、コードがコンソールに送信され、そこで評価される。ショートカットは、Ctrl + R (Windows) または Cmd + R (Mac)である。

## パッケージ {#packages}

---

\index{Package, _R_ }

\index{Function, _R_ }

\index{Function Argument}

ここでは、 _R_ のコードを使用して、いくつかの**パッケージ**をインストールする。パッケージは _R_  が非常に強力である主な理由の1つである。パッケージによって、世界中の専門家が一連の**関数**を開発し、他の人がそれをダウンロードして _R_ で使用できるようになる。関数は _R_ の中核的な要素であり、事前に定義された種類の操作を、通常は自分のデータに対して実行できるようにする。

関数 $f(x)$ の数学的定式化と _R_ における関数の定義の仕方は並行している。 _R_ では、関数はまずその名前を書き、その後に入力や関数の指定（いわゆる**引数**）を括弧で囲んでコーディングされる。

例えば、9の平方根が何であるかを知りたいとする。 _R_ では、 `sqrt` 関数を使用することが可能である。結果を得るためには、関数への入力として `9` を与えるだけでよいのである。自分で試してみてみよう。コンソールの小さな矢印(`>`)の横に `sqrt(9)` と書いて、Enter キーを押してみてみよう。何が起こるか見てみよう。


```{r}
sqrt(9)
```

これで _R_ から最初の**出力**が得られた。 _R_ にはこれよりはるかに複雑な関数があるが、すべて同じ原理で支配されている。関数が必要とするパラメータの情報を提供すると、関数はその情報を使って計算を行い、最終的に出力を提供する。

\index{tidyverse Package}
\index{meta Package}
\index{metafor Package}

_R_ では、`install.packages` という関数を使って、パッケージの**インストール** を行う。この関数に伝えるべきことは、インストールしたいパッケージの名前だけである。とりあえず、後々役に立つ３つのパッケージをインストールしておこう。

* **{tidyverse}**. **{tidyverse}** [@tidyverse] は単一のパッケージではなく、実際には _R_  でのデータの操作と視覚化を容易にするパッケージのバンドルである。**{tidyverse}** パッケージをインストールすると、同時に **{ggplot2}**, **{dplyr}**, **{tidyr}**, **{readr}**, **{purr}**, **{stringr}**, **{forcats}** パッケージが提供される。Tidyverse に含まれる関数は、近年 _R_ コミュニティで非常に人気があり、多くの研究者、プログラマー、データ科学者に利用されている。Tidyverse についてもっと知りたい方は、その[ウェブサイト](https://www.tidyverse.org/)を参照されたい。

* **{meta}**. このパッケージには、様々なタイプのメタアナリシスを簡単に実行するための関数が含まれている [@meta]。このガイドでは主にこのパッケージに焦点を当てる。なぜなら、このパッケージは使いやすく、よく文書化されており、非常に汎用性が高いからである。**{meta}** パッケージの詳細については、 [ウェブサイト](http://www.imbi.uni-freiburg.de/lehre/lehrbuecher/meta-analysis-with-r) を参照されたい。

* **{metafor}**. **{metafor}** パッケージ [@urviecht]  もメタアナリシスの実施に特化したパッケージで、機能面ではまさに強豪と言える。このパッケージは後の章で時々使用するし、**{meta}** パッケージが多くのアプリケーションで使用するため、インストールしておくとよいだろう（訳注: 通常、`meta` をインストールすると自動的に `metafor` もインストールされる。）。また、**{metafor}** パッケージには、メタ分析関連の様々なトピックに関する優れた[ドキュメント](http://www.metafor-project.org/doku.php/metafor)がある。

`install.packages` 関数は、インストールしたいパッケージの名前のみを入力として要求する。ひとつずつパッケージを追加するコードは次のようになるはずである。

```{r, eval=F}
install.packages("tidyverse")
install.packages("meta")
install.packages("metafor")
```

コンソールに上記のコードを入力し、Enter キーを押すだけでインストールが開始される（Figure \@ref(fig:rstudio-1)）。

```{r rstudio-2, fig.cap='パッケージをインストール中。', out.width='75%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rstudio_2_col.png')
```

```{block2, type='boximportant'}
パッケージ名を**引用符** (`""`) で囲むことを忘れないように。これを忘れると、エラーメッセージが表示される。
```


Enter を押すと、 _R_ はパッケージのインストールを開始し、インストールの進行状況についての情報を表示する。`install.packages` 関数が終了すると、そのパッケージを使用する準備が整ったことになる（訳注：この際のメッセージが赤字の英語で表示されるため、エラーが出たと勘違いする人が多い。じっくり読んで、successful とあれば成功である。）。インストールされたパッケージは、 _R_ の **システム・ライブラリ** に追加される。このシステムライブラリは、R Studio の画面左下にある**パッケージ**ペインでアクセス可能である。インストールされたパッケージを使いたいときは、`library` 関数を使ってライブラリから読み込むことが可能である。試しに、**{tidyverse}** パッケージをロードしてみよう。

```{r, eval=F}
library(tidyverse)
```

<br></br>

## **{dmetar}** パッケージ {#dmetar}

---

\index{dmetar Package}

このガイドでは、研究者としてメタアナリシスの実施をできるだけアクセスしやすく、簡単にできるようにしたい。メタ分析には **{meta}** や **{metafor}** パッケージのような素晴らしいパッケージがあり、ほとんどの重労働をこなしてくれるが、メタ分析にはまだいくつかの重要な側面があり、現在 _R_ で行うのは簡単ではない。

不足している機能を補うため、我々は本書のコンパニオン _R_ パッケージとして、**{dmetar}** パッケージを開発した。**{dmetar}** パッケージは独自のドキュメントを持っており、[オンライン](https://dmetar.protectlab.org/)で見ることが可能である。**{dmetar}** パッケージの関数は、このガイドで頻繁に使用する **{meta}** と **{metafor}** パッケージ（と、より高度な他のいくつかのパッケージ）のための追加機能を提供している。**{dmetar}** パッケージに含まれる関数がどのようにメタ分析のワークフローを改善するかを、この本を通じて詳細に説明していこう。このガイドで使用するサンプルデータセットのほとんどは、**{dmetar}** に含まれている。

```{block2, type='boxinfo'}
このガイドを読み進めていくためには、**{dmetar}** パッケージをインストールすることを強く推奨するが、**必須ではない**。パッケージの各関数について、ソースコード（関数をローカルに保存するために使用可能）と、それらの関数が依存する追加の _R_ パッケージも提供している。また、パッケージに含まれるデータセットの補足的なダウンロードリンクも提供する。

しかし、あらかじめ **{dmetar}**  パッケージをインストールしておくと、すべての機能、データセットがコンピュータにプリインストールされるので、より便利である。
```


\index{Version, _R_ }

**{dmetar}** パッケージをインストールするには、 _R_ のバージョンが 3.6 以降である必要がある。最近 _R_  を（再）インストールしたのであれば、おそらく大丈夫だろう。 _R_ のバージョンが十分に新しいかどうかを確認するには、次のコード行をコンソールに貼り付けて、Enterキーを押す。

```{r, eval=F}
R.Version()$version.string
```

これにより、現在の _R_ バージョンが表示される。もし、 _R_ のバージョンが3.6以下であれば、アップデートする必要がある。この方法については、インターネット上に良い[ブログ記事](https://www.linkedin.com/pulse/3-methods-update-r-rstudio-windows-mac-woratana-ngarmtrakulchol/)があり、案内されている。

**{dmetar}** をインストールする場合、先にインストールしなければならないパッケージがある。このパッケージは **{devtools}** と呼ばれている。**{devtools}** がまだコンピュータにインストールされていない場合は、先程と同じようにインストールしておこう。

```{r, eval=F}
install.packages("devtools")
```

そして、この行を使って **{dmetar}** をインストールすることが可能である。

```{r, eval=F}
devtools::install_github("MathiasHarrer/dmetar")
```

これでインストールが開始される。**{dmetar}** パッケージが正しく機能するためには、他のパッケージも一緒にインストー ルする必要があるため、インストールに時間がかかる可能性がある。インストール中に、インストールマネージャが以下のように訪ねてくることがあるがこれは、すでにインストール済みの _R_ パッケージを更新するかどうか尋ねている。

```
## These packages have more recent versions available.
## Which would you like to update?
## 
## 1: All                          
## 2: CRAN packages only            
## 3: None                          
## 4: ggpubr (0.2.2 -> 0.2.3) [CRAN]
## 5: zip    (2.0.3 -> 2.0.4) [CRAN]
## 
## Enter one or more numbers, or an empty line to skip updates:
```

このメッセージが表示されたら、パッケージ更新をしたくないことをインストールマネージャに伝えるとよい。この例では、コンソールに `3` を貼り付けて Enter キーを押す。同じように、インストールマネージャが、

```
## There are binary versions available but the source versions are later:
##  
##  [...]
##  
##   Do you want to install from sources the package which needs compilation?
##   y/n: 
```

このような質問をした場合、`n` (いいえ) を選ぶとよいだろう。この方法でインストールに失敗した場合（つまり `Error` が表示された場合）、もう一度インストールを実行し、今度はすべてのパッケージをアップデートする。

本書を執筆し、パッケージを開発する際には、誰もがエラーなくインストールできるように配慮した。とはいえ、初回でパッケージのインストールがうまくいかない可能性もある。それでもインストールに問題がある場合は、本書のまえがきにある「問い合わせ」の項を参照されたい。

<br></br>

## データ準備とインポート {#data-prep-R}

---

この章では、R Studio を使用してデータを _R_ にインポートする方法について説明する。データの準備は、面倒で疲れるものではあるが、後のすべてのステップの基礎となる。したがって、先に進む前にデータを正しい形式にすることに細心の注意を払わなければならない。


通常、 _R_ に取り込んだデータは、 **Microsoft Excel** のスプレッドシートに格納されている。インポートを非常に簡単に行うことができるため、データを _Excel_ に保存することを勧める。 _Excel_ でデータを準備する際には、いくつかの「すべきこと」と「してはいけないこと」がある。

* _Excel_ シートの列にどのように名前を付けるかは非常に重要である。列に正しく名前を付けておけば、 _R_ を使用してデータを変換する必要がないため、後で時間を大幅に節約することが可能である。スプレッドシートの列に「名前を付ける」とは、単に変数の名前を列の最初の行に書き込むことである。（訳注: 日本では２行目以降にも列名を書くことがあるが、あまりよい習慣とは言えない。）

* 列名にはスペースを含めてはいけない。列名の2つの単語を区切るには、アンダースコアまたはポイントを使用した(例："column_name")。

* _Excel_ のスプレッドシートで列をどのように並べるかは重要ではない。ただ、正しくラベル付けされている必要がある。

* また、列の書式設定も必要ない。スプレッドシートの最初の行に列名を入力すると、 _R_ はそれを列名として自動的に検出する。

* インポート時に、ä、ü、ö、á、é、ê などの特殊文字が文字化けする可能性があることも知っておくとよいだろう。インポートする前に、これらの文字を「通常の」文字に変換しておくとよいだろう。（訳注: 列名に日本語を使っても問題ないが、英語論文作成を意図している場合は英語にしておく方が良いだろう。）

* _Excel_ ファイルにシートが1つだけ入っていることを確認する。

* もし、以前にデータを含んでいて現在空になっている行や列が1つまたはいくつかある場合、それらの列や行を完全に削除することを確認する。

まず、データセットの例から見てみよう。これから、自殺防止プログラムのメタアナリシスを実施する予定だとする。研究で注目したいアウトカムは、質問票によって評価された自殺念慮の重症度（すなわち、個人がどの程度、自分の人生を終わらせることを考え、検討し、計画するか）である。あなたはすでに研究の検索とデータ抽出を完了し、次に _R_ でメタ分析データをインポートしたいと思っている。

したがって、次の作業は、関連するすべてのデータを含む _Excel_ シートを準備することである。Table \@ref(tab:suicidedata) は、インポートするすべてのデータを示している。この表の最初の行には、上で挙げたルールに基づき、 _Excel_ ファイル内の列にどのような名前を付けるかも示されている。スプレッドシートには、各研究が1行にリストされていることがわかる。各研究について、介入群と対照群の両方のサンプルサイズ（$n$）、平均値、標準偏差（$SD$）が含まれている。これは効果の大きさを計算するために必要なアウトカムデータで、詳しくは Chapter \@ref(effects) で説明する。次の3列は、後でメタ分析で分析したい変数である。

このデータをまとめた **"SuicidePrevention.xlsx"**という _Excel_ ファイルを用意した。このファイルは、[インターネット](https://protectlab.org/en/datasets/suicide-prevention/)からダウンロードすることが可能である。

```{r suicidedata, echo=F, message=F, warning=F}
library(openxlsx)
library(kableExtra)
openxlsx::read.xlsx("data/SuicidePrevention.xlsx") -> SuicidePrevention

rbind(SuicidePrevention[1:5,], rep("...", 10)) -> SuicidePrevention


colnames(SuicidePrevention) = c("Author", "N ", "Mean ", "SD", "N", "Mean", "SD ", "Year", "Age Group", "Control Group")

kableExtra::kable(SuicidePrevention, "html", booktabs = T,
                  caption = 'The suicide prevention dataset.',
                  linesep = "") %>% 
  kable_styling(bootstrap_options = c("striped", "condensed", "responsive", "hover"), font_size = 12) %>%
  add_header_above(c(" ", "Intervention Group" = 3, "Control Group" = 3, "Subgroups" = 3)) %>% 
  add_header_above(c("'author'", "'n.e'", "'mean.e'", "'sd.e'", "'n.c'", 
                     "'mean.c'", "'sd.c'", "'pubyear'", "'age_group'", "'control'"))

```


R Studioで _Excel_ ファイルをインポートするには、まず**作業ディレクトリ**を設定する必要がある。作業ディレクトリとは、 _R_ がデータを使用することができ、出力が保存されるコンピュータ上のフォルダのことである。作業ディレクトリを設定するには、まず、メタアナリシスのデータと結果をすべて保存するフォルダをコンピュータ上に作成する必要がある。また、インポートしたい **"SuicidePrevention.xlsx"** ファイルもこのフォルダに保存する。

R Studio を起動し、左下の **Files** ペインに新しく作成したフォルダを開く。フォルダを開くと、先ほど保存した _Excel_ ファイルが表示されているはずである。次に、ペイン上部の小さな歯車をクリックし、ポップアップメニューの **Set as working directory** をクリックして、このフォルダを作業ディレクトリとして設定する。これで、現在開いているフォルダが作業ディレクトリになる。

```{r wd, fig.cap='作業ディレクトリを設定し、R 環境にデータセットを読み込む。', out.width='100%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/wd_col_sep.png')
```

これで、 _R_ にデータをインポートできるようになった。**Files** ペインで、**"SuicidePrevention.xlsx"** ファイルをクリックしよう。次に、**Import Dataset...** をクリックする。インポートアシスタントがポップアップ表示され、データのプレビューが読み込まれるはずである。これは時間がかかる場合があるので、このステップをスキップして、そのまま **Import** をクリックする。

\index{Data Frame}

すると、右上の **Environment** ペインに `SuicidePrevention` という名前でデータセットが表示されるはずである。これは、データが読み込まれ、 _R_ コードで使用できるようになったことを意味している。今回インポートしたような表形式のデータセットは、 _R_ では **データフレーム** (`data.frame`) と呼ばれている。データフレームは、先ほどインポートした _Excel_ のシートのように、列と行を持つデータセットである。 

\index{openxlsx Package}

```{block2, type='boxinfo'}
**{openxlsx}**

\vspace{4mm}

また、コードを使用してデータファイルを直接インポートすることも可能である。このために使える良いパッケージは **{openxslx}** [@openxlsx] と呼ばれるものである。他の _R_ パッケージと同様に、最初にこれをインストールする必要がある。それから `read.xlsx` 関数を使って _Excel_ シートをインポートすることが可能である。

\vspace{2mm}

ファイルが作業ディレクトリに保存されている場合、関数にファイル名を与え、インポートしたデータを _R_ のオブジェクトに代入するだけでよい。例えば、データセットが _R_ 内で `data` という名前になるようにしたい場合は、次のようなコードを使用する。

`library(openxlsx)` <br/>
`data <- read.xlsx("SuicidePrevention.xlsx")`
```

<br></br>

## データ操作 {#data-manip-R}

---

R Studio を使って最初のデータセットをインポートしたので、いくつかの操作を行ってみよう。**データ操作**とは、さらなる分析に使えるようにデータを変換することであり、すべてのデータ分析に不可欠な作業である。データサイエンティストのような職業は、生の「整頓されていない」データを「整頓された」(tidy) データセットに変えることに大半の時間を費やしている。**{tidyverse}** の関数は、データ操作のための優れたツールボックスを提供している。もしまだパッケージをライブラリからロードしていないなら、次の例のために今ロードすべきである。

```{r, eval=F}
library(tidyverse)
```


<br></br>

### クラス変換 {#class-conversion}

---

まず、前章でインポートした `SuicidePrevention` データセットを覗いてみよう。これを行うには、 **{tidyverse}** が提供する `glimpse` 関数を使用する。（訳注: あるいは `Environment` ペイン内の `SuicidePrevention` の左にある丸印をクリックすれば表示される。）

```{r, echo=F, message=F, warning=F}
library(tidyverse)
library(openxlsx)
SuicidePrevention = read.xlsx("data/SuicidePrevention.xlsx")
```


```{r}
glimpse(SuicidePrevention)
```


これにより、データセットの各列に格納されているデータの種類の詳細を知ることができる。データの種類を示す略語はさまざまである。 _R_ では、これらは**クラス**と呼ばれている（訳注: クラスではなく型である）。

* `<num>` は **numeric** の略である。これは、数字として格納されているすべてのデータである（例：1.02）。（訳注: 実際は <dbl> と表示されているはずである。）

* `<chr>` は **character** の略である。これは、単語として格納されているすべてのデータである。

* `<log>` は **logical** の略で、ある条件が `TRUE` または `FALSE` のいずれかであることを示すバイナリ変数である。

* `<factor>` は数値として保存され、各数値は変数の異なる水準を意味する。変数の因子水準は、1 = "low"、2 = "medium"、3 = "high" とすることができる。

また、 `class` 関数を使用して、列のクラスを確認することも可能である。データフレームの列の名前に `$` 演算子を付けて、列の名前を指定すれば、データフレーム内の列に直接アクセスすることが可能である。これを試してみよう。まず、 _R_ に `n.e` という列に含まれるデータを提供させる。その後、その列のクラスを確認する。

```{r}
SuicidePrevention$n.e

class(SuicidePrevention$n.e)
```

介入グループのサンプルサイズを含む列 `n.e` は、クラス `character` を持っていることがわかる。しかし、待ってみよう、これは間違ったクラスである。インポート時に、この列は誤って `character` 変数として分類されたが、実際には `numeric` クラスであるべきである。この間違いは、今後の分析段階に影響を与える。例えば、サンプルサイズの平均を計算したい場合、このような警告が表示される。

```{r, results='hold'}
mean(SuicidePrevention$n.e)
```

データセットを使えるようにするためには、まず列を正しいクラスに変換しなければならないことがよくある。これを行うには、すべて "`as.`" で始まる一連の関数を使用することが可能である。すなわち、 `as.numeric`, `as.character`, `as.logical` そして `as.factor` である。それでは、いくつかの例を見てみよう。

先ほどの `glimpse` 関数の出力では、いくつかの列が `numeric` であるべきなのに `character` クラスに設定されていることがわかる。これは `n.e`, `mean.e`, `sd.e`, `mean.c`, `sd.c` という列に関係している。出版年 `pubyear` は `<dbl>` というクラスを持っていることがわかる。これは **double** の略で、列が数値ベクトルであることを意味する。 _R_ では、数値データ型を参照するために `double` と `numeric` の両方が使用されるのは歴史的な例外である。しかし、通常、これは実際のところ何の意味もない。

しかし、このデータセットでは、いくつかの数値が**文字** (character) としてコード化されているため、今後問題が発生することが予想される。したがって、 `as.numeric` 関数を使用してクラスを変更する必要がある。この関数に変更したい列を指定し、**代入演算子** (`<-`) を使って出力を元の場所に保存する。これは次のようなコードになる。

```{r}
SuicidePrevention$n.e <- as.numeric(SuicidePrevention$n.e)
SuicidePrevention$mean.e <- as.numeric(SuicidePrevention$mean.e)
SuicidePrevention$sd.e <- as.numeric(SuicidePrevention$sd.e)
SuicidePrevention$n.c <- as.numeric(SuicidePrevention$n.c)
SuicidePrevention$mean.c <- as.numeric(SuicidePrevention$mean.c)
SuicidePrevention$sd.c <- as.numeric(SuicidePrevention$sd.c)
SuicidePrevention$n.c <- as.numeric(SuicidePrevention$n.c)
```

また、`glimpse` の出力では、データのサブグループである `age_group` と `control` が文字としてコード化されていることがわかる。しかし、実際には、それぞれ2つの因子水準を持つ因子としてエンコードする方が適切である。クラスを変更するには、 `as.factor` 関数を使用する。

```{r}
SuicidePrevention$age_group <- as.factor(SuicidePrevention$age_group)
SuicidePrevention$control <- as.factor(SuicidePrevention$control)
```

`levels` と `nlevels` 関数を使用すると、因子のラベルと因子の水準数を確認することも可能である。

```{r}
levels(SuicidePrevention$age_group)
nlevels(SuicidePrevention$age_group)
```

また、`levels` 関数を使用して、因子ラベルの名前を変更することが可能である。単に、元のラベルに新しい名前を割り当てるだけである。これを _R_ で行うには、 **concatenate** または `c` 関数を使用する必要がある。この関数は2つ以上の単語や数字を結びつけて、1つの要素を作ることが可能である。これを試してみよう。

```{r}
new.factor.levels <- c("gen", "older")
new.factor.levels
```

完璧である。これで、新しく作成した `new.factor.levels` オブジェクトを使用して、`age_group` 列の因子ラベルに割り当てることができるようになった。

```{r}
levels(SuicidePrevention$age_group) <- new.factor.levels
```

リネームがうまくいったかどうか、確認してみよう。

```{r}
SuicidePrevention$age_group
```

また、`as.logical` を使用して論理値を作成することも可能である。例えば、 `pubyear` 列を再コード化し、2009年以降に発表された研究のみを表示するようにしたいとしよう。これを行うには、コードでイエス/ノーのルールを定義する必要がある。「以上」演算子 `>=` を使用し、`as.logical` 関数の入力として使用する。

```{r}
SuicidePrevention$pubyear
as.logical(SuicidePrevention$pubyear >= 2010)
```

これは `pubyear` の各要素を、出版年が2010年以上かそうでないかによって `TRUE` または `FALSE` としてエンコードしていることがわかる。

<br></br>

### データのスライス {#data-slicing}

---

_R_ では、データフレームの部分集合を抽出する方法がいくつかある。そのうちのひとつである `$` 演算子を使って列を抽出する方法についてすでに説明した。データセットからスライスを抽出する、より一般的な方法は、角括弧を使用することである。角括弧を使用する一般的な形式は、 `data.frame[rows, columns]` である。行と列は、データセットに現れる番号を使って抽出することができる。例えば、データフレームの2行目のデータを取り出すには、以下のようなコードを使用する。

```{r}
SuicidePrevention[2,]
```

さらに具体的に、2行目の1列目の情報だけが欲しいと _R_ に伝えることが可能である。

```{r}
SuicidePrevention[2, 1]
```

特定のスライスを選択するには、再び concatenate (`c`) 関数を使用する必要がある。たとえば、2行目と3行目、および4列目と6列目を抽出したい場合は、次のようなコードを使用する。

```{r}
SuicidePrevention[c(2,3), c(4,6)]
```


通常、行は番号によってのみ選択することができる。しかし、列の場合は、番号の代わりに列の**名前**を指定することも可能である。

```{r}
SuicidePrevention[, c("author", "control")]
```

別の方法として、行の値に基づいてデータセットに**フィルタ**を行うこともできる。これを行うには、関数 `filter` を使用する。この関数では、データセット名とフィルタ条件を指定する必要がある。比較的簡単な例として、`n.e` が50以下である研究をすべてフィルタしてみよう。

```{r}
filter(SuicidePrevention, n.e <= 50)
```

名前によるフィルタも可能である。例えば、著者である **Meijer** と **Zaytsev** による研究を抽出したいとする。そのためには、`%in%`演算子と concatenate 関数を用いて、フィルタ条件を定義する必要がある。

```{r}
filter(SuicidePrevention, author %in% c("Meijer et al.",
                                        "Zaytsev et al."))
```

逆に、フィルタの論理式の前に感嘆符（`!`）をつけることで、**Meijer** と **Zaytsev** による研究を**除く**すべての研究を抽出することも可能である。

```{r, eval=F}
filter(SuicidePrevention, !author %in% c("Meijer et al.", 
                                         "Zaytsev et al."))
```


<br></br>

### データ変換 {#data-transform}

---

もちろん、 _R_ のデータフレーム内の特定の値を変更したり、拡張したりすることも可能である。 _R_ で内部保存したデータを変更するには、**代入演算子**を使用する必要がある。以前、データスライスについて学んだことを再利用して、データセットの特定の値を変更することにしよう。私たちが間違いを犯し、**DeVries et al.** による研究の出版年が、2018であるべきところを2019と誤って報告されたとする。データセットを適宜スライスし、新しい値を割り当てることで、値を変更することが可能である。**DeVries et al.** の結果は、データセットの2行目に報告されていることを忘れないように。

```{r, eval=F}
SuicidePrevention[2, "pubyear"] <- 2018
SuicidePrevention[2, "pubyear"]
```
```
## [1] 2018
```

また、一度に複数の値を変更することもできる。例えば、データセットのすべての介入グループの平均に5を加えたい場合、次のコードで可能である。

```{r}
SuicidePrevention$mean.e + 5
```

また、2つ以上の列を使用して計算を行うこともできる。実用的な例としては、各研究の介入群の平均と対照群の平均の**平均差** (mean difference) を計算したいとする。他のプログラミング言語と比較すると、 _R_ では、これは驚くほど簡単である。

```{r}
SuicidePrevention$mean.e - SuicidePrevention$mean.c
```

今見たように、これは各研究の介入群の平均から対照群の平均を引くが、毎回同じ行の値を使用する。この平均差 (**m**ean **d**ifference) を後で利用することにしよう。そこで、これを `md` というオブジェクトとして保存し、 `SuicidePrevention` データフレームに新しい列として追加したいと思ったとする。どちらも代入演算子を使えば簡単にできる。

```{r}
md <- SuicidePrevention$mean.e - SuicidePrevention$mean.c

SuicidePrevention$md <- SuicidePrevention$mean.e - 
                            SuicidePrevention$mean.c
```

\index{Pipe, _R_ }

最後に紹介するのは、**パイプ演算子**である。 _R_ では、パイプは `%>%` と表記される（訳注: R 4.2 から、`|>` というパイプも導入された）。パイプを使うと、関数を呼び出す際にオブジェクト名を直接指定することなく、オブジェクトに関数を適用することが可能である。単に、オブジェクトと関数をパイプ演算子でつなげるだけである。簡単な例を挙げてみよう。対照群のサンプル数の平均を計算したい場合、`mean` 関数とパイプ演算子を次のように使用する。

```{r}
SuicidePrevention$n.c %>% mean()
```

この例では、パイプの価値を見ることは困難である。パイプの特別な強みは、多くの関数を**連結**することができる点にある。例えば、2009年以降に発表された研究のみを対象として、対照群サンプルサイズの平均値の平方根を知りたいとする。パイプを使えば、これを1ステップで簡単に行うことが可能である。

```{r}
SuicidePrevention %>% 
  filter(pubyear > 2009) %>% 
  pull(n.c) %>% 
  mean() %>% 
  sqrt()
```

パイプの中では、これまで取り上げていない関数として、`pull` 関数を使った。この関数は、パイプで使用できる `$` 演算子と同等と見なすことができる。この関数は、関数内で指定した変数を単に「引き出す」だけで、パイプの次の部分に送り込むことが可能である。

```{block, type='boxinfo'}
**_R_ のドキュメントにアクセス**

\vspace{2mm}

_R_ の多くの関数は複数の引数を必要とし、全ての関数の使い方を正しく記憶することは不可能である。ありがたいことに、各関数の使い方を丸暗記する必要はない。R Studio では、 _R_ のドキュメントに簡単にアクセスでき、各関数には詳細な説明ページが用意されている。

関数のドキュメントページを検索するには、2つの方法がある。一つは、R Studio の左下（訳注：「右下」にあることの方が多い。）にある **Help** ペインにアクセスし、検索バーを使って特定の関数に関する情報を見つける方法である。もっと便利な方法は、コンソールで `?` の後に関数名をつけて、例えば `?mean` のように実行することである。これで自動的にこの関数のドキュメントのエントリーが開かれる。

関数の _R_ ドキュメントには通常、少なくとも**使用法** (Usage)、**引数** (Arguments)、**例** (Examples) のセクションがある。特に、**引数**と**例**のセクションは、関数がどのように使用されるかを理解するのに役立つことが多いだろう。
```

<br></br>

### データの保存 {#saving-data}

---

データを変換して _R_ に内部保存した後、ある時点で**エクスポート**する必要がある。 _R_ のデータフレームを保存する際には、2種類のファイル形式を使用することをお勧めする。 _.rda_ と _.csv_ である。

ファイルの末尾 _.rda_ は、 _R_ **Data** の略である。これは _R_ 専用のファイル タイプで、すべての利点と欠点がある。 _.rda_ ファイルの利点は、 _R_ で簡単に再オープンできることと、エクスポート中にデータが歪む心配がないことである。また、汎用性が高く、表計算ソフトの形式に収まらないデータも保存可能である。欠点は、 _R_ でしか開けないことであるが、プロジェクトによっては、これで十分である。

オブジェクトを _.rda_ データファイルとして保存するには、 `save` 関数を使用する。この関数では、(1) オブジェクトの名前、(2) ファイルの末尾を含めた**正確な**ファイル名、を指定する必要がある。この関数を実行すると、ファイルが作業ディレクトリに保存される。

```{r, eval=F}
save(SuicidePrevention, file = "suicideprevention.rda")
```

ファイルの末尾 _.csv_ は **comma-separated values** の略である。この形式は、一般的なデータで最もよく使用されるものの1つである。これは、_Excel_を含む多くのプログラムで開くことが可能である。データを _.csv_ として保存するには、 `write.csv` 関数を使用する。コードの構成や動作は `save` とほぼ同じであるが、提供するオブジェクトはデータフレームなどの表形式データオブジェクトである**必要**がある。そしてもちろん、ファイルタイプは ".csv" を指定する必要がある。

```{r, eval=F}
write.csv(SuicidePrevention, file = "suicideprevention.csv")
```

ここでは、 _R_ におけるデータ操作の戦略について簡単に説明する。特に、データの操作のように簡単だと思われるものを扱う場合、 _R_ をゼロから学ぶのは疲れることがある。しかし、 _R_  の動作に慣れるには、練習するのが一番である。しばらくすると、 _R_ の一般的なコマンドは自然に使えるようになる。

学習を続けるには、Hadley Wickham and Garrett Grolemund の著書 **R for Data Science** [-@wickham2016r] に目を通しておくとよいだろう。このガイドと同様に、この本もオンラインで完全に[無料](https://r4ds.had.co.nz/transform.html)で読むことが可能である 。さらに、次のページでいくつかの演習も集めたので、ここで学んだことを実践するために使うことを勧める。

$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block, type='boxquestion'}
**データ操作の演習**

\vspace{2mm}


この演習では、`data` という新しいデータセットを使用する。このデータセットは、以下のコードを使って _R_ で直接作成することが可能である。



```{r}
data <- data.frame("Author" = c("Jones", "Goldman", 
                                "Townsend", "Martin", 
                                "Rose"),
                   "TE" = c(0.23, 0.56, 
                            0.78, 0.23, 
                            0.33),
                  "seTE" = c(0.324, 0.235, 
                             0.394, 0.275, 
                             0.348),
                  "subgroup" = c("one", "one", 
                                 "two", "two", 
                                 "three"))
```


```{block, type="boxempty"}

このデータセットの演習を紹介する。

1. 変数 `Author` を表示しなさい。

\vspace{-2mm}

2. `subgroup` を因子型 (factor) に変換しなさい。

\vspace{-2mm}

3. "Jones" と "Martin" の研究のデータをすべて選択しなさい。

\vspace{-2mm}

4. 研究名 "Rose" を "Bloom" に変更しなさい。

\vspace{-2mm}

5. `TE` から `seTE` を引いて、新しい変数 `TE_seTE_diff` を作成し、結果を `data` に保存しなさい。

\vspace{-2mm}

6. パイプを使用して、(1) `subgroup` が"one" または "two" に属するすべての研究をフィルタし、(2) 変数 `TE_seTE_diff` を選択し、(3) その変数の平均をとり、それに `exp` 関数を適用しなさい。 _R_ のドキュメントにアクセスして、`exp` 関数が何をするのか調べてみなさい。

\vspace{4mm}

**問題の解答は、本書の巻末 [Appendix A](#qanda2) にある。**

```


<br></br>

## 概要

* _R_ は、世界で最も強力かつ頻繁に使用される統計プログラミング言語の1つとなっている。

* _R_ は、グラフィカル・ユーザー・インターフェースとあらかじめ定義された機能を持つコンピュータ・プログラムではない。世界中の人々が自由に利用できるアドオン、いわゆる**パッケージ**を提供できる完全なプログラミング言語である。

* R Studio は、 _R_ を使った統計解析を便利に行うためのコンピュータ・プログラムである。

* _R_ の基本的な構成要素は関数である。これらの関数の多くは、インターネットからインストールできるパッケージを通じてインポートすることが可能である。

* _R_ を使ったデータの取り込み、操作、解析、保存に関数を使用することが可能である。


<!--chapter:end:04-discovering_R-ja.Rmd-->

# (PART) Rでメタ分析 {-}

# 効果量 {#effects}

---

<img src="_figs/effect_sizes.jpg" />

<br></br>

<span class="firstcharacter">前</span>
章では、 _R_ の世界に慣れ親しみ、データのインポートと操作に役立ついくつかのツールを学んだ。本書の第 2 部では、 _R_ の知識を応用して拡張しながら、メタ分析で使用される主要な統計技術について学習していこう。

\index{Mean, Arithmetic}\index{平均, 算術}

Chapter \@ref(what-are-mas) では、メタ分析を「複数の研究から得られた定量的な結果を要約する手法」と定義した。メタ分析では、個人ではなく研究が分析の基本単位となる。

これは新たな問題を引き起こす。一次研究において、収集したデータを記述するための**要約統計**を計算することは、通常、非常に簡単である。例えば一次研究では、連続変数アウトカムの**算術平均** (arithmetic mean) $\bar{x}$ と**標準偏差** (standard deviation) $s$ を計算するのは、非常によくある手法である。

しかし、これが可能なのは、通常、一次研究において本質的な前提条件が満たされているからである。私たちは、アウトカム変数がすべての研究対象者において**同じ方法で測定された**ことを知っている。メタ分析では、この前提は通常満たされていない。中学校 2年の数学のスキルをアウトカムとするメタ分析を実施したいと想像してみよう。厳密な包括基準を適用したとしても（Chapter \@ref(research-question) 参照）、すべての研究がまったく同じテストを使って数学のスキルを測定しているとは限らない。また、テストの合格・不合格の割合だけを報告している研究もあるかもしれない。このため、アウトカムを直接定量的に統合することは事実上不可能である。

メタ分析を行うには、すべての研究にわたって要約される**効果量** (effect size) を見つけなければならない。そのような効果量は、論文から直接抽出できることもあるが、多くの場合、研究で報告された他のデータから計算する必要がある。効果量の計量は、メタ分析の結果およびその解釈可能性に大きな影響を与える可能性がある。そのため、重要な基準を満たす必要がある [@lipsey2001practical; @higgins2019cochrane]。特に、メタ分析で選択される効果量指標は、以下のようなものであるべきである。

* **比較できる** (Comparable). 効果量の測定は、すべての研究において同じ意味を持つことが重要である。再び数学のスキルを例にとってみよう。異なるテストを使用した研究において、数学のテストで達成した点数における実験群と対照群の差をプールすることは意味がない。例えば、テストは難易度や達成できる最大点数が異なる場合がある。

* **計算できる** (Computable). 効果量の指標は、主要な研究からその数値を導き出すことが可能である場合のみ、メタ分析に使用することが可能である。含まれるすべての研究のデータに基づいて、効果量を計算することが可能でなければならない。

* **信頼できる** (Reliable).  たとえ含まれるすべての研究の効果量を計算できたとしても、それらを統計的に**プール**することもできなければならない。メタ分析で何らかの指標を用いるには、少なくとも**標準誤差**（次章参照）を算出できなければならない。また、効果量の形式が、適用したいメタ分析手法に適しており、推定値に誤差やバイアスが生じないことも重要である。

* **解釈できる** (Interpretable). 効果量の種類は、リサーチクエスチョンに答えるために適切でなければならない。例えば、2つの連続変数間の関連性の強さに関心がある場合、効果の大きさを表すには相関を用いるのが一般的である。相関の大きさを解釈するのは比較的簡単で、多くの研究者が理解することが可能である。しかし、この後の章では、解釈しやすく、かつ統計計算に最適な結果指標を用いることができない場合があることを学びる。このような場合、効果量をプールする前に、より良い数学的特性を持つ形式に変換する必要がある。

「効果量」という言葉は、すでにどこかで目にしたことがあるのではないだろうか。私たちも、この言葉が何を表しているのか、あまり気にせずに使ってきた。そこで、次節では、「効果量」という言葉が実際に何を意味しているのかを探ってみたい。

<br></br>

## 効果量とは何か？ {#what-is-es}

---

本書で使用する用語では、効果量は2つの実体の間の関係を定量化する指標と定義される。これは、この関係の**方向**と**大きさ**を捉えたものである。関係性が同じ効果量として表現されていれば、それらを比較することが可能である。

\index{Correlation}\index{相関}\index{相関}\index{相関}\index{相関}
\index{Standardized Mean Difference}\index{標準化平均差}

ここで強調したいのは、これは効果量の意味を定義するための**1つ**の方法に過ぎないということである。効果量の定義には幅があり、人によって使い方が異なる [@borenstein2011introduction, chapter 3]。研究者の中には、介入研究の結果に言及する際にのみ効果量を語る人もおり、それは治療群と対照群の差として表現される（Chapter \@ref(s-md) 参照）。この概念では、「効果量」とは、ある治療の効果とその大きさを指す。

我々の考えでは、これはかなり狭い定義である。治療が何らかの変数に影響を与えるだけでなく、人間が直接介入しなくても、効果は**自然に**現れることもある。例えば、親の収入や親の教育などの社会人口統計学的変数が、その子どもの教育達成度に影響を与える可能性がある。相関は、ある変数の値から別の変数の値をどれだけ予測できるかを記述し、効果量の一形態として見ることもできる。

逆に、メタ分析としてプールできるものはすべて自動的に効果量になる、というのは行き過ぎかもしれない。これから学ぶように、サンプル平均のような**中心的傾向**の指標はメタ分析に用いることが可能だが、これだけでは2つの現象の関係を定量化することはできず、「効果」は存在しない。とはいえ、本書では、実際の効果の推定値だけでなく、「一変数」や「中心傾向」の指標も表す、**全体を代表する部分** (pars pro toto) として、「効果量」という言葉をよく使う。これは正確だからではなく、その方が便利だからである。

また、「効果量」という言葉を全面的に否定する人もいる。その主張は、「効果量」の「効果」という言葉が、**因果関係**があることを示唆していると強調しているためである。しかし、私たちは皆、**相関は因果関係ではない**ことを知っており、介入群と対照群の差が自動的に治療そのものを原因とするものであってはならない。最終的にどちらの定義を好むかは使う人次第であるが、効果量について話すとき、人々は異なる概念を持っているかもしれないことを意識する必要がある。

\index{Sampling Error}\index{サンプル誤差}

数学の表記法では、**真の**効果量を表す記号としてギリシャ文字の**シータ**（$\theta$）を用いるのが一般的である^[本書では、効果量を議論する際に Schwarzer ら[-@schwarzer2015meta]が用いた表記法をほぼ踏襲した]。より正確には、 $\theta_k$ は研究 $k$ の真の効果量を表している。真の効果量は、公表された研究アウトカムに見られる**観察された効果量**と**同一ではない**という点は重要である。観測された効果量は、真の効果量の**推定値**に過ぎない。私たちが言及する実体が推定値に過ぎないことを明確にするために、**ハット** (^) の記号を使用するのが一般的である。したがって、真の効果量の推定値である $k$ 試験で観測された効果量は、$\hat\theta_k$ （「シータ・ハット・k」と読む）と書くことが可能となる。

しかし、なぜ $\hat\theta_k$ と $\theta_k$  は異なるのだろうか？それは、**サンプル誤差**のためで、 $\epsilon_k$ （「イプシロン・k」と読む）として記号化できる。どのような一次調査でも、研究者は母集団全体から小さなサンプルしか抽出することができない。例えば、プライマリケア患者の心臓血管の健康に対する定期的な運動の効果を調べたい場合、世界中のプライマリケア患者すべてではなく、ごく一部の患者を対象とすることが可能である。無限に大きな母集団から小さなサンプルしか取れないということは、観察された効果が真の母集団効果とは異なることを意味する。

つまり、 $\hat\theta_k$ は $\theta_k$ にサンプル誤差 $\epsilon_k$  を加えたものと同じになる^[観測された効果量が真の効果量とサンプル誤差以上に異なることもよくある。例えば、研究の方法論におけるバイアスや測定誤差である。この点については、Chapter \@ref(es-correction) で詳しく説明する。]。

\begin{align}
\hat\theta_k = \theta_k + \epsilon_k
(\#eq:es1)
\end{align}

研究 $k$ の効果量推定値 $\hat\theta_k$ が真の効果量にできるだけ近く、かつ $\epsilon_k$ が最小であることが望ましいのは明らかである。すべての条件が同じであれば、$\epsilon$ が小さい研究ほど、真の効果量の**正確な**推定値を提供すると考えることが可能である。メタ分析の手法では、効果量の推定値の精度を考慮する（Chapter \@ref(pooling-es) 参照）。異なる研究の結果をプールする場合、精度が高い（サンプル誤差が少ない）効果ほど、真の効果量の推定精度が高いため、高いウェイトを与える [@hedges2014statistical]。

しかし、サンプル誤差の大きさはどのようにして知ることができるのだろうか。当然のことながら、研究の真の効果は $\theta_k$ なので、$\epsilon_k$ も不明である。しかし、多くの場合、統計理論を使ってサンプル誤差を近似的に求めることが可能である。一般に、$\epsilon$ を定量化する方法として、**標準誤差**（$SE$）がある。標準誤差は、**サンプル分布**の標準偏差として定義される。サンプル分布とは、母集団から同じサンプルサイズ $n$ のサンプルを**多数回**無作為に抽出したときに得られる指標の分布のことである。

_R_ でデータをシミュレートすることによって、これをより具体的に見てみよう。`rnorm` 関数を使って、より大きな母集団から無作為にサンプルを抽出しているようにしてみたい。この関数名は、正規 (**norm**al) 分布から 無作為 (**r**andom)  サンプルを作成することからきている。`rnorm` 関数は、真の母集団で値がどのように分布しているかを**知っている**という「完璧な世界」をシミュレートし、サンプルを取ることを可能にする。

この関数は、以下の3つの引数を取る。すなわち、`n`: サンプルとして取得したい観測数、 `mean`: 母集団の**真の**平均値、 `sd`: **真の**標準偏差である。`rnorm` 関数は乱数要素を持っているので、結果を再現するために、まず **seed** を設定する必要がある。これは `set.seed` 関数で行うことができるが、数値を指定する必要がある。この例では、`123` を seed に設定する。さらに、母集団の真の平均は $\mu =$ 10、真の標準偏差は $\sigma =$ 2、サンプルは $n=$ 50のランダムに選んだ観測からなり、これを `sample` という名前で保存するシミュレーションをしたい。

このようなコードになる。

```{r}
set.seed(123)
sample <- rnorm(n = 50, mean = 10, sd = 2)
```

さて、サンプルの平均を計算することが可能である。

```{r}
mean(sample)
```


\index{Central Limit Theorem}\index{中心極限定理}

平均は $\bar{x} =$ 10.07 であり、すでに母集団における真の値に非常に近いことがわかる。ここでやったことを繰り返すと、サンプル分布ができあがる。このプロセスをシミュレートするために、先ほどのステップを 1000 回実行する。

その結果を Figure \@ref(fig:samplingdist) のヒストグラムに示す。サンプルの平均は、平均が 10 の正規分布に近いことがわかる。さらに多くのサンプルを抽出すれば、平均の分布はさらに正規分布に近くなる。この考え方は、統計学の最も基本的な考え方の1つである「**中心極限定理**」 [@aronow2019foundations, chapter 3.2.4] で表現されている。

```{r samplingdist, fig.cap='平均値の「サンプル分布」（1000 件のサンプル）。', warning=F, message=F, echo=F, out.width='70%', fig.align='center'}

library(magrittr)
set.seed(123)
res = list()
for (i in 1:1000){
  x = rnorm(50, 10, 2)
  c(mean(x), sd(x)) -> res[[i]]
}

do.call(rbind, res) %>% as.data.frame() %>% 
  set_colnames(c("mu", "sigma")) -> res_1000

par(bg="#FFFEFA")
hist(res_1000$mu, breaks = 25,
     main = "",
     xlab = "Calculated Mean")

```

標準誤差はこのサンプル分布の標準偏差と定義される。そこで、標準誤差の近似値を得るために、1000 個の模擬平均の標準偏差を計算しておいた。その結果、$SE =$ 0.267 となる。

前にも述べたように、現実世界ではサンプル分布をシミュレーションして標準誤差を計算することはできない。しかし、統計理論に基づいた公式があるので、観測されたサンプルが1つしかない（通常の）場合でも、標準誤差の推定値を計算することが可能である）。**平均値**の標準誤差を計算する公式は次のように定義されている。

\begin{align}
SE = \frac{s}{\sqrt{n}}
(\#eq:es2)
\end{align}

つまり、サンプル $s$ の標準偏差をサンプルサイズ $n$ の平方根で割ったものを標準誤差と定義している。この式を使って、 _R_ を使う前に作った `sample` オブジェクトの標準誤差を簡単に計算することが可能である。ランダムサンプルのサイズは $n =$ 50 であったことを思い出す。

```{r}
sd(sample)/sqrt(50)
```

この値をサンプル分布のシミュレーションで求めた値と比較すると、ほぼ同じであることがわかる。この公式を使えば、手持ちのサンプルだけで、かなり正確に標準誤差を推定することができるのである。

式3.2から、平均値の標準誤差は研究のサンプルサイズに依存することがわかる。$n$ が大きくなると標準誤差は小さくなり、真の母平均の推定値がより正確になることを意味している。

この関係を説明するために、別のシミュレーションを行おう。ここでも、`rnorm` 関数を使用し、母集団の平均を $\mu =$ 10、$\sigma =$ 2 とする。しかし、今回は、$n =$ 2から $n =$ 500まで、サンプルサイズを変化させる。各シミュレーションについて、式3.2を用いて、平均と標準誤差を計算する。

```{r simulse, fig.cap = 'サンプルサイズの関数としてのサンプル平均とサンプル誤差。', message=F, echo=F, fig.height=2.5}
library(ggplot2)
library(gridExtra)

load("data/simul_SE.rda")

plotdat_mean = data.frame(x = 2:500,
                          y = resul$mean)

plotdat_se = data.frame(x = 2:500,
                          y = resul$se)


ggplot(data = plotdat_mean, aes(x = x, y = y)) +
  geom_smooth(method = "gam", se = F, color = "black", 
              linetype = "dotted", size = 0.5) +
  geom_line(color = "gray39") +
  scale_color_grey() +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#FFFEFA",
                                        size = 0),
        plot.background = element_rect(fill = "#FFFEFA",
                                       size = 0)) +
  ylab("Mean") +
  xlab("Sample Size") -> p1

ggplot(data = plotdat_se[2:499,], aes(x = x, y = y)) +
  geom_smooth(method = "gam", se = F, color = "black", 
              linetype = "dotted", size = 0.5) +
  geom_line(color = "gray39") +
  scale_color_grey() +
  theme_minimal() +
  theme(panel.background = element_rect(fill = "#FFFEFA",
                                        size = 0),
        plot.background = element_rect(fill = "#FFFEFA",
                                       size = 0)) +
  ylab("Standard Error") +
  xlab("Sample Size") -> p2

grid.arrange(p1, p2, nrow=1)



```

その結果を Figure \@ref(fig:simulse) に示す。サンプルサイズが大きくなるにつれて、平均値の推定値はどんどん正確になっていき、10に向かって収束していく。この精度の向上は標準誤差で表される。サンプルサイズが大きくなると、標準誤差はどんどん小さくなっていく。

ここまで、メタ分析を行うために必要な要素、すなわち、（１）観察された効果量またはアウトカム指標、および（２）標準誤差として表されるその精度について探ってきた。発表された研究からこの2つの情報を算出することができれば、通常はメタ分析合成を行うことも可能である（Chapter \@ref(pooling-es) 参照）。

シミュレーションでは、例として変数の平均を使用した。上で見た特性は、よく使われる効果量など、他のアウトカム指標でも見られることを理解することが重要である。もし、平均ではなく、サンプルの平均**差**を計算したとすると、この平均差は、同じような形のサンプル分布を示し、平均差の標準誤差もサンプルサイズが大きくなると小さくなる（標準偏差が同じであることが条件）。例えば、（Fisher's $z$ 変換された）相関関係についても同様である。

以下のセクションでは、メタ分析で最も一般的に使用される効果量とアウトカム指標について説明する。これらの効果量測定がよく使われる理由の1つは、本章の最初に定義した2つの基準、すなわち、**信頼できる**、**計算できる**を満たしているからである。

式3.2で平均値の標準誤差を計算する方法を説明したが、この式は**平均値**に**のみ**容易に適用することができる。他の効果量やアウトカム指標では、標準誤差を計算するための異なる公式が必要である。ここで取り上げる効果量の測定基準については、幸いにも公式が存在するので、それらをすべて紹介していこう。公式のコレクションは、[Appendix](#formula)でも見ることが可能である。公式の中にはやや複雑なものもあるが、標準誤差を手動で計算する必要はほとんどない。 _R_ は、この大変な計算を代行してくれる様々な関数がある。

以下のセクションでは、様々な効果量の測定基準についての理論的な議論を提供するだけではない。後で使用する _R_ メタ分析関数が効果量を簡単に計算できるように、データセットにどのような情報を用意しなければならないかも紹介する。

研究デザインの種類ごとに、通常現れる効果量をグループ分けしよう。すなわち、**単群デザイン**（例：自然主義研究、調査、非対照試験）、**対照群デザイン**（例：実験研究、対照臨床試験）である。これはあくまで大まかな分類であり、厳密なルールではないことに注意したい。ここで提示する効果量の多くは、アウトカムデータの種類が適切であれば、技術的にはどのようなタイプの研究デザインにも適用可能である。

<br></br>

## 単群デザインにおける測定値と効果量 {#single-group-es}

---

### 平均値 {#means}

---


\index{Mean, Arithmetic}\index{平均, 算術}

**算術平均**は、おそらく最もよく使われる中心的傾向の尺度である。平均がアウトカム指標として使われることはあまりないが、メタ分析では簡単にプールすることが可能である。例えば、男性の平均身長をセンチメートルやインチで表現し、いくつかの代表的な研究をプールして調査することが可能である。

算術平均は、サンプル中の個々の値 $x_i$ をすべて合計し、その合計をサンプルサイズで割ったものである。



\begin{equation}
\bar{x} = \frac{\sum^{n}_{i=1}x_i}{n}
(\#eq:es3)
\end{equation}

平均の標準誤差の求め方は、すでに説明した（Chapter \@ref(what-is-es) 参照）。サンプルの標準偏差 $s$ をサンプルサイズの平方根で割ればいいだけである。


\begin{equation}
SE_{\bar{x}} = \frac{s}{\sqrt{n}}
(\#eq:es4)
\end{equation}

先に見たように、 _R_ では平均とその標準誤差を簡単に計算することが可能である。

```{r}
# 再現性のために123のシードを設定する
# そして、無作為にサンプルを取る (n=50)
set.seed(123)
sample <- rnorm(n = 50, mean = 20, sd = 5)

# 平均値を計算する
mean(sample)

# 標準誤差を計算する
sd(sample)/sqrt(50)

```

平均値のメタ分析を行うには、データセットに少なくとも以下の列が含まれている必要がある。

* **`n`**. 研究の観測数（サンプルサイズ）。
* **`mean`**. 研究で報告された平均値。
* **`sd`**. 研究で報告された変数の標準偏差。


<br></br>

### 割合 {#props}

---

\index{Proportion}\index{割合}

**割合** (proportion) は、もう一つの中心傾向測定タイプである。これは、サンプルの何件が特定のサブグループに分類されるかを指定する。割合は、0から1の値を取ることができ、100を掛けることで**パーセント**に変換することが可能である。割合は、例えば、ある時点の病気の有病率を調べたいときに、アウトカム指標として使われることがある。割合 $p$ を計算するためには、特定のサブグループに属する個人の数 $k$ を全サンプルサイズ $n$ で割る必要がある。



\begin{equation}
p = \frac{k}{n}
(\#eq:es5)
\end{equation}

割合の標準誤差は、このように計算することができる。

\begin{equation}
SE_{p} = \sqrt{\frac{p(1-p)}{n}}
(\#eq:es6)
\end{equation}

このコードを使って、 _R_ の割合とその標準誤差を計算することが可能である。

```{r}
# k と n に以下の値を定義する。
k <- 25
n <- 125

# 割合を計算する
p <- k/n
p

# 標準誤差を計算する
sqrt((p*(1-p))/n)

```

\index{Odds}\index{オッズ}
\index{Logit-Transformation}\index{Logit-変換}
\index{Logarithm, Natural}\index{対数, 自然}

割合の範囲が 0 と 1 の間に制限されていることが問題になることがある [@lipsey2001practical, chapter 3]。$p$ が 0 に近いか 1 に近いと、標準誤差が人為的に圧縮され、割合の推定値の精度が過大評価されることになる。

これは、サンプル分布と関係がある。$p$ の値が非常に小さい、または非常に大きい場合、サンプル分布は Figure \@ref(fig:samplingdist) のような正規分布にまずならない。0-1の範囲外の計算された割合を持つランダムなサンプルは不可能であるため、分布は**右側に裾が伸びる** (right-skewed) か、または**左側に裾が伸びる** (left-skewed)。

これを避けるために、割合をプールする前に **logit** 変換するのが一般的である。logit 変換では、まず**オッズ**を計算する（Chapter \@ref(or) 参照）。オッズは、特定のカテゴリーに該当する参加者の割合を、そのカテゴリーに該当しない参加者の割合で割ったものとして定義される。

そして、自然対数関数 $\log_e$ を使って、オッズを $p=$ 0.5 が値0に等しく、かつ範囲制限のない形式に変換している。これにより、サンプル分布がほぼ正規分布となり、標準誤差にバイアスがないことが確認できる。

logit 変換された割合とその標準誤差の計算は以下の式でできる [@lipsey2001practical, chapter 3]^[logit-割合を元の尺度に戻すには、以下の式を使えば良い。$p=\frac{\exp(p_{\text{logit}})}{1+\exp(p_{\text{logit}})}$。ここで $\exp$ は _R_ の `exp` で実装された**指数関数**である （Chapter \@ref(ppoolbin) 参照）。]:


\begin{equation}
p_{\text{logit}} = \log_{e} \left(\frac{p}{1-p}\right)
(\#eq:es7)
\end{equation}


\begin{equation}
SE_{p_{\text{logit}}} = \sqrt{\frac{1}{np}+\frac{1}{n(1-p)}}
(\#eq:es8)
\end{equation}

幸い、 _R_ のメタ分析機能を使えば、この logit 変換を自動的に行ってくれる。そのため、データセットには以下の列を用意するだけでよい。

* **`event`**. 特定のサブグループ ($k$) に含まれる観測数。
* **`n`**. サンプルサイズの合計 $n$.

<br></br>

### 相関関係 {#cors}

---

#### ピアソン積率相関 {#pearson-cors}

---

\index{Correlation}\index{相関}\index{相関}\index{相関}\index{相関}
\index{History of Meta-Analysis}\index{メタ分析の歴史}

相関とは、2つの変数間の**共分散**の大きさを表す効果量である。最も一般的なのは、2つの連続変数に対して計算できる**ピアソン積率相関** (Pearson Product-Moment Correlation)^[この相関は、メタ分析の歴史にも関わる有名な統計学者 Karl Pearson（Chapter \@ref(history) 参照）から名付けられた]であり、この積率相関は、例えば、メタ分析の研究者が2つの変数の間の**共分散**の量を表す効果量として用いることが可能である。積率相関は、例えば、メタ分析で関係の質と幸福度の関係を調べたいときに、効果量として使うことができる。

変数 $x$ と変数 $y$ の相関 $r_{xy}$ は、$x$ と $y$ の **共分散** $\text{Cov}(x,y)=\sigma^{2}_{xy}$ を、それらの標準偏差$\sigma_x$ と $\sigma_y$ の**積** で割ったもので定義される。


\begin{equation}
r_{xy} = \frac{\sigma^{2}_{xy}}{\sigma_x \sigma_y}
(\#eq:es9)
\end{equation}

サンプルサイズ $n$ を用いると、$r_{xy}$ の標準誤差は次のように計算できる。


\begin{equation}
SE_{r_{xy}} = \frac{1-r_{xy}^2}{\sqrt{n-2}}
(\#eq:es10)
\end{equation}

積率相関を計算するとき、2つの変数の間の共変動をそれらの標準偏差で標準化する。つまり、2つ以上の研究が同じ尺度で構成要素を測定していれば、あまり意味がなく、相関を計算すれば、自動的に効果を比較することが可能になる。

相関は -1 ～ 1 の値をとる。相関の大きさは、しばしば Cohen  [-@cohen1988statistical] の慣例を用いて解釈される。

* $r \approx$ 0.10: 小さい効果。
* $r \approx$ 0.30: 中程度の効果。
* $r \approx$ 0.50: 大きい効果。

しかし、これらの慣例はあくまで経験則であることに留意すべきである。対象や先行研究に応じて、相関の大小を定量化する方がはるかに良い場合が多いのである。

\index{Fisher's \textit{z}}
\index{History of Meta-Analysis}\index{メタ分析の歴史}

残念ながら、相関は割合（Chapter \@ref(props)） と同様に範囲が限定されており、サンプルサイズの小さい研究に対して標準誤差を推定する際にバイアスをもたらす可能性がある [@alexander1989statistical]。

そのため、メタ分析では相関を **Fisher's** $z$^[Fisher's $z$ は、Chapter \@ref(history) で紹介した有名な統計学者 Ronald A. Fisher にちなんで名づけられた] に変換することが一般的である。これも logit 変換と同様に、サンプル分布がほぼ正規分布になるように自然対数関数を用いる（詳しい説明は、Chapter \@ref(ratios) を参照）。式は次のようになる。


\begin{equation}
z = 0.5\log_{e}\left(\frac{1+r}{1-r}\right)
(\#eq:es11)
\end{equation}

サンプルサイズ $n$ がわかれば、Fisher's $z$ の近似標準誤差はこの式で求めることができる [@olkin1995correlations]。


\begin{equation}
SE_{z} = \frac{1}{\sqrt{n-3}}
(\#eq:es12)
\end{equation}

また、 _R_ では `cor` と `log` 関数を用いて $r_{xy}$ と $z$ を直接計算することが可能である。

```{r}
# 2 つの連続変数 x と y をシミュレート
set.seed(12345)
x <- rnorm(20, 50, 10)
y <- rnorm(20, 10, 3)

# x と y の相関を計算する
r <- cor(x,y)
r

# Fisher's z を計算する
z <- 0.5*log((1+r)/(1-r))
z

```

ありがたいことに、 _R_ の相関のメタ分析を行う際に、Fisher's $z$ 変換を手動で行う必要はない。データセットに必要な列は以下の通りである。

* **`cor`**. ある研究の（変換されていない）相関係数。
* **`n`**. 研究のサンプルサイズ。

 
<br></br>

#### 点双列相関 {#pb-cors}

---

\index{Correlation}\index{相関}\index{相関}\index{相関}\index{相関}
\index{Correlation, Point-Biserial}\index{相関, 点双列}

ピアソン積率相関は、2つの連続変数間の関係を記述する。一方の変数 $y$ だけが連続的で、もう一方の変数 $x$ が二値的（つまり、2つの値だけをとる）な場合、$x$ のグループ・メンバーシップから $y$ がどれだけ予測できるかを表す**点双列相関** (point-biserial correlation) を計算することができる。

点双列相関は、この式で計算できる。


\begin{equation}
{r_{pb}}= \frac{(\bar{y_1}-\bar{y_2})\sqrt{p_1(1-p_1)}}{s_y}
(\#eq:es13)
\end{equation}

この式で、$\bar{y_1}$ は二項変数 $x$ の第1群のみを考えたときの連続変数の平均、$\bar{y_2}$ は $x$ の第2群のみを考えたときの平均、$p_1$ は $x$ の第1群に該当する症例の割合、$s_y$ は $y$ の標準偏差とする。

点双列相関は、 _R_ で `cor` 関数を使って計算することが可能である（前のセクションを参照する）。与えられた変数の1つが2つの値しかとらず、もう1つが連続的である場合、（近似的な）点双列相関が自動的に計算される。

\index{Standardized Mean Difference}\index{標準化平均差}

点双列相関は、後述する**標準化平均差**とよく似ている（Chapter \@ref(b-group-smd)）。どちらの効果量指標も、連続変数の値が2群間でどれだけ異なるかを定量化するものである。しかし、点双列相関がメタ分析でプールされることはあまり一般的ではない。積率相関と同様に、点双列相関は、群比率が不同の場合に範囲制限を受けるなど、メタ分析には好ましくない統計的性質を持っている [@bonett2019point]。

連続的なアウトカム変数の群間差に興味がある場合、メタ分析のために点双列相関を標準化平均差に変換することが推奨される [@lipsey2001practical, chapter 3]。点双列相関を標準化平均差に変換する公式は、本書の「各種ツール」の Chapter \@ref(convert-corr)  に掲載されている。

<br></br>

## 対照群デザインにおける効果量

---

### （標準化）平均差 {#s-md}

---

#### 群間平均差 {#b-group-md}

---

**群間平均差** (group between mean difference) $\text{MD}_{\text{between}}$ は、2つの **独立した** 群間の平均の未標準化の差として定義される。群間平均差は、対照試験や他のタイプの実験的研究で通常見られるように、研究が少なくとも2つの群を含んでいる場合に計算することが可能である。メタ分析では、すべての研究が全く同じ尺度でアウトカムを測定した場合のみ、平均値を使用することが可能である。例えば、体重は科学研究においてほぼ常にキログラムで測定され、糖尿病学では、HbA$_{\text{1c}}$値が血糖値の測定に一般的に使用される。

平均差は、グループ1の平均値 $\bar{x}_1$ からグループ2の平均値 $\bar{x}_2$ を引いた値と定義される。



\begin{equation}
\text{MD}_{\text{between}} = \bar{x}_1 - \bar{x}_2
(\#eq:es14)
\end{equation}

標準誤差は、この式で求めることができる。


\begin{equation}
SE_{\text{MD}_{\text{between}}} = s_{\text{pooled}}\sqrt{\frac{1}{n_1}+\frac{1}{n_2}}
(\#eq:es15)
\end{equation}

\index{Pooled Standard Deviation}

式中、$n_1$ はグループ1のサンプルサイズ、$n_2$ はグループ2のサンプルサイズ、$s_{\text{pooled}}$ は両群の**プール標準偏差** (pooled standard deviation) であることを表している。グループ1の標準偏差 ($s_1$) とグループ2の標準偏差 ($s_2$) を用いて、$s_{\text{pooled}}$ の値は以下のように計算することができる。


\begin{align}
s_{\text{pooled}} = \sqrt{\frac{(n_1-1)s^2_1+(n_2-1)s^2_2}{(n_1-1)+(n_2-1)}}
(\#eq:es16)
\end{align}

ここでは、 _R_ で平均差とその標準誤差を計算する例を示す。

```{r}
# 母平均が異なる2つの確率変数を生成する
set.seed(123)
x1 <- rnorm(n = 20, mean = 10, sd = 3)
x2 <- rnorm(n = 20, mean = 15, sd = 3)

# 数式に必要な値を計算する
s1 <- sd(x1)
s2 <- sd(x2)
n1 <- 20
n2 <- 20

# 差の平均を計算する
MD <- mean(x1) - mean(x2)
MD

# s_pooled を計算する
s_pooled <- sqrt(
  (((n1-1)*s1^2) + ((n2-1)*s2^2))/
    ((n1-1)+(n2-1))
)

# 標準誤差を計算する
se <- s_pooled*sqrt((1/n1)+(1/n2))
se

```

通常、これらの計算を手作業で行う必要はない。平均値の差のメタ分析では、データセットに以下の列を用意するだけでよい。

* **`n.e`**. 介入・実験群の観測数。
* **`mean.e`**. 介入・実験群の平均値。
* **`sd.e`**. 介入・実験群の標準偏差。
* **`n.c`**. 対照群の観測数。
* **`mean.c`**. 対照群の平均値。
* **`sd.c`**. 対照群の標準偏差。

<br></br>

#### 群間標準化平均差 {#b-group-smd}

---

\index{Standardized Mean Difference}\index{標準化平均差}
\index{Cohen's \textit{d}}

群間の標準化平均差 (standardized mean difference, SMD) $\text{SMD}_{\text{between}}$ は、プールした標準偏差 $s_{\text{pooled}}$ で標準化した、独立した2群間の平均値の差と定義される。文献では、標準化平均差は、心理学者で統計学者の Jacob Cohen にちなんで命名された **Cohen's** $d$ とも呼ばれる。

標準化されていない平均差とは対照的に、$\text{SMD}_{\text{between}}$ は2群間の差を**標準偏差の単位**で表現する。これは、2つのグループの生の平均差 $\bar{x_1}$ と $\bar{x_2}$ を、両グループのプール標準偏差 $s_{\text{pooled}}$ で割ることにより実現できる。


\begin{equation}
\text{SMD}_{\text{between}} = \frac{\bar{x}_1 - \bar{x}_2}{s_{\text{pooled}}}
(\#eq:es17)
\end{equation}

ここで、$s_{\text{pooled}}$ は、既に取り上げた式（3.16）を用いて計算する。メタ分析では標準化平均差の方が非標準化平均差よりもずっとよく使われる。これは、$\text{SMD}_{\text{between}}$ が研究間で比較できるためで、それぞれの研究が同じ測定器を使ってアウトカムを測定していなかったとしても、比較することが可能になる。

標準化によって、$\text{SMD}_{\text{between}}=$ 1 は常に2群の平均が互いに1サンプル標準偏差離れていることを意味し（Figure \@ref(fig:smd) 参照）、$\text{SMD}_{\text{between}}=$ 2 は2標準偏差の差を表す、という効果がある^[Kristoffer Magnusson は標準化平均差の値を変えて2群の分布を可視化する素晴らしいインタラクティブなツールを開発した。このツールはオンラインで見ることができる：https://www.rpsychologist.com/d3/cohend/]。

```{r smd, fig.cap='標準化平均差が1（正規性、標準偏差が等しく、両群のサンプルサイズが等しいと仮定した場合）。', out.width='85%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/smd_sep.png')
```

標準化することで、平均値の差の大きさを評価することが非常に容易になる。標準化された平均値の差は、Cohen [-@cohen1988statistical] による慣例を用いて解釈されることが多い。

* SMD $\approx$ 0.20: 小さい効果。
* SMD $\approx$ 0.50: 中程度の効果。
* SMD $\approx$ 0.80: 大きい効果。

ピアソン積率相関と同様 (Chapter \@ref(pearson-cors))、経験則に過ぎない。

通常、標準化された平均値の差は、その「現実的な」意味合いに基づいて解釈する方がずっと良いのである。効果量は Cohen の基準では小さいかもしれないが、それでも非常に重要である可能性がある。例えば、多くの深刻な病気では、統計的な効果が非常に小さくても、集団レベルでは大きな影響を与え、何百万人もの命を救う可能性があるのである。ある研究では、うつ病の治療において、$\text{SMD}_{\text{between}}=$ 0.24 のような小さな効果でさえ、患者の命に臨床的に重要な影響を与えることができることが示された [@cuijpers2014threshold]。

この式を使って$\text{SMD}_{\text{between}}$ の標準誤差を計算することができる [@borenstein2011introduction]。

\begin{equation}
SE_{\text{SMD}_{\text{between}}} = \sqrt{\frac{n_1+n_2}{n_1n_2} + \frac{\text{SMD}^2_{\text{between}}}{2(n_1+n_2)}}
(\#eq:es18)
\end{equation}

ここで、$n_1$と$n_2$はグループ1とグループ2のサンプルサイズであり、$\text{SMD}_{\text{between}}$ は計算された群間標準化平均差である。

\index{esc Package}

_R_ には、$\text{SMD}_{\text{between}}$ /Cohen's $d$ を一度に計算できる関数がいくつかある。ここでは、**{esc}** パッケージ [@esc] に含まれる `esc_mean_sd` 関数を使用する。このパッケージは今まで使用したことがないので、まずインストールする必要がある（Chapter \@ref(packages) 参照）。

```{r, message=F, eval=F}
# esc パッケージのロード
library(esc)

# SMD/d を計算するために必要なデータを定義する。
grp1m <- 50   # mean of group 1
grp2m <- 60   # mean of group 2
grp1sd <- 10  # sd of group 1
grp2sd <- 10  # sd of group 2
grp1n <- 100  # n of group1
grp2n <- 100  # n of group2

# 効果量を計算する
esc_mean_sd(grp1m = grp1m, grp2m = grp2m, 
            grp1sd = grp1sd, grp2sd = grp2sd, 
            grp1n = grp1n, grp2n = grp2n)

```

```
## Effect Size Calculation for Meta Analysis
## 
##      Conversion: mean and sd to effect size d
##     Effect Size:  -1.0000
##  Standard Error:   0.1500
##            [...]
```

この出力では、言及すべきことが2つある。まず、計算された標準化平均の差がちょうど1であることがわかる。これは、私たちが定義した2つの平均の差が（プールされた）標準偏差と等しいので、理にかなっている。

次に、効果量が**マイナス**であることがわかる。これは、グループ2の平均がグループ1の平均より大きいからである。これは数学的には正しいのであるが、他の人がより簡単に解釈できるように、計算された効果量の符号を変えなければならないことがある。

この例のデータは、介入 (group 1) または介入なし (group 2) を受けた後、人々が1週間に吸うタバコの平均本数を測定した研究から得られたと想像する。この文脈では、介入群では平均喫煙本数が少なかったので、研究結果は**肯定的**であったとする。したがって、効果量を-1.0ではなく1.0と報告することは理にかなっており、他の人が直感的に介入には正の効果があったと理解できるようになる。

効果量の符号が特に重要になるのは、ある研究では**高い**値が良いアウトカムを意味し、他の研究では**低い**値が良いアウトカムを意味する尺度を用いた場合である。この場合、すべての効果量が一貫して同じ方向にコード化されていることが不可欠である（例えば、メタ分析のすべての研究で、効果量が大きいほど介入群における転帰が良いことを意味することを確認する必要がある）。

\index{Hedges' \textit{g}}

多くの場合、標準化平均差に対して小サンプル補正を行い、**Hedges'** $g$ と呼ばれる効果量になる。この補正については、Chapter \@ref(hedges-g) で取り上げる。

標準化平均差のメタ分析を行うには、データセットに少なくとも以下の列が含まれている必要がある。

* **`n.e`**. 介入・実験群の観測数。
* **`mean.e`**. 介入・実験群の平均値。
* **`sd.e`**. 介入・実験群の標準偏差。
* **`n.c`**. 対照群の観測数。
* **`mean.c`**. 対照群の平均値。
* **`sd.c`**. 対照群の標準偏差。

<br></br>

```{block2, type='boxinfo'}
**標準偏差の外部推定値による標準化**

\vspace{2mm}

SMD を計算するとき、$s_{\text{pooled}}$ を使うのは、それが母集団における真の標準偏差の代理として機能するからである。しかし、特に研究の規模が小さい場合、サンプルに基づいて計算された標準偏差は、母集団の標準偏差の推定値としては不適切な場合がある。

この場合、可能な解決策は、平均差を標準化するために $s_{\text{pooled}}$ の**外部**推定値を使用することである [@higgins2019cochrane]。このような外部推定値は、類似の集団でこの研究と同じ測定器を使用した大規模な横断研究から抽出されるかもしれない。

```


<br></br>

#### 群内（標準化）平均差 {#w-group-smd}

---

\index{Standardized Mean Difference}\index{標準化平均差}

**群内**の差を調べる場合、非標準化または標準化された平均差を計算することが可能である。これは通常、同じグループの人々が2つの異なる時点（例えば、介入前と介入後）で測定される場合である。

群間平均差とは異なり、$\text{(S)MD}_{\text{within}}$は**独立ではない**データを用いて計算される。例えば、測定点 $t_1$ での人物 $i$ の値が、測定点 $t_2$ での同じ人物の値に影響を与えている可能性がある。群内平均差は、通常、異なる時点で測定されたデータに基づいていることから、**（標準化）平均利得** ((standardized) mean gain)とも呼ばれる。

群内平均差 $\text{MD}_{\text{within}}$ は、同じ群の $t_1$ と $t_2$ の2つの時点の値を比較するようになった以外は、$\text{MD}_{\text{between}}$ と同じ方法（ Chapter \@ref(b-group-md) 参照）で計算される。

\begin{equation}
\text{MD}_{\text{within}} = \bar{x}_{\text{t}_2} - \bar{x}_{\text{t}_1}
(\#eq:es19)
\end{equation}

群内平均差の標準化版を計算したい場合は、より複雑になる。$\text{SMD}_{\text{within}}$ をどのように計算すべきかについて、完全なコンセンサスはない。[ブログ記事](http://jakewestfall.org/blog/index.php/2016/03/25/five-different-cohens-d-statistics-for-within-subject-designs/)で、Jake Westfall は少なくとも5つの異なる計算方法があることを指摘している。

直感的なオプションは、両評価点のプールされた標準偏差 $s_{\text{t}_1}$ と $s_{\text{t}_2}$ を使って平均  $\text{MD}_{\text{within}}$ を標準化することである。群内デザインでは観測点数が通常同じなので、2つの標準偏差の二乗の和を2で割って $s^2_{\text{pooled}}$ を求めればよいことになる。そうでない場合は、Chapter \@ref(b-group-md) の式（3.16）を使って $s_{\text{pooled}}$ を計算することが可能である。このことから、以下の式が導かれる。

\begin{equation}
\text{SMD}_{\text{within}} = \frac{\bar{x}_{\text{t}_2} - \bar{x}_{\text{t}_1}}{s_{\text{pooled}}}
(\#eq:es20)
\end{equation}

Becker [-@becker1988synthesizing] は、さらに良い解決策を提案した。すなわち、$\text{MD}_{\text{within}}$ を介入前の得点の標準偏差 ($s_{\text{t}_1}$) で割ることである。この理由は、$s_{\text{t}_1}$ の方が介入効果の影響を受けにくいことがある^[分母に $\sqrt{(s_{\text{t}_1}^2 + s_{\text{t}_2}^2/2)}$ ではなく、$s_{\text{t}_1}$ を使っている理由は、もう一つ「統計的」な理由がある。群内デザインでは、$s_{\text{t}_1}$ と $s_{\text{t}_2}$ は独立ではない。これは、$s_{\text{t}_1}^2 + s_{\text{t}_2}^2$ が $\chi^2$ 分布に従わないことを意味し、$\text{SMD}_{\text{within}}$ の標準誤差を計算する際に下記の式（3.23）を適用するために必要なものである。分母に $\sqrt{(s_{\text{t}_1}^2 + s_{\text{t}_2}^2/2)}$ を用いたときの $\text{SMD}_{\text{within}}$ の近似サンプル分布の「正しい」式が最近記載されている [@cousineau2020approximating]; これも $r_{\text{t}_1\text{t}_2}$ が分かっているものと仮定している。@cousineau2021ci は、この新しく「発見された」分布に基づいて信頼区間を計算する方法を議論した。しかし、ここでは、分母に $s_{\text{t}_1}$ だけを使ったときの $\text{SMD}_{\text{within}}$ とその標準誤差の式に限定する。これは、これらの式が実際に適用するのが比較的簡単で、文献にもよく見られること、また、テスト前の標準偏差 $s_{\text{t}_1}$ で標準化するのが一般的に妥当な方法だからである]。

\begin{equation}
\text{SMD}_{\text{within}} = \frac{\bar{x}_{\text{t}_2} - \bar{x}_{\text{t}_1}}{s_{\text{t}_1}}
(\#eq:es201)
\end{equation}

また、$\text{MD}_{\text{within}}$ と $\text{SMD}_{\text{within}}$ の標準誤差はこれらの式を使って計算可能である [@borenstein2011introduction, chapter 4; @becker1988synthesizing]。

\begin{equation}
SE_{\text{MD}_{\text{within}}}=\sqrt{\dfrac{s^2_{\text{t}_1}+s^2_{\text{t}_2}-(2r_{\text{t}_1\text{t}_2}s_{\text{t}_1}s_{\text{t}_2})}{n}}
(\#eq:es21)
\end{equation}

\begin{equation}
SE_{\text{SMD}_{\text{within}}} = \sqrt{\frac{2(1-r_{\text{t}_1\text{t}_2})}{n}+\frac{\text{SMD}^2_{\text{within}}}{2n}}
(\#eq:es22)
\end{equation}

群内（標準化）平均値の差の標準誤差を計算するために、評価点間の相関 $r_{\text{t}_1\text{t}_2}$ を2つ知る必要があることは、実務上しばしば問題となることである。ある変数の前後相関は発表された研究でほとんど報告されていないため、先行研究に基づいて $r_{\text{t}_1\text{t}_2}$ の値を仮定せざるを得ない。

しかし、相関を正確に把握しないと、結果に誤差が生じる可能性がある。一般的に、メタ分析で群内効果量を計算することは避けた方が良いと言われている [@cuijpers2017pre]。特に、**実験群と**対照群の両方のデータがある場合は、前後比較ではなく、$t_2$ における**群間**（標準化）平均差を計算して、治療の効果を測定する方がずっと良い。ただし、対照群を含まない研究のみにメタ分析を行う場合は、群内平均差を計算することが可能である。

群内標準化平均差（群内 (within-group) Cohen's $d$ とも呼ばれる）は _R_ でこのように計算できる。

```{r, message=F}
# Define data needed for effect size calculation
x1 <- 20    # mean at t1
x2 <- 30    # mean at t2
sd1 <- 13   # sd at t1
n <- 80     # sample size
r <- 0.5    # correlation between t1 and t2

# Caclulate the raw mean difference
md_within <- x2 - x1

# Calculate the smd:
# Here, we use the standard deviation at t1
# to standardize the mean difference
smd_within <- md_within/sd1
smd_within

# Calculate standard error
se_within <- sqrt(((2*(1-r))/n) + 
              (smd_within^2/(2*n)))
se_within

```

群内（標準化）平均差のメタ分析は、 _R_ では**事前に計算された効果量**を用いてのみ実行可能となる（Chapter \@ref(es-formats-different) 参照）。今回のデータセットでは、以下の列が必要である。
 
* **`TE`**: 算出された群内効果量。
* **`seTE`**: 群内効果量の標準誤差。
 
<br></br>

```{block2, type='boximportant'}
**標準化の限界**

\vspace{2mm}

標準化平均差は、間違いなくメタアナリシスで**最も頻繁に使用される**効果量の指標の1つである。Chapter \@ref(b-group-smd) で述べたように、標準化により、少なくとも理論的には、異なる研究で観察された効果の強さを比較することができる。

しかし、標準化は、**「免罪符」**ではない。ある研究の $\text{SMD}$ の大きさは、そのサンプルの**多様性**に大きく依存する  [@viechtbauer2007approximate も参照]。2つの同じ研究を行い、アウトカムを測定するために同じ測定器を使用するが、2つの研究は大幅に異なる分散を持つ2つの集団で行われたと想像してみよう。この場合、両研究の「生の」平均差が**同じ**であっても、両研究の $\text{SMD}$ 値は**大きく異なる**であろう。

この場合、一方の研究の効果の「因果」の強さが他方よりはるかに大きいか小さいかを論じることはやや困難です。Jacob Cohen [-@cohen1994earth] が有名な論文で「私にとってのAのBに対する効果は、私が大きく変動するグループにいるか[...]、まったく変動しない別のグループにいるかには、ほとんど依存しない」(p. 1001) と述べた。
ところで、この問題は、一般に使用されている「標準化された」メタアナリシスにおける効果量の測定、例えば相関関係にも当てはまる。

さらに、標準化する**単位**は、思ったよりも**明確に定義されていない**ことが多いことも見てた。群間と群内の $\text{SMD}$s には様々な選択肢があり、特定の研究でどのアプローチが選ばれたかを切り分けるのは難しい。メタ分析のための標準化効果量の計算方法については、常に研究間で**可能な限り**一貫性を保つことが必要である。それでも、たとえ標準化を行ったとしても、**効果量の一致度**には限界があることを心に留めておく必要がある。

もちろん、アウトカムが**すべての研究で結果が同じ尺度で測定され**、**生平均差**が利用できれば、最高の解決策になるであろう。しかし、多くの研究分野では、そのような方法論的な調和からはほど遠いところにいるのが現状で。したがって、残念ながら、標準化効果量は、**第二の最良の選択肢**となることもある。


```



<br></br>

### リスク比とオッズ比 {#ratios}

---

#### リスク比 {#rr}

---

\index{Risk Ratio}\index{リスク比}

**リスク比**（別名：**相対リスク**）とは、その名の通り、2つの**リスク**の比のことである。リスクとは基本的に**割合** (proportion) のことである（Chapter \@ref(props) 参照）。リスクは、バイナリ（**二値**）データを扱う場合に計算可能である。

このようなアウトカムは、医学研究において、病気の発症や死亡の**リスク**を調べる場合によく見られるため、「割合」ではなく「リスク」という用語を使用する。このような事象は、**イベント**と呼ばれる。治療群と対照群からなる対照臨床試験を行っているとする。ここで興味があるのは、研究期間中に何人の患者があるイベント $E$ を経験したかである。

このような研究から得られる結果は、$2 \times 2$ の表に分類できる [@schwarzer2015meta, chapter 3.1]。

```{r twobytwo, echo=F, message = F}
library(kableExtra)

df = data.frame(
  `x` = c("Treatment", "Control", " "),
  event = c("$a$", "$c$", "$n_E$"),
  `no event` = c("$b$", "$d$", "$n_{\\neg E}$"),
  `sample size` = c("$n_{\\text{treat}}$", "$n_{\\text{control}}$", " "))

colnames(df) = c(" ", "Event", "No Event", " ")

kable(df, "html", booktabs = TRUE, escape = FALSE, align="lccl",
      cap = "Results of controlled studies using binary outcome data.",
      full_width = F) %>% 
  kable_styling(latex_options = c("hold_position", "condensed"),
                bootstrap_options = c("condensed"),
                full_width = F) %>% 
  column_spec(1, border_right = TRUE) %>% 
  column_spec(4, border_left = TRUE) %>% 
  row_spec(2, hline_after = TRUE)

```

このデータに基づいて、治療群と対照群の両方について、調査期間中にイベント $E$ を経験するリスクを計算することが可能である。$E$ を経験した人の数を、その群の総サンプルサイズで割ればよいのである。

したがって、治療群のリスクである ${p_{E}}_{\text{treat}}$ は、次のように計算される。

\begin{equation}
{p_{E}}_{\text{treat}} = \frac{a}{a+b} = \frac{a}{n_{\text{treat}}}
(\#eq:es23)
\end{equation}

そして、対照群のリスク、${p_{E}}_{\text{control}}$ は、以下のようになる。
 
\begin{equation}
{p_{E}}_{\text{control}} = \frac{c}{c+d} = \frac{c}{n_{\text{control}}}
(\#eq:es24)
\end{equation}


そして、リスク比は、治療・介入群のリスクを対照群のリスクで割ったものと定義される。

\begin{equation}
\text{RR} = \frac{{p_{E}}_{\text{treat}}}{{p_{E}}_{\text{control}}}
(\#eq:es25)
\end{equation}

\index{Log-Risk Ratio}\index{対数リスク比}

${p_{E}}_{\text{treat}}$ と ${p_{E}}_{\text{control}}$ はどちらも0と1の間の値しか持ち得ないので、RR はいくつかの興味深い性質を持っている。まず、リスク比が負になることはない。次に、治療群と対照群の間に差がない場合、RR は（SMDのように0ではなく）1という値になる。RR が1より大きければ、治療群がイベント $E$ のリスクを増加させることを意味し、RR が1より小さければ、介入によってリスクが減少することを意味する。

RR の特徴は、同じ大きさの効果は**等価ではない**ということである。例えば、RR $=$ 0.5 は、介入群でリスクが半分になることを意味する。これはリスク比が正規分布に従わないことを意味し、メタ分析では問題になることがある。

この問題を避けるために、統合する前にリスク比を **対数リスク比** (log-risk ratio) に変換することもよくある。これにより、漸近正規性、効果量が任意の値になること、値が0（効果がないことを意味する）を中心になることが保証される。この変換は、RRの自然対数を取ることによって行われる。

\begin{equation}
\log \text{RR}  = \log_{e}(\text{RR})
(\#eq:es26)
\end{equation}

そして、対数リスク比の標準誤差は、この式を用いて計算することができる。

\begin{equation}
SE_{\log \text{RR}} = \sqrt{\frac{1}{a}+\frac{1}{c} - \frac{1}{a+b} - \frac{1}{c+d}}
(\#eq:es27)
\end{equation}


_R_ の（対数）リスク比はこのように計算することができる。

```{r}
# データを定義
a <- 46         # 治療群のイベント数
c <- 77         # 対照群のイベント数
n_treat <- 248  # 治療群のサンプルサイズ
n_contr <- 251  # 対照群のサンプルサイズ

# リスクを計算
p_treat <- a/n_treat
p_contr <- c/n_contr

# リスク比を計算
rr <- p_treat/p_contr
rr

# 対数リスク比と標準語差を計算
log_rr <- log(rr)
log_rr

se_log_rr <- sqrt((1/a) + (1/c) - (1/n_treat) - (1/n_contr))
se_log_rr

```

\index{Zero Cell Problem}\index{ゼロセル問題}
\index{Continuity Correction}\index{連続性補正}
\index{Mantel-Haenszel Method}\index{Mantel-Haenszel 法}\index{Mantel-Haenszel 法}

**ゼロセル**があると、リスク比の計算が難しくなる。実際には、$a$ または $c$ （あるいはその両方）がゼロであることがあり、これは治療群でも対照群でもイベントが記録されていないことを意味する。RRの計算式を見ると、なぜこれが問題なのかがよくわかる。$a$（治療群のイベント）がゼロなら、${p_{E}}_{\text{treat}}$ もゼロで、RR はゼロになる。$c$ がゼロの場合はさらに問題で、${p_{E}}_{\text{control}}$ がゼロということになり、**ゼロで割れない** ということがわかる。

この問題は、**連続性補正** (continuity correction) を用いて対処されることがよくある。最も一般的な連続性補正の方法は、ゼロになっている全てのセルに0.5の増分を加えることである [@gart1967bias] 。また、対照群と治療群のサンプルサイズが非常に不均等な場合は、**治療群連続性補正** [@j2004add] を用いることもできる。

しかし、そのような補正は偏った結果につながるという証拠もある [@efthimiou2018practical]。（固定効果）**Mantel-Haenszel** 法というメタ解析のプール手法は、メタ解析の**すべての研究**にゼロセルが存在しない限り、**補正せずに**扱うことが可能である。したがって、後者のシナリオに当てはまらない限り、連続性補正は避けた方がよいだろう。

**ゼロセル**問題の特殊な形として、**ダブルゼロスタディ**がある。これは、$a$ と $c$ の両方がゼロである研究である。直感的には、このような研究の結果は、介入群と対照群のリスクが同程度であり、RR=1であることを意味していると考えるだろう。

残念ながら、そう簡単ではない。2つのグループの間に本当の効果があるけれども、その差を検出するにはサンプルサイズが小さすぎたということは大いにあり得る。特に、$E$ が発生する確率が非常に低い場合には、この可能性が高くなる。

あるマッドサイエンティストが、雷に打たれる危険を減らすとされる薬、**Fulguridone** の効果を評価する無作為化比較試験を行ったとする。彼は100人を薬物投与群と対照群のどちらかに均等に割り振り、3年間観察した。試験の結果は、治療群でも対照群でも雷に打たれた人はいなかったので、残念な結果になった。しかし、私たちは、雷に打たれる可能性がどれほど低いか、**一般的に**知っている。たった100人の観察では、たとえ治療が効くという奇妙な考えを受け入れたとしても、このような稀な出来事における違いを検出するには十分ではない。このため、ダブルゼロ研究は、効果をプールする際に完全に捨てられることが多いのである。

リスク比は、ある事象が**一般的に**どの程度よく起こるかという情報を与えてはくれないのである。メタ分析でリスク比が0.5と報告された場合、例えば、ある介入によってリスクが半分に減少したことがわかる。しかし、リスクが40%から20%に減少したかどうか、あるいは0.004%から0.002%に減少したかどうかはわからない。リスク比が実用的であるかどうかは、文脈に依存する。リスク比0.5が0.002%のリスク低下に相当する場合、集団レベルでは大きな影響を与えないかもしれないが、対象となる事象が例えば重症で衰弱する病気であれば、それでも重要である可能性がある。

_R_ でメタ分析を行う場合、通常、研究の対数リスク比を手作業で計算する必要はない。また、データをインポートする際にも、ゼロセルについて心配する必要はない。以下の列はデータセットに含まれている必要がある。

* **`event.e`**. 治療群・実験群におけるイベント数。
* **`n.e`**. 治療群・実験群のサンプルサイズ。
* **`event.c`**. 対照群におけるイベント数。
* **`n.c`**. 対照群のサンプルサイズ。


<br></br>

#### オッズ比 {#or}

---

\index{Odds Ratio}\index{オッズ比}
\index{Odds}\index{オッズ}

リスク比（Chapter \@ref(rr)）と同様に、**オッズ比**も2群2値のアウトカムデータがある場合に計算することが可能である。前回の割合の章（Chapter \@ref(props)）で、オッズを「あるカテゴリーに該当する個数を、そのカテゴリーに該当しない個数で割ったもの」と定義したが、今回は「あるカテゴリーに該当する個数を、そのカテゴリーに該当しない個数で割ったもの」と定義する。

Table \@ref(tab:twobytwo) の表記を使うと、治療群と対照群のオッズの計算式は次のようになる。

\begin{equation}
\text{Odds}_{\text{treat}} = \frac{a}{b}
(\#eq:es28)
\end{equation}

\begin{equation}
\text{Odds}_{\text{control}} = \frac{c}{d}
(\#eq:es29)
\end{equation}


オッズが実際に何を意味するのかを正しく解釈するのは難しいだろう。オッズは事象と非事象の比率を表すのであって、事象の **確率** を表すのではない。3人の個人を調査したとする。2人は興味のある事象を経験し、1人は経験しなかったとする。このデータから、その事象の確率（またはリスク）は $p = 2/3 \approx 66\%$ となる。しかし、事象の発生確率は、Odds = $\frac{2}{1}$ = 2となり、1人の非事象に対して2人の事象があることになる。

そして、オッズ比（OR）は、治療群でのオッズを対照群でのオッズで割ったものと定義される。

\begin{equation}
\text{OR} = \frac{a/b}{c/d}
(\#eq:es30)
\end{equation}

\index{Log-Odds Ratio}\index{対数オッズ比}

リスク比と同様に (Chapter \@ref(rr) 参照)、オッズ比もメタ分析には好ましくない統計的性質を持っている。そのため、オッズ比を自然対数を使って**対数オッズ比** (log-odds ratio) に変換することも一般的である。

\begin{equation}
\log \text{OR}  = \log_{e}(\text{OR})
(\#eq:es31)
\end{equation}

対数オッズ比の標準誤差は、この式で計算できる（表記は Table \@ref(tab:twobytwo) を使用する）。

\begin{equation}
SE_{\log \text{OR}}  = \sqrt{\frac{1}{a}+\frac{1}{b}+\frac{1}{c}+\frac{1}{d}}
(\#eq:es32)
\end{equation}


**{esc}** パッケージの `esc_2x2` 関数は、 _R_ における（対数）オッズ比を簡単に計算する方法を提供する。

```{r, message=F, warning=F}
library(esc)

# データを定義
grp1yes <- 45  # 治療群のイベント数
grp1no <- 98   # 治療群の非イベント数
grp2yes <- 67  # 対照群のイベント数
grp2no <- 76   # 対照群の非イベント数

# es.type に "or" と設定し、OR を計算
esc_2x2(grp1yes = grp1yes, grp1no = grp1no,
        grp2yes = grp2yes, grp2no = grp2no,
        es.type = "or")

# es.type に "logit" と設定し、logOR を計算
esc_2x2(grp1yes = grp1yes, grp1no = grp1no,
              grp2yes = grp2yes, grp2no = grp2no,
              es.type = "logit")

```

\index{Zero Cell Problem}\index{ゼロセル問題}
\index{Risk Ratio}\index{リスク比}

リスク比の問題点である**ゼロセル**や**ダブルゼロ研究**はオッズ比を計算するときにも同じように関係する（Chapter \@ref(rr) 参照）。しかし、オッズ比は RR に比べて、多くの人が理解しにくく、OR を RR と誤って解釈してしまうという欠点がある。

したがって、メタ分析ではリスク比のみを用いるか、結果を報告する際にオッズ比をリスク比に変換することが望ましい場合が多い [@higgins2019cochrane, chapter 6.4.1.2]。この変換は以下の式で行うことが可能である [@zhang1998whats]。（訳注:臨床論文でこれを行なっていることはほとんどない。）

\begin{equation}
\text{RR} = \frac{\text{OR}}{\left(1-\dfrac{c}{n_{\text{control}}}\right)+ \left(\dfrac{c}{n_{\text{control}}}\times \text{OR} \right)}
(\#eq:es33)
\end{equation}


_R_ のオッズ比のメタ分析を行うには、以下の列をデータセットに含める必要がある。

* **`event.e`**. 治療群・実験群におけるイベントの数。
* **`n.e`**. 治療群・実験群のサンプルサイズ。
* **`event.c`**. 対照群におけるイベントの数。
* **`n.c`**. 対照群のサンプルサイズ。


<br></br>

### 発生率比 {#irr}

---

前に調べた二値アウトカムのデータに対する効果量、リスク比やオッズ比は、2つのグループのイベントの数を比較する方法である。しかし、これらのイベントが発生した**時間**は直接的には符号化されない。リスク比やオッズ比を計算するとき、両群の観察期間が同等であることを暗黙のうちに仮定している。さらに、リスク比とオッズ比は、イベントが発生するまでの**時間**に関する情報を提供しない。

時間軸がリサーチクエスチョンにそれほど関係しない場合、これでよいだろう。また、二値データが横断的で時間軸が全くない場合もある^[例えば、横断的な調査データに基づいて、女性と男性の喫煙者の割合の違いを表すためにリスク比やオッズ比を使うことも可能である。この文脈では、RRとORはそれぞれ**有病率比**（PR）、**有病率オッズ比**（POR）と呼ばれることが多い[@tamhane2016prevalence]。]。このような場合、リスク比やオッズ比は通常、適切な効果量の指標となる。

しかし、ここで、2つのグループの個人の10年間の死亡率を調べる研究を想像してみてみよう。この10年間に起こった出来事（例えば、死亡）の数は、両群でほぼ同じである可能性がある。しかし、死亡がいつ起こったかを詳しく見てみると、一方の群では最初の数年間に多くのイベントが起こり、他方の群では10年間の観察期間の終わりまでやや多くのイベントが起こっていることがわかる。このデータから計算されるオッズまたはリスク比はおよそ1であり、群間差はないことを示す。しかし、これは重要なことを見逃している。一方のグループの参加者は、たとえ最終的に死亡したとしても、**いくらか長く**生存しているということである。



\index{Incidence Rate Ratio}\index{発生率比}
\index{Person-Time}\index{人-時間}\index{人-時間}

効果量の推定に時間を組み込むために、**発生率比** (incidence rate ratio) を計算することができ、これは英語では単に **rate ratio** と呼ばれることもある。発生率比は、2つの**発生率**から構成されている。この発生率を計算するためには、まず**人-時間**の概念を理解する必要がある。

人-時間とは、研究参加者がイベントを起こす危険性があった時間の総和を表す。人-時間を計算するためには、すべての研究対象者のリスク時間（日、週、年として表される）を合計する。しかし、リスク時間は人によって異なる。

例として、6人の被験者で研究を行う場合を考えてみよう。この研究は、ちょうど10年間続く。各年が終わるごとに、参加者にインタビューを行い、彼らがあるイベントを経験したかどうかを調べる。イベントが発生したことが確認された場合、その参加者の研究は終了し、研究が終了するまでその参加者を調査することはない。本研究の結果を図に示す。


```{r incidence, fig.cap = '時間-イベントデータの例', message=F, echo=F, fig.height=2.5}
library(ggplot2)

df = data.frame(name = c("Rebecca", "Marvin", "Nicole", "Victoria", "Marie", "Lea"),
                value = c(2, 5, 6, 10, 9, 10))

ggplot(data = df, aes(x = name, y = value)) +
  geom_bar(stat = "identity", width = 0.4) +
  geom_hline(yintercept = 1:9, color = "white") +
  geom_hline(yintercept = 10, color = "black") +
  coord_flip() +
  theme_void() +
  theme(axis.text.x = element_text(),
        axis.title.x = element_text(),
        axis.text.y = element_text()) +
  scale_y_continuous(breaks = 0:10) +
  ylab("Year") +
  theme(panel.background = element_rect(fill = "#FFFEFA",
                                        size = 0),
        plot.background = element_rect(fill = "#FFFEFA",
                                       size = 0))

```

\index{Survival Analysis}\index{生存解析}
\index{Odds Ratio}\index{オッズ比}
\index{Censoring}
\index{Person-Time}\index{人-時間}\index{人-時間}

今回の参加者のうち、最後まで研究に参加したのは、Victoria と Lea の2人だけであることがわかる。これは、彼らが10年間の観察期間中、イベントを経験しなかったからである。したがって、両者とも10年間は**アットリスク**であった。

他の参加者は全員、調査期間中にイベントを体験している。例えば、レベッカが2年目に調査されたとき、我彼女が最後の1年間にイベントを経験したことを発見する。しかし、私たちが知っているのは、その出来事が2年目に起こったという**こと**だけで、正確にはいつ起こったかわからないのである。

このような研究データは、**区間打ち切り**データと呼ばれ、いわゆる**生存解析**を行う臨床試験で非常によく見受けられる。データが打ち切られているということは、レベッカが最終的にイベントを経験するまでにどれくらいの期間危険にさらされていたかを部分的にしか知らないということである。私たちは、彼女が1年目以降、2年目の終わりまでにイベントを経験したことを知っているが、それ以上のことは知ることはない。他の情報がないので、イベントが中間のどこかで発生したと仮定して、リスク時間を1.5年とすることにする。

打ち切られたデータ全てに同じ方式を適用すれば、我々の研究における**人-年**のリスクを計算することができる。

$$10 + 1.5+5.5+4.5+8.5+10 = 40$$
すなわち、この研究での推定総人-年は40人年ということになる。1年は52週なので、この研究の**人-週**は $40 \times 52 = 2080$ と計算可能である。
 
実験参加者年数がわかったので、これを $T$ とすると、1年以内の発生率も計算できる。調査期間中に4人の参加者がイベントを経験したことが分かっているので、イベントの数は $E=4$ となる。そして、この式で発生率 IR を計算することができる。

\begin{equation}
\text{IR} = \frac{E}{T}
(\#eq:es33)
\end{equation}

この例では、$3/40 = 0.075$ の発生率になる。この発生率は、1000人を1年間追跡調査した場合、75人がその間にそのイベントを経験することを意味する。
 
発生率比 (incidence rate ratio, IRR) を計算するためには、あるグループの発生率を他のグループの発生率で割る必要がある。


\begin{equation}
\text{IRR} = \frac{ E_{\text{treat}}/T_{\text{treat}} }{E_{\text{control}}/T_{\text{control}}}
(\#eq:es34)
\end{equation}


この式で、$E_{\text{treat}}$ と $T_{\text{treat}}$ は治療群のイベント数と人時、$E_{\text{control}}$ と $T_{\text{control}}$ は対照群のイベント数と人時である。もちろん、2つのグループは、例えば、女性と男性、喫煙者と非喫煙者など、関心のある他の二項対立変数を表すこともできる。

IRR は、リスク比やオッズ比と多くの特性を共有している。つまり、IRR は 1 を中心とし、マイナスになることはない。OR や RR と同様に、発生率比もメタ分析のために対数変換され、対数発生率比が作成される。

\index{Log-Incidence Rate Ratio}\index{対数発生率比}

\begin{equation}
\log \text{IRR} = \log_{e}(\text{IRR})
(\#eq:es35)
\end{equation}

これについては、次のように標準誤差を計算することが可能である [@rothman2008modern, chapter 14]。


\begin{equation}
SE_{\log \text{IRR}} = \sqrt{\frac{1}{E_{\text{treat}}}+\frac{1}{E_{\text{control}}}}
(\#eq:es36)
\end{equation}

このように（対数）発生率比と _R_ の標準誤差を計算することができる。

```{r}
# Define Data
e_treat <- 28    # 治療群のイベント数
e_contr <- 28    # 対照群のイベント数
t_treat <- 3025  # 治療群の Person-time
t_contr <- 2380  # 対照群の Person-time

# IRR を計算
irr <- (e_treat/t_treat)/(e_contr/t_contr)
irr

# log-IRR を計算
log_irr <- log(irr)

# 標準誤差を計算
se_log_irr <- sqrt((1/e_treat)+(1/e_contr))

```

この例では、イベント数 $E_{\text{treat}}$ と $E_{\text{control}}$ が全く等しいが、治療群の方がリスクでの人時時間が長い場合をシミュレーションしている。この時間差は、IRR を計算するときに考慮される。したがって、得られる結果は1ではなく、IRR $\approx$ 0.79となり、治療群の方が発生率が小さいことがわかる。

発生率比は、疫学や予防医学の研究でよく使われる。参加者を長期間にわたって追跡調査し、その間に定期的な評価を行う場合に使用することが可能である。しかし、実際には、メタ分析の一部としてIRRを計算する際に考慮すべき注意点が1つある。含まれる論文で報告された発生率データが十分に細かいことが重要である。時々、論文は研究期間中のイベントの総数のみを報告し、その間の各評価ポイントで記録されたイベントの数は報告しません。また、そもそも中間評価が行われていない可能性もある。

上記の例（Figure \@ref(fig:incidence) 参照）では、参加者の危険にさらされている時間を推定するために、単純に、最後の「イベントのない」評価点とイベントが記録された評価点との間の**中間点**を取ることにする。これは、イベントがいつ起こったかの**最良の推測**に過ぎないということを心に留めておくことが重要である。中間点を取る場合でも、この例では、推定はまだ約半年ずれている可能性がある。

評価点間の時間をできるだけ小さくすれば、人-時推定値は最適になる。研究の評価間隔が粗すぎるかどうかはメタ分析の文脈に依存する。ただし、そのような感度分析を行うことは常に推奨される [@panageas2007you]。

これは、異なる人-時推定値に基づく研究のIRRを再計算することを意味する。

* インターバルの**中点**を使用し

* **最後の「イベントのない」評価ポイント**を使用し

* イベントが**検出された**評価ポイントを使用している。

これらの3つのメタ分析の結果がすべて同じ方向を向いていれば、より確信を持って調査結果を公表することが可能である。また、評価期間が研究間であまりに異ならないことを確認する必要がある（例えば、ある研究では毎日イベントを調査し、他の研究では年１回だけ調査する）。メタ分析での IRR の適用性に疑問がある場合、代わりに（または追加で）リスク比またはオッズ比を計算する可能性が常に存在する。ただし、この場合、評価時点が各研究で類似していることを確認する必要がある（例えば、1年後）。

_R_ の発生率比に基づくメタ分析を計算するためには、データセットに以下の列を用意する必要がある。

* **`event.e`**: 治療群・実験群におけるイベント総数。
* **`time.e`**: 治療群・実験群における人-時（person-time）。全ての研究で人-時の単位（人-日、人-週、人-年）を統一して表記する。
* **`event.c`**: 対照群におけるイベント総数。
* **`time.c`**: 対照群における人-時（person-time）。全ての研究で人-時の単位（人-日、人-週、人-年）を統一して表記する。

<br></br>


```{block2, type='boximportant'}
**ハザード比と発生率比の限界**

\vspace{2mm}

発生率やIRRは、事象データやその事象が発生する時間帯を要約する直感的な方法である。しかし、欠点がないわけではない。発生率を計算するためには、母集団における**基礎となるリスク**が時間と共に**一定**であると仮定する（例えば、研究の1年目と2年目の間など）。IRRでは、基礎となるリスクは治療群と対照群で異なるかもしれないが（例えば、治療が事象を経験するリスクを減らすため）、各群**内** (within) のリスクは一定であると仮定する。

この仮定が非常に単純であることは容易に理解できる。イベントリスクが時間とともに変化しないと仮定することが非常に**非現実的**なシナリオは多い [@kraemer2009events, 例: 転移性癌患者の死亡]。Bender and Beckmann  [-@bender2019limitations]  は、シミュレーション研究に基づいて、IRRの使用は、両群の平均**観察期間**が大きく**異ならない**とき、および調査対象イベントの**ベースラインリスク**が比較的**低い**（25%未満）場合にのみ適切であると結論づけている。

時間-事象データに基づく群間差を表現する代替指標として望ましいのが**ハザード比**（HR）である。ハザード比は、2つの（比例する）**ハザード関数**の比で、ある時点 $t$ である事象を経験することの（変化する）瞬間的なリスク（これを、「ハザード」と言う）を記述している。

ハザード比は、一般的に**Cox回帰**モデルを用いて、個々の参加者データを基に推定される。すべての研究から対数ハザード比 $\log_{\text{e}}(\text{HR})$ とそれに対応する標準誤差を抽出できれば、**逆変量プーリング** を用いたメタアナリシスを行うことができる（Chapter \@ref(fem) 参照)。これは、例えば対数リスクやオッズ比をプールするのと同じように機能する。 _R_ では、対数ハザード比のプーリングは `metagen` 関数で、`sm` 引数を `"HR"` に設定して行う（Chapter \@ref(pre-calculated-es) 参照）。

すべての研究が（対数）ハザード比とその標準誤差を**報告**しているわけではないので、HRをプールすることは実際には大変な問題になることもある。@parmar1998extracting は、特に **log-rank test** の結果や **生存曲線** から対数ハザード比とその分散を導き出す様々な方法について説明している。この方法は手間がかかるが、報告されたデータからIRRを導出する方法も間違いなく手間がかかる。

```



<br></br>

## 効果量補正 {#es-correction}

---

ある研究 $k$ に対して計算した効果量 $\hat\theta_k$ はその研究の真の効果量 $\theta_k$ の推定値であり、サンプル誤差 $\epsilon_k$ により $\hat\theta_k$ は $\theta_k$ から乖離すると、Chapter \@ref(what-is-es) では取り上げた。残念ながら、多くの場合、これは過度の単純化である。先ほどの式では、推定された効果量と真の効果量を分けるのは、サンプル誤差だけである。式に従えば、サンプル誤差が小さくなれば、効果量の推定値は母集団における真の効果量に「自然に」収束していく。

しかし、効果量の推定に系統的な誤差、すなわち**バイアス**が加わると、この限りではない。このようなバイアスは、さまざまな理由がある。効果量指標の数学的特性そのものに起因するものもあれば、研究の実施方法によって生じるバイアスもある。

研究の進め方に起因するバイアスに対しては、バイアスの危険性を評価することで対応可能である（バイアスの危険性評価ツールの紹介は Chapter \@ref(data-extraction)、バイアスの危険性の可視化方法は Chapter \@ref(risk-of-bias-plots) を参照）。この判断は、例えばサブグループ解析において、バイアスリスクがプールされた効果の違いに関連しているかどうかを判断するためにも使用可能である（Chapter \@ref(subgroup)）。

効果量の統計的性質に起因するバイアスに対処するために、メタ解析を始める前に、特定の**効果量補正**手法を用いてデータを調整することが可能である。

この章では、よく使われる3つの効果量補正の方法と、それらを _R_ でどのように実装するかを説明する。


<br></br>

### スモールサンプルバイアス {#hedges-g}

---

\index{Hedges' \textit{g}}
\index{Standardized Mean Difference}\index{標準化平均差}

標準化平均差 (SMD) は、2群の連続したアウトカムデータがある場合に計算できる効果量である。しかし、標準化平均差は、研究のサンプルサイズが小さいとき、特に $n \leq$  20（@hedges1981distribution）のとき、**上方バイアス** (upward bias) を持つことが分かっている。このサンプルサイズが小さいというバイアスは、研究のサンプルサイズが小さい場合、SMD が系統的に真の効果量を過大評価することを意味する。

そこで、すべての研究の標準化平均差をスモールサンプルバイアスで補正し、Hedges' $g$ と呼ばれる効果量を算出することが賢明である。Hedges' $g$ はこの補正の考案者である Larry Hedges にちなんで名づけられた。未補正の SMD/Cohen's $d$ を Hedges' $g$ に変換する式は次のようになる。


\begin{equation}
g = \text{SMD} \times (1-\frac{3}{4n-9})
(\#eq:es37)
\end{equation}

\index{esc Package}

この式で、$n$ は研究の総サンプルサイズを表す。標準化されていない SMD/Cohen's $d$ を Hedges' $g$ に変換するには、**{esc}** パッケージの `hedges_g` 関数を使うと簡単に可能である。

```{r}
# esc パッケージをロード
library(esc)

# 未補正 SMD とサンプルサイズ n を定義
SMD <- 0.5
n <- 30

# Hedges g に変換
g <- hedges_g(SMD, n)
g
```



出力でわかるように、Hedges' $g$ は未補正の SMD より小さくなっている。Hedges' $g$ は補正前の SMD より大きくなることはなく、サンプルサイズが小さいほど2つの指標の差は大きくなる (Figure \@ref(fig:dtog)参照)。


```{r dtog, fig.height=2, fig.width=4, fig.cap='サンプルサイズを変化させた時の未補正 SMD 0.2 と補正済み SMD 値', echo=F, fig.align='center'}
library(esc)
library(ggplot2)

data = data.frame(es = c(rep(0.2, 97), hedges_g(0.2, 4:100)),
                  val = rep(4:100, 2),
                  esm = rep(c("d", "g"), each = 97))

cols = c("")

ggplot(data, aes(x = val, y = es, group = esm, color=esm, linetype = esm)) +
  geom_line(size = 1) +
  scale_linetype_manual(values=c(3,1),
                        name = " ", labels = c(bquote("Uncorrected"~italic(SMD)), 
                                                        bquote("Hedges'"~italic(g)))) +
  theme_classic() +
  scale_color_manual(values = c("black", "gray40"),
                     name = " ", labels = c(bquote("Uncorrected"~italic(SMD)), 
                                                        bquote("Hedges'"~italic(g)))) +
  ylab(" ") +
  xlab("Sample Size") +
  theme(panel.background = element_rect(fill = "#FFFEFA",
                                        size = 0),
        plot.background = element_rect(fill = "#FFFEFA",
                                       size = 0),
        legend.background = element_rect(fill = "#FFFEFA",
                                       size = 0))

```

ここで重要なことは、SMD と Hedges' $g$ という用語が研究報告で同じように使われることがあることである。ある研究が SMD として結果を報告している場合、著者が本当に未補正の標準化平均差を指しているのか、それとも小サンプルバイアス補正が適用されているのか（つまり Hedges' $g$ が使われているのか）を確認することが適切である。


<br></br>

### 非信頼性 {#unreliable}

---

\index{Unreliability Correction}

**測定誤差**のために効果量の推定値にバイアスがある可能性もある。ほとんどのアンケートやテストは、興味のある結果を完璧に測定することはできない。測定誤差が生じにくい測定器（訳注: instrument、測定器と訳したが質問紙なども含まれる）ほど、**信頼性が高い**と言える。ある変数 $x$ を測定する測定器の信頼性は、信頼性係数 $r_{xx}$ で表すことができ、0から1の間の値をとることができる。信頼性はしばしば**テスト・再テスト信頼性**と定義され、同一人物を同じような状況で短期間に2回以上測定し、その値の相関を計算することで求められる^[測定器の信頼性を見積もる様々な方法について、よりわかりやすく、より詳しい議論が Hunter and Schmidt [-@hunter2004methods], chapter 3 にある]。

\index{Attenuation}\index{減衰}

2つの連続変数の関係を調べるとき、これらの変数を評価するために使用される調査測定器の一方または両方に信頼性が欠けていると、**減衰** (attenuation) と呼ばれる現象が起こることがある。この問題は、1904年に有名な心理学者 Charles Spearman  [-@spearman1904reprinted] によって早くも記述されている。例えば、相関を計算するときに、片方または両方の変数に誤差があると、真の相関を**過小評価**することになる。相関は**希釈される**のである。しかし、良いニュースもある。もし、測定の（非）信頼性の推定値があれば、真の効果の大きさをより良く推定するために、この減衰を補正することが可能なのである。

John Hunter and Frank Schmidt は、メタ分析の分野で重要な貢献者であり、メタ分析の一部として減衰の補正を行う方法を開発し推進している [@hunter2004methods, chapters 3 and 7]。この補正は他のいくつかの手法の一つであり、これらをまとめて「Hunter and Schmidt techniques」または「Hunter and Schmidt 法」と呼ぶこともある [@hough1994comparison]。

Hunter and Schmidt の減衰補正は、（積率）相関と標準化平均差に適用することができる。まず、メタ解析の一環として研究の積率相関 $r_{xy}$ を計算する際に、変数 $x$ の測定における信頼性の低さを補正したいと仮定する。$r_{xx}$ で示される $x$ の測定の信頼性がわかれば、相関の**補正版**である ${r_{xy}}_{c}$ を計算することが可能である。

\begin{equation}
{r_{xy}}_{c} = \frac{r_{xy}}{\sqrt{r_{xx}}}
(\#eq:es38)
\end{equation}

アウトカム $x$ が2群で観測され、その群間の標準化平均差を計算することが目的である場合、同様の方法で補正を行い、$\text{SMD}_c$を得ることができる。

\begin{equation}
\text{SMD}_c = \frac{\text{SMD}}{\sqrt{r_{xx}}}
(\#eq:es39)
\end{equation}

二つの連続変数 $x$ と $y$ を用いて積率相関を計算するとき、$y$ の信頼性係数 $r_{yy}$ もわかっていれば、$x$ と $y$ の両方の信頼性の低さを補正することも可能である。


\begin{equation}
{r_{xy}}_{c} = \frac{r_{xy}}{\sqrt{r_{xx}}\sqrt{r_{yy}}}
(\#eq:es40)
\end{equation}

最後に、標準誤差の補正も必要である。標準誤差の補正は、効果量そのものと同じ方法で行いる。1つの変数 $x$ を補正する場合は、以下の式で計算可能である。


\begin{equation}
SE_c = \frac{SE}{\sqrt{r_{xx}}}
(\#eq:es41)
\end{equation}

$x$ と $y$ の両方について補正（積率相関）したい場合は、以下の式が使える。


\begin{equation}
SE_c = \frac{SE}{\sqrt{r_{xx}}\sqrt{r_{yy}}}
(\#eq:es42)
\end{equation}

\index{Hedges' \textit{g}}
\index{Fisher's \textit{z}}

相関やSMDを補正した後、${r_{xy}}_c$ を Fisher's $z$ に変換したり(Chapter \@ref(cors)) $\text{SMD}_c$ を Hedges' $g$ に変換するなど(Chapter \@ref(hedges-g))、一般的な変換を適用することが可能である。

ここでは 、 _R_ を使った例で補正方法を試してみよう。

```{r}
# 未補正の相関と SMD とその標準誤差を定義
r_xy <- 0.34
se_r_xy <- 0.09
smd <- 0.65
se_smd <- 0.18

# xとyの信頼性を定義
r_xx <- 0.8
r_yy <- 0.7

# x の信頼性の低さを考慮して SMD を補正
smd_c <- smd/sqrt(r_xx)
smd_c

se_c <- se_smd/sqrt(r_xx)
se_c

# x と y の信頼性の低さを考慮して相関を補正
r_xy_c <- r_xy/(sqrt(r_xx)*sqrt(r_yy))
r_xy_c

se_c <- se_r_xy/(sqrt(r_xx)*sqrt(r_yy))
se_c
```

この例の結果を詳しく見ていこう。補正により、相関と SMD が補正前の初期値より大きくなっていることがわかる。しかし、標準誤差が大きくなっていることもわかる。この結果は意図的なもので、標準誤差を補正することで、データに想定される測定誤差を取り込むことができるのである。

組織心理学など一部の分野では、減衰補正を適用することが一般的である。しかし、生物医学分野を含む他の分野では、この手順はほとんど使用されていない。メタ分析では、各研究で信頼性係数 $r_{xx}$ （および $r_{yy}$）が報告されている場合のみ、信頼性の低さに対する補正を実行することが可能である。

信頼性係数が報告されていない場合も非常に多い。このような場合、先行研究に基づく測定器の信頼性の値を仮定することがある。しかし、補正が効果量の値に大きな影響を与えることを考えると、$r_{xx}$ の推定値が不適切だと、結果がかなり歪んでしまう。また、メタ分析において、**一部**の効果量だけを補正し、他の効果量を補正しないようにすることは不可能である。これらの理由により、残念ながら信頼性補正の適用範囲は実際には限定されることが多い。

<br></br>


### 範囲指定 {#range}

---

\index{Range Restriction Correction}\index{範囲制限の補正}

Hunter and Schmidt [-@hunter2004methods, chapter 3 and 7] によって提案されたもう一つの効果量調整は、範囲制限の問題を扱うものである。範囲制限とは、ある変数 $x$ の変動が、興味のある実際の母集団よりも研究で小さいときに起こる現象である。これは、母集団全体を代表していない可能性のある個体から非常に選択的にサンプルを採取した場合によく起こる。

例えば、ある研究で、被験者の年齢と認知機能の相関が報告された場合を考えてみよう。直感的には、これらの変数には確かに相関があると考えるだろう。しかし、65歳から69歳の参加者だけを対象とした研究であれば、この2つの変数の間に（高い）相関が見られる可能性は極めて低い。これは、調査サンプルの年齢が非常に限定されているためである。年齢には実際の変動がないため、この変数は認知能力の良い予測因子にはなり得ないということである。

測定器の信頼性の低さ（前章参照）と同様、これは研究の効果を人為的に減衰させることにつながる。実際には重要な関連がある場合でも、それを検出することができない。

SMD や相関 $r_{xy}$ の範囲制限を補正することは可能である。ただし、そのためには、対象母集団の無制限標準偏差 $s_{\text{unrestricted}}$ を知っている（または推定している）ことが必要である。興味のある母集団は、メタ分析のリサーチクエスチョンによって決定される。

例えば、**高齢者**における年齢と認知機能の関係を調べたい場合、65歳以上の高齢者（一般的に研究において「高齢者」はこのように定義される）の大規模代表サンプルにおける標準偏差の推定値を検索することが考えられる。もちろん、これは範囲限定であるが、メタ分析で扱う研究集団を反映しているため、年齢を**重要な**範囲に限定している。

範囲制限を補正するためには、制限されていない母集団の標準偏差 $s_{\text{unrestricted}}$ と、本研究で制限した変数の標準偏差 $s_{\text{restricted}}$ の比である $U$ を計算する必要がある。


\begin{equation}
U =  \frac{s_{\text{unrestricted}}}{s_{\text{restricted}}}
(\#eq:es43)
\end{equation}

$s_{\text{unrestricted}}$ の値は、例えば、興味のある変数を評価した過去の代表的な研究から得ることができる。そして、$U$ を用いて、この式で相関の値 $r_{xy}$ を補正することができる。


\begin{equation}
{r_{xy}}_c = \frac{U\times r_{xy}}{\sqrt{(U^2-1)r_{xy}^2+1}} 
(\#eq:es44)
\end{equation}


これにより、補正後の相関 ${r_{xy}}_c$ を求めることができる。また、同じ式で SMD の補正版も計算できる。


\begin{equation}
\text{SMD}_c = \frac{U\times \text{SMD}}{\sqrt{(U^2-1)\text{SMD}^2+1}}
(\#eq:es45)
\end{equation}

また、$r_{xy}$とSMDの標準誤差も、それぞれこれらの式で補正する必要がある。


\begin{equation}
SE_{{r_{xy}}_c} = \frac{{r_{xy}}_c}{r_{xy}}SE_{r_{xy}}
(\#eq:es46)
\end{equation}


\begin{equation}
SE_{{\text{SMD}}_c} = \frac{{\text{SMD}}_c}{\text{SMD}}SE_{\text{SMD}}
(\#eq:es47)
\end{equation}

\index{Hedges' \textit{g}}
\index{Fisher's \textit{z}}

相関やSMDを補正した後、${r_{xy}}_c$ を Fisher's $z$ に変換したり（Chapter \@ref(pearson-cors) ）、$\text{SMD}_c$ を Hedges' $g$ に変換するなど（Chapter \@ref(hedges-g) ）、よくある変換を行うことができるようになっている。では、 _R_ を使った補正を試してみよう。

```{r}
# 補正するための相関関係を定義
r_xy <- 0.34
se_r_xy <- 0.09

# 指定 SD と非制限 SD を定義
sd_restricted <- 11
sd_unrestricted <- 18

# U を計算
U <- sd_unrestricted/sd_restricted

# 相関を補正
r_xy_c <- (U*r_xy)/sqrt((U^2-1)*r_xy^2+1)
r_xy_c

# 標準誤差を補正
se_r_xy_c <- (r_xy_c/r_xy)*se_r_xy
se_r_xy_c

```


他の Hunter and Schmidt の調整と同様に、範囲制限の補正は、他の研究分野よりもある研究分野でより一般的に見られるものである。範囲制限の補正を適用する場合、メタ分析における**すべての**効果量に対して補正を実行することが重要である。技術的には、すべてのメタ分析で範囲制限の補正を行うことは可能であるが、多くの場合、これは必要ではない。

実際には、各研究がメタ分析の範囲を完全に表現していることはほとんどない。実際、メタ分析の目的は、個々の研究の結果を**超える**ことである。したがって、範囲制限の補正は、いくつかの研究の範囲が大きく制限されている場合にのみ必要となる場合がある。

\index{Psychometric Meta-Analysis}\index{計量心理学的メタアナリシス}

```{block, type='boxinfo'}
**更なる学習**

\vspace{2mm}

このガイドでは、信頼性の低さと範囲制限に関する補正のみを取り上げる。なぜなら、これらの問題は実際に最もよく見られるからである。しかし、Hunter and Schmidt は、他にも様々な種類の誤差補正を提案している。いくつかの追加手法とともに、この手法は、**心理測定メタ分析** (psychometric meta-analysis) と呼ばれることもある。

Hunter and Schmidt の方法について詳しく知りたい方は、彼らの著書である **Methods of Meta-Analysis** [@hunter2004methods] がわかりやすく、包括的な概要を提供しているので、参照されたい。Borenstein et al. [-@borenstein2011introduction] の38章にも、短い紹介がある。

Hunter and Schmidt の手法の多くは、[**{psychmeta}**](https://psychmeta.com/) [@psychmeta] と呼ばれる _R_ パッケージにも実装されている。

```

<br></br>

## よくある問題

---

この章では、効果量を計算する際に、実際によく直面する問題にもう少し時間を割きたいと思いる。まず、効果量のデータが異なる形式で報告されている場合にどうすればよいかを説明する。その後、後のステップでメタ解析のプーリングに影響を与える解析単位の問題を検討する。

<br></br>

### 効果量のデータ形式が異なる {#es-formats-different}

---

\index{Analysis of Variance}\index{分散分析}

前の章で効果量の計測方法について説明したとき、データセットの列として必要な変数の種類についても触れた。これらの変数は、 _R_ 関数が効果量を計算し、メタ分析を実行するために必要である。例えば、群間標準化平均差のメタ分析を計算するためには、両群の平均値、標準偏差、サンプルサイズを準備する必要がある。

すべての研究からこの情報を抽出することができれば、すべてがうまくいく。しかし、実際には、すべての研究が適切な形式で結果を報告しているわけではないことにすぐに気がつくだろう。例えば、2群の生データを報告せず、標準化平均差の計算値とその信頼区間だけを報告する研究もある。また、2群間の差を調べる$t$-検定や**分散分析**（ANOVA）の結果のみを報告する研究もある。

このような場合、メタ分析に生の効果量データを使うことができなくなることがよくある。その代わりに、各研究の効果量をあらかじめ計算して、それをプールする必要がある。メタ分析に最低限必要な情報は、研究の効果量と標準誤差であることは、Chapter \@ref(what-is-es) ですでに確認した。したがって、結果を効果量と標準誤差の推定値に変換することができれば、その研究を取り入れることができるのである。Chapter \@ref(es-calc) では、他のタイプの報告データから効果量を導き出すのに役立つ効果量コンバータをいくつか紹介している。

しかし、これらのツールを使っても、効果量が算出できない研究がある可能性がある。そのような場合に残された方法としては、「研究選択」の章で述べたように、それぞれの論文の著者に何度も連絡を取り、効果量を算出するために必要なデータを提供してもらえないかお願いすることである。それでもダメなら、その研究は除外するしかない。

Chapter \@ref(pre-calculated-es) では、 _R_ の特殊な関数である `metagen` について学ぶ。この関数を使うと、事前に計算された効果量のデータをメタ分析することが可能である。この関数を使うには、データセットに以下の列を用意する必要がある。

* **`TE`**. 各研究の効果量の計算値。
* **`seTE`**. 各効果量の標準誤差。
 
<br></br>


### 分析単位問題 {#unit-of-analysis}

---

\index{Unit-of-Analysis Problem}\index{分析単位問題}\index{分析単位問題}

メタ分析において、1つの研究が2つ以上の効果量に寄与することは珍しいことではない。特に、(1)ある研究が2つ以上のグループを含んでいる、(2)ある研究が2つ以上の道具を使って結果を測定している、などの場合がある。どちらの場合も問題がある。メタ分析において、研究が複数の効果量を寄与する場合、メタ分析における各効果量は**独立**であるという中核的な仮定の1つに違反した [@higgins2019cochrane, chapters 6.2 and 23; @borenstein2011introduction, chapter 25]。この仮定が満たされない場合、**分析単位** (unit of analysis) の問題を扱っていることになる。

\index{Double-Counting}\index{二重カウント}

例えば、治療Aを検査する群、治療Bを投与する群、そして対照群Cがある。この研究では、**2**個の効果量を計算することが可能である。結果のデータによって、これらはリスク比、オッズ比、または発生率比、あるいは標準化平均差になる。治療Aと対照を比較する効果量 $\hat\theta_{\text{A-C}}$ と、対照と比較した治療Bの効果を表す効果量 $\hat\theta_{\text{B-C}}$ の2つがある。$\hat\theta_{\text{A-C}}$ と $\hat\theta_{\text{B-C}}$ の両方を同じメタ分析に含めると、Cの情報が2回含まれているため、これらの効果量は独立したものではない。この問題は、**二重カウント**とも呼ばれる。

Cの二重カウントのため、2つの効果量は**相関**がある。サンプルサイズが全群で等しい場合、この相関は $r =$ 0.5 であることがわかる [@borenstein2011introduction, chapter 25]。これは、AとBが独立した群であるため、相関がないためである。しかし、両方の効果量における対照群は同一であるため、完全な相関は1となり、その中点は0.5となる。群の二重カウントは、影響を受ける効果量の精度（すなわち、標準誤差）を過大評価することになる。これは、メタ分析でこれらの効果に与える重みを増大させ、最終的に結果を歪めることになる。この問題に対処するために、3つの方法がある。

1. **共有群のサンプルサイズを分割する**。これは、効果量を計算するときに、C群のサンプルサイズ（例えば$n =$ 200）をAとの比較とCとの比較で均等に分けることを意味する。二値結果のデータを扱う場合は、イベントの数も均等に分割する。この例では、先ほどと同じように2つの効果量を計算したが、今度はCが両方の計算で100人のみで構成されているように見せかける。このアプローチにより、効果量の精度がダブルカウントのために人為的に高くなるという問題が解決される。しかし、効果量が相関したままなので、まだ最適とは言えない [@higgins2019cochrane, 23.3.4]。

2. **群を削除する**。非常に腕力を使う手法は、単純に1つの比較、例えば $\hat\theta_{\text{B-C}}$ をメタ分析から完全に削除することである。これは分析単位の問題を解決するものの、新たな問題を引き起こす。効果量を1つ捨てるだけだと、関連する可能性のある情報を失ってしまうのである。

3. **群を合体する**。この手法は、2つの群の結果を組み合わせて、1つの比較しか残らないようにするものである。この例では、AとBのデータを組み合わせて、プールした結果をCと比較することを意味する。これは、両群の参加者数とイベント数を合計すればよい二値アウトカムデータでは比較的簡単なことである。しかし、平均値や標準偏差のような連続的なデータでは、少し複雑になる。「各種ツール」の Chapter \@ref(pool-groups) には、このようなデータを結合するための _R_ 関数がある。群を合体することで、二重カウントや効果量の相関を回避することが可能である。そのため、この方法はコクランでも推奨されている  [@higgins2019cochrane, chapter 23.3.4]。とはいえ、この方法にも欠点がある。2群があまりにも異なり、実際には比較できないものを一緒にしてしまう可能性があるのである。Aは最先端の介入、Bはエビデンスベースの乏しい時代遅れのアプローチでなど、A群とB群の治療がまったく異なることもある。この2つの治療を組み合わせても効果が見られない場合、これが両方のタイプの介入に当てはまるのか、Bの効果のなさが単にAの効果を希釈したのかを切り分けるのはほぼ不可能である。したがって、アプローチ（1）と（2）は、2群があまりにも異質な場合に使用される。

\index{Multilevel Meta-Analysis}\index{マルチレベルメタ分析}

分析単位の問題は、ある研究が複数の測定器を用いて結果を測定した場合にも発生する。これは、解析したい変数をどのように選ぶべきかを決定する明確な「ゴールド・スタンダード」がない場合によくあることである。これらの測定のそれぞれについて効果量を計算しメタ分析に含めると、二重カウントになってしまう。さらに、効果の測定に同じサンプルが使用されるため、効果量には相関がある。この状況に対処するためには、3つのアプローチがある。

- まず、単純に1つの研究につき1つの測定器を選択する方法である。この選択は、体系的かつ再現可能な方法で行うことが重要である。できることといえば、解析計画書（Chapter \@ref(analysis-plan)）において、メタ解析のための測定器の階層を定義しておくくらいである。この階層は、特定の測定器の信頼性に関する過去の証拠に基づくことも、どのタイプの測定器が研究課題の内容を最もよく反映しているかに基づくこともできる。そして、この階層によって、複数の測定器が利用可能な場合に、どの測定器を選択するかを明確に決定する。

- また、計算された効果量を用いてそれらを集約し、各研究が1つの効果量（集約されたもの）しか提供しないようにすることも可能である。これはやや「総当り」的なアプローチである。この場合、効果量が研究内でどの程度強く相関しているかを特定する必要があるが、この値は通常知られていない。Chapter \@ref(aggregate-es) では、あらかじめ計算された効果量を、各研究について1つの推定値に集約できる関数を紹介する。

- 第三のアプローチは、利用可能なすべての測定器からのデータを含み、メタ分析において研究が1つ以上の効果量に寄与するという事実を説明できるメタ分析モデルを使用することである。これは「３レベル」メタ分析モデルによって実現されるもので、Chapter \@ref(multilevel-ma) で検討する。

$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block, type='boxquestion'}
**知識を試そう！**

\vspace{4mm}

1. 効果量という言葉に明確な定義はあるか？人々は、効果量という言葉で何を指すか？

\vspace{-2mm}

2. 観測された効果量が母集団の真の効果量から乖離する主な理由を挙げなさい。それはどのように定量化できるのか。

\vspace{-2mm}

3. なぜ大規模な研究は小規模な研究よりも真の効果の推定に優れているのか？

\vspace{-2mm}

4. 効果量の指標は、どのような基準を満たせばメタ分析に使えるのか？

\vspace{-2mm}

5. 標準化平均差 (Standardized Mean Difference, SMD) が1であることは何を表しているのか？

\vspace{-2mm}

6. 比（オッズ比など）に基づく効果量をプールするためには、どのような変換が必要か。

\vspace{-2mm}

7. 効果量補正の種類を3つ挙げよ。

\vspace{-2mm}

8. 分析単位の問題はどのような場合に発生するか？どうすれば回避できるか？


\vspace{4mm}



**問題の解答は、本書の巻末 [Appendix A](#qanda3) にある。**

```

<br></br>

## 概要

* 効果量は、メタ分析の構成要素である。メタ分析を行うには、少なくとも効果量とその標準誤差の推定値が必要である。

* 効果量の標準誤差は、その研究による効果量の推定がどれだけ正確であるかを表している。メタ分析では、精度の高い効果量は、真の効果をより良く推定できるため、より高い重みが与えられる。

* メタ分析で使用する効果量には様々なものがある。一般的なものは、「1変数」の関係尺度（平均や割合など）、相関、（標準化）平均差、そしてリスク比、オッズ比、発生率比などである。

* 効果量には、測定誤差や範囲制限などによるバイアスが生じることがある。標準化平均差の小サンプルバイアス、信頼性の低さによる減衰、範囲制限の問題など、いくつかのバイアスを補正する公式がある。

* その他のよくある問題としては、効果量を計算するために必要なデータを異なる形式で報告している研究、また、複数の効果量を報告している研究で生じる分析単位の問題などがある。


<!--chapter:end:05-effect_sizes-ja.Rmd-->

# 効果量のプール {#pooling-es}



<img src="_figs/pooling_es.jpg" />

<br></br>

<span class="firstcharacter">険</span> しい道はもう過ぎ去った。幸いなことに、私たちは今、すべてのメタ分析の核となる部分、すなわち効果量のプールに到達している。この章から直接始めるという誘惑には勝つことができたと思われる。本書では、研究課題の定義、研究データの検索・選択・抽出のガイドライン、効果量の作成方法など、様々なトピックを既に取り上げている。

徹底的な準備は優れたメタ分析の重要な要素であり、これから続くステップで大いに役立つことだろう。これまでの章に費やした時間は、十分に投資されたと断言できる。

\index{meta Package}

_R_ で効果量をプールすることができるパッケージは数多く存在する。ここでは、Chapter \@ref(packages) で既にインストールした **{meta}** パッケージの機能を中心に説明する。このパッケージは非常に使い勝手が良く、数行のコードでほぼ全ての重要なメタ分析結果を得ることが可能である。前章では、効果の大きさはアウトカムによって異なる「フレーバー」があることを取り上げた。 **{meta}** パッケージには、これらの効果量のそれぞれのメトリクス（訳注：標準化平均差やオッズ比など）について特化したメタ分析関数が含まれている。また、全ての関数はほぼ同じ構造をしている。

このように、 **{meta}** の動作の基本を理解すれば、どの効果量に注目しても、メタ分析のコーディングは簡単にできるようになる。この章では、 **{meta}** パッケージの一般的な構造について説明する。もちろん、パッケージのメタ分析機能についても、実例を用いてより詳しく解説する。

 **{meta}** パッケージでは、効果量がプールされる方法について、多くの詳細を微調整することが可能である。以前述べたように、メタ分析には多くの 「研究者の自由度」が伴う。適用できる統計手法やアプローチに関する選択肢は無数にあり、ある手法が他の手法より優れているかどうかは、しばしば文脈に依存する。

\index{Fixed-Effect}\index{固定効果モデル}
\index{Random-Effects Model}\index{ランダム効果モデル}

したがって、 _R_ で分析を始める前に、メタ分析の統計的な前提条件と、その背後にある数学について基本的な理解を深める必要があるのである。メタ分析の背後にある「考え方」についても触れておくことも重要である。統計学では、この「考え方」は**モデル**と訳されるが、メタ分析のモデルがどのようなものかを見ていきる。

これから見ていくように、メタ分析の性質上、すぐに基本的な判断をしなければならない。**固定効果モデル**か**ランダム効果モデル**のどちらかを仮定しなければならないのである。他の分析仕様と合わせて、この2つのモデルのうちどの文脈でどちらがより適切なのか、情報に基づいて決定を下すためには、メタ分析プールの背後にある概念についての知識が必要である。

<br></br>

## 固定効果モデルとランダム効果モデルの比較 {#fem-rem}



メタ分析モデルを規定する前に、まず統計モデルとは実際にどのようなものかを明らかにする必要がある。統計学には「モデル」がたくさんあり、「モデル」と言う言葉は聞いたことがあるだろう。「線形モデル」「一般化線形モデル」「混合モデル」「ガウス加法モデル」「構造方程式モデル」などがある。

統計学においてモデルが遍在していることは、この概念がいかに重要であるかを示している。統計ツールボックスはすべて、何らかの形でモデルが基礎となっている。$t$ 検定、ANOVA、回帰の背後にはモデルがある。すべての仮説検定には、それに対応する統計モデルがある。

統計モデルを定義するとき、すでに与えられている情報から始める。これは文字通り、**データ**^["data" はラテン語の **datum** に由来し、「与えられたもの」を意味する] である。メタ分析では、データは、含まれる研究で観察された効果量である。私たちのモデルは、これらの観察されたデータが生成されたプロセスを記述するために使用される。

データは**ブラックボックス**の産物であり、私たちのモデルはそのブラックボックスの中で何が起こっているかを明らかにすることを目的としている。

```{r model, out.width='50%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/model_concept_sep.png')
```


一般に、統計モデルとは特殊な「理論」のようなものである。モデルは、観測されたデータを生成したメカニズムを説明しようとするもので、特にそのメカニズム自体が直接観測できない場合に有効である。特に、そのメカニズム自体が直接観測できない場合、そのメカニズムを説明しようとするものである。

モデルが説明的であるという性格は、現代の統計学に深く根付いており、メタ分析も例外ではない。説明のための手段としてのモデルの概念化は、統計「文化」の特徴である。Breiman [-@breiman2001statistical] の有名に推定によると、全統計学者の98％が信奉しているようである。

統計モデルを指定することで、データの背後にある「現実」の近似的な表現を見つけようとしている。観測された結果に基づいて、すべての研究の根底にある**真の**効果量を見つける方法を説明する数式が欲しいのである。Chapter \@ref(what-are-mas) で学んだ通り、メタ分析の最終的な目的は、効果量が研究ごとに異なる場合でも、研究**全体**を特徴づける1つの数値を見つけることである。したがって、メタ分析モデルは、全体的な効果は1つであるにもかかわらず、観察された研究結果がなぜ、どの程度異なるのかを説明する必要がある。

まさにこの問いに答えようとするモデルとして、**固定効果モデル**と**ランダム効果モデル**の2つがある。両者は異なる仮定に基づいているが、すぐにわかるように、両者の間には強い結びつきがある。

<br></br>

### 固定効果モデルの場合 {#fem}


\index{Fixed-Effect}\index{固定効果モデル}
\index{Sampling Error}\index{サンプル誤差}

固定効果モデルは、すべての効果量が単一の均質な集団に由来すると仮定している。これは、すべての研究が、同じ**真の**効果量を共有していることを述べている。この真の効果は、メタ分析で計算したい全体的な効果量で、$\theta$ と表記される。

固定効果モデルによると、ある研究 $k$ の観測された効果量 $\hat\theta_k$ （「シータ・ハットk」と読む）が $\theta$ から逸脱する唯一の理由は、そのサンプル誤差 $\epsilon_k$ （「イプシロン・k」と読む）のためである。固定効果モデルは、ブラックボックスの中身である研究の効果量の違いを生み出す過程が単純で、すべての研究が同じ真の効果量の推定者であることを教えてくれる。しかし、すべての研究は、無限に大きな研究集団から多少なりとも大きなサンプルを抽出することしかできないため、結果はサンプリングエラーに悩まされることになる。このサンプル誤差は、観察された効果が全体的な真の効果から乖離する原因となる。

このような関係を表現することが可能である [@borenstein2011introduction, chapter 11]。

\begin{equation}
\hat\theta_k = \theta + \epsilon_k 
(\#eq:pes1)
\end{equation}

注意深く見ると、この数式が不思議なことに Chapter \@ref(what-is-es) の数式と似ていると思われるだろう。それは間違いではない。先ほどの式では、ある研究 $k$ の観測された効果量 $\hat\theta_k$ は、その研究の真の効果量 $\theta_k$ の推定値であり、研究のサンプル誤差 $\epsilon_k$ が負担している、と定義する。

先ほどの式と固定効果モデルの式では、ほんのわずかだが重要な違いがある。固定効果モデルの式では、真の効果量を $\theta_k$ ではなく、$\theta$ で表し、添え字 $k$ を削除している。

これまでは、個々の研究 $k$ の真の効果量についてのみ記述してきた。固定効果モデルでは、さらに一歩踏み込む。研究 $k$ の真の効果量を見つけると、この効果量は $k$ だけでなく、メタ分析における**すべての**研究についても真であることを教えてくれる。**ある研究**の真の効果量 $\theta_k$ と、**全体**のプール効果量 $\theta$ は、**同一**である。


```{block2, type='boxinfo'}
**固定効果モデル**の背景にある考え方は、観察された効果量は研究ごとに異なるかもしれないが、それはサンプリング誤差のためだけである、というものである。実際には、真の効果量はすべて同じであり、**固定**されている。
```



固定効果モデルの式から、観測された効果量 $\theta_k$ が真の全体効果から乖離する理由はただ一つ、サンプル誤差 $\epsilon_k$ によることがわかる。サンプルエラーとサンプルサイズには関連性があることは、Chapter \@ref(what-is-es) で既に述べた。すべての条件が同じであれば、サンプルサイズが大きくなれば、サンプリングエラーは小さくなる。また、サンプリングエラーは**標準誤差**で数値で表すことができ、これもサンプルサイズが大きくなると小さくなることを学ぶ。

研究の真の全体効果量は不明であるが、この関係を利用して真の全体効果 $\hat\theta$ の最良の推定値に到達することが可能である。したがって、標準誤差が小さい研究は、標準誤差が大きい研究よりも、真の全体効果のより良い推定値になるはずである。

これをシミュレーションで説明することが可能である。前に使った `rnorm` 関数を用いて、真の全体効果が $\theta = 0$ である研究の選択をシミュレートしよう。複数のサンプルを取るが、サンプルサイズを変えて、標準誤差が「観察された」効果間で異なるようにする。シミュレーションの結果は、Figure \@ref(fig:funnel1) で見ることが可能である。

```{r funnel1, fig.height=5, fig.width=5, fig.cap='効果量と標準誤差の関係', echo=F, fig.align='center', message=FALSE, out.width="50%"}
library(plotrix)
library(data.table)
library(ggplot2)

set.seed(1234)
res = list()
for (i in 5:54){
  vec = list()
  for (x in 1:50){
    dat = rnorm(i, 0, sd = 10)
    vec[[x]] = data.frame(value = mean(dat),
                          SE = std.error(dat))
  }
  vec = do.call(rbind, vec)
  res[[i-4]] = vec
}

res = rbindlist(res)

ggplot(data = res, aes(x = value, y = log(SE))) +
  geom_point(alpha = 0.5, size = 0.8) +
  scale_y_reverse() +
  geom_vline(xintercept = 0, color = "gray", size = 2, alpha = 0.5) +
  theme_classic() +
  xlab("Effect Size") +
  ylab("log-Standard Error") +
  theme(panel.background = element_rect(fill = "#FFFEFA",
                                        size = 0),
        plot.background = element_rect(fill = "#FFFEFA",
                                       size = 0))


```


シミュレーションの結果、興味深いパターンが示された。サンプリング誤差が小さい効果量は、真の効果量 $\theta = 0$ の周りに凝集していることがわかる。y軸の標準誤差^[パターンがわかりやすいように標準誤差を対数変換してからプロットしている]が大きくなると、効果量の**分散**が大きくなり、観測された効果が真の効果からどんどんずれていくことがわかる。

この挙動は、固定効果モデルの式で予測することが可能である。標準誤差が小さい研究は、サンプル誤差が小さく、全体的な効果量の推定値が真実に近い可能性が高いことが分かっている。

\index{Weight}\index{重み}

観測された効果量はすべて真の効果の推定量であるが、あるものは他のものよりも優れていることを見てきた。したがって、メタ分析で効果をプールする場合、より高い**精度**（すなわち、より小さい標準誤差）を持つ効果量に、より大きな**重み**を与える必要がある。固定効果モデルでプール効果量を計算する場合は、全研究の**加重平均**を使用する。

各研究 $k$ の重み $w_k$ を計算するには、標準誤差を用い、それを二乗して各効果量の**分散** $s^2_k$ を求めることができる。分散が**小さい**ほど精度が高いことを示すので、分散の**逆数**を用いて各研究の重みを決定する。

\begin{equation}
w_k = \frac{1}{s^2_k}
(\#eq:pes2)
\end{equation}


重みがわかれば、加重平均を計算し、真のプール効果 $\hat\theta$ を推定することが可能である。各研究の効果量 $\hat\theta_k$ に対応する重み $w_k$ を掛け、メタ分析の全研究 $K$ で結果を合計し、すべての個々の重みの合計で割ればよい。

\begin{equation}
\hat\theta = \frac{\sum^{K}_{k=1} \hat\theta_kw_k}{\sum^{K}_{k=1} w_k}
(\#eq:pes3)
\end{equation}
\index{Inverse-Variance Weighting}\index{逆分散重み付け}
\index{Mantel-Haenszel Method}\index{Mantel-Haenszel 法}
\index{Peto 法}\index{Peto Method}


この方法は、メタ分析で平均効果を計算する最も一般的な方法である。分散の逆数を使用するので、しばしば **逆分散重み付け** (Inverse-Variance Weighting) または単に**逆分散メタ分析**と呼ばれる。

二値効果量データの場合、加重平均を計算する方法として、**Mantel-Haenszel** 法、**Peto** 法、あるいは Bakbergenuly によるサンプルサイズ加重法 [-@bakbergenuly2020methods] などがある。これらの方法については、Chapter \@ref(pooling-or-rr) で説明する。

**{meta}**  パッケージを使うと、固定効果メタ分析がとても簡単に可能である。しかし、その前に _R_ で 「手動で」逆分散プーリングを試してみよう。この例では、Chapter \@ref(data-prep-R) でインポートした `SuicidePrevention` データセットを使用する。

\index{dmetar Package}
```{block2, type='boxdmetar'}
**"SuicidePrevention" データセット**

`SuicidePrevention` のデータセットも **{dmetar}** パッケージに直接含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(SuicidePrevention)` を実行すると、自動的に _R_ 環境にデータセットが保存される。これでデータセットが利用できる。もし、**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/suicideprevention.rda)から _.rda_ ファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R Studio ウィンドウでクリックするとインポートすることができる。
```


\index{esc Package}
\index{Standardized Mean Difference}\index{標準化平均差}
\index{Hedges' \textit{g}}

`SuicidePrevention` のデータセットには、生の効果量が含まれているので、まず効果量を計算する必要がある。この例では、小サンプル調整済み標準化平均差（Hedges' $g$）を計算する。これを行うには、 **{esc}** パッケージの `esc_mean_sd` 関数を使用する（Chapter \@ref(b-group-smd)）。

この関数には `es.type` という追加の引数があり、これを用いてスモールサンプル補正を行うかどうかを指定することが可能である（`es.type = "g"` と指定; Chapter \@ref(hedges-g)）。

```{r, message=F, eval=F}
# dmetar, esc and tidyverse をロード
library(dmetar)
library(esc)
library(tidyverse)

# dmetar からデータセットをロード
data(SuicidePrevention)

# Hedges' g と標準誤差を計算
# - 研究名を "study" に保存
# - その後、パイプを使って
#   結果をデータフレームに変換
SP_calc <- esc_mean_sd(grp1m = SuicidePrevention$mean.e,
                       grp1sd = SuicidePrevention$sd.e,
                       grp1n = SuicidePrevention$n.e,
                       grp2m = SuicidePrevention$mean.c,
                       grp2sd = SuicidePrevention$sd.c,
                       grp2n = SuicidePrevention$n.c,
                       study = SuicidePrevention$author,
                       es.type = "g") %>% 
                     as.data.frame()

# データの glimpse を見よう
# データは Hedges' g ("es") と標準誤差 ("se") を含む
glimpse(SP_calc)

```
```
## Rows: 9
## Columns: 9
## $ study       <chr> "Berry et al.", "DeVries et al.", "Fleming et al." …
## $ es          <dbl> -0.14279447, -0.60770928, -0.11117965, -0.12698011 …
## $ weight      <dbl> 46.09784, 34.77314, 14.97625, 32.18243, 24.52054 …
## $ sample.size <dbl> 185, 146, 60, 129, 100, 220, 120, 80, 107data
## $ se          <dbl> 0.1472854, 0.1695813, 0.2584036, 0.1762749 …
## $ var         <dbl> 0.02169299, 0.02875783, 0.06677240, 0.03107286 …
## $ ci.lo       <dbl> -0.4314686, -0.9400826, -0.6176413, -0.4724727 …
## $ ci.hi       <dbl> 0.145879624, -0.275335960, 0.395282029 …
## $ measure     <chr> "g", "g", "g", "g", "g", "g", "g", "g", "g"

```

```{r, message=F, eval=F}
# 各研究の 逆分散重みを計算
SP_calc$w <- 1/SP_calc$se^2

# 重みを使って効果量をプール
pooled_effect <- sum(SP_calc$w*SP_calc$es)/sum(SP_calc$w)
pooled_effect

```

```
## [1] -0.2311121
```


計算の結果、固定効果モデルを仮定したプール効果量は $g \approx$ -0.23 であった。

<br></br>


### ランダム効果モデル {#rem}


\index{Random-Effects Model}\index{ランダム効果モデル}


これまで見てきたように、固定効果モデルは、メタ分析データの成り立ちや、効果をプールする方法を概念化する一つの方法である。しかし、重要なのは、この方法が現実を適切に反映しているかということである。

固定効果モデルは、すべての研究が均質な母集団の一部であり、観察された効果の差の唯一の原因は研究のサンプリング・エラーであると仮定している。もし、サンプリング・エラーなしに各研究の効果量を計算するとしたら、すべての真の効果量は完全に同じになる。

\index{Heterogeneity}\index{異質性}

この考え方を現実的に確認すると、固定効果モデルの仮定は、多くの実世界のアプリケーションにおいて単純すぎる可能性があることがわかる。メタ分析における研究が常に完全に均質であることは、単純に非現実的である。たとえ微妙な違いであっても、研究内容が異なることはよくある。興味のあるアウトカムは、異なる方法で測定されただろう。治療の種類や強さ、長さが全く同じでないこともある。研究の対象者が全く同じでなかっただろうし、使用した対照群に違いがあっただろう。

メタ分析に含まれる研究は、これらの側面のうちの1つだけでなく、同時に複数の側面で異なる可能性がある。もしそうであれば、真の効果におけるかなりの研究間の**異質性**が予想される。

これらのことは、固定効果モデルの有効性を疑わせるものである。例えば、ある研究が異なるタイプの治療法を用いていた場合、一方の治療法が他方の治療法よりも効果的であることは、ごく普通のことと思われる。このような違いが、研究のサンプル誤差によるノイズに過ぎないと考えるのは、あまりに不自然なことだろう。

その逆で、研究の効果量に本当の差がある理由は無数にあるのである。ランダム効果モデルは、このような懸念に対応するものである。このモデルは、私たちのデータの背後にある現実をよりよく反映するモデルを提供してくれる。

\index{Sampling Error}\index{サンプル誤差}

ランダム効果モデルでは、効果量が単一の均質な母集団から抽出された場合よりも分散を示すという事実を考慮したいと思われる [@hedges1998fixed]。したがって、個々の研究の効果は、サンプル誤差だけによる偏差ではなく、**別の**分散の原因があると仮定する。

この追加的な分散成分は、研究が1つの集団から生じているわけではないという事実によってもたらされる。その代わり、各研究は、母集団の「宇宙」から独立に抽出されたものとみなされる。

```{block2, type='boxinfo'}
ランダム効果モデルは、真の効果量が1つだけでなく、真の効果量の**分布**があることを仮定している。したがって、ランダム効果モデルの目的は、すべての研究の1つの真の効果量を推定することではなく、真の効果量の**分布**の**平均値**を推定することである。
```


ランダム効果モデルがどのように数式で表現されるかを見てみよう。ランダム効果モデルは、固定効果モデルと同様に、観測された効果量 $\hat\theta_k$ が、サンプリングエラー $\epsilon_k$ を含む研究の真の効果量 $\theta_k$ の推定値であると仮定することから始まる。

\begin{equation}
\hat\theta_k = \theta_k + \epsilon_k 
(\#eq:pes4)
\end{equation}

このように、$\theta$ の代わりに $\theta_k$ を使っていることが、すでに重要な違いを示している。ランダム効果モデルは、$\theta_k$ が**1**個の単一研究 $k$ の真の効果量であると仮定しているだけである。このモデルでは、$\theta_k$ の他に、$\zeta_k$ （訳注: $\zeta$ は「ゼータ」と読む）で示される第二の誤差要因が存在することを仮定している。この第二の誤差の原因は、研究 $k$ の真の効果量 $\theta_k$ でさえ、平均 $\mu$ を持つ真の効果量の包括的な分布の一部に過ぎないという事実によってもたらされる。

\begin{equation}
\theta_k  = \mu + \zeta_k
(\#eq:pes5)
\end{equation}

ランダム効果モデルは、ブラックボックス [@thompson2001multilevel] の内部で、2つのプロセスの階層が起こっていることを教えてくれる：研究の観察された効果量は、サンプル誤差のためにその真の値から逸脱している。しかし、真の効果量でさえも、真の効果の宇宙からの引き出しに過ぎず、その平均 $\mu$ を、メタ分析のプール効果として推定したい。

2番目の式を1番目の式にあてじはめる（つまり、$\theta_k$ を2番目の式の定義に置き換える）ことで、ランダム効果モデルを1行で表現可能である [@borenstein2011introduction, chapter 12]。

\begin{equation}
\hat\theta_k = \mu + \zeta_k + \epsilon_k
(\#eq:pes6)
\end{equation}

この式から、観測された効果量がプール効果 $\mu$ から乖離するのは、$\zeta_k$ と $\epsilon_k$ の二つの誤差項のためであることが明らかになった。この関係を可視化したものが Figure \@ref(fig:random) である。

\index{Exchangeability Assumption}

ランダム効果モデルの重要な前提は、$\zeta_k$ の大きさは、$k$ から**独立**していることことである。つまり、ある研究の $\zeta_k$ が他の研究の $\zeta_k$ よりも高いことを**事前**に示すものは何もないと仮定する。また、$\zeta_k$ のサイズは偶然の産物だけであると仮定する。

これはランダム効果モデルの**交換可能性**の仮定として知られている [@higgins2009re; @lunn2012bugs, chapter 10.1]。データを見る前に、ある研究 $k$ で $\zeta_k$ がどの程度大きいかを知ることができるものがない限り、すべての真の効果量は交換可能であると仮定される。  


\index{Heterogeneity}\index{異質性}

```{block2, type='boxinfo'}
**どちらのモデルを使うべきか？**

\vspace{2mm}

実際には、完全に均質な研究のセレクションを見つけることは非常に稀である。これは、ベストプラクティスに従って、PICO (Chapter \@ref(research-question)) で分析範囲をできるだけ正確にしようと思っても同じである。

\vspace{4mm}

医学や社会科学など多くの分野では、ある程度の研究間異質性が予測されるため、**常に**ランダム効果モデルを用いるのが通例である。固定効果モデルは、研究間異質性を検出できなかった場合（異質性の検出方法については、Chapter \@ref(heterogeneity) で説明する）、**および**真の効果が固定であると仮定する十分な理由がある場合にのみ使用することができる。これは、例えば、ある研究の正確な複製だけを検討する場合や、1つの大きな研究の部分集合をメタ分析する場合などである。言うまでもなく、このようなことはめったにないため、固定効果モデルを「実際に」適用することはむしろ稀である。

\vspace{4mm}

a priori にランダム効果モデルを用いるのが通例であるとしても、このアプローチに議論されないわけでもない。ランダム効果モデルは、メタ分析の全体効果を計算する際に、小規模な研究にたいしてより注意を払う [@schwarzer2015meta, chapter 2.3]。しかし、特に小規模研究はバイアスがかかっていることが多い（Chapter \@ref(small-study-effects) 参照）。そのため、固定効果モデルが望ましいとする意見もある（場合もある）[@poole1999random; @furukawa2003low] 。


```


```{r random, fig.cap='ランダム効果モデルのパラメータを示す図。', out.width='60%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rem_sep2.png')
```


<br></br>


#### 研究間異質性の推定値 {#tau-estimators}


\index{Weight}\index{重み}


ランダム効果モデルに関連する課題は、誤差 $\zeta_k$ を考慮に入れなければならないことである。これを行うには、真の効果量の分布の**分散** を推定する必要がある。この分散は、$\tau^2$（タウ２乗）として知られている。いったん $\tau^2$ の値がわかれば、各効果量の逆分散の重みを決定するときに、研究間の異質性を含めることが可能になる。

したがって、ランダム効果モデルでは、各観測の調整済み**ランダム効果重み** $w^*_k$ を計算する。その式は次のようになる。

\begin{equation}
w^*_k = \frac{1}{s^2_k+\tau^2} 
(\#eq:pes7)
\end{equation}
\index{Inverse-Variance Weighting}\index{逆分散重み付け}

調整済みランダム効果重みを用いて、固定効果モデルを用いた場合と同様に、逆分散法を用いてプール効果量を算出する。

\begin{equation}
\hat\theta = \frac{\sum^{K}_{k=1} \hat\theta_kw^*_k}{\sum^{K}_{k=1} w^*_k}
(\#eq:pes8)
\end{equation}

この $\tau^2$ を推定する方法はいくつかあるが、そのほとんどは手作業で行うには複雑すぎる。しかし、幸運なことに、これらの推定量は **{meta}** パッケージの関数に実装されており、私たちのために自動的に計算をしてくれるのである。以下は、最も一般的な推定量と、それらが **{meta}** で参照されるコードのリストである。

\index{DerSimonian-Laird Estimator}\index{DerSimonian-Laird 推定法}
\index{Restricted Maximum Likelihood Estimator}\index{制限付き最尤推定}
\index{Maximum Likelihood}
\index{Sidik-Jonkman Estimator}

* **DerSimonian-Laird** (`"DL"`) 推定法 [@dersimonian1986meta]。
* **制限付き最尤推定** (Restricted Maximum Likelihood, `"REML"`) または**最尤推定** (Maximum Likelihood, `"ML"`) 法 [@viechtbauer2005bias]。
* **Paule-Mandel** (`"PM"`) 法 [@paule1982consensus]。
* Paule-Mandel 法と実質的に同じである **Empirical Bayes** (`"EB"`) 法 [@sidik2019note]。
* **Sidik-Jonkman** (`"SJ"`) 推定量 [@sidik2005simple]。

これらの推定量のうち、どの推定量が異なる種類のデータに対して最も有効であるかは、現在進行中の研究課題である。研究数 $k$、各研究の参加者数 $n$、研究ごとに $n$ がどの程度異なるか、$\tau^2$ がどの程度大きいかなどのパラメータに依存することが多い。このような様々なシナリオの下での $\tau^2$ 推定量のバイアスを分析した研究がいくつかある [@veroniki2016methods; @viechtbauer2005bias; @sidik2007comparison; @langan2019comparison]。

\index{Review Manager (RevMan)}
\index{Comprehensive Meta-Analysis (CMA)}

おそらく、最もよく使われている推定量は、DerSimonian and Lairdによるものであろう。この推定量は、**RevMan**（Cochraneが開発したプログラム）や **Comprehensive Meta-Analysis** など、過去にメタ分析者がよく使用したソフトウェアに実装されている。また、 **{meta}** でもデフォルトの推定量として使用されている。この歴史的な遺産により、「ランダム効果モデルの使用」が DerSimonian-Laird 推定量の使用と同義で使用されている研究論文をよく見かける。

しかし、特に研究数が少なく異質性が高い場合、この推定量に偏りが生じることが分かっている [@hartung1999alternative; @hartung2001refined; @hartung2001tests; @follmann1999valid; @makambi2004effect]。研究数が少なく異質性の高いメタ分析はよくあることなので、これはかなり問題である。

\index{Paule-Mandel Estimator}
\index{metafor Package}
\index{Sidik-Jonkman Estimator}
\index{Restricted Maximum Likelihood Estimator}\index{制限付き最尤推定}

Veroniki ら [-@veroniki2016methods] は、概要論文において、様々な$\tau^2$推定量の頑健性に関するエビデンスをレビューしている。彼らは、二値・連続効果量のデータには Paule-Mandel 法を、連続アウトカムには制限付き最尤推定量を推奨している。制限付き最尤推定量は、 **{metafor}** パッケージで使用されるデフォルトの方法でもある。

Langan ら [-@langan2019comparison] による最近のシミュレーション研究でも同様の結果が得られているが、研究のサンプルサイズが大きく異なる場合、Paule-Mandel 推定量は最適でない可能性があることが分かっている。また、Bakbergenuly ら [-@bakbergenuly2020methods] の研究では、特に研究数が少ない場合には Paule-Mandel 推定量がよく適していることが分かっている。Sidik-Jonkman 推定量は、**モデル誤差分散法**としても知られているが、$\tau^2$が非常に大きい場合のみ適している [@sidik2007comparison]。

```{block2, type='boxinfo'}
**どの推定法を使うべきか？**

\vspace{2mm}

どの推定法を使うべきかという鉄則はない。多くの場合，様々な推定量によって得られる結果にはわずかな違いしかないので，この問題はあまり気にする必要はないだろう．

\vspace{4mm}

疑いがあれば、いつでも異なる $\tau^2$ 推定量を使って分析を再実行し、結果の解釈が変わるかどうかを確認することができる。以下は、メタ分析における暫定的なガイドライン。

1. 連続的なアウトカムデータに基づく効果量については、まず制限付き最尤推定量を使用することができる。

2. バイナリ効果量のデータでは、サンプルサイズに極端なばらつきがなければ、最初に Paule-Mandel 推定量を選択すると良い。

3. サンプル内の効果の不均一性が非常に大きいと信じる十分な理由があり、偽陽性を避けることが非常に高い優先度を持つ場合、Sidik-Jonkman推定量を使用することができる。

4. 他の人があなたの結果を _R_ 外でできるだけ正確に再現できるようにしたい場合は、DerSimonian-Laird 推定量が選択される方法である。

\vspace{2mm}

```


全体として、$\tau^2$ の推定量は2つのカテゴリに分類される。DerSimonian-Laird や Sidik-Jonkman の推定量のように、**閉形式**に基づくものもある。つまり、数式を使って直接計算することが可能である。

（制限付き）最尤推定量、Paule-Mandel推定量、経験的ベイズ推定量は、**繰り返しアルゴリズム**によって $\tau^2$ の最適値を見つける。そのため、後者の推定量では、計算結果が少し長くなることがある。しかし、ほとんどの場合、このような時間の差はせいぜいわずかなものである。

<br></br>

#### Knapp-Hartung 調整法 {#knapp-hartung}



\index{Knapp-Hartung Adjustment}\index{Knapp-Hartung 調整法}
\index{Wald 型検定}
\index{t-Distribution}\index{t-分布}

また、$\tau^2$ 推定量の選択に加えて、いわゆる Knapp-Hartung 調整法^[この手法は、「Hartung-Knapp 調整法」または「Hartung-Knapp-Sidik-Jonkman (HKSJ) 法」としても知られている]を適用するかどうかを決定しなければならない [@knapp2003improved; @sidik2002simple]。この調整は、プール効果量 $\hat\theta$ の標準誤差（したがって信頼区間）の計算方法に影響する。

Knapp-Hartung 調整法は、研究間異質性の推定値の不確実性を対照しようとするものである。プール効果の有意性検定が通常、正規分布を仮定するのに対して（いわゆる **Wald 型** 検定）、Knapp-Hartung 法は $t$ 分布に基づいている。Knapp-Hartung の調整はランダム効果モデルでのみ使用でき、通常、プール効果の信頼区間がわずかに大きくなる。

\index{Heterogeneity}\index{異質性}

```{block, type='boxreport'}
**メタ分析においてモデルの種類を報告**

\vspace{2mm}

メタ分析を報告する場合、Methods セクションに、使用したモデルの種類を明記することを強く勧める。以下はその例である。（訳注：英文論文を書くことを想定しているため、以下は訳さずそのままとしている。）

> _"As we anticipated considerable between-study heterogeneity, a random-effects model was used to pool effect sizes. The restricted maximum likelihood estimator (Viechtbauer, 2005) was used to calculate the heterogeneity variance $\tau^2$. We used Knapp-Hartung adjustments (Knapp & Hartung, 2003) to calculate the confidence interval around the pooled effect."_

```


Knapp-Hartung調整を適用することは通常賢明である。いくつかの研究 [@inthout2014hartung; @langan2019comparison] は、特に研究数が少ない場合に、これらの調整によって偽陽性の可能性を減らすことができることを示す。

しかし、Knapp-Hartung調整の使用は議論の余地がないわけではない。例えば、Wiksten ら [-@wiksten2016hartung] は、効果が非常に均質な場合、この方法は（滅多にない）反保守的な結果を引き起こすことがあると論じている。

<br></br>

## _R_ で効果量をプール {#pooling-es-r}



\index{meta Package}

学んだことを実践する時が来た。この章の残りの部分では、 _R_ で直接、異なる効果量のメタ分析を実行する方法を探る。このために使用する **{meta}** パッケージは特別な構造を持っている。メタ分析関数がいくつか含まれており、それぞれが効果量のデータの1つのタイプに焦点を当てている。例えば、固定効果モデルかランダム効果モデルか、どの $\tau^2$ 推定量を使うか、などである。それとは別に、特定の種類のデータにのみ関連するメタ分析の詳細を調整することができる**関数固有の**引数がある。

Figure \@ref(fig:metaflow) は、 **{meta}** の構造を概観したものである。どの関数を使うかを決めるには、まず、どのような効果量データを合成したいのかを明確にする必要がある。最も基本的な区別は、**生** (raw) と **事前計算済み** (pre-calculated) 効果量データの間のものである。「生」のデータとは、目的の効果量を計算するために必要なすべての情報がデータフレームに格納されているが、実際の効果量はまだ計算されていない場合を指す。先ほど使用した `SuicidePrevention` データセットには、標準化平均差を計算するために必要な2つのグループの平均、標準偏差、サンプルサイズという生データが含まれている。

一方、効果量データには、各研究の最終的な効果量と標準誤差がすでに含まれており、これを「事前計算済み」と呼んでいる。効果指標の補正版（例えば、Hedges' $g$、Chapter \@ref(hedges-g)）を使用したい場合、プールを始める前に、既に計算済みの効果量データにこの補正が適用されていることが必要である。

```{r metaflow, out.width='100%', fig.cap='メタ分析に関する関数の概略図', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/meta_flow_sep.png')
```



可能であれば、メタ分析には生データを使用することが望ましい。そうすれば、他の人が効果量の計算方法を理解し、結果を再現することが容易になる。しかし、研究結果は異なる方法で報告されることが多いため、実際には生データを使用できないことが多い（Chapter \@ref(es-formats-different)）。

このため、各研究の望ましい効果量をすぐに事前計算して、すべての形式が同じになるようにする以外に方法がない。本書の「各種ツール」の Chapter \@ref(es-calc) では、報告された効果量を目的のメトリックに変換するのに役立つ公式を紹介している。

あらかじめ計算された効果量に対応する関数として、 `metagen` がある。この名前は、 **gen**eric inverse variance meta-analysis の略である。もし、二値データ（割合、リスク比、オッズ比など）で `metagen` を使用する場合は、 Chapter \@ref(ratios)  で説明したように、この関数を使用する前に効果量を対数変換しておくことが重要である。

生の効果量データに頼ることができる場合、  **{meta}**  はそれぞれの効果量タイプに特化した関数を提供する。平均、（標準化）平均差、相関には、それぞれ `metamean` , `metacont` , `metacor` 関数を使用可能である。 `metarate` , `metaprop` , `metainc` 関数を用いて、（発生）率、割合、発生率比をプールすることが可能である。 `metabin` 関数は、リスク比やオッズ比を扱うときに使用する。

**{meta}** のメタ分析関数はすべて同じ構造を持っている。効果量のデータ（生データまたは計算済みデータ）と、解析の詳細を制御するための引数を関数に与えなければならない。各関数で指定可能なコア引数は6つである。

* **`studlab`**. この引数は、各効果量に **研究ラベル** を関連付ける。もし、データセットに研究名や著者が保存されている場合は、それぞれの列の名前を指定するだけである（例： `studlab =  author`）。
* **`sm`**. この引数は、メタ分析で使用する効果量の指標である**要約手法**を制御する。このオプションは、生の効果量データを使用する関数で特に重要である。 **{meta}** パッケージは、例えば `"SMD"` や `"OR"` など、異なる効果量のフォーマットに対するコードを使用する。利用できる要約尺度は各関数で同じではないので、以下のセクションでそれぞれのケースで最も一般的な選択肢を説明する。
* **`fixed`**. この引数に論理値（`TRUE` または `FALSE`）を与える必要があり、固定効果モデルのメタ分析を計算するかどうかを示す^[古いバージョンの **{meta}** （バージョン 5.0-0 以前）では、この引数は `comb.fixed` と呼ばれていた]。
* **`random`**. 同様の方法で、この引数はランダム効果モデルを使用するかどうかを制御する。もし `comb.fixed` と` comb. random` の両方が `TRUE` に設定されていると、両方のモデルが計算されて表示される^[古いバージョンの  **{meta}**  (version 5.0-0) では、この引数は `comb.random` と呼ばれていた]。
* **`method.tau`**. この引数は $\tau^2$ 推定量を定義する。全ての関数は、前の章で既に紹介した異なる推定量のコードを使用する（例えば、DerSimonian-Laird 法の場合: `method.tau = "DL"`）。
* **`hakn`**. これはまた別の論理的な引数で、ランダム効果モデルを使用する際に、Knapp-Hartung 調整を適用するかどうかを制御する。
* **`data`**. この引数では、メタ分析データセットの名前を  **{meta}**  で指定する。
* **`title`** (**必須ではない**). この引数には、解析の名前を文字列で指定する。この引数への入力は必須ではないが、後で分析結果を特定するのに役立つ。

また、いくつかの追加の引数もあるが、それは後の章で知ることになる。このガイドでは、 **{meta}** 関数の引数は100以上あるので、**すべての**引数を説明することはできない。

ありがたいことに、これらの引数のほとんどはほとんど必要なく、また賢明なデフォルト値が設定されている。疑問がある場合は、 _R_ コンソールで関数名の前にクエスチョンマーク（例： `?metagen`）を付けて実行すると、関数のドキュメントを開くことが可能である。


\index{Function Argument}
\index{Position Matching}
\index{Documentation, _R_}

```{block, type='boxinfo'}
**デフォルトの引数とポジションマッチング**

\vspace{2mm}

_R_ の初心者にとって、関数における**デフォルト引数**と**位置ベースのマッチング**について学んでおくと良い。

\vspace{2mm}

デフォルトの引数は、関数を書いた人が指定したものである。関数では引数をあらかじめ定義された値に設定し、別の値を明示的に指定しない限り自動的に使用される。**{meta}** では、すべての引数ではないが、多くの引数がデフォルト値を持っている。

\vspace{2mm}

デフォルト値は、関数ドキュメントの「使用法」のセクションに表示される。関数が引数のデフォルト値を定義している場合、デフォルトの動作に満足できない場合を除き、関数呼び出しに含める必要はない。

\vspace{2mm}

デフォルト値が**ない**引数は、常に関数呼び出しの中で指定する必要がある。**{meta}** パッケージには `gs` という便利な関数があり、これを使うことで特定の引数に使われるデフォルト値を確認することができる。例えば、 `gs("method.tau")` を実行してみよう。もし、デフォルト値がなければ、 `gs` は `NULL` を返す。

\vspace{2mm}

_R_ 関数のもう一つの興味深い点は、ポジション・マッチングである。通常、関数を呼び出す際には、引数の名前とその値を書かなければならない。しかし、ポジション・マッチングを使えば、引数の名前を書かずに、引数の値だけを入力すればよい。これは、引数をドキュメントに登場するのと同じ **位置** で指定すれば可能である。

例えば、`sqrt` 関数を考えてみよう。この関数を書き出すと、`sqrt(x = 4)` となる。しかし、数値である `x` が最初の引数であることが分かっているので、単に `sqrt(4)` とタイプしても同じ結果になる。

```


<br></br>


### 事前算出された効果量のデータ {#pre-calculated-es}



それでは、メタ分析関数のツアーを `metagen` から始めよう。これまで学んだように、この関数は事前に計算された効果量のデータに使用することが可能である。最初の例では、この関数を使用して `ThirdWave` データセットのメタ分析を実行する。

\index{Hedges' \textit{g}}
\index{Standardized Mean Difference}\index{標準化平均差}

このデータセットには、いわゆる "Third Wave" の心理療法が大学生の知覚ストレスに及ぼす影響を調べた研究が含まれている。各研究について、試験後における治療群と対照群の標準化平均差を計算し、小サンプル補正を適用する。したがって、このメタ分析で使用される効果量の指標は、Hedges' $g$である。それでは、データを見てみよう。

\index{dmetar Package}
```{block, type='boxdmetar'}
**"ThirdWave" データセット**

\vspace{2mm}

`ThirdWave` のデータセットも **{dmetar}** パッケージに直接含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(SuicidePrevention)` を実行すると、自動的に _R_ 環境にデータセットが保存される。これでデータセットが利用できる。もし、**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/thirdwave.rda)から _.rda_ ファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R Studio ウィンドウでクリックするとインポートすることができる。

```


```{r, message=F}
library(tidyverse) # 'glimpse' に必要
library(dmetar)
library(meta)

data(ThirdWave)
glimpse(ThirdWave)

```

このデータセットには8つの列があり、そのうち最も重要なのは `Author`、`TE` 、`seTE` であることがわかる。`TE` 列は各研究の $g$ 値、 `seTE` は $g$ の標準誤差を表している。その他の列は、各研究が該当するサブグループカテゴリを記述する変数を表す。これらの変数は今のところ関係ない。

これで、どのようなメタ分析を行いたいかを考え始めることが可能である。サブグループの列を見ると、少なくともバイアスリスク、対照群、介入期間、介入タイプ、実施形態に関して研究が異なっていることがわかる。

このことから、研究間の異質性が予想され、すべての研究の真の効果が一定であると仮定することは意味がないことがよくわかる。したがって、私たちはプールのためにランダム効果モデルを使用することができる。連続アウトカムデータでのロバストなパフォーマンスから、この例では制限付き最尤推定量(`"REML"`) を選択する。また、偽陽性結果のリスクを減らすために Knapp-Hartung 調整を使用する。

基本的な疑問が解決されたので、`metagen` の呼び出し方法もかなり簡単になる。この関数を使用する際には、必ず指定しなければならない関数固有の引数が2つある。

* **`TE`**. 計算された効果量が含まれるデータセットの列の名前である。

* **`seTE`**. 効果量の標準誤差が格納される列の名前。

残りは、前章ですでに取り上げた一般的な  **{meta}**  引数である。この解析では標準化平均差を扱うので、`sm = "SMD"` も指定している。しかし、この例では、効果量がすでに各研究で計算されているので、これは結果に対して実際の効果はない。出力で効果量を SMD としてラベル付けするように関数に指示すだけである。

これで `metagen` の最初の呼び出しを設定するのに必要なすべての情報が得られた。この関数の結果を `m.gen` というオブジェクトに格納する。

```{r}
m.gen <- metagen(TE = TE,
                 seTE = seTE,
                 studlab = Author,
                 data = ThirdWave,
                 sm = "SMD",
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "REML",
                 hakn = TRUE,
                 title = "Third Wave Psychotherapies")
```

これで `m.gen` オブジェクトにすべてのメタ分析結果が格納された。概要を知る簡単な方法は `summary` 関数を使うことである^[古いバージョンの  **{meta}**  (バージョン 5.0-0 以前) では、この概要は `summary` を使わずに表示すことが可能である。新しく作成したメタ分析オブジェクトを _R_ コンソールで直接呼び出すだけである。]。

```{r, eval=F}
summary(m.gen)
```

```
## Review:     Third Wave Psychotherapies
##                       SMD            95%-CI %W(random)
## Call et al.        0.7091 [ 0.1979; 1.2203]        5.0
## Cavanagh et al.    0.3549 [-0.0300; 0.7397]        6.3
## DanitzOrsillo      1.7912 [ 1.1139; 2.4685]        3.8
## de Vibe et al.     0.1825 [-0.0484; 0.4133]        7.9
## Frazier et al.     0.4219 [ 0.1380; 0.7057]        7.3
## Frogeli et al.     0.6300 [ 0.2458; 1.0142]        6.3
## Gallego et al.     0.7249 [ 0.2846; 1.1652]        5.7
## Hazlett-Steve…     0.5287 [ 0.1162; 0.9412]        6.0
## Hintz et al.       0.2840 [-0.0453; 0.6133]        6.9
## Kang et al.        1.2751 [ 0.6142; 1.9360]        3.9
## Kuhlmann et al.    0.1036 [-0.2781; 0.4853]        6.3
## Lever Taylor…      0.3884 [-0.0639; 0.8407]        5.6
## Phang et al.       0.5407 [ 0.0619; 1.0196]        5.3
## Rasanen et al.     0.4262 [-0.0794; 0.9317]        5.1
## Ratanasiripong     0.5154 [-0.1731; 1.2039]        3.7
## Shapiro et al.     1.4797 [ 0.8618; 2.0977]        4.2
## Song & Lindquist   0.6126 [ 0.1683; 1.0569]        5.7
## Warnecke et al.    0.6000 [ 0.1120; 1.0880]        5.2
## 
## Number of studies combined: k = 18
## 
##                         SMD           95%-CI    t  p-value
## Random effects model 0.5771 [0.3782; 0.7760] 6.12 < 0.0001
## 
## Quantifying heterogeneity:
##  tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944];
##  I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]
## 
## Test of heterogeneity:
##      Q d.f. p-value
##  45.50   17  0.0002
## 
## Details on meta-analytical method:
## - Inverse variance method
## - Restricted maximum-likelihood estimator for tau^2
## - Q-profile method for confidence interval of tau^2 and tau
## - Hartung-Knapp adjustment for random effects model

```


さあ、 _R_ を使った最初のメタ分析の結果である。解き明かすことがたくさんあるので、順を追って出力を見ていきよう。

\index{Weight}\index{重み}

* 出力の最初の部分には、個々の研究、その効果量と信頼区間が含まれている。効果は事前に計算されているので、ここで見るべき新しいものはあまりない。`%W(random)` 列は、ランダム効果モデルが各研究に帰着させた重み（パーセント）を示している。メタ分析では、de Vibe の研究が7.3％と最も大きな重みを占めていることがわかる。最小の重みは Ratanasiripong による研究に与えられている。この研究の信頼区間を見ると、なぜこのような結果になったのかがわかる。プールされた効果の信頼区間は非常に広く、標準誤差が非常に大きく、したがってこの研究の効果量の推定はあまり正確ではないことを意味している。



* さらに、メタ分析に含まれる研究の総数も出力される。$K=$ 18件の研究が組み合わされたことがわかる。



* 次節では、その中核となるプール効果量を示す。推定値は約 0.58 であり、95%信頼区間は約 0.38～0.78 であることがわかる。また、効果量が有意であるかどうかの検定結果も示されている。その結果、$p<$ 0.001となった。重要なのは、関連する検定統計量も表示されることで、これは `t` で表示される。これは、$t$ 分布に基づく Knapp-Hartung 調整を適用する。


* その下に、研究間異質性に関する結果が表示されている。ここで表示される結果のいくつかについては、後の章で詳しく説明するので、ここでは $\tau^2$ にのみ注目しよう。$\tau^2$ の横には、真の効果の分散の推定値 $\tau^2$ = 0.08 が表示されている。$\tau^2$ の信頼区間は0を含まないので (0.03--0.35) 、$\tau^2$ は0より有意に大きいことがわかる。これらのことから、私たちのデータには研究間の異質性が存在し、ランダム効果モデルが良い選択であったことがわかる。


* 最後のセクションは、メタ分析についての詳細である。逆分散法を用いて効果をプールしたこと、制限付き最尤推定量を用いたこと、Knapp-Hartung 調整を適用したことなどがわかる。


また、 `m.gen` に格納されている情報にも直接アクセス可能である。メタ分析の結果である  **{meta}**  には、たくさんのオブジェクトがデフォルトで格納されており、ドキュメントの "value" セクションを見れば、これが何を意味しているかが分かる。また、 `$` 演算子を使って、特定の分析結果を表示すことが可能である。例えば、プール効果は `TE.random` として格納される。

```{r}
m.gen$TE.random
```

\index{Fixed-Effect}\index{固定効果モデル}

`fixed =  FALSE` を指定した場合でも、 **{meta}** の関数は常に内部で固定効果モデルの結果も計算している。そのため、固定効果モデルを仮定したプール効果にもアクセスすることが可能である。

```{r}
m.gen$TE.fixed
```

この推定値はランダム効果モデルの結果とはかなり乖離していることがわかる。

分析の詳細を変更したい場合、 `update.meta` 関数が役に立つ。この関数は、入力として **{meta}** オブジェクトと、変更したい引数を必要とする。例えば、制限付き最尤推定量の代わりに Paule-Mandel を使用した場合に結果が大きく異なるかどうかをチェックしたいとする。このコードを使ってそれを行うことが可能である。

```{r}
m.gen_update <- update.meta(m.gen, 
                            method.tau = "PM")

# Get pooled effect
m.gen_update$TE.random

# Get tau^2 estimate
m.gen_update$tau2
```

プール効果はあまり変わらないが、Paule-Mandel 推定量では、$\tau^2$の近似値がやや大きくなることがわかる。

最後に、結果を保存しておくと後々便利である。 **{meta}** で生成されたオブジェクトは、`save` 関数を使って簡単に _.rda_ ( _R_ data) ファイルとして保存することが可能である。

```{r, eval=F}
save(m.gen, file = "path/to/my/meta-analysis.rda") # example path
```


<br></br>

### （標準化）平均差 {#pooling-smd}



\index{Standardized Mean Difference}\index{標準化平均差}
\index{Glass' Delta}

2つの群の平均と標準偏差の形式で表される生の効果量データは、 `metacont` を使ってプールすることが可能である。この関数は、標準化された群間平均差と標準化されていない群間平均差の両方に使用することが可能である。これらは `sm = "SMD"` または `sm = "MD"` を指定することで得ることが可能である。それ以外では、7つの関数固有の引数を指定する必要がある。

* **`n.e`**. 治療・実験群の観測数。

* **`mean.e`**. 治療・実験群における平均値。

* **`sd.e`**. 治療・実験群における標準偏差。

* **`n.c`**. 対照群の観測数。

* **`mean.c`**. 対照群の平均値。

* **`sd.c`**. 対照群の標準偏差。

* **`method.smd`**. これは `sm = "SMD"` のときのみ関係する。 `metacont` 関数では、3種類の標準化平均差を計算することが可能である。 `metacont` 関数では、3種類の標準化平均差を計算することが可能である。 `method.smd = "Cohen"` と設定すると、補正されていない標準化平均差（Cohen's $d$）が効果量指標として使用される。他の2つのオプションは、Hedges' $g$ を計算する `"Hedges"` （デフォルトと推奨）と、Glass' $\Delta$（「デルタ」と読む）を計算する `"Glass"` である。Glass' $\Delta$は、平均差を標準化するために、プールされた標準偏差の代わりに対照群の標準偏差を使用する。この効果量は、一次研究で複数の治療群がある場合に使われることがあるが、通常、メタ分析では好まれない指標である。

\index{Knapp-Hartung Adjustment}\index{Knapp-Hartung 調整法}

今回の分析例では、Chapter \@ref(data-prep-R) と Chapter \@ref(fem) で扱った "SuicidePrevention" データセットを再利用している。サンプルに含まれるすべての研究が完全に同一ではないので、ランダム効果モデルを使用することが保証される。また、Knapp-Hartung 調整と$\tau^2$の制限付き最尤推定量も再び使用する予定である。 `metacont` にスモールサンプルバイアスを補正するように指示し、効果量のメトリックとしてHedges' $g$ を生成する。結果はオブジェクトに保存され、 `m.cont` と名付ける。

全体としては、このようなコードになる。

```{r}
# meta と dmetar がロードされていることを確認
library(meta)
library(dmetar)
library(meta)

# dmetar からデータセットをロード (またはネットからダウンロードし自分で開く)
data(SuicidePrevention)

# metcont を使って結果をプール。
m.cont <- metacont(n.e = n.e,
                   mean.e = mean.e,
                   sd.e = sd.e,
                   n.c = n.c,
                   mean.c = mean.c,
                   sd.c = sd.c,
                   studlab = author,
                   data = SuicidePrevention,
                   sm = "SMD",
                   method.smd = "Hedges",
                   fixed = FALSE,
                   random = TRUE,
                   method.tau = "REML",
                   hakn = TRUE,
                   title = "Suicide Prevention")


```

その結果を見てみよう。

```{r}
summary(m.cont)
```

この出力を見て、Chapter \@ref(pre-calculated-es) で受け取った出力と比較すると、すでに **{meta}** の最大の資産の1つが見えている。すなわち、`metagen` や `metacont` とは異なるデータ型を必要とする異なる関数であるが、出力の構造はほぼ同じように読むことができる。このため、結果の解釈は非常に容易である。ランダム効果モデルによるプール効果は $g=$ -0.23 であり、95%信頼区間は -0.09 から -0.37 の範囲であることがわかる。この効果は有意である ($p=$ 0.006)。

効果量が負の符号を持つことがわかる。このメタ分析の文脈では、好ましいアウトカムであることを表し、対照群と比較して治療群で自殺念慮がより低かったことを意味する。これを他の人にわかりやすくするために、効果量の符号を一貫して逆にし（たとえば、代わりに $g=$ 0.23 と書く）、正の効果量が常に「正の」結果を表すようにしてもよいだろう。

制限付き最尤法では、研究間の異質性分散は $\tau^2$ = 0.004と推定される。$\tau^2$ 値を見ると、信頼区間は0を含んでおり、真の効果量の分散は0より有意に大きくないことがわかる。

詳細では、効果量の指標としてHedges' $g$ が使われたことが示されている。


<br></br>

### 二値アウトカム



#### リスク比とオッズ比 {#pooling-or-rr}



\index{Risk Ratio}\index{リスク比}
\index{Odds Ratio}\index{オッズ比}
\index{Inverse-Variance Weighting}\index{逆分散重み付け}
\index{Sparse Data}


`metabin` 関数は、二値データ、特にリスク比とオッズ比に基づく効果量をプールするために使用することが可能である。この関数を使い始める前に、まず、これらの効果量に基づくメタ分析について、いくつかの特殊性を議論する必要がある。

Chapter \@ref(fem) と Chapter \@ref(tau-estimators) で取り上げた一般的な逆分散 (generic inverse variance) 法を用いて、二値の効果量をプールすることが可能である。各効果の対数オッズ比または対数リスク比、および標準誤差を計算する必要があり、その後、効果量の分散の逆数を使用してプーリング重みを決定することが可能である。

しかし、この方法は二値アウトカムのデータには最適ではない [@higgins2019cochrane, chapter 10.4.1]。**薄い**データを扱っているとき、すなわちイベント数または総サンプルサイズが小さいとき、標準誤差は二値効果量の推定値としては精度が高くない可能性がある。

<br></br>

##### Mantel-Haenszel法 {#mantel-haenszel}



\index{Mantel-Haenszel Method}\index{Mantel-Haenszel 法}

このため、**Mantel-Haenszel** 法 [@mantel1959statistical; @robins1986general] は、二値アウトカム・データを持つ研究の重みを計算する代替手段としてよく使用されている。また、`metabin` で使用されるデフォルトのアプローチでもある。この方法は、研究の重みを決定するために、治療と対照群におけるイベントと非イベントの数を使用する。リスク比を計算するかオッズ比を計算するかで、異なる計算式がある。

\vspace{8mm}

**リスク比:**

\begin{equation}
w_k = \frac{(a_k+b_k) c_k}{n_k}
(\#eq:pes9)
\end{equation}

**オッズ比:**

\begin{equation}
w_k = \frac{b_kc_k}{n_k}
(\#eq:pes10)
\end{equation}

式中、Chapter \@ref(rr) と同じく、$a_k$ は治療群のイベント数、$c_k$ は対照群のイベント数、$b_k$ は治療群の非イベント数、$d_k$ は対照群の非イベント数、$n_k$ は全体のサンプルサイズとしている。



\index{Peto 法}\index{Peto Method}
\index{Peto Odds Ratio}
<br></br>

##### Peto 法



第二のアプローチは、**Peto** 法 [@yusuf1985beta]である。このアプローチの本質は、私たちがすでに知っている逆分散の原則に基づくものである。ただし、特殊な効果量である**Peto オッズ比**を使用し、ここでは $\hat\psi_k$ （訳注: $\psi$ は「プサイ」と読む）と表記する。

この $\hat\psi_k$ を計算するためには、治療群で観測された事象である $O_k$ を知り、治療群の**予想**例数である $E_k$ を計算する必要がある。$O_k-E_k$の差を $O_k$ と $E_k$ の差の分散 $V_k$ で割ると、対数変換された $\hat\psi_k$ になる。先ほどと同じセル表記で、$E_k$、$O_k$、$V_k$を計算する式は以下の通りである。

\begin{equation}
O_k = a_k
(\#eq:pes11)
\end{equation}
\begin{equation}
E_k = \frac{(a_k+b_k)(a_k+c_k)}{a_k+b_k+c_k+d_k}
(\#eq:pes12)
\end{equation}

\vspace{4mm}


\begin{equation}
V_k = \frac{(a_k+b_k)(c_k+d_k)(a_k+c_k)(b_k+d_k)}{{(a_k+b_k+c_k+d_k)}^2(a_k+b_k+c_k+d_k-1)}
(\#eq:pes13)
\end{equation}

\vspace{4mm}

\begin{equation}
\log\hat\psi_k = \frac{O_k-E_k}{V_k}
(\#eq:pes14)
\end{equation}

そして、効果量のプール時には、$\log\hat\psi_k$の分散の逆数を重みとして用いる^[log Petoオッズ比$\log\hat\psi_k$の分散は、$\text{SE}_{\log\hat\psi_k}^2 = \widehat{\text{Var}}(\log\hat\psi_k)=V_k^{-1}$ として定義されている。Peto法によるプール重みは $w^{\text{(Peto)}}_k=\widehat{\text{Var}}(\log\hat\psi_k)^{-1}$ と定義される。]。

<br></br>


##### Bakbergenuly-サンプルサイズ法



最近、Bakbergenuly ら [-@bakbergenuly2020methods] は、効果の重みが研究のサンプルサイズだけで決まる別の方法を提案し、この方法が Mantel and Haenszel による方法より望ましい可能性があることを示している。これを**サンプルサイズ法**と呼ぶことにする。この方法の計算式はとても簡単である。治療群と対照群のサンプルサイズ $n_{\text{treat}_k}$ と $n_{\text{control}_k}$ だけ分かれば良い。

\begin{equation}
w_k = \frac{n_{\text{treat}_k}n_{\text{control}_k}}{n_{\text{treat}_k} + n_{\text{control}_k} }
(\#eq:pes15)
\end{equation}

このプール法を `metabin` に実装すると、固定効果モデルとランダム効果モデルによる重みと全体効果は同じになる。プールされた効果の $p$ 値と信頼区間だけが異なる。

\index{Continuity Correction}
\index{Zero Cell Problem}


```{block2, type='boxinfo'}
**プール方法はどれを使うべきか？**

\vspace{4mm}

Chapter \@ref(rr) では、**ゼロセル**と**連続性補正**の問題について、すでに詳しく述べた。ゼロセルがある場合、Peto法、サンプルサイズ法ともにそのまま使用できるが、Mantel-Haenszel 法を使用する場合はゼロセルに0.5を加算するのが一般的である。これは `metabin` のデフォルトの動作でもある。

しかし、連続性補正の使用は、バイアスのある結果につながる可能性があるため、推奨されていない [@efthimiou2018practical]。Mantel-Haenszel 法は、ある特定のセルが含まれる研究で**すべて**ゼロである場合にのみ**本当に**連続性補正を必要とするが、そのようなケースはほとんどない。そのため、通常は `metabin` で `MH.exact = TRUE` と設定し、連続性補正を行わない **exact** Mantel-Haenszel 法を使用することが推奨される。

\vspace{4mm}

Peto 法にも限界がある。まず、オッズ比にしか使用できない。また、シミュレーション研究では、(1) 治療群と対照群の観察数が同程度のとき、(2) 観察された事象が稀なとき（<1%）、
(3) 治療効果が過度に大きくないときにのみ,
この方法がうまく機能することが示された [@bradburn2007much; @j2004add]。

最後に、Bakbergenuly-サンプルサイズ法は、かなり新しい手法であり、他の2つの手法に比べて研究が進んでいない。

\vspace{2mm}

全体として，ほとんどの場合，コクランの一般的な評価 [@higgins2019cochrane, chapter 10.4]  に従い、Mantel-Haenszel 法（連続性補正なし）を使用することが望ましいと思われる。オッズ比が望ましい効果量の指標であり、関心のある事象が稀であると予想される場合は、Peto 法を用いることができる。

```


<br></br>

##### _R_ における二値効果量のプール {#ppoolbin}



`metabin` には、8つの重要な関数固有の引数がある。

* **`event.e`**. 治療・実験群におけるイベント数。

* **`n.e`**. 治療/実験群の観測数。

* **`event.c`**. 対照群におけるイベント数。

* **`n.c`**. 対照群の観測数。

* **`method`**. 使用するプール法。これは、 `"Inverse"` (一般的な逆分散プール)、 `"MH"` (Mantel-Haenszel; デフォルトおよび推奨)、 `"Peto"` (Peto method)、または `"SSW"` （Bakbergenuly-サンプルサイズ法; `sm = "OR"` 時のみ）のいずれかになる。

* **`sm`**. 計算する要約指標（＝効果量の指標）。リスク比には `"RR"` を、オッズ比には `"OR"` を使用することができる。

* **`incr`**. ゼロセルの連続性補正のために追加する増分を指定する。`incr = 0.5` とすれば、0.5 の増分値が加算される。`incr = "TACC"` とすると、治療群連続性補正法が用いられる（Chapter \@ref(rr)参照）。前述したように、通常はこの引数を省略し、連続性補正を適用しないことが推奨される。

* **`MH.exact`**. もし `method = "MH"` ならば、この引数を `TRUE` に設定し、 Mantel-Haenszel 法の連続性補正を使用しないようにすることが可能である。

この実践的な例では、 `DepressionMortality` データセットを使用する。このデータセットは、Cuijpers and Smit [-@cuijpers2002excess] によるメタ分析に基づいており、全死因死亡率に対するうつ病の影響を調査している。このデータセットには、うつ病のある人とない人の数、そして両群の何人が数年後に死亡したかが含まれている。

\index{dmetar Package}

```{block, type='boxdmetar'}
**"DepressionMortality" データセット**

\vspace{2mm}

`DepressionMortality` のデータセットも **{dmetar}** パッケージに直接含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(SuicidePrevention)` を実行すると、自動的に _R_ 環境にデータセットが保存される。これでデータセットが利用できる。もし、**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/depressionmortality.rda)から _.rda_ ファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R Studio ウィンドウでクリックするとインポートすることができる。

```


まず、データセットを見てみよう。

```{r, message = F}
library(dmetar)
library(tidyverse)
library(meta)

data(DepressionMortality)
glimpse(DepressionMortality)
```

\index{Paule-Mandel Estimator}
\index{Mantel-Haenszel Method}\index{Mantel-Haenszel 法}

この例では、Cuijpers and Smit が行ったように、効果量の指標としてリスク比を計算する。ランダム効果プールモデルを使用し、二値アウトカムデータを扱うので、$\tau^2$の Paule-Mandel 推定量を使用する。

データを見ると、サンプルサイズが研究によってかなり異なっており、Paule-Mandel 法がややバイアスされる可能性がある（Chapter \@ref(tau-estimators) 参照）。これを踏まえて、感度分析として他の $\tau^2$ 推定量も試してみて、結果が大きく異なるかどうかを確認することも可能である。

このデータセットにはゼロセルが含まれていないので、連続性補正の心配はなく、すぐに正確な Mantel-Haenszel 法を使うことができる。メタ分析の結果は `m.bin` というオブジェクトに保存する。

```{r, eval=F}
m.bin <- metabin(event.e = event.e, 
                 n.e = n.e,
                 event.c = event.c,
                 n.c = n.c,
                 studlab = author,
                 data = DepressionMortality,
                 sm = "RR",
                 method = "MH",
                 MH.exact = TRUE,
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "PM",
                 hakn = TRUE,
                 title = "Depression and Mortality")
summary(m.bin)
```

```{r, echo=F, message=F, warning=F}
m.bin <- metabin(event.e = event.e, 
                 n.e = n.e,
                 event.c = event.c,
                 n.c = n.c,
                 studlab = author,
                 data = DepressionMortality,
                 sm = "RR",
                 method = "MH",
                 MH.exact = TRUE,
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "PM",
                 hakn = TRUE,
                 title = "Depression and Mortality")


```

```

## Review:     Depression and Mortality
##                           RR        95%-CI %W(random)
## Aaroma et al., 1994     2.09 [1.41;  3.12]        6.0
## Black et al., 1998      1.75 [1.31;  2.33]        6.6
## Bruce et al., 1989      2.51 [1.07;  5.88]        3.7
## Bruce et al., 1994      1.16 [0.85;  1.57]        6.5
## Enzell et al., 1984     1.82 [1.28;  2.60]        6.3
## Fredman et al., 1989    0.39 [0.05;  2.78]        1.2
## Murphy et al., 1987     1.76 [1.26;  2.46]        6.4
## Penninx et al., 1999    1.46 [0.93;  2.29]        5.8
## Pulska et al., 1998     1.94 [1.34;  2.81]        6.2
## Roberts et al., 1990    2.30 [1.92;  2.75]        7.0
## Saz et al., 1999        2.18 [1.55;  3.07]        6.3
## Sharma et al., 1998     2.05 [1.07;  3.91]        4.7
## Takeida et al., 1997    6.97 [4.13; 11.79]        5.3
## Takeida et al., 1999    5.81 [3.88;  8.70]        6.0
## Thomas et al., 1992     1.33 [0.77;  2.27]        5.3
## Thomas et al., 1992     1.77 [1.10;  2.83]        5.6
## Weissman et al., 1986   1.25 [0.66;  2.33]        4.8
## Zheng et al., 1997      1.98 [1.40;  2.80]        6.3
## 
## Number of studies combined: k = 18
## 
##                          RR           95%-CI    t  p-value
## Random effects model 2.0217 [1.5786; 2.5892] 6.00 < 0.0001
## 
## Quantifying heterogeneity:
##  tau^2 = 0.1865 [0.0739; 0.5568]; tau = 0.4319 [0.2718; 0.7462];
##  I^2 = 77.2% [64.3%; 85.4%]; H = 2.09 [1.67; 2.62]
## 
## Test of heterogeneity:
##      Q d.f.  p-value
##  74.49   17 < 0.0001
## 
## Details on meta-analytical method:
## - Mantel-Haenszel method
## - Paule-Mandel estimator for tau^2
## - Q-profile method for confidence interval of tau^2 and tau
## - Hartung-Knapp adjustment for random effects model
```

プール効果量はRR $=$ 2.02であることがわかる。このプール効果は有意であり（$p<$ 0.001）、うつ病にかかると死亡リスクが2倍になることを示している。研究間の異質性分散の推定値は、$\tau^2 \approx$ 0.19である。

また、$\tau^2$ の信頼区間はゼロを含まず、研究間の実質的な異質性を示している。最後に、出力の詳細セクションを見ると、 `metabin` 関数は、意図したようにプールに Mantel-Haenszel 法を使用したことがわかる。

上記で発表したように、$\tau^2$ の推定方法が結果に影響を与えるかどうか見てみよう。`update.meta` 関数を使って、分析を再実行するが、今回は制限付き最尤推定量を使用する。

```{r}
m.bin_update <- update.meta(m.bin, 
                            method.tau = "REML")

```

\index{Exponentiation}

ここで、 `TE.random` を調べて、プールされた効果をもう一度見てみよう。ここで忘れてはならないのは、二値アウトカムのメタ分析は、実際には効果量を対数変換したものを使用して行われるということである。結果を表示す際に、 `metabin` は便宜上、効果量のメトリクスを元の形式に再変換しているだけである。このステップは、メタ分析オブジェクトの要素を検査する場合には実行されていない。

対数変換された効果量を再変換するには、その値を**指数化**する必要がある。指数化は対数変換の「逆関数」であり、 _R_ で `exp` 関数を使って実行可能である^[一般に、指数化は2つの変数 $b$ と $x$ を含む操作と言われている。$x$ を指数にするときは、$b$ (底)を $x$ (指数)のべき乗 $b^x$ となる。$b$ はオイラー数 $e \approx$ 2.718 とするのが一般的である。）$e^x$ を使うと、**指数関数** $exp(x)$ ができ、これを使うと、対数変換した値 $x$ を元の尺度に戻すことができる]。これを実際に使ってみよう。

```{r}
exp(m.bin_update$TE.random)
```

制限付き最尤推定量によるプール効果もほぼ同じであることがわかる。次に、$\tau^2$ の推定値を見てみよう。

```{r}
m.bin_update$tau2
```

この値は多少乖離しているが、最初の結果の妥当性を心配するほどではない。

`metabin` の呼び出しは、オッズ比をプールすることにしても、全く同じになる。変更する必要があるのは `sm` 引数だけで、これは `"OR"` に設定する必要がある。もう一度関数呼び出し全体を書き出す代わりに、`update.meta` 関数を再度使用して、プールされた OR を計算することが可能である。

```{r, eval=F}
m.bin_or <- update.meta(m.bin, sm = "OR")
m.bin_or
```

```
## Review:     Depression and Mortality
##
## [...]
## 
## Number of studies combined: k = 18
## 
##                          OR           95%-CI    t  p-value
## Random effects model 2.2901 [1.7512; 2.9949] 6.52 < 0.0001
## 
## Quantifying heterogeneity:
##  tau^2 = 0.2032 [0.0744; 0.6314]; tau = 0.4508 [0.2728; 0.7946];
##  I^2 = 72.9% [56.7%; 83.0%]; H = 1.92 [1.52; 2.43]
## 
## Test of heterogeneity:
##      Q d.f.  p-value
##  62.73   17 < 0.0001
## 
## Details on meta-analytical method:
## - Mantel-Haenszel method
## - Paule-Mandel estimator for tau^2
## - Q-profile method for confidence interval of tau^2 and tau
## - Hartung-Knapp adjustment for random effects model
```

出力では、オッズ比を用いたプール効果はOR = 2.29であることがわかる。

<br></br>

##### 事前に計算された二値効果量のプール {#m-gen-bin}



各研究のリスク比やオッズ比を計算するために必要な生の効果量のデータを抽出できないことがある。例えば、主要な研究でオッズ比が報告されていても、この効果量の根拠となるデータがない場合がある。著者が元のデータを提供してくれない場合、事前に計算された効果量のデータに基づいてメタ分析を行う必要が出てくるだろう。学習したように、これを行うために使用できる関数は `metagen` である。

二値アウトカムデータを扱うとき、事前に計算された効果量データを使う以外に選択肢がない場合は、本当に注意しなければならない。 `metagen` 関数は逆分散法を用いて効果量をプールし、Mantel-Haenszel 法のようなより良いオプションは使用できない。しかし、他のすべてがうまくいかない場合には、まだ有効な選択肢である。

`DepressionMortality` のデータセットを使って、事前に計算された効果量のメタ分析を行うシミュレーションをしてみよう。`m.bin` の `TE` と `seTE` オブジェクトを抽出し、各研究の効果量と標準誤差を取得することが可能である。この情報を `DepressionMortality` データセットに保存する。

```{r}
DepressionMortality$TE <- m.bin$TE
DepressionMortality$seTE <- m.bin$seTE
```

\index{Logarithm, Natural}

ここで、信頼区間の下限と上限はわかっているが、標準誤差がわからない効果が1つあると想像してみよう。このようなシナリオをシミュレートするために、 (1) 研究7 (Murphy et al., 1987) の標準誤差を欠損と定義し（つまり、その値を `NA` に設定）、 (2) データセットに新しい空の2列、 `lower` と `upper` を定義し、 (3) `lower` と `upper` に研究7で対数変換した「報告」信頼区間を記入することにする。

```{r}
# 研究 7 の seTE を NA に設定
DepressionMortality$seTE[7] <- NA

# 空の列 'lower' と 'upper' を作成
DepressionMortality[,"lower"] <- NA
DepressionMortality[,"upper"] <- NA

# 研究 7 の 'lower' と 'upper' に値を入れる
# いつものごとく、二値効果量は対数変換が必要
DepressionMortality$lower[7] <- log(1.26)
DepressionMortality$upper[7] <- log(2.46)

```

では、先ほど作成したデータを見てみよう。

```{r, eval=F}
DepressionMortality[,c("author", "TE", "seTE", "lower", "upper")]
```

```
##                   author      TE    seTE  lower  upper
## 1    Aaroma et al., 1994  0.7418 0.20217     NA     NA
## 2     Black et al., 1998  0.5603 0.14659     NA     NA
## 3     Bruce et al., 1989  0.9235 0.43266     NA     NA
## 4     Bruce et al., 1994  0.1488 0.15526     NA     NA
## 5    Enzell et al., 1984  0.6035 0.17986     NA     NA
## 6   Fredman et al., 1989 -0.9236 0.99403     NA     NA
## 7    Murphy et al., 1987  0.5675      NA 0.2311 0.9001
## 8   Penninx et al., 1999  0.3816 0.22842     NA     NA
## [...]
```

このようなデータセットを見つけることは、実際には珍しいことではない。ほとんどの研究では対数リスク比を計算することができるだろうが、その他のいくつかの研究では、（対数変換した）リスク比とその信頼区間しか情報がないことが多いのである。

幸いなことに、 `metagen` を使用すると、そのようなデータであってもプールすることが可能である。引数 `lower` と `upper` には、信頼区間の下限と上限を含む列の名前を指定するだけでよいのである。標準誤差が利用できない場合、 `metagen` 関数はこの情報を使って効果に重み付けをする。関数の呼び出しは次のようになる。

```{r, eval=F}
m.gen_bin <- metagen(TE = TE,
                     seTE = seTE,
                     lower = lower,
                     upper = upper,
                     studlab = author,
                     data = DepressionMortality,
                     sm = "RR",
                     method.tau = "PM",
                     fixed = FALSE,
                     random = TRUE,
                     title = "Depression Mortality (Pre-calculated)")

summary(m.gen_bin)
```

```
## Review:     Depression Mortality (Pre-calculated)
##
## [...]
## 
## Number of studies combined: k = 18
## 
##                          RR           95%-CI    z  p-value
## Random effects model 2.0218 [1.6066; 2.5442] 6.00 < 0.0001
## 
## Quantifying heterogeneity:
##  tau^2 = 0.1865 [0.0739; 0.5568]; tau = 0.4319 [0.2718; 0.7462];
##  I^2 = 77.2% [64.3%; 85.4%]; H = 2.09 [1.67; 2.62]
## 
## [...]
```

出力では、$K=$ 18 すべての研究がメタ分析で結合できたことがわかる。これは、 `metagen` が研究7について提供された `lower` と `upper` の情報を使用したことを意味する。また、逆分散法を用いた結果は、先ほどの Mantel-Haenszel 法の結果とほぼ同じであることが出力されている。

<br></br>

#### 発生率比 {#pooling-irr}



\index{Incidence Rate Ratio}
\index{Person-Time}\index{人-時間}

発生率 (incidence rate) に基づく効果量（すなわち、発生率比、Chapter \@ref(irr)）は、 `metainc` 関数を使用してプールすることが可能である。この関数の引数は `metabin` と非常によく似ている。

* **`event.e`**: 治療・実験群におけるイベント数。

* **`time.e`**: 治療・実験群におけるリスクパーソン時間。

* **`event.c`**: 対照群におけるイベント数。

* **`time.c`**: 対照群におけるリスクパーソン時間。

* **`method`**: `metabin` と同様に、デフォルトのプール法は Mantel and Haenszel によるもの (`"MH"`) である。また、一般的な逆分散プーリング (`"Inverse"`) を利用することも可能である。

* **`sm`**: 要約尺度を指定する。発生率比 (`"IRR"`) と発生率差 (`"IRD"`) のどちらかを選ぶことができる。

* **`incr`**: ゼロセルの連続性補正のために追加したいインクリメント。

\index{Inverse-Variance Weighting}\index{逆分散重み付け}

`metabin` とは対照的に、 `metainc` はデフォルトでは連続性補正を使用しない。そのため、 `MH.exact` を `TRUE` として指定する必要はない。連続性補正は、一般的な逆分散プール法 (`method = "Inverse"`) を選択したときのみ行われる。

今回の実践例では、 `EatingDisorderPrevention` データセットを使用する。このデータは、摂食障害の発生率に対する大学ベースの予防的介入の効果を検討したメタ分析に基づいている [@harrer2020prevention]。このデータセットでは、リスクのある人の時間は人-年として表現されている。

```{block, type='boxdmetar'}
**"EatingDisorderPrevention" データセット**

\vspace{2mm}

`EatingDisorderPrevention` のデータセットも **{dmetar}** パッケージに直接含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(SuicidePrevention)` を実行すると、自動的に _R_ 環境にデータセットが保存される。これでデータセットが利用できる。もし、**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/eatingdisorderprevention.rda)から _.rda_ ファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R Studio ウィンドウでクリックするとインポートすることができる。

```


いつものように、まずはデータを見てみよう。

```{r, message=F}
library(dmetar)
library(tidyverse)
library(meta)

data(EatingDisorderPrevention)

glimpse(EatingDisorderPrevention)
```

\index{Mantel-Haenszel Method}\index{Mantel-Haenszel 法}
\index{Paule-Mandel Estimator}

効果量のデータのプールには `metainc` を用い、効果量の指標は発生率比とする。プールには Mantel-Haenszel 法を用い、研究間異質性分散の計算には Paule-Mandel 推定量を用いている。

```{r}
m.inc <- metainc(event.e = event.e, 
                 time.e = time.e,
                 event.c = event.c,
                 time.c = time.c,
                 studlab = Author,
                 data = EatingDisorderPrevention,
                 sm = "IRR",
                 method = "MH",
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "PM",
                 hakn = TRUE,
                 title = "Eating Disorder Prevention")

summary(m.inc)
```

プールされた効果は IRR = 0.62 であることがわかる。この効果は、前の例よりも従来の有意水準にやや近いとはいえ、有意である ($p=$ 0.04）。プール効果に基づき、予防的介入は1年以内の摂食障害の発生を38%減少させたと言うことが可能である。最後に、異質性分散 $\tau^2$ の推定値が0であることがわかる。

<br></br>

### 相関関係 {#pooling-cor}



\index{Correlation}\index{相関}\index{相関}
\index{Fisher's \textit{z}}

相関は `metacor` 関数を用いてプールすることができ、これは一般的な逆分散プーリング法を用いる。Chapter \@ref(pearson-cors) では、相関をプールする前に Fisher's $z$ 変形が必要であることを説明した。デフォルトでは、 `metacor` がこの変換を自動的に行ってくれる。したがって、この関数には、研究で報告されたオリジナルの未変換の相関を与えれば十分である。 `metacor` 関数には、関数固有の引数が2つだけある。

* **`cor`**. （変換前の）相関係数。
* **`n`**. 調査における観測数。

`metacor` の機能を説明するために、 `HealthWellbeing` のデータセットを使用する。このデータセットは、健康と幸福の関連性を調べた大規模なメタ分析に基づいている [@ngamaba2017strongly]。

\index{dmetar Package}

```{block, type='boxdmetar'}
**"HealthWellbeing" データセット**

\vspace{2mm}

`HealthWellbeing` のデータセットも **{dmetar}** パッケージに直接含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(SuicidePrevention)` を実行すると、自動的に _R_ 環境にデータセットが保存される。これでデータセットが利用できる。

\vspace{2mm}

もし、**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/healthwellbeing.rda)から _.rda_ ファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R Studio ウィンドウでクリックするとインポートすることができる。

```


それでは、データを見てみよう。

```{r, message=F}
library(dmetar)
library(tidyverse)
library(meta)

data(HealthWellbeing)
glimpse(HealthWellbeing)
```

\index{Restricted Maximum Likelihood Estimator}\index{制限付き最尤推定}

このメタ分析では、研究間の異質性がかなり高いと予想されるため、ランダム効果モデルを採用する。また、$\tau^2$は制限付き最尤推定量を用いている。

```{r, eval=F}
m.cor <- metacor(cor = cor, 
                 n = n,
                 studlab = author,
                 data = HealthWellbeing,
                 fixed = FALSE,
                 random = TRUE,
                 method.tau = "REML",
                 hakn = TRUE,
                 title = "Health and Wellbeing")
summary(m.cor)
```

```
## Review:     Health and Wellbeing
##                        COR           95%-CI %W(random)
## An, 2008            0.6200 [0.4964; 0.7189]        2.8
## Angner, 2013        0.3720 [0.2823; 0.4552]        3.4
## Barger, 2009        0.2900 [0.2870; 0.2930]        3.8
## Doherty, 2013       0.3330 [0.2908; 0.3739]        3.7
## Dubrovina, 2012     0.7300 [0.7255; 0.7344]        3.8
## Fisher, 2010        0.4050 [0.2373; 0.5493]        2.8
## [...]
## 
## Number of studies combined: k = 29
## 
##                         COR           95%-CI     t  p-value
## Random effects model 0.3632 [0.3092; 0.4148] 12.81 < 0.0001
## 
## Quantifying heterogeneity:
##  tau^2 = 0.0241 [0.0141; 0.0436]; tau = 0.1554 [0.1186; 0.2088];
##  I^2 = 99.8% [99.8%; 99.8%]; H = 24.14 [23.29; 25.03]
## 
## Test of heterogeneity:
##         Q d.f. p-value
##  16320.87   28       0
## 
## Details on meta-analytical method:
## - Inverse variance method
## - Restricted maximum-likelihood estimator for tau^2
## - Q-profile method for confidence interval of tau^2 and tau
## - Hartung-Knapp adjustment for random effects model
## - Fisher's z transformation of correlations
```

プールされた健康と幸福の関連は $r=$ 0.36 であり、この効果は有意であることがわかる（$p<$ 0.001）。Cohen の法則に従えば、これは中程度のサイズの相関とみなすことができる。

出力では、 `metacor` がすでに Fisher's $z$ 変換された相関を元の形式に再変換している。しかし、詳細セクションの最後の行を見ると、確かに $z$ 値が効果をプールするために使用されていることがわかる。最後に、このメタ分析で推定された異質性分散は、0より有意に大きいことがわかる。

<br></br>

### プール平均 {#pooling-mean}



\index{Mean, Arithmetic}

平均のメタ分析は、 `metamean` 関数を用いて行うことが可能である。この関数は、データをプールするために一般的な逆分散法を使用する。 `metamean` を使用する場合、まず、生の平均値と対数変換された平均値のどちらでメタ分析を行うかを決定する必要がある。

オッズ比やリスク比とは対照的に、平均の対数変換は通常必要ない。しかし、非負の量（例えば、身長）の平均を扱うときや、いくつかの平均がゼロに近いときには、変換を使用することが推奨される。これは `sm` 引数で制御される。`sm = "MRAW"` と設定すると、生の平均がプールされる。`sm = "MLN"` とすると、対数変換が行われる。関数固有の引数は以下の通りである。

* **`n`**: 観測数。
* **`mean`**: 平均値。
* **`sd`**: 平均の標準偏差。
* **`sm`**: プーリングに使用する要約尺度の種類（上記参照）。

今回の実践例では、 `BdiScores` データセットを使用する。このデータセットには、心理療法や抗うつ剤の治験に参加しているうつ病患者のサンプルで測定された Beck Depression Inventory II [@beck1996beck] の平均スコアが含まれている [@furukawa2020translating]。

\index{dmetar Package}

```{block, type='boxinfo'}
**"BdiScores" データセット**

\vspace{2mm}

`BdiScores` のデータセットも **{dmetar}** パッケージに直接含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(SuicidePrevention)` を実行すると、自動的に _R_ 環境にデータセットが保存される。これでデータセットが利用できる。もし、**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/bdiscores.rda)から _.rda_ ファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R Studio ウィンドウでクリックするとインポートすることができる。

```


```{r, message=F}
library(dmetar)
library(tidyverse)
library(meta)
data(BdiScores)

# 最初の４列だけ必要
glimpse(BdiScores[,1:4])
```

ここでの目標は、この研究のコレクションに基づいて、全体の平均的なうつ病スコアを計算することである。ランダム効果モデルと制限付き最尤推定量を使って、データセット内の生の平均をプールする。その結果を `m.mean` というオブジェクトに保存する。

```{r}
m.mean <- metamean(n = n,
                   mean = mean,
                   sd = sd,
                   studlab = author,
                   data = BdiScores,
                   sm = "MRAW",
                   fixed = FALSE,
                   random = TRUE,
                   method.tau = "REML",
                   hakn = TRUE,
                   title = "BDI-II Scores")
summary(m.mean)
```

ランダム効果モデルを仮定したプール平均は $m$ = 31.12である。また、このメタ分析における研究間異質性分散 $\tau^2$ は、0より有意に大きいことがわかる。


<br></br>

### 割合 {#pooling-props}



\index{Proportion}
\index{Logit-Transformation}

`metaprop` 関数は、割合のプールに使用することが可能である。Chapter \@ref(props)で、メタ分析を行う前に割合を logit 変換しておくとよいことを既に説明した。`sm = "PLOGIT"` を指定すると、 `metaprop` 関数が自動的にこれを行う。もし、生の比率をプールしたい場合は、 `sm = "PRAW"` を使用することができるが、これは推奨されていないことを覚えていただきたい。

\index{Mixed-Effects Model}\index{混合効果モデル}

`metaprop` が割合のプールを行うデフォルトの方法は、少々特殊である。logit 変換された値を使用する場合、この関数はプールのために逆分散法を使用せず、**一般化線形混合効果モデル** (generalized linear mixed-effects model, GLMM) を構築する。基本的には、この関数はロジスティック回帰モデルをデータに当てはめ、真の効果量が研究間で異なるという事実を説明するために、ランダム効果を含んでいる。

「混合効果モデル」という言葉を聞いたことがあるだろう。このようなモデルは、多くの研究分野の一次研究でよく使用されている。この章では、混合効果モデルの特殊な応用例であるサブグループ解析やメタ回帰について説明し、このテーマをもう少し深く掘り下げていきる。しかし、今のところ、混合効果モデルとは何かという一般的な考え方を理解しておけば十分である。

混合効果モデルは、「固定」成分と「ランダム」成分の両方を含む回帰モデルである。固定要素は、$\beta$ **重み**である。非常に単純な回帰モデルでは、切片 ${\beta_0}$ と回帰項 ${\beta_1}x$ の2つの $\beta$ 項が含まれる。これらを組み合わせて、他の量 $x$ を通じて観測データ $y$ を予測する。この予測は完全とは言い難く、ランダムな誤差 $\epsilon_i$ が残る。これを合わせると、次のような式になる。

\begin{equation}
{y}_i = {\beta_0} + {\beta_1}x_i +  \epsilon_i
(\#eq:pes16)
\end{equation}

重要なのは、この式の$\beta$ 重みの値は各観測 $i$ で同じままであることである。$x$ の値は観測ごとに変わるだろうが、$\beta_0$ と $\beta_1$ は固定なので変わることはない。

この回帰式は、ランダム効果を加えると**混合**効果モデルになる。このランダム効果項を $u_i$ と表記する。添え字 $i$ で示すように、ランダム効果項は各オブザベーションで異なる値を持つことができる。$u_i$ 項は0を中心とし、固定効果による推定値を増加させたり、減少させたりすることができる。

\begin{equation}
{y}_i = {\beta_0} + {\beta_1}x_i + u_i + \epsilon_i
(\#eq:pes17)
\end{equation}

メタ分析は、このモデルの特殊なタイプで、$\beta_1x_i$ 項が存在しないものと見なすことができる。このモデルは切片 $\beta_0$ のみを含み、これはランダム効果モデルにおける全体の効果量 $\mu$ に相当する。$u_i$ と $\epsilon_i$ の部分は、メタ分析における $\zeta_k$ と $\epsilon_k$ の誤差項に相当する。このことから、メタ分析は混合効果回帰モデルと等価であることがわかる。しかし、この混合効果モデルには切片とそれに連なるランダム効果しか含まれていない。二項ロジットリンクを用いると^[研究 $k$ の logit 変換は、$\theta_k^{\text{LO}}=\log_e\left(\frac{p_k}{1-p_k}\right)$と定義される。$u_k \sim \mathcal{N}(0, \tau^2)$　を用いて、$\theta_k^{\text{LO}} \sim \theta+u_k$ と導かれる。割合のメタ分析 GLMM では、ある研究のイベント数（$a_k$）が二項分布に従うと仮定する: $a_k \sim \text{B}\left(n_k, \frac{\exp(\theta_k^{\text{LO}})}{1+ \exp(\theta_k^{\text{LO}})}\right)$。より詳しい説明は @schwarzer2019seriously, A.2.2. を参照]、したがって、（一般化）ロジスティック混合効果モデルを適用してプール効果を推定することが可能である。

GLMM は割合だけでなく、オッズ比や発生率比のような二値やカウントデータに基づく他のアウトカム指標にも適用できる  [@stijnen2010random] 。GLMMは二値アウトカムデータのメタ分析に普遍的に推奨されているわけではないが [@bakbergenuly2018meta] 、割合についてはその使用が提唱されている [@schwarzer2019seriously]。

\index{Maximum Likelihood}

GLMM を `metaprop` の一部として使用すると、次の3つの意味がある：(1) 出力は、各効果のメタ分析重みを表示しない、 (2) $\tau^2$推定量は `"ML"` にしか設定できない（最尤法を使用してGLMMを推定するので）、 (3) $\tau^2$ の推定量の信頼区間が存在しなくなる。この情報が必要な場合は、逆分散メタ分析の実行に切り替えることが可能である。 `metaprop` には、5つの関数固有の引数がある。

* **`event`**. イベント数。

* **`n`**. 観測数。

* **`method`**. プーリング手法。GLMM (`method = "GLMM"`) あるいは逆 (Inverse) 分散プーリング (`method = "Inverse"`) のいずれかを指定することができる。

* **`incr`**. ゼロセルでの連続性補正のために追加される増分。これは、逆分散プーリングが使用される場合にのみ関係する。

* **`sm`**. 使用する要約尺度を指定する。`sm = "PLOGIT"` (デフォルト)とすることで、logit 変換された比率を使用することが推奨される。

`metaprop` 関数の説明のために、 `OpioidMisuse` データセットを使用することにする。このデータは、米国の青年・若年成人における処方オピオイドの誤用12ヶ月有病率を調査したメタ分析から得られたものである [@jordan2017past]。


\index{dmetar Package}

```{block, type='boxdmetar'}
**"OpioidMisuse" データセット**

\vspace{2mm}

`OpioidMisuse` のデータセットも **{dmetar}** パッケージに直接含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(SuicidePrevention)` を実行すると、自動的に _R_ 環境にデータセットが保存される。これでデータセットが利用できる。もし、**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/opioidmisuse.rda)から _.rda_ ファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R Studio ウィンドウでクリックするとインポートすることができる。

```


データセットをロードして見てみよう。

```{r, message=F}
library(dmetar)
library(meta)
library(tidyverse)

data(OpioidMisuse)
glimpse(OpioidMisuse)
```

GLMM と logit 変換された割合を用いて有病率データをプールする。


```{r, eval=F}
m.prop <- metaprop(event = event,
                   n = n,
                   studlab = author,
                   data = OpioidMisuse,
                   method = "GLMM",
                   sm = "PLOGIT",
                   fixed = FALSE,
                   random = TRUE,
                   hakn = TRUE,
                   title = "Opioid Misuse")
summary(m.prop)

```

```
## Review:     Opioid Misuse
##                proportion           95%-CI
## Becker, 2008       0.1002 [0.0962; 0.1042]
## Boyd, 2009         0.0998 [0.0811; 0.1211]
## Boyd, 2007         0.1162 [0.0978; 0.1368]
## Cerda, 2014        0.0710 [0.0654; 0.0770]
## Fiellin, 2013      0.1176 [0.1150; 0.1204]
## [...]
## 
## 
## Number of studies combined: k = 15
## Number of observations: o = 434385
## Number of events: e = 41364
## 
##                      proportion           95%-CI
## Random effects model     0.0944 [0.0836; 0.1066]
## 
## Quantifying heterogeneity:
##  tau^2 = 0.0558; tau = 0.2362; I^2 = 98.3% [97.9%; 98.7%]; H = 7.74 [6.92; 8.66]
## 
## Test of heterogeneity:
##       Q d.f.  p-value             Test
##  838.21   14 < 0.0001        Wald-type
##  826.87   14 < 0.0001 Likelihood-Ratio
## 
## Details on meta-analytical method:
## - Random intercept logistic regression model
## - Maximum-likelihood estimator for tau^2
## - Hartung-Knapp adjustment for random effects model
## - Logit transformation
## - Clopper-Pearson confidence interval for individual studies
```

出力では、選択された研究における処方オピオイドの誤用のプールされた12ヶ月の有病率は9.4％であり、信頼区間の範囲は8.36から10.66％であることがわかる。

前述したように、この出力には各効果の個別の重みが表示されていない。同じように、研究間の異質性の推定値（$\tau^2 =$ 0.056）が得られるが、その周りの信頼区間はない。

$$\tag*{$\blacksquare$}$$
<br></br>

## 演習問題

```{block, type='boxquestion'}
**知識を試そう！**

\vspace{4mm}

1. 固定効果モデルとランダム効果モデルの違いは何か？

\vspace{-2mm}

2. 固定効果モデルとランダム効果モデルの結果が同じになるケースは考えられるか。

\vspace{-2mm}

3. $\tau^2$  とは何か？どのように推定するのか？

\vspace{-2mm}

4. Knapp-Hartung の調整はどの分布に基づいているか？どのような効果があるか？

\vspace{-2mm}

5. 「逆分散」 (inverse-variance) プーリングとはどういう意味か？この方法が最適解でないのはどのような場合か？

\vspace{-2mm}

6. 二値アウトカムデータをメタ分析したい。試験群の観察数はほぼ同じで、観察された事象は非常にまれで、治療効果が大きくなることは期待できない。どのようなプール方法を使用するか？

\vspace{-2mm}

7. GLMM はどのようなアウトカム指標に使用できるのか。


\vspace{4mm}



**問題の解答は、本書の巻末 [Appendix A](#qanda4) にある。**

```

<br></br>


## 要約

* 統計学において、モデルは、観測されたデータが生成された過程を記述する、簡略化された「理論」と見なすことができる。メタ分析には、固定効果モデルとランダム効果モデルの2つのモデルがある。

* 固定効果モデルが真の効果量が1つであることを仮定しているのに対し、ランダム効果モデルは真の効果量がメタ分析内でも変化することを述べている。したがって、ランダム効果モデルの目的は、データの根底にある真の効果量の分布の平均を見つけることである。

* ランダム効果メタ分析では、真の効果量の分散 $\tau^2$ （研究間異質性分散とも呼ばれる）を推定する必要がある。これにはいくつかの方法があり、どれが一番効果的かは文脈によって異なる。

* プール効果量を計算する最も一般的な方法は、逆分散法である。しかし、二値アウトカム・データでは、Mantel-Haenszel 法のような他のアプローチが望ましい場合がある。

*  **{meta}** パッケージには、事前に計算された効果量データのメタ分析を行う関数と、さまざまな種類の「生の」アウトカムデータに対して使用できる関数群がある。


<!--chapter:end:06-pooling_effect_sizes-ja.Rmd-->

# 研究間異質性  {#heterogeneity}

---

<img src="_figs/heterogeneity.jpg" />

<br></br>

<span class="firstcharacter">B</span>
メタ分析で効果量をプールする方法については、すでに説明してきた。今まで見てきたように、固定効果モデルもランダム化モデルも、多くの異なる研究の効果を1つの数値に統合することが目的である。しかし、これは、りんごとオレンジを比較していない場合にのみ意味がある。例えば、メタ分析で計算した全体的な効果は小さいが、非常に高い効果量を持つ外れ値がいくつか残っているということがあり得る。このような情報は集計された効果からは失われ、すべての研究が小さな効果量をもたらしたのか、それとも例外があったのかはわからない。 

\index{Heterogeneity}\index{異質性}
\index{Random-Effects Model}\index{ランダム効果モデル}

メタ分析において、真の効果量がどの程度異なるかを**研究間異質性** (between-study heterogeneity) と呼ぶ。この概念については、前章でランダム効果モデルとの関連ですでに簡単に触れた。ランダム効果モデルは、研究間の異質性によって研究の真の効果量が異なることを想定している。そのため、この真の効果の分散を定量化する推定値 $\tau^2$  を含む。これにより、真の効果量分布の平均値として定義されるプール効果を計算することが可能である。

ランダム効果モデルは、たとえ異質な研究であっても、常にプール効果量を計算することが可能である。しかし、このプールされた効果が意味のある方法で**解釈**できるかどうかはわからない。プール効果だけでは、メタ分析におけるデータをうまく表現できないシナリオがたくさんある。

異質性が非常に高く、（例えば、ある治療法の）真の効果の大きさが正から負までの範囲である場合を想像してみよう。このようなメタ分析のプール効果がプラスであったとしても、真の**マイナス**効果を持つ研究がいくつかあったということを伝えることができない。その治療法がいくつかの研究で悪影響を及ぼしたという事実は失われてしまう。 

異質性が高いということは、研究が、真の効果が異なる2つ以上の**サブグループ**に分けられるという事実によって引き起こされることもある。このような情報は研究者にとって非常に貴重であり、効果が低いまたは高い特定の条件を見つけることができるかもしれない。しかし、プール効果を単独で見ると、このような詳細は見逃される可能性がある。極端な場合、異質性が非常に高いと、研究に共通点がなく、プールされた効果を解釈することが全く意味をなさなくなる可能性すらある。

したがって、メタ分析では、常に分析した研究のばらつきを考慮しなければならない。優れたメタ分析では、全体的な効果を報告するだけでなく、この推定値がどの程度信頼できるかを明記する必要がある。そのために不可欠なのが、研究間の異質性を定量化し、分析することである。 

この章では、異質性を測定するさまざまな方法と、その解釈の仕方を詳しく見ていく。また、データ中の異質性に寄与している研究を検出することができるいくつかのツールについても説明する。最後に、「現実の」メタ分析で大量の異質性に対処する方法について説明する。 

<br></br>

## 異質性の尺度  {#het-measures}

---

異質性の尺度の議論を始める前に、まず異質性にはさまざまな意味があることを明らかにしておく必要がある。例えば、Rücker ら [-@rucker2008undue] は、**ベースライン**または**デザイン関連**の異質性と、**統計的**異質性を区別している。

* **ベースライン**または**デザイン関連**異質性は、研究の母集団または研究設計が研究間で異なる場合に生じる。この種の異質性については、「りんごとオレンジ」問題（Chapter \@ref(pitfalls)）や、研究課題の定義方法（Chapter \@ref(research-question)）について説明したときにも取り上げた。デザインに関連する異質性は、どのような種類の集団やデザインがメタ分析に適格であるかを決定する適切なPICOを設定することによって、**a priori**に低減させることが可能である。

* 一方、統計的異質性は、メタ分析に含まれる効果量推定値の広がりや精度によって影響を受ける、定量化可能な特性である。ベースライン異質性は、統計的異質性（例えば、含まれる集団間で効果が異なる場合）につながる可能性があるが、必ずしもそうである必要はない。また、メタ分析では、含まれる研究自体が事実上同一であっても、高い統計的異質性を示すことがある。このガイド（および他のほとんどのメタ分析のテキスト）では、「研究間の異質性」という用語は、**統計的**な異質性のみを指す。 

\index{Cochran's \textit{Q}}

<br></br>

### Cochran's $Q$  {#cochran-q}

---

ランダム効果モデルに基づくと、観察された効果が研究ごとに異なる原因となる変動要因は2つあることが分かっている。サンプリングエラー $\epsilon_k$  と、研究間の異質性による誤差 $\zeta_k$ である（Chapter \@ref(rem)）。研究間異質性を定量化したいとき、困難なのは、変動のどれだけがサンプリングエラーに起因し、どれだけが本当の効果量の違いに起因するのかを識別することである。

伝統的にメタ分析では、研究のサンプル誤差と実際の研究間の異質性を区別するために、**Cochran's** $Q$  [@cochran1954some] を使用している。Cochran's $Q$  は、**加重二乗和** (weighted sum of squares, _WSS_)として定義されている。これは、各研究の観察効果 $\hat\theta_k$  の要約効果 $\hat\theta$  からの偏差を、研究の分散の逆数 $w_k$ で重み付けしたものである。

\begin{equation}
Q = \sum^K_{k=1}w_k(\hat\theta_k-\hat\theta)^2
(\#eq:het1)
\end{equation}

\index{Inverse-Variance Weighting}\index{逆分散重み付け}

この式を詳しく見てみよう。まず、プール効果量に適用されるのと同じ逆分散加重が使われていることがわかる。この式の平均値 $\hat\theta$  は、固定効果モデルによるプール効果である。個々の効果が要約効果から逸脱する量である**残差**は、二乗され（値が常に正になるように）、重み付けされ、そして合計される。その結果の値が Cochran's $Q$ である。

$w_k$ による重み付けのため、$Q$ の値は、$\hat\theta_k$ が $\hat\theta$  からどれだけ乖離しているかだけでなく、研究の精度にも依存する。効果量の標準誤差が非常に小さい（つまり精度が非常に高い）場合、要約効果からの乖離が小さくても高い重みが与えられ、$Q$  の値が高くなる。

$Q$ の値は、データに**過剰な変動**があるかどうか、つまり、サンプル誤差だけから予想されるよりも多くの変動があるかどうかを確認するために使用することが可能である。もしそうであれば、残りの変動は研究間の異質性に起因すると考えることが可能である。このことをちょっとしたシミュレーションで説明しよう。

\index{Sampling Error}\index{サンプル誤差}

このシミュレーションでは、$Q$  が2つの異なるシナリオの下でどのように振る舞うかを検証したいと思われる：研究間の異質性がない場合と、異質性がある場合である。まず、異質性がない場合から始めよう。これは、$\zeta_k=0$  、残差 $\hat\theta_k-\hat\theta$  はサンプリング誤差 $\epsilon_k$ の積のみであることを意味する。ある平均効果量 $\hat\theta$  からの偏差をシミュレートするために、 `rnorm`  関数を使用することが可能である（正規分布に従うと仮定した）。それらは $\hat\theta$  を中心としているので、これらの「残差」の平均はゼロ（ $\mu$  = 0）であると期待可能である。この例では、母集団の標準偏差が $\sigma=$ 1 で、**標準**正規分布になると仮定しよう。 

正規分布は通常 $\mathcal{N}$  で示され、残差は $\mu=$  0 と $\sigma=$  1 の正規分布から得られることを次のように記号化することが可能である。

\begin{equation}
\hat\theta_k-\hat\theta \sim \mathcal{N}(0,1)
(\#eq:het2)
\end{equation}

これを  _R_  で試してみよう。 $K$ =40 効果量の残差 $\hat\theta_k-\hat\theta$  を  `rnorm`  を使って描画してみる。

```{r, eval=F}
set.seed(123) # needed to reproduce results
rnorm(n = 40, mean = 0, sd = 1)
```
```
##  [1] -0.56048 -0.23018  1.55871  0.07051  0.12929
##  [6]  1.71506  0.46092 -1.26506 -0.68685 -0.44566
##  [...]

```

標準正規分布が  `rnorm`  のデフォルトなので、より単純なコード  `rnorm(40)`  を使うこともできる。 

さて、この $n=$  40 回サンプルを描くという作業を何度も何度も繰り返すというシミュレーションをしてみよう。これは  `replicate`  関数を使って実現可能である。この関数では、 `rnorm`  の呼び出しを1万回繰り返すように指示した。その結果得られた値を  `error_fixed`  というオブジェクトに保存する。

```{r}
set.seed(123)
error_fixed <- replicate(n = 10000, rnorm(40))
```

サンプリングエラー $\epsilon_k$ に加えて、**研究間の異質性**（$\zeta_k$  誤差）が存在すると仮定する2番目のシナリオを続ける。これは、真の効果量の分散を表す  `rnorm`  の2回目の呼び出しを追加することでシミュレートすることが可能である。この例では、真の効果量が標準正規分布に従うと仮定する。 

このコードを使って、$K$ =40 件の研究に、かなりの研究間異質性を持たせて1万回のメタ分析の残差をシミュレートすることが可能である。

```{r}
set.seed(123)
error_random <- replicate(n = 10000, rnorm(40) + rnorm(40))
```

異質性**あり**と**なし**のメタ分析について、$\hat\theta_k-\hat\theta$  の残差をシミュレーションしたので、$Q$  の値についても同じことをしてみよう。 このシミュレーションでは、分散、したがって各研究の重み $w_k$  が**1**であると仮定することによって $Q$  の式を少し単純化し、結果として $w_k$  が式から脱落するようにすることが可能である。つまり、先ほどの  `rnorm`  の呼び出しを使って、結果を二乗して合計し、この処理を1万回繰り返せばよいことになる。 

以下はそのコードである。

```{r}
set.seed(123)
Q_fixed <- replicate(10000, sum(rnorm(40)^2))
Q_random <- replicate(10000, sum((rnorm(40) + rnorm(40))^2))
```

 $Q$  の重要な特性は、$\chi^2$  の分布に（おおよそ）従うと仮定されていることである。 $\chi^2$  分布は、加重二乗和のように、正の値のみを取ることが可能である。これは、その **自由度** 、または d.f. によって定義される。 $\chi^2$  分布は、小さな d.f. では右斜めになっているが、自由度が大きくなると正規分布に近づいていきる。同時に、自由度は、それぞれの $\chi^2$  分布の **期待値**、つまり平均値でもある。 

 $Q$  が $K-1$  の自由度を持つ $\chi^2$  分布にほぼ従うと仮定した（ $K$  はメタ分析における研究数）--**if** 効果量の差がサンプリングエラーによって **only** 起きたものである場合。これは、$K-1$  の自由度を持つ $\chi^2$  分布の平均が、サンプリング・エラーだけによって期待できる $Q$  の値を教えてくれることを意味した。

この説明は非常に抽象的なものであったので、より具体的にするために、シミュレーションした値の分布を見てみよう。以下のコードでは、効果量「残差」と $Q$  の値のヒストグラムをプロットするために、 `hist` 関数を使用している。また、各プロットに理想化された分布を示す線を追加している。 

このような分布は、正規分布の場合は  `dnorm`  関数で、$\chi^2$  の場合は  `dchisq`  関数で生成することが可能である。

```{r, eval=F}
# 残渣 (theta_k - theta) のヒストグラム
# - error_fixed と error_random 両方の
#   シミュレーション値のヒストグラムを作成
# - `lines` を使い、青色で正規分布を追加

hist(error_fixed, 
     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, 
     breaks = 100, ylim = c(0, .45), xlim = c(-4,4),
     main = "No Heterogeneity")
lines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), 
      col = "blue", lwd = 2)

hist(error_random, 
     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, 
     breaks = 100,ylim = c(0, .45), xlim = c(-4,4),
     main = "Heterogeneity")
lines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), 
      col = "blue", lwd = 2)


# Q-values のヒストグラム
# - Q_fixed と Q_random 両方の
#   シミュレーション値のヒストグラムを作成
# - `lines` を使い、青色でカイ二乗分布を追加

# まず、自由度 (k-1)　を計算
# 注意: k=40 件の研究を毎回のシミュレーションで使用
df <- 40-1

hist(Q_fixed, xlab = expression(italic("Q")), prob = TRUE, 
     breaks = 100, ylim = c(0, .06),xlim = c(0,160),
     main = "No Heterogeneity")
lines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), 
      col = "blue", lwd = 2)

hist(Q_random,  xlab = expression(italic("Q")), prob = TRUE, 
     breaks = 100, ylim = c(0, .06), xlim = c(0,160),
     main = "Heterogeneity")
lines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), 
      col = "blue", lwd = 2)

```


以下は、 _R_ が描いてくれるプロットである。



```{r, out.width="50%", echo=FALSE, collapse=TRUE, message=F, warning=F}

par(bg="#FFFEFA")

hist(error_fixed, 
     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, 
     breaks = 100, ylim = c(0, .45), xlim = c(-4,4),
     main = "No Heterogeneity")
lines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), col = "#014d64", lwd = 2)

hist(error_random, 
     xlab = expression(hat(theta[k])~-~hat(theta)), prob = TRUE, 
     breaks = 100,ylim = c(0, .45), xlim = c(-4,4),
     main = "Heterogeneity")
lines(seq(-4, 4, 0.01), dnorm(seq(-4, 4, 0.01)), col = "#014d64", lwd = 2)

df = 40-1

hist(Q_fixed, xlab = expression(italic("Q")), prob = TRUE, 
     breaks = 100, ylim = c(0, .06),xlim = c(0,160),
     main = "No Heterogeneity")
lines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), 
      col = "#014d64", lwd = 2)

hist(Q_random,  xlab = expression(italic("Q")), prob = TRUE, 
     breaks = 100, ylim = c(0, .06), xlim = c(0,160),
     main = "Heterogeneity")
lines(seq(0, 100, 0.01), dchisq(seq(0, 100, 0.01), df = df), 
      col = "#014d64", lwd = 2)


```


プロット生成に使用したコードがわかりにくいと思われるだろうが、ご心配なく。このシミュレーションのためだけに使用したものであり、実際のメタ分析の一部として作成されるプロットではない。

4つのヒストグラムに見られるものを見ていこう。最初の行は、効果量「残差」の分布で、異質性のあるものとないものがある。異質性のないデータは、私たちがプロットに含めた標準正規分布の線に忠実に沿っていることがわかる。これは、データがこの正確な分布を仮定して  `rnorm`  によって生成されたので、非常に論理的である。しかし、異質性を追加したデータは、標準正規分布に従いない。データの分散はより大きくなり、より重い尾を持つ分布になる。

\index{Cochran's \textit{Q}}

さて、これが2行目の $Q$  の値の分布とどう関係しているのかを探ってみよう。異質性がない場合、$Q$  の値は、特徴的な右肩上がりの $\chi^2$  分布に従いる。プロットでは、実線は自由度39の $\chi^2$  分布の形状を示している（d.f. = $K-1$ および $K$  = 40 が各シミュレーションで使われたので）。シミュレーションされたデータはこの曲線にかなりよく従っていることがわかる。これは大きな驚きではない。私たちは、異質性がないとき、$Q$  が $K-1$  の自由度を持つ $\chi^2$  分布に従うことを知りることとした。私たちのシミュレーションデータもまさにこのケースです：バラツキはサンプル誤差によってのみ存在した。 

異質性のある例では、分布は全く異なるように見える。シミュレーションされたデータは、期待された分布に全く従っていないように見える。値は目に見えて右にシフトしており、分布の平均は約2倍高くなっている。研究間にかなりの異質性がある場合、$Q$  の値は、異質性がないという仮定で期待される $K-1$  の値よりもかなり高くなると結論づけることが可能である。これは、研究間の異質性の存在をシミュレートするために、データに余分な変動を加えたので、驚くことではない。

\index{meta Package}

これはやや長い説明であったが、それでも、$Q$  の統計的特性をどのように利用できるかをより理解するのに役立っただろう。 コクランの $Q$  は、メタ分析における変動が、異質性がないという帰無仮説の下で期待する量を著しく超えているかどうかを**検定**するのに利用可能である。 

この**異質性の検定**はメタ分析でよく使われるもので、Chapter \@ref(pooling-es)  に戻ると、**{meta}**  もデフォルトで提供してくれていることがわかる。これはよく **Cochran's** $Q$  **test** と呼ばれるが、実はこれは誤記である。Cochran自身は $Q$  をこのように使うことを意図してはいないかった [@hoaglin2016misunderstandings]。

\index{DerSimonian-Laird Estimator}\index{DerSimonian-Laird 推定法}
\index{I$^2$, Higgins \& Thompson's}

 **{Cochranの $Q$  は、非常に重要な統計量である。これは、Higgins and Thompsonの $I^2$  統計量や $H^2$  など、異質性を定量化する他の一般的な方法がこれに基づいていることが主な理由である。これらの尺度については、次のセクションで説明した。Cochranの $Q$  は、いくつかの異質性分散推定器でも使われており、$\tau^2$  を計算した。最も有名なのは DerSimonian-Laird 推定量^[The DerSimonian-Laird method estimates the heterogeneity variance using $\hat\tau^2 = \dfrac{Q-(K-1)}{\sum_{k=1}^{K}w_k-\frac{\sum_{k=1}^Kw^2_k}{\sum_{k=1}^Kw_k}}$。$Q<(K-1)$ のとき、$\hat\tau^2 := 0$ である。 Chapters \@ref(rem) and \@ref(tau-estimators) も参照]。 

```{block, type='boximportant'}
**Problems With $Q$ & the $Q$-Test**

\vspace{2mm}

$Q$ はメタアナリシスでよく使われ報告されているが、いくつかの欠点がある。例えばHoaglin [-@hoaglin2016misunderstandings] は、$Q$ が自由度 $K-1$ の $\chi^2$ 分布に従うという仮定はメタ分析における $Q$ の実際の振る舞いを反映しておらず、したがって DerSimonian-Laird 法などにはバイアスがあるかもしれないと論じている。

\vspace{2mm}

より現実的な問題として、$Q$ は研究の数 $K$ と精度（すなわち研究のサンプルサイズ）が増加したときの両方で増加する。したがって、$Q$ とそれが有意であるかどうかは、メタアナリシスの規模、ひいてはその統計的検出力に大きく依存することになる。

このことから、異質性を評価する際には、$Q$-検定の有意性だけに頼るべきではないことがわかる。メタアナリシスでは、$Q$-検定の有意性に基づいて固定効果モデルかランダム効果モデルのどちらを適用するかを決めることがある。ここで述べた理由から、このアプローチは全く推奨されない。

```

<br></br>

### Higgins & Thompson’s $I^2$ 統計量  {#i-squared}

---

\index{I$^2$, Higgins \& Thompson's}

$I^2$ 統計量 [@higgins2002quantifying] は、研究間の異質性を定量化する別の方法で、Cochran's $Q$ に直接基づいている。これは、サンプリングエラーによって引き起こされない効果量の変動の割合と定義されている。$I^2$ は、異質性がないという帰無仮説のもと、自由度 $K-1$ を持つ $\chi^2$  分布に従っているという前提に基づいて作成されている。これは、異質性がない場合（すなわち、 $K-1$） のとき、$Q$ **観察**値が **期待された** $Q$ 値をどの程度超えているかをパーセントで定量化するものである。

$I^2$  の計算式は次のようになる。

\begin{equation}
I^2 = \frac{Q-(K-1)}{Q}
(\#eq:het3)
\end{equation}

ここで、$K$  は研究の総数である。 $I^2$  の値は 0% より低くすることはできないので、$Q$  が $K-1$  より小さい場合は、負の値ではなく、単に $0$  を使用した。 

 $I^2$  がどのように計算されるかを説明するために、先ほどの $Q$  のシミュレーション値を使用することが可能である。まず、異質性がないと仮定した  `Q_fixed`  の10番目のシミュレーション値をランダムに選びる。そして、上の式を使って、$I^2$  を計算する。

```{r}
# Display the value of the 10th simulation of Q
Q_fixed[10]

# Define k
k <- 40

# Calculate I^2
(Q_fixed[10] - (k-1))/Q_fixed[10]
```

結果がマイナスなので、ゼロに切り上げると、$I^2$  = 0%となる。この値は、効果量のばらつきの0%が研究間の異質性に起因していることを示している。これは、私たちのシミュレーションに使用された設定と一致している。

今度は、 `Q_random` の10番目のシミュレート値で同じことをした。

```{r}
(Q_random[10] - (k-1))/Q_random[10]
```

このシミュレーションの $I^2$  値は約50％で、変動の約半分が研究間異質性に起因していることがわかる。この例の変動は、サンプル誤差と研究間異質性のシミュレーションに等しく基づいているので、これも私たちの予想に沿ったものである。

メタ分析における研究間異質性を報告するために $I^2$  統計量を使用することは一般的であり、$I^2$  は **{meta}**  から得られる出力にデフォルトで含まれている。この統計量の人気は、この統計量をどう解釈するかの「経験則」が存在することと関連しているだろう [@higgins2002quantifying]。

* $I^2$  = 25%: 低い異質性

* $I^2$  = 50%：中程度の異質性

* $I^2$  = 75%: 実質的な異質性を有する。

<br></br>

### $H^2$ 統計量

---

 $H^2$  統計量 [@higgins2002quantifying] も Cochran の $Q$  から派生したもので、$I^2$  に似ている。これは、$Q$  で測定される観測された変動と、サンプル誤差による期待分散の比を記述するものである。

\begin{equation}
H^2 = \frac{Q}{K-1}
(\#eq:het4)
\end{equation}

 $Q$  が $K-1$  より小さい場合、その値を人為的に修正する必要がないため、$H^2$  の計算は $I^2$  の計算より少しエレガントである。研究間の異質性がない場合、$H^2$  は1（またはそれ以下）に相当した。1より大きい値は、研究間の異質性があることを示した。

 **{ $I^2$  と比較すると、発表されたメタ分析でこの統計量が報告されることは、はるかに少ない。しかし、$H^2$  は **{meta}**  のメタ分析関数の出力にデフォルトで含まれている。

<br></br>

### 異質性分散 $\tau^2$ &amp; 標準偏差 $\tau$.  {#tau}

---

異質性分散 $\tau^2$  については、すでに Chapter \@ref(rem)  で詳しく説明してきた。そこで述べたように、$\tau^2$  は、私たちのデータの基礎となる真の効果量の**分散**を定量化するものである。 $\tau^2$  の平方根をとると、$\tau$  が得られ、これは真の効果の大きさの**標準偏差**である。 

 $\tau$  の大きな特徴は、効果量と同じ尺度で表現されていることである。これは、たとえば、一次調査におけるサンプルの年齢の平均と標準偏差を解釈するのと同じように、これを解釈できることを意味した。 $\tau$  の値は、真の効果量の**範囲**について何かを教えてくれる。 

例えば、$\tau$  に 1.96 を掛け、プール効果量にこの値を加減することで、真の効果量の95%信頼区間を計算することが可能である。 Chapter \@ref(pre-calculated-es)  で計算した  `m.gen`  メタ分析を使って、これを試してみることが可能である。 

このメタ分析におけるプール効果と $\tau$  推定値がどのようなものであったか、もう一度見てみよう。

```{r, echo=F, message=F, warning=F}
library(meta)
library(dmetar)
data(ThirdWave)
m.gen <- metagen(TE = TE,
                 seTE = seTE,
                 studlab = Author,
                 data = ThirdWave,
                 sm = "SMD",
                 comb.fixed = FALSE,
                 comb.random = TRUE,
                 method.tau = "REML",
                 hakn = TRUE,
                 title = "Third Wave Psychotherapies")

```


```{r}
# 効果プール
m.gen$TE.random

# tau 推定
m.gen$tau
```

 $g=$  0.58、$\tau=$  0.29であることがわかる。このデータに基づいて、95%真の効果量の信頼区間の下限と上限を計算することが可能である： 0.58 $-$  1.96 $\times$  0.29 = 0.01 と 0.58 $+$  1.96 $\times$  0.29 = 1.15.

```{block2, type='boxinfo'}
**「不確かさの不確かさは？」: $\tau^2$ の信頼区間の計算**

\vspace{2mm}

研究間異質性分散推定値の不確実性（すなわち、$\tau^2$ 付近の信頼区間）を定量化する方法は、現在も検討されている分野である。いくつかのアプローチが考えられますが、その妥当性は $\tau^2$ 推定量の種類に依存する（Chapter \@ref(tau-estimators)）。

\vspace{4mm}

**{meta}** パッケージは Veronikki  [-@veroniki2016methods]の推奨に従い、ほとんどの推定量に対して $Q$**-Profile** 法 [@viechtbauer2007confidence] を使用する。

\vspace{4mm}

The $Q$-Profile method is based on an altered $Q$ version , the **generalized** $Q$**-statistic** $Q_{\text{gen}}$. While the standard version of $Q$ uses the pooled effect based on the fixed-effect model, $Q_{\text{gen}}$ is based on the random-effects model. It uses the overall effect according to the random-effects model, $\hat\mu$, to calculate the deviates, as well as weights based on the random-effects model:
$Q$-Profile 法は、$Q$ の改良版である**一般化** $Q$**-統計量** $Q_{\text{gen}}$を用いた手法である．標準版の$Q$が固定効果モデルに基づくプール効果を用いるのに対し，$Q_{\text{gen}}$ はランダム効果モデルに基づいている。ランダム効果モデルによる全体効果である $\hat\mu$ とランダム効果モデルに基づく重みを用いて偏差を計算する。

\begin{equation}
Q_{\text{gen}} = \sum_{k=1}^{K} w^*_k (\hat\theta_k-\hat\mu)^2
(\#eq:het5)
\end{equation}

ここで、$w^*_k$  はランダム効果重み（ Chapter \@ref(tau-estimators)  を参照）である。

\begin{equation}
w^*_k = \frac{1}{s^2_k+\tau^2} 
(\#eq:het6)
\end{equation}

また、$Q_{\text{gen}}$ は自由度 $K-1$ の $\chi^2$ 分布に従うことが示されている。一般化　$Q$　統計量は $\tau^2)$ の値が大きいか小さいかで異なる値の $Q_{\text{gen}}$ を返す関数 $Q_{\text{gen}}(\tau^2)$  と考えることができる。この関数の結果は、$\chi^2$ 分布となる。

\vspace{4mm}

この$\chi^2$ 分布は明確に予測できるパターンに従っているので、例えば95%包含の信頼区間を簡単に求めることができる。その自由度 $K-1$ に基づいて、2.5\textsuperscript{th}  と97.5\textsuperscript{th} パーセンタイルの $\chi^2$ の値を求めればよい。 _R_ では、これは**分位数関数** `qchisq` を使用して簡単に行うことができる。例えば： `qchisq(0.975, df=5)`。

\vspace{4mm}

$Q$-Profile 法は、この関係を利用して、$\tau^2$ 付近の信頼区間を繰り返し計算する手法である(いわゆる「プロファイリング」)。この方法では、$Q_{\text{gen}}(\widetilde{\tau}^2)$ の値を増加させながら、$\chi^2$ 分布に基づく信頼区間の下限と上限の期待値に到達するまで繰り返し計算する。

\vspace{4mm}

$Q$-Profile 法は、**{meta}** 関数の中で `method.tau.ci = "QP"` という引数で指定することができる。これはデフォルトの設定であり、この引数を手動で追加する必要はない。唯一の例外は、DerSimonian-Laird 推定法 (`method.tau = "DL"`) を使用した場合である。この場合，自動的に Jackson [-@jackson2013confidence] による別の手法が使用される（手動で `method.tau.ci = "J"` と指定することで可能）。

通常、**{meta}** のデフォルトの動作から外れる必要はないが、メタアナリシスにおいて、どの方法で $\tau^2$ の信頼区間を計算したかを報告することは、他の人にとって有益な場合があります。

```

<br></br>

## どの方法を使うべきか？ {#het-measure-which}

---

メタアナリシスで異質性を評価・報告する場合、統計的検出力の影響をあまり受けず、かつ頑健な指標が必要です。コクランの $Q$ は、研究の数が増えれば増えるほど、また精度（すなわち研究のサンプルサイズ）が上がれば上がる。

つまり、$Q$ とそれが有意であるかどうかは、メタアナリシスの規模、その統計的検出力に大きく依存することになる。したがって、研究間の異質性を評価する際には、$Q$、特に $Q$-検定だけに頼るべきではない。

一方、$I^2$ は、分析対象の研究数の変化に対して敏感ではない。解釈も比較的簡単で、多くの研究者がその意味を理解している。一般的に、メタアナリシス報告書に異質性の指標として$I^2$ を含めることは悪い考えではない。特に、この統計量の信頼区間を示すことで、他の人が推定値の正確さを評価することができるようになる。

\index{Sampling Error}\index{サンプル誤差}
\index{I$^2$, Higgins \& Thompson's}
\index{Heterogeneity}\index{異質性}

しかし、文献上ではよく使われているが、$I^2$ も異質性を測る完璧な指標ではない。異質性の絶対的な尺度ではなく、その値はやはり含まれる研究の精度に大きく依存する [@borenstein2017basics; @rucker2008undue]。先ほども言ったように、$I^2$ は単純にサンプリングエラー $\epsilon$ によって引き起こされない変動の割合である。我々の研究がどんどん大きくなれば、サンプリングエラーはゼロになる傾向があり、同時に $I^2$ は100%になる傾向がある--単に研究のサンプルサイズが大きくなったからである。

したがって、$I^2$に**だけ**頼るのは良い選択肢とは言えません。$H^2$ は $I^2$ と似たような挙動をするので、この統計量にも同じ注意点があります。

一方、$\tau^2$ と $\tau$ の値は、研究数とその精度に依存しない。研究数や研究規模が大きくなっても系統的に増加することはありません。しかし、$\tau^2$ が実用上どの程度の意味を持つのか、解釈しにくいことがあります。例えば、我々の研究で真の効果量の分散が $\tau^2=$ 0.08であることが分かったとします。この分散が意味のあるものなのか、そうでないものなのかを判断するのは、自分自身にとっても、他の人にとっても、難しい場合があります。

\index{Prediction Interval}

**予測区間** (Prediction intervals, PIs)) は、この制限を克服する良い方法である [@inthout2016plea]。予測区間は、現在の証拠に基づき、将来の研究の効果がどの範囲に収まると予想できるかを示している。

我々の予測区間が完全に介入に有利な「正」側にあるとする。これは、効果はさまざまであっても、我々が調査した文脈全体では、介入は将来有益であると期待されることを意味する。予測区間にゼロが含まれる場合、これについてはあまり確信が持てないが、広い予測区間はかなり一般的であることに注意する必要がある。

全体効果の予測区間 $\hat\mu$ を計算するために、推定された研究間異質性分散 $\hat\tau^2$ とプールされた効果の標準誤差 $SE_{\hat\mu}$ の両方を使用する。標準誤差の二乗と $\hat\tau^2$ の値を合計し、その平方根をとる。これによって、予測区間の標準偏差 $SD_{\text{PI}}$ が得られる。予測範囲は自由度$K-1$の$t$分布を仮定しているので、$SD_{\text{PI}}$ に $t_{K-1}$  の97.5\textsuperscript{th}値を掛け、その結果を $\hat\mu$ に加算・減算することになる。これは、プールされた効果の95%予測区間を与える。

95%予測区間の計算式は次のようになる。


\begin{align}
\hat\mu &\pm t_{K-1, 0.975}\sqrt{SE_{\hat\mu}^2+\hat\tau^2} \notag \\
\hat\mu &\pm t_{K-1, 0.975}SD_{\text{PI}} (\#eq:het7)
\end{align}

 **{meta}** のすべての関数は、プールされた効果に対する予測区間を提供することができるが、デフォルトではない。メタ分析を実行する際には、予測区間が出力されるように  `prediction = TRUE`  という引数を追加する必要がある。

まとめると、メタ分析の異質性を特徴付ける際に、一つの指標だけに頼らないことが望ましいということである。少なくとも、常に $I^2$ （信頼区間付きで）、予測区間を報告し、それに従って結果を解釈することが推奨される。

<br></br>

##  _R_  の異質性を評価する  {#het-R}

---

異質性指標について学んだことを、実際にどのように使うことができるかを見てみよう。例として、私たちの  `m.gen`  メタ分析オブジェクトの異質性をもう少し詳しく調べてみよう（このオブジェクトは Chapter \@ref(pre-calculated-es)  で生成してきた）。 

`metagen` オブジェクトのデフォルトの出力には予測区間が含まれていないため、まずそれを更新する必要がある。単純に `update.meta` 関数を使用し、`prediction` の区間を追加で出力するように指示する。

```{r}
m.gen <- update.meta(m.gen, prediction = TRUE)
```

これで、結果を再確認することができる。

```{r, eval=F}
summary(m.gen)
```

```
## Review:     Third Wave Psychotherapies
## 
## [...]
## 
## Number of studies combined: k = 18
## 
##                         SMD            95%-CI    t  p-value
## Random effects model 0.5771 [ 0.3782; 0.7760] 6.12 < 0.0001
## Prediction interval         [-0.0619; 1.2162]              
## 
## Quantifying heterogeneity:
##  tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944];
##  I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]
## 
## Test of heterogeneity:
##      Q d.f. p-value
##  45.50   17  0.0002
## 
## Details on meta-analytical method:
## - Inverse variance method
## - Restricted maximum-likelihood estimator for tau^2
## - Q-profile method for confidence interval of tau^2 and tau
## - Hartung-Knapp adjustment for random effects model
```

出力では、前に定義したすべての異質性測定の結果が表示される。まず、`Quantifying heterogeneity` のセクションから始めよう。ここで、$\tau^2=$  0.08であることがわかる。 $\tau^2$  (0.03 - 0.35)の信頼区間はゼロを含まず、私たちのデータに何らかの研究間異質性が存在することを示している。 $\tau$  の値は0.29である。これは、真の効果量が、効果量の尺度（ここでは、Hedges' $g$ ）で表される、$SD=$  0.29 の推定標準偏差を有することを意味する。

2行目を見ると、$I^2=$  63%、$H$ （$H^2$  の平方根）は1.64であることがわかる。これは、データにおける変動の半分以上が、真の効果量の差から生じていると推定されることを意味している。Higgins and Thompson の「経験則」を用いると、この異質性の量は中程度から大きいと特徴づけることが可能である。 

プール効果の直下に、予測区間が表示されている。これは、$g=$  -0.06 から 1.21 までの範囲である。これは、現在のエビデンスに基づいて、将来のいくつかの研究が負の治療効果を発見する可能性があることを意味する。しかし、この区間はかなり広く、非常に高い効果も可能であることを意味する。

\index{Cochran's \textit{Q}}

最後に、$Q$ と `Test of heterogeneity` も提示されている。 $Q$ =45.5であることがわかる。これは、この分析の $K-1=$  17の自由度に基づいて期待されるものよりずっと多いものである。その結果、異質性検定は有意である ($p<$  0.001)。しかし、前に述べたように、$Q$  の欠陥が知られている以上、 この検定だけに基づいて評価を行うべきではない。

```{block, type='boxreport'}
**メタアナリシスにおける不均一性の量を報告**

\vspace{4mm}

この例における異質性の量をどのように報告する文章を例示する。

> _"The between-study heterogeneity variance was estimated at $\hat\tau^2$ = 0.08 (95%CI: 0.03-0.35), with an $I^2$ value of 63% (95%CI: 38-78%). The prediction interval ranged from $g$ = -0.06 to 1.21, indicating that negative intervention effects cannot be ruled out for future studies."_

```


では、これらの結果から何がわかるのだろうか。全体として、私たちの指標は、中程度からかなりの異質性が私たちのデータに存在することを教えてくれる。メタ分析における効果は完全な異質性ではないが、研究間の真の効果量には明らかにいくつかの違いがある。 

したがって、この異質性の原因を探るのは良いアイデアだろう。効果量が大きいため、実際には「当てはまらない」研究が1つまたは2つある可能性がある。これは、私たちの分析における異質性を増大させ、さらに悪いことには、真の効果の**過大評価**につながった可能性がある。 

一方、プールされた効果は、サンプルサイズが非常に大きい1つの研究が予想外に小さい効果量を報告したことに大きく影響されている可能性もある。これは、プール効果が治療の真の効果を**過小評価**していることを意味する可能性がある。 

これらの懸念に対処するため、次に、プールした結果の頑健性を評価するための手続きを説明する。**外れ値分析**と**影響度分析**である。

\index{I$^2$, Higgins \& Thompson's}

```{block2, type='boxinfo'}
**$I^2$ > 50% "Guideline"**

\vspace{4mm}

研究間の異質性について、具体的にいつさらなる解析が必要かを決める鉄則はない。実際に使われることもあるアプローチは、$I^2$ が 50%より大きいときに外れ値や影響力のあるケースをチェックすることである。この閾値に達すると、少なくとも中程度の異質性があり、変動の（半分以上が）真の効果量の差に起因していると仮定することができる。

\vspace{4mm}

この「経験則」は、やや恣意的なものであり、これまで述べてきた $I^2$ の問題を考えると、決して完全なものではない。しかし、メタ分析でプールされた効果のよりロバストなバージョンを得ようとするときに、**a priori** に一貫した方法で指定することができるので、実用的な観点から役に立つ。

\vspace{4mm}

避けなければならないのは、結果が気に入ったからと言って、厳密な根拠もなく、外れ値や影響力のあるケースを削除することである。そのような結果は、たとえ意識的に「好ましい」方向に結果を曲げようとしなかったとしても、「研究者の意図」（Chapter \@ref(pitfalls) 参照）によって大きバイアスになってしまう。
```

<br></br>

## 外れ値と影響力のある事例  {#outliers}

---

\index{Outlier}\index{外れ値}
\index{Influential Case}

前述したように、研究間の異質性は、効果量が極端に大きい1つまたは複数の研究によって引き起こされることがあり、それは全く「適合」しない。これはプールされた効果の推定値を歪める可能性があり、そのような**外れ値**を分析から取り除いた後にプールされた効果を再検査することは良い考えである。

一方、私たちは、私たちが見つけたプール効果推定値が頑健であるかどうか、つまり、一つの研究に大きく依存しないかどうかも知りたいと思われる。したがって、私たちの分析の効果を一方向に大きく押し上げるような研究があるかどうかも知りたいのである。このような研究は、**影響力のあるケース**と呼ばれ、この章の後半でこのトピックに時間を割くことになる。

<br></br>

### 基本的な外れ値除去  {#basic-outlier}

---

ある研究の効果を「外れ値」と定義するには、いくつかの方法がある [@viechtbauer2010outlier]。簡単で、やや「強引な」アプローチは、研究の信頼区間がプール効果の信頼区間と重ならない場合、その研究をoutlierとみなすことである。外れ値の効果量は、全体の効果量と著しく異なるほど**極端**である。このような外れ値を検出するために、すべての研究を検索することが可能である。

* 95%信頼区間の上限**がプール効果信頼区間の下限**より**低い**もの（すなわち、極端に**小さい**効果）。

* 95%信頼区間の**下限**がプール効果信頼区間の**上限**より**高い**もの（すなわち、極めて**大きい**効果）。

この方法の背景にある考え方は非常に単純である。サンプル誤差が大きい研究は、プール効果からかなり乖離することが予想される。しかし、そのような研究の信頼区間も大きくなるので、信頼区間がプールされた効果の信頼区間と重なる可能性が高くなる。 

しかし、ある研究が**低い**標準誤差を持ち、**それでも**（予想外に）プール効果から大きく逸脱している場合、信頼区間が重ならず、その研究は外れ値として分類される可能性が高い。

\index{dmetar Package}

 **{dmetar}** パッケージには  `find.outliers`  という関数があり、この単純な外れ値除去アルゴリズムが実装されている。これは、**{meta}**  オブジェクトから外れ値の研究を検索し、それらを削除して、結果を再計算する。

```{block, type='boxdmetar'}
**"find.outliers" 関数**

\vspace{4mm}

`find.outliers` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

\vspace{2mm}

1. 関数のソースコードにアクセスする [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R). 
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。
3. **{meta}** と **{metafor}** パッケージがインストールされ、ロードされていることを確認する。

```


`find.outliers` 関数は、**{meta}**  メタ分析関数によって生成されたオブジェクトを入力として必要とするだけである。それでは、`m.gen` オブジェクトに対してどのような結果が得られるか見てみよう。

```{r, eval=F}
find.outliers(m.gen)
```

```
## Identified outliers (random-effects model) 
## ------------------------------------------ 
## "DanitzOrsillo", "Shapiro et al." 
##  
## Results with outliers removed 
## ----------------------------- 
## Number of studies combined: k = 16
## 
##                         SMD           95%-CI    t  p-value
## Random effects model 0.4528 [0.3257; 0.5800] 7.59 < 0.0001
## Prediction interval         [0.1693; 0.7363]              
## 
## Quantifying heterogeneity:
##  tau^2 = 0.0139 [0.0000; 0.1032]; tau = 0.1180 [0.0000; 0.3213];
##  I^2 = 24.8% [0.0%; 58.7%]; H = 1.15 [1.00; 1.56]
## 
## Test of heterogeneity:
##      Q d.f. p-value
##  19.95   15  0.1739
## 
## [...]
```

\index{Weight}\index{重み}

`find.outliers` 関数が、"DanitzOrsillo" と "Shapiro et al." という2つの外れ値を検出したことがわかる。また、この関数は、検出された研究を除外しながら、自動的に分析を再実行してきた。各研究のランダム効果重みを表示す列、`%W(random)` では、外れ値の研究の重みが0に設定され、分析から除外されていることがわかる。

\index{I$^2$, Higgins \& Thompson's}

出力に基づき、2つの研究が除外されると、$I^2$  異質性がかなり縮小し、$I^2=$  63%から25%になることがわかる。 $\tau^2$  の信頼区間はゼロを含み、$Q$ -異質性の検定は有意ではなくなりることとした。その結果、私たちの推定値の予測区間も狭くなっている。今、それは正の値だけを含み、将来の研究にわたるプールされた効果の頑健性をより確実なものにしている。

<br></br>

### 影響力分析  {#influence-analysis}

---

\index{Influential Case}

ここまでで、メタ分析における外れ値の検出と除去の基本的な方法を学びることとした。しかし、プールされた効果の頑健性についての懸念を引き起こすのは、極端な効果量だけではない。効果量が特に大きくなくても小さくても、全体の結果に非常に大きな影響力を及ぼす研究もある。 

例えば、メタ分析で全体的な効果を発見しても、その有意性は1つの大きな研究に依存している可能性がある。これは、影響力のある研究を取り除くと、プールされた効果が統計的に有意でなくなることを意味した。このような情報は、私たちの結果がいかに頑健であるかを一般に伝えるために非常に重要である。

外れ値のある研究と影響力のある研究とは、重複してい流部分もあるが、若干意味が異なる。外れ値は効果の大きさによって定義されるが、必ずしもメタ分析の結果に大きな影響を与える必要はない。外れ値を削除しても、平均効果量やデータの異質性が大きく変化しないことは十分にあり得る。 

一方、影響力のある事例とは、効果の高低にかかわらず、定義上、プールされた効果や異質性に大きな影響を与える研究のことを指す。もちろん、効果量が極端に大きい研究が影響力のあるケースになりえないということではない。実際、前章の例で説明したように、外れ値も影響力があることが多いのである。しかし、必ずしもそうでなければならないわけではない。

\index{Leave-One-Out Method}

影響力のある研究を特定するテクニックはいくつかあり、前回説明した基本的な外れ値除去よりも少し高度なものである。これらは **leave-one-out** 法に基づいている。このアプローチでは、メタ分析の結果を $K$  回再計算し、毎回 **leave out** している。 

このデータに基づいて、さまざまな**影響度診断**を計算することが可能である。影響度診断は、メタ分析の全体推定値に最も影響を与える研究を検出し、この大きな影響力がプール効果を歪めていないかどうかを評価することが可能である [@viechtbauer2010outlier]。


\index{dmetar Package}

 **{dmetar}** パッケージには  `InfluenceAnalysis`  という関数が含まれており、1つの関数でこれらの様々な影響度診断を計算することが可能である。この関数は、**{meta}** 関数で作成されたあらゆるタイプのメタ分析オブジェクトに使用することが可能である。

```{block, type='boxdmetar'}
**"InfluenceAnalysis" 関数**

\vspace{4mm}

`InfluenceAnalysis` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

\vspace{2mm}

1. 関数のソースコードにアクセスする [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R). 
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。
3. **{meta}**, **{metafor}**, **{ggplot2}** and **{gridExtra}** パッケージがインストールされ、ロードされていることを確認する。

```

`InfluenceAnalysis` 関数の使用方法は比較的簡単である。影響度分析を行いたいメタ分析オブジェクトの名前を指定するだけである。ここでは、再び `m.gen` オブジェクトを使用した。 

`InfluenceAnalysis` はデフォルトで固定効果モデルを使用するので、 `random = TRUE` を設定して、ランダム効果モデルが使用されるようにする必要がある。この関数は他の引数も取ることができ、それらは主に関数が生成するプロットの種類を制御した。これらの引数については、関数のドキュメントで詳しく説明されている。

関数の結果を  `m.gen.inf`  というオブジェクトに保存する。


```{r, eval=F}
m.gen.inf <- InfluenceAnalysis(m.gen, random = TRUE)

```

```{r, echo=F}
load("data/m_gen_inf.rda")
```

`InfluenceAnalysis` 関数は、4つの影響診断プロットを作成した：**Baujat**プロット、Viechtbauer and Cheung [-@viechtbauer2010outlier] による**影響診断**、効果量と $I^2$  値でソートされた leave-one out メタ分析結果である。これらのプロットはそれぞれ `plot` 関数で個別に開くことが可能である。それでは、順を追って見ていこう。

<br></br>

#### Baujat プロット  {#baujat}

---

Baujat プロットは  `plot`  関数を用いて、第2引数に `"baujat"`  を指定することで表示できる。

```{r, eval=F}
plot(m.gen.inf, "baujat")
```

```{r, out.width='70%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/baujat_col_sep.png')
```

Baujat plots [@baujat2002graphical] は、メタ分析における異質性に過度に寄与している研究を検出するための診断プロットである。**横**軸に全体の**異質性**（Cochranの $Q$  で測定）に対する各研究の寄与を、**縦**軸に**プール効果量**に対するその**影響**を示している。 

この「影響力」の値は、leave-one-out 法により決定され、その研究がメタ分析に含まれる場合と含まれない場合の全体効果の標準化された差を表している。 

プロットの右側にある研究は、私たちのメタ分析における全体的な異質性に大きく寄与しているので、潜在的に関連するケースと見なすことが可能である。プロットの右上にある研究は、推定された異質性とプールされた効果の両方に大きな影響を与えるので、特に影響力があると思われる。

お気づきのように、プロットの右側にある2つの研究は、以前すでに検出したものである（"DanitzOrsillo" と "Shapiro et al."）。これらの研究は全体の結果に大きな影響を与えないが（サンプルサイズが小さいためと思われる）、メタ分析で見られる異質性に大きな影響を及ぼしている。

<br></br>

#### 影響力診断  {#inf-diags}

---

次のプロットは、各研究のいくつかの影響度診断を含んでいる。これらは、このコードを使ってプロットすることが可能である。

```{r, eval=F}
plot(m.gen.inf, "influence")
```

```{r, out.width='70%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/influence_col_sep.png')
```

このプロットは、各研究について、さまざまな影響度の値を表示していることがわかる。これらの尺度は、どの研究がメタ分析モデルにうまく適合して、どの研究が適合しないかを特徴づけるために使用される。診断の意味を理解するために、左から右、上から下へと簡単に見ていこう。


<br></br>

##### 外部標準化残差

---

\index{Leave-One-Out Method}

最初のプロットは、各研究の外部標準化残差を表示した。名前にあるように、これらの残差は、観察された各効果量 $\hat\theta_k$  のプール効果量からの偏差を表している。残差は標準化されており、偏差を計算するために、研究を含まないプールされた効果の "外部 "推定値を使用する。 

 「外部」プール効果 $\hat\mu_{\setminus k}$  は、leave-one-out 法の原則に従って、研究 $k$  を除いた全体効果を計算することによって得られる。そして、得られた残差は、(1) 外部効果の**分散**（すなわち、$\hat\mu_{\setminus k}** $  の標準誤差の2乗）、(2) 外部プール効果の推定値 $\tau^2$  、および (3) $k$  の分散によって標準化される。

\begin{equation}
t_{k} = \frac{\hat\theta_{k}-\hat\mu_{\setminus k}}{\sqrt{\mathrm{Var}(\hat\mu_{\setminus k})+\hat\tau^2_{\setminus k}+s^2_k}} 
(\#eq:het8)
\end{equation}

\index{Sampling Error}\index{サンプル誤差}

研究 $k$  がメタ分析にうまく適合すると仮定すると、分母の3つの項は、効果量が平均効果量からどれくらい異なるかを決定する変動源を捕捉した。これらの変動要因は、$k$  のサンプル・エラー、真の効果量の分散、およびプールされた効果量の推定値の不正確さである。 

もし研究が全体の母集団に**合わない** ならば、残差は3つの分散項だけから予想されるよりも**大きくなる**と仮定可能である。これは、$t_k$  の値を高くし、その研究が「適合しない」影響力のあるケースであることを示した。 

<br></br>

##### $\mathrm{DFFITS}$ 値

---

$\mathrm{DFFITS}$ 量の計算は、外部標準化残差の計算と同様である。したがって、DFFITSと $t_k$  の値のパターンは、多くの場合、研究間で比較可能である。これが計算式である。

\begin{equation}
\mathrm{DFFITS}_k =  \dfrac{\hat\mu-\hat\mu_{\setminus k}}{\sqrt{\dfrac{w_k^{(*)}}{\sum^{K}_{k=1}w_k^{(*)}}(s^2_k+\hat\tau^2_{\setminus k})}}
\end{equation}

計算には、研究 $k$  ( Chapter \@ref(fem) ) の（ランダム効果）重みである $w_k^{(*)}$ も必要で、これを重みの合計で割って研究の重みをパーセントで表現することになる。 

一般に、$\mathrm{DFFITS}$  の値は、ある研究（ $k$  ）を削除したときに、プールされた効果がどの程度変化するかを示し、標準偏差で表される。ここでも、値が高いほど、平均効果への影響が大きいので、ある研究が影響力のあるケースである可能性を示している。

<br></br>

##### Cook 距離

---

\index{Cook's Distance}

ある研究の Cook 距離 $D_k$  は、$\mathrm{DFFITS}$  の値と非常によく似た式で計算できる。最大の違いは、$D_k$  の場合、$k$  の有無によるプール効果の差は **2乗** になることである。 

この結果、$D_k$  は正の値のみをとることになる。しかし、研究間のパターンは、$\mathrm{DFFITS}$  の値と似ていることが多い。以下はその式である。

\begin{equation}
D_k =  \frac{(\hat\mu-\hat\mu_{\setminus k})^2}{\sqrt{s^2_k+\hat\tau^2}}.
(\#eq:het9)
\end{equation}

\vspace{1mm}

<br></br>

##### 共分散比

---

研究 $k$  の共分散比は、$k$  のないプール効果の分散（すなわち、その二乗標準誤差）を初期平均効果の分散で割ることによって算出することが可能である。

\begin{equation}
\mathrm{CovRatio}_k = \frac{\mathrm{Var}(\hat\mu_{\setminus k})}{\mathrm{Var}(\hat\mu)}
(\#eq:het10)
\end{equation}

$\mathrm{CovRatio}_k$ が 1 ß以下の値は、研究 $k$  を削除することで、プール効果量 $\hat\mu$ のより正確な推定値が得られることを示す。

<br></br>

##### Leave-One-Out $\tau^2$ 値と $Q$ 値

---

\index{Cochran's \textit{Q}}

この行の値は非常に簡単に解釈可能である。これらは単に、$\tau^2$  と Cochranの $Q$  、研究 $k$  を削除した場合に測定される推定異質性を表示しているだけである。 $Q$  、特に $\tau^2$  の値が低いほど、異質性が低いことを意味するので、望ましい。


<br></br>

##### ハット値と研究の重み

---

最後の行には、各研究の重みとハット値が表示されている。研究重みの計算と意味については、すでに Chapter \@ref(fem)  で詳しく説明したので、この指標についてはこれ以上説明する必要はないだろう。一方、ハット値とは、研究の重みと等価な別の指標に過ぎない。したがって、影響力分析では、ハット値と重みのパターンは同一になる。 

これらの指標はすべて、極端な場合、その研究が影響力のあるケースであることを示し、プールした結果の頑健性に悪影響を及ぼす可能性のある値を示している。しかし、このポイントに到達するタイミングはあまり明確ではない。 $\mathrm{DFFITS}$ , Cook 距離または標準化残差値が高**すぎる**という厳密なルールはない。研究を削除することが適切かどうかを判断するために、研究課題の文脈で影響度分析の結果を評価することが常に必要である。

しかし、私たちの判断の指針となる「経験則」がいくつかある。`InfluenceAnalysis `関数は、以下の条件のいずれかを満たす場合、その研究を影響力のあるケースとみなす^[これらの条件は、**{metafor}** の[`influence.rma.uni`]（https://www.rdocumentation.org/packages/metafor/versions/2.4-0/topics/influence.rma.uni）関数が使用している「親指のルール」から派生している。`InfluenceAnalysis` はこの関数を「隠れて」適用する]:

\begin{equation}
\mathrm{DFFITS}_k > 3\sqrt{\frac{1}{k-1}}
(\#eq:het11)
\end{equation}

\vspace{1mm}

\begin{equation}
D_k > 0.45
(\#eq:het12)
\end{equation}

\vspace{1mm}

\begin{equation}
\mathrm{hat_k} > 3\frac{1}{k}.
(\#eq:het13)
\end{equation}

影響力があると判断された研究は、 `InfluenceAnalysis` 機能で生成されたプロットで赤色で表示される。 

この例では、"DanitzOrsillo" 研究である "Dan" の場合のみ、こうなる。しかし、この研究だけが影響力があると定義されたが、実際にはほとんどのプロットで**2**個のスパイクが存在した。また、"Sha" (Shapiro et al.) の値も非常に極端なので、影響力のあるケースとして定義することが可能である。

そこで、"DanitzOrsillo" と"Shapiro et al." の研究が影響力を持つ可能性があることがわかる。これは、Baujat プロットに基づき、統計的外れ値だけを見たときに、同じ研究を選択したため、興味深い発見である。 

このことは、この2つの研究がプールされた効果推定値を歪め、最初のメタ分析で見出された研究間異質性の一部を引き起こしている可能性をさらに裏付けるものである。

<br></br>

#### Leave-One-Out メタ分析結果  {#loo-ma}

---

\index{Leave-One-Out Method}
\index{Forest Plot}\index{フォレストプロット}

最後に、leave-one-out 法を用いて実施されたすべてのメタ分析の全体効果および $I^2$  異質性をプロットすることも可能である。1つはプール効果量、もう1つは leave-one-out メタ分析の $I^2$  値でソートされた2つの**フォレストプロット** （ Chapter \@ref(forest-R)  でもっと詳しく知ることになるプロットのタイプ）を表示すことが可能である。プロットを作成するコードは次のようなものである。

```{r, eval=F}
plot(m.gen.inf, "es")
plot(m.gen.inf, "i2")
```

```{r, out.width='100%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/forestesi2_col_sep.png')
```

これらの2つのフォレストプロットでは、毎回1つの研究を省略して再計算されたプール効果を見ることが可能である。両方のプロットで、中央に破線のある陰影のある領域がある。これは、元のプール効果量の95%信頼区間と推定されたプール効果そのものを表している。

最初のプロットは、効果量（低から高）順に並べたものである。ここでは、異なる研究を削除したときに、全体の効果推定値がどのように変化するかを見ている。"DanitzOrsillo "と "Shapiro et al." の2つの研究は、非常に高い効果量を持っているので、それらを取り除くと、全体の効果量が最も小さくなることがわかる。

2番目のプロットは、$I^2$  で測定された異質性（低から高）順に並んでいる。このプロットは、"DanitzOrsillo" と "Shapiro et al." の研究を除外すると、$I^2$  異質性が最も低くなることを示している。これは、この2つの研究がメタ分析で見られた研究間の異質性の主な「犯人」であるという私たちの発見を裏付けるものである。

全体として、この例の外れ値解析と影響力解析の結果は同じ方向を向いている。影響力のある外れ値であると思われる研究が2つある。この2つの研究は、効果量の推定値だけでなく、その精度も歪めてしまうだろう。したがって、この2つの研究を除外した感度分析の結果も実施し、報告する必要がある。


<br></br>

### GOSH プロット解析  {#gosh}

---

前章では、leave-one-out 法に基づく影響度分析を用いて、私たちのメタ分析の頑健性を探ってみた。データ中の異質性のパターンを探るもう一つの方法は、いわゆる **Graphic Display of Heterogeneity** (GOSH) Plot [@olkin2012gosh] である。これらのプロットでは、含まれる研究の**すべての可能なサブセット**に、同じメタ分析モデルを当てはめる。leave-one-out 法とは対照的に、$K$  モデルだけでなく、$2^{k-1}$ 対の可能なすべての研究の組み合わせに対してモデルを当てはめる。 

これは、研究の総数が多い場合、GOSHプロットの作成にかなりの計算量がかかることを意味した。そのため、ここで取り上げる _R_ の実装は、最大100万件のランダム化されたモデルしか適合させない。

モデルが計算されると、X軸にプール効果量、Y軸に研究間の異質性を表示し、プロットすることが可能である。これにより、例えば、効果量や異質性の量が異なるクラスターなど、特定のパターンを探すことが可能である。 

GOSHプロットにいくつかの異なるクラスタがある場合、データ中に複数の効果量の「集団」が存在する可能性を示し、サブグループ解析を正当化する。一方、サンプル中の効果量が均質である場合、GOSHプロットは、ほぼ対称的で均質な分布を示す。 

\index{metafor Package}

GOSHプロットを生成するには、**{metafor}**  パッケージの  `gosh`  関数を使用することが可能である。まだパッケージをインストールしていない場合は、今すぐインストールし、ライブラリからロードしてみよう。

```{r, message=F}
library(metafor)
```

メタ分析オブジェクト  `m.gen`  に対して、GOSHプロットを生成してみよう。そのためには、まず、**{meta}**  パッケージによって作成されたこのオブジェクトを、**{metafor}** メタ分析オブジェクトに「変換 」する必要がある。 

**{metafor}** でメタ分析を行うために使用する関数は  `rma`  と呼ばれる。**{meta}** オブジェクトを  `rma`  メタ分析に変換するのはそれほど複雑なことではない。効果量（ `TE` ）、標準誤差（ `seTE` ）、試験間異質性推定量（ `method.tau` ）を  `m.gen`  に格納してこの関数に提供するだけである。引数  `test = "knha"`  を指定することで、Knapp-Hartung 調整を使用するように指定することが可能である。 

新しく生成された**{metafor}** ベースのメタ分析を `m.rma` という名前で保存した。

```{r, eval=F}
m.rma <- rma(yi = m.gen$TE,
             sei = m.gen$seTE,
             method = m.gen$method.tau,
             test = "knha")
```

 **{meta}** で固定効果モデルを使用した場合、 `method.tau` を `rma` の呼び出しに単純にコピーすることはできないことに注意してみよう。代わりに、 `rma`  の  `method`  引数を  `"FE"`  に設定する必要がある。 

そして、 `m.rma` オブジェクトを使用して、GOSH プロットを生成することが可能である。解析の研究数にもよるが、これにはある程度の時間、最大で数時間かかることがある。その結果を  `res.gosh`  として保存する。

```{r, eval=F}
res.gosh <- gosh(m.rma)
```

```{r, echo=F, message=F}
load("data/res_gosh.rda")
```


そして、  `res.gosh`  オブジェクトを  `plot`  関数に代入することでプロットを表示すことが可能である。追加の  `alpha`  引数は、グラフ内のドットがどの程度透明であるかを制御する。グラフにはたくさんのデータポイントがあるので、値が "積み重なる "場所を明確にするために小さなアルファ値を使用することは理にかなっている。

```{r, fig.align="center", fig.width = 3, fig.height=3, eval=F}
plot(res.gosh, alpha = 0.01)
```

```{r, out.width='50%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/gosh0_sep.png')
```

データには興味深いパターンが見られる。ほとんどの値が比較的高い効果と高い異質性を持つクラスターに集中している一方で、$I^2$  の値の分布は大きく右肩下がりの二峰性になっている。推定された異質性がかなり低く、プール効果量も小さい研究の組み合わせがあるようで、結果として「彗星のような」尾を持つ形状になっている。

\index{Machine Learning}
\index{dmetar Package}

効果量 $-$ 異質性のパターンを見て、本当に重要な質問は、どの研究がこの形状を引き起こすのか、ということである。この質問に答えるために、 `gosh.diagnostics` 関数を使用することが可能である。 

この機能は、3つのクラスタリングまたは**教師なし機械学習**アルゴリズムを用いて、GOSHプロットデータからクラスタを検出した。特定されたクラスタに基づいて、この関数は自動的にどの研究が各クラスタに最も貢献しているかを決定した。例えば、異質性の高いクラスターに1つまたは複数の研究が過剰に存在することが分かった場合、これらの研究は単独または組み合わせで、高い異質性の**原因**である可能性があることを示した。 

```{block, type='boxdmetar'}
**"gosh.diagnostics" 関数**

\vspace{4mm}

`gosh.diagnostics` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

\vspace{2mm}

1. 関数のソースコードにアクセスする [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R). 
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。
3. **{gridExtra}**, **{ggplot2}**, **{fpc}**, **{mclust}** パッケージがインストールされ、ロードされていることを確認する。

```


\index{Gaussian Mixture Model}
\index{DBSCAN}
\index{K-Means}

`gosh.diagnostics` 関数は、$k$ -means algorithm [@hartigan1979algorithm], **density reachability and connectivity clustering**, または DBSCAN [@schubert2017dbscan] および **gaussian mixture models** [@fraley2002model] という3種類のクラスタアルゴリズムを使用してデータのパターンを検出している。 

これらのアルゴリズムのパラメータのいくつかを調整することが可能である。`km.params`, `db.params` と `gmm.params` の引数に、各アルゴリズムの挙動を制御する仕様を記述したリスト要素を追加することができる。この例では、$k$-means と DBSCAN アルゴリズムの細部を少し調整する。 $k$ -meansアルゴリズムは、データ中の2つのクラスタ（「中心」）を探索するよう指定する。`db.params`  では、DBSCAN が使用する  `eps`  、つまり $\epsilon$  の値を変更した。また、各クラスタに必要な最小限のポイント数を決定する `MinPts` 値も指定する。 

アルゴリズムのパラメータについては、  `gosh.diagnostics`  のドキュメントで詳しく説明されている。どのようなパラメータ指定が最適なのか明確なルールはないので、各アルゴリズムの詳細を何度か試してみて、それが結果にどのような影響を与えるかを確認するとよいだろう。

`gosh.diagnostics` を呼び出すコードは次のようになる。（訳注：数分かかることがある。）

```{r, eval=F}
res.gosh.diag <- gosh.diagnostics(res.gosh, 
                                  km.params = list(centers = 2),
                                  db.params = list(eps = 0.08, 
                                                   MinPts = 50))
res.gosh.diag
```

```{r, echo=F}
load("data/res_gosh_diag.rda")
res.gosh.diag
```

出力には、各アルゴリズムが検出したクラスタの数が表示される。各アプローチは異なる数学的戦略でデータを分割しているので、クラスタ数が同じでないのは当然である。 

`Identification of potential outliers` では、この手順により、クラスタの構成に大きな影響を与える3つの研究（研究3、研究4、研究16）を特定できたことがわかる。

また、 `gosh.diagnostics` オブジェクトをプロットして、結果をもう少し詳しく調べることも可能である。

```{r, eval=F}
plot(res.gosh.diag)
```

```{r, out.width='100%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/gosh1_col_sep.png')
```

```{r, out.width='80%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/gosh2_col_sep.png')
```

\index{Cook's Distance}

これは、いくつかのプロットを生成した。最初の3つのプロットは、各アルゴリズムによって見つかったクラスタリングソリューションと、各クラスタ内の各研究に関連するクラスタインバランスの量を表示した。この情報に基づいて、Cook 距離が各研究について計算され、これは、ある研究が検出されたクラスタに大きな影響を与えるかどうか（したがって、影響力のあるケースであるかもしれない）を判断するために使用される。

他のプロットも GOSH プロットであるが、選択された研究が含まれる解析を表す陰影のついたポイントが表示された。例えば、研究3が含まれるほぼすべての結果は、高い異質性の値と高い効果量を持つクラスターに属していることがわかる。研究4が含まれる結果は、異質性にばらつきがあるが、一般的に平均効果がやや**小さい**ことがわかる。研究16の結果は、研究3の結果と似ているが、もう少し分散している。

`gosh.diagnostics`関数が特定した3つの研究を削除して、メタ分析を再実行するとどうなるかを見てみよう。

```{r, eval=F}
update.meta(m.gen, exclude = c(3, 4, 16)) %>% 
  summary()
```

```
## Review:     Third Wave Psychotherapies
##                           SMD            95%-CI %W(random) exclude
## Call et al.            0.7091 [ 0.1979; 1.2203]        4.6        
## Cavanagh et al.        0.3549 [-0.0300; 0.7397]        8.1        
## DanitzOrsillo          1.7912 [ 1.1139; 2.4685]        0.0       *
## de Vibe et al.         0.1825 [-0.0484; 0.4133]        0.0       *
## Frazier et al.         0.4219 [ 0.1380; 0.7057]       14.8        
## Frogeli et al.         0.6300 [ 0.2458; 1.0142]        8.1        
## Gallego et al.         0.7249 [ 0.2846; 1.1652]        6.2        
## Hazlett-Stevens & Oren 0.5287 [ 0.1162; 0.9412]        7.0        
## Hintz et al.           0.2840 [-0.0453; 0.6133]       11.0        
## Kang et al.            1.2751 [ 0.6142; 1.9360]        2.7        
## Kuhlmann et al.        0.1036 [-0.2781; 0.4853]        8.2        
## Lever Taylor et al.    0.3884 [-0.0639; 0.8407]        5.8        
## Phang et al.           0.5407 [ 0.0619; 1.0196]        5.2        
## Rasanen et al.         0.4262 [-0.0794; 0.9317]        4.7        
## Ratanasiripong         0.5154 [-0.1731; 1.2039]        2.5        
## Shapiro et al.         1.4797 [ 0.8618; 2.0977]        0.0       *
## Song & Lindquist       0.6126 [ 0.1683; 1.0569]        6.1        
## Warnecke et al.        0.6000 [ 0.1120; 1.0880]        5.0        
## 
## Number of studies combined: k = 15
## 
##                         SMD           95%-CI    t  p-value
## Random effects model 0.4819 [0.3595; 0.6043] 8.44 < 0.0001
## Prediction interval         [0.3586; 0.6053]              
## 
## Quantifying heterogeneity:
##  tau^2 < 0.0001 [0.0000; 0.0955]; tau = 0.0012 [0.0000; 0.3091];
##  I^2 = 4.6% [0.0%; 55.7%]; H = 1.02 [1.00; 1.50]
## 
## Test of heterogeneity:
##      Q d.f. p-value
##  14.67   14  0.4011
## [...]
```

\index{Weight}\index{重み}

3番と16番の研究が "DanitzOrsillo" と "Shapiro et al." であることがわかる。この2つの研究は、以前の分析でも影響力があることが分かっている。研究番号4は "de Vibe" によるものである。この研究は、特に極端な効果量ではないが、観察された効果量が平均より小さいにもかかわらず、信頼区間が狭いことから、**高い重み**を持つことがわかる。このことは、この研究が影響力を持つ理由を説明できるだろう。

この3つの研究を取り除くと、推定される異質性に大きな影響を与えることがわかる。 $\tau^2$  の値はほぼゼロになり、$I^2$  の値も非常に低く、効果量の変動の4.6%のみが真の効果量の差によるものであることを示している。プールされた効果 $g$  = 0.48は、私たちの最初の推定値 $g=$  0.58よりいくらか小さいが、それでも同じ桁の範囲内である。 

全体として、最初に計算した平均的な効果は、外れ値や影響力のある研究によって、**あまり**大きくバイアスされてはいないことを示している。

```{block2, type='boxreport'}
**影響力解析の結果を報告**

\vspace{2mm}


"DanitzOrsillo", "de Vibe et al.", "Shapiro et al." がメタアナリシスで影響力のある研究だと判断されたとする。この場合、これらの研究を除外した感度解析の結果も報告するべきである。

\vspace{2mm}

影響力のある研究を削除した場合の変化を読者にわかりやすくするために、元の結果と感度分析の結果の両方を表示した表を作成することができる。この表には、少なくともプール効果、その信頼区間、$p$ 値、そして予測区間や $I^2$ 統計量（およびその信頼区間）のような異質性のいくつかの尺度を含める必要がある。

\vspace{2mm}

また、どの研究が影響力のあるケースとして削除されたかを明記し、新しい結果がどのデータに基づいているのかを他の人が理解できるようにすることも重要である。以下は、以前行った `m.gen` メタアナリシスにおいて作成した表の一例である。

<font size="2">
  
Analysis                               | $g$    | 95%CI      | $p$     | 95%PI       | $I^2$  | 95%CI  |
-------------------------------------- | ------ | ---------- | ------- | ----------- | ------ | ------ |
Main Analysis                          | 0.58   | 0.38-0.78  | <0.001  | -0.06-1.22  | 63%    | 39-78  |       
Infl. Cases Removed<sup>1</sup> | 0.48   | 0.36-0.60  | <0.001  | 0.36-0.61   | 5%     | 0-56   |

<sup>1</sup>Removed as outliers: DanitzOrsillo, de Vibe, Shapiro.

</font>
  
このような表は、他の感度解析の結果をさらに行に追加することができ、非常に便利である。例えば、バイアスリスクの低い研究（Chapter \@ref(data-extraction)）のみを考慮した分析を行った場合、その結果を3行目に報告することができる。

```

$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block, type='boxquestion'}
**知識を試そう！**

\vspace{4mm}

1. なぜメタ分析の研究間異質性を調べることが重要なのか。

\vspace{-2mm}

2. 異質性の2つのタイプを挙げられるか？メタ分析の計算にはどちらが関係するか？

\vspace{-2mm}

3. Cochran's $Q$ の**有意性**が、研究間異質性の十分な指標とならないのはなぜか。

\vspace{-2mm}

4. メタ分析で異質性の大きさを表現するために予測区間を使うメリットは何か。

\vspace{-2mm}

5. 統計的外れ値と影響力のある研究の違いは何か？

\vspace{-2mm}

6. GOSH のプロットは何に使えるのか。


\vspace{4mm}


**問題の解答は、本書の巻末 [Appendix A](#qanda5) にある。**

```

<br></br>

## 要約

* メタ分析では、プール効果量だけでなく、この平均的な効果量の根拠となったデータの**異質性**にも注意を払わなければならない。全体的な効果では、いくつかの研究における真の効果が私たちの点推定値と大きく異なる可能性があることを把握できないのである。

* コクランの $Q$  は、データのばらつきを定量化するためによく使われる。 $Q$  は $\chi^2$  分布に従うことが分かっているので、この尺度を使うと、サンプル誤差だけに基づいて予想されるよりも多くの変動が存在するかどうかを検出することが可能である。この**過剰な変動**は、研究の効果量における真の差異を表している。

* $Q$  の統計的検定は、しかし、手元にあるデータの種類に大きく依存した。異質性の量を評価するために、$Q$  にだけ頼るべきではない。 $I^2$ , $\tau$  や予測区間など、追加で使用することができる他の尺度がある。

* メタ分析における平均的な効果は、データに外れ値がある場合、偏りが生じることがある。外れ値は、メタ分析の結果に必ずしも大きな影響を与えるとは限りない。しかし、そのような場合は、「影響力のあるケース（influential cases）」と呼ばれる。

* 外れ値や影響力のある症例を特定する方法はいろいろある。もし、そのような研究が検出された場合は、それらを除外してメタ分析を再計算し、私たちの結果の解釈が変わるかどうかを確認することが望ましい。




<!--chapter:end:07-heterogeneity-ja.Rmd-->

# フォレストプロット {#forest} 

---

<img src="_figs/forest2.jpg" />

<br></br>

\index{Forest Plot}\index{フォレストプロット}

<span class="firstcharacter">前</span>
章では、 _R_ で効果量をプールする方法と、メタ分析で異質性を評価する方法について学んだ。ここからは、メタ分析の中でも、前のステップで得た結果を可視化する楽しい部分である。

メタ分析を可視化する最も一般的な方法は、**フォレストプロット**である。このプロットは、観察された効果、信頼区間、そして通常は各研究の重み付けをグラフィカルに表示する。また、メタ分析で計算されたプール効果も表示される。全体として、この図によって、含まれる研究の精度や広がり、プール効果が観察された効果量とどのように関連しているのかを素早く調べることが可能である。

\index{meta Package}

**{meta}** パッケージには、 _R_ で直接美しいフォレストプロットを非常に簡単に作成するための関数が組み込まれている。この関数は幅広い機能を持ち、プロットの外観を好きなように変更することが可能である。このフォレストプロット関数と、それを実際にどのように使うことができるかが、この章の主な焦点である。さらに、メタ分析の結果を可視化するための別のアプローチについても簡単に説明する。

<br></br>

## フォレストプロットとは？

---

Figure \@ref(fig:forest) は、フォレストプロットの主な構成要素を示している。フォレストプロットの左側には、メタ分析に含まれる各研究の名前が表示される。各研究について、通常はプロットの中央に効果量のグラフが表示され、x軸に研究の点推定値を示している。点推定値からは線が伸びており、観察された効果量に対して計算された信頼区間の範囲を示している。通常、点推定値は四角で囲まれている。この四角の大きさは効果量の重み（Chapter \@ref(fem)）で決まり、重みの大きな研究では大きな四角が、重みの小さな研究では小さな四角が与えられる。

通常、フォレストプロットにはメタ分析に使用した効果量のデータも掲載している。これにより、結果を再現するために必要なデータを他の人に提供することが可能である。

```{r forest, out.width='100%', message = F, echo = F, fig.align='center', fig.cap = "フォレストプロットの重要要素"}
library(OpenImageR)
knitr::include_graphics('images/forest_sep.png')
```

プロットの下部にある菱形は、平均効果を表している。菱形の長さは、X軸上のプールされた結果の信頼区間を表している。通常、フォレストプロットには垂直の**参照線**がある。この線は x 軸上の効果がない値を示している。さらに、フォレストプロットは、例えば、$I^2$ や $\tau^2$ のような異質性指標を表示すことによって強化されることがある。これについては、例で見ていこう。

\index{Logarithm, Natural}

フォレストプロットにおける効果量と信頼区間は、通常、線形スケールで表示される。しかし、要約尺度が**比**（オッズ比やリスク比など）である場合、代わりに x 軸に**対数**スケールを使用することが一般的である。これは、1 よりずっと低い値や高い値よりも、1 付近の値の方がより多くあることを意味する。

比に意味がある効果量の測定基準は「線形」に解釈することができない（すなわち、RR = 0.50 の「反対」は 1.5 ではなく 2 である。Chapter \@ref(ratios) を参照）。この場合の効果量の基準線は、通常 1 であり、1 が効果がないことを示す。

<br></br>

##  _R_  のフォレストプロット {#forest-R}

---

メタ分析オブジェクト（例：`metagen`、`metacont`、`metabin` の結果）の種類に関わらず、 `forest.meta` 関数を使用してフォレストプロットを作成することが可能である（訳注: 関数名は `forest` でよい。一般に、 _R_ では、 `forest` 関数が `forest.meta` のようにドット以降にクラスを指定したものを自動的に読み込む。）。`forest.meta` に  **{meta}**  オブジェクトを渡すだけで、プロットが作成される。通常、フォレストプロットはデフォルトで非常に良い見た目をしているが、この関数はさらに見た目を整えるための追加引数をたくさん持っている。すべての引数は関数のドキュメントに記載されている（`?forest.meta`を実行することでアクセス可能）。ここでは、より重要なものをリストアップしよう。

* **`sortvar`**. メタ分析データセットの変数で、フォレストプロットで研究をソートするためのもの。例えば、効果量によって結果を並べ替えたい場合、`sortvar = TE` というコードを使用することが可能である。

* **`comb.fixed`**. 論理値。固定効果モデルの推定値をプロットに含めるかどうかを示す。

* **`comb.random`**. 論理値。ランダム効果モデルの推定値をプロットに含めるかどうかを示す。

* **`text.fixed`**. 固定効果モデルによるプール効果の**ラベル**を表示する。デフォルトでは `"Fixed effect model"` と表示される。

* **`text.random`**. ランダム効果モデルによるプール効果のラベル。デフォルトでは `"Random effects model"` と表示される。

* **`prediction`**. 論理値。予測区間をプロットに追加するかどうかを示す。

* **`label.left`** と **`label.right`**. フォレストプロットの左側と右側に追加されるラベル。例えば、この側の効果は治療に有利であることを明示できる（例： `label.left = "Favors treatment"`）。

* **`smlab`**. プロットの上に表示されるラベル。どの効果量メトリックを使用したかを示すために使用できる。

* **`xlim`**. x 軸の限界値、または対称的なフォレストプロットを作成したいときは文字 `"s"` を指定する。結果がゼロから大きく外れている場合や、外れ値を表示させたい場合に関係する。例えば、x 軸を 0 から 2 の範囲にしたい場合、コードは `xlim = c(0,2)` となる。

* **`ref`**. プロットにおける参照線。使用した要約尺度に依存し、デフォルトでは 0 または 1 のどちらかになる。

* **`leftcols`** と **`rightcols`**. ここでは、フォレストプロットの左側と右側に表示する変数を指定することができる。この関数がデフォルトで使用する要素がいくつかある。例えば、`"studlab"` は研究のラベル、 `"effect"` は観測された効果量、 **`effect.ci`** は効果量とその信頼区間を表す。また、最初に **{meta}** 関数に提供した `data.frame` に含まれていれば、ユーザー定義の列を追加することも可能である。この場合、列の名前を文字列として追加するだけである。

* **`leftlabs`** と **`rightlabs`**. フォレストプロットの左側と右側に表示される列に使用されるラベル。

* **`print.I2`** と **`print.I2.ci`**. 論理値。$I^2$ 値とその信頼区間を表示すかどうかを指定する。デフォルトでは `TRUE`。

* **`print.tau2`** と **`print.tau`**. 論理値。$\tau^2$ と $\tau$ の値を表示すかどうかを指定する。デフォルトでは、$\tau^2$ の値を表示する。

* **`col.square`**, **`col.diamond`**, **`col.predict`**. それぞれ、正方形、菱形、予測区間の色（例: `"blue"`）を指定する。



それではフォレストプロットを作成してみよう。この例では、前の例で使用した `m.gen` オブジェクトをプロットしている。フォレストプロットでは、効果量によって研究を並べ替え、予測区間を追加し、左側にユーザー定義のラベルを追加している。`forest.meta` 関数は、デフォルトで $\tau^2$ 値を出力するが、ここでは不要なので、`print.tau2` を `FALSE` に設定する。

最終的にこのようなコードになる。（訳注：原著では引数が間違っていた。`pdrediction` が正しい。）

```{r ch08-87, fig.height=6, fig.width=8, eval=F}
forest.meta(m.gen, 
            sortvar = TE,
            prediction = TRUE, 
            print.tau2 = FALSE,
            leftlabs = c("Author", "g", "SE"))
```

```{r ch08-95, fig.height=6, fig.width=8, echo=F}
par(bg="#FFFEFA")
forest(m.gen, 
       sortvar = TE,
       prediction = TRUE, 
       print.tau2 = FALSE,
       leftlabs = c("Author", "g", "SE"))
```


`forest.meta` のプロットの見た目は、すでにかなり良い。また、太めの線がプロットに追加され、プール効果の予測区間を表していることがわかる。

\index{Risk of Bias}


各研究のバイアスリスクを表示す列を追加することで、プロットを強化することが可能である。`m.gen` の生成に使用した `ThirdWave` データセットには、`RiskOfBias` という列があり、そこに各研究のバイアスリスク評価が保存されている。

メタ分析の計算に `metagen` を使用している場合 (Chapter \@ref(pre-calculated-es)) 、この関数は自動的にこのデータを `m.gen` 内に保存する。したがって、 `leftcols`  引数を使用して、プロットに列を追加することが可能である。この結果、次のようなコードになる。

```{r, fig.height=6, fig.width=9, eval=F, echo=F}
forest.meta(m.gen, 
            sortvar = TE,
            prediction = TRUE, 
            print.tau2 = FALSE,
            leftcols = c("studlab", "TE", "seTE", "RiskOfBias"),
            leftlabs = c("Author", "g", "SE", "Risk of Bias"))
```

```{r, fig.height=6, fig.width=9}
par(bg="#FFFEFA")
forest(m.gen, 
       sortvar = TE,
       prediction = TRUE, 
       print.tau2 = FALSE,
       leftcols = c("studlab", "TE", "seTE", "RiskOfBias"),
       leftlabs = c("Author", "g", "SE", "Risk of Bias"))
```


フォレストプロットに各研究のバイアスリスク情報が追加されたことがわかる。

\vspace{4mm}

<br></br>

### レイアウトの種類

---

`forest.meta` 関数には2つの 「パッケージ済み」レイアウトがあり、これを使用すると、多数の引数を指定することなくフォレストプロットを特定の形式にすることが可能である。そのうちの1つは `"JAMA"` レイアウトで、**Journal of the American Medical Association** のガイドラインに従ったフォレストプロットを提供するものである。このレイアウトは、メタ分析を医学雑誌に掲載したい場合に使用される。

\vspace{2mm}

```{r, eval=F}
forest.meta(m.gen, layout = "JAMA")
```

```{r, echo=F, fig.height=6, fig.width=8, out.width="75%", fig.align='center'}
par(bg="#FFFEFA")
forest.meta(m.gen, layout = "JAMA")
```

\index{Review Manager (RevMan)}

もう一つのレイアウトは `"RevMan5"` で、Cochrane の **Review Manager 5** で生成されるものと同様のフォレストプロットを生成する。

```{r, eval=F}
forest.meta(m.gen, layout = "RevMan5")
```

```{r, echo=F, fig.height=6, fig.width=9, out.width="75%", fig.align='center'}
par(bg="#FFFEFA")
forest.meta(m.gen, layout = "RevMan5")
```

<br></br>

### フォレストプロットを保存

---

`forest.meta` によって生成されたフォレストプロットは、PDF、PNG、または **scalable vector graphic** (SVG) ファイルとして保存することが可能である。base _R_ や **{ggplot2}** パッケージによって生成される他のプロットとは対照的に、`forest.meta` の出力はファイルとして保存する際に自動的にリスケーリングされていない。このため、フォレストプロットは2辺または4辺が切り取られることがあり、すべてが見えるように幅と高さを手動で調整する必要がある。

`pdf`、`png`、`svg` 関数を使用すると、 _R_ のコードでプロットを保存することができる。まず、いずれかの関数をコールして、次のコードの出力をドキュメントに保存するように _R_ に指示する。そして、`forest.meta` 関数の呼び出しを追加する。最後の行では、 `dev.off()` をインクルードして、生成された出力を上記で指定したファイルに保存する。

どの関数も `file` という引数を指定し、引数にファイル名を指定する。ファイルは、その名前で自動的に作業ディレクトリに保存される。さらに、 `width` と `height` 引数でプロットの大きさを指定することができるので、出力が途切れるような場合に役立つ。

最初のフォレストプロットを "forestplot" という名前で保存すると仮定して、以下のようなコードで PDF、PNG、SVG ファイルを生成することが可能である。

\vspace{2mm}

**PDF**

```{r, eval=F}
pdf(file = "forestplot.pdf", width = 8, height = 7)

forest.meta(m.gen, 
            sortvar = TE,
            predict = TRUE, 
            print.tau2 = FALSE,
            leftlabs = c("Author", "g", "SE"))

dev.off()
```

\vspace{2mm}

**PNG**

```{r, eval=F}
png(file = "forestplot.png", width = 2800, height = 2400, res = 300)

forest.meta(m.gen, 
            sortvar = TE,
            predict = TRUE, 
            print.tau2 = FALSE,
            leftlabs = c("Author", "g", "SE"))

dev.off()
```

\vspace{2mm}

**SVG**

```{r, eval=F}
svg(file = "forestplot.svg", width = 8, height = 7)

forest.meta(m.gen, 
            sortvar = TE,
            predict = TRUE, 
            print.tau2 = FALSE,
            leftlabs = c("Author", "g", "SE"))

dev.off()
```

<br></br>

## ドレーパリープロット {#drapery}

---

\index{Drapery Plot}

\index{P-Value}\index{P-値}

フォレストプロットは、メタ分析を可視化する最も一般的な方法である。発表されたメタ分析のほとんどにフォレストプロットが含まれており、多くの研究者がその解釈方法を理解している。フォレストプロットは、調査結果の包括的で理解しやすい要約を提供するので、メタ分析レポートにもフォレストプロットを含めることが推奨される。

しかし、フォレストプロットだけが結果を説明する手段ではない。メタ分析は、例えば、**ドレーパリープロット** [@rucker2020beyond]（drapery plot、訳注：ドレーパリーとは、衣服やカーテンなどのひだのこと。美術史では、衣文とも訳される。） などでも可視化することが可能である。フォレストプロットの欠点は、固定された有意閾値、慣習的に$p<$ 0.05を仮定した信頼区間しか表示できないことである。研究者は、これらの信頼区間に基づいて、効果が有意であるか否かを決定している。

近年、$p$ 値の利用をめぐる論争があり [@wellek2017critical]、$p$ 値に基づく仮説検定が、多くの研究領域で「再現性の危機」に寄与しているという議論もある [@nuzzo2014statistical]。

ドレーパリープロットは、$p$-**値関数**に基づいている。この $p$ 値関数とは、解析結果を解釈する際に $p$ < 0.05 の有意性閾値だけに頼らないために提案されたものである [@infanger2019p]。

したがって、$p$ 値関数は95%信頼区間を計算するだけでなく、$p$ の値を変化させた場合の信頼区間を示す連続曲線を提供する。ドレーパリープロットでは、各研究の信頼曲線と平均効果の信頼曲線がプロットされる。x 軸は効果量指標を示し、y軸は仮定された $p$ 値を示す。

ドレーパリープロットは、 **{meta}** の `drapery` 関数によって生成することが可能である。`forest.meta` と同様に、この関数に **{meta}** メタ分析オブジェクトを与えると、自動的にプロットが生成される。追加引数が複数あるが、最も重要なのは以下の引数である。

* **`type`**: y 軸にプロットされる値の種類を定義する。検定統計量の `"zvalue"` (デフォルト)、または $p$-値 (`"pvalue"`) とする。

* **`study.results`**: 論理値。各研究の結果をプロットに含めるかどうかを指定する。`FALSE` の場合、効果の要約のみが表示される。

* **`labels`**: この引数を `"studlab"` に設定すると、試験のラベルがプロットに含まれるようになる。

* **`legend`**: 論理値。凡例を表示すかどうかを示す。

* **`pos.legend`**. 凡例の位置。`"bottomright"`、`"bottom"`、`"bottomleft"`、`"left"`、`"topleft"`、`"top"`、`"topright"`、`"right"`、`"center"` のいずれかを指定。

メタ分析オブジェクト `m.gen` を使って `drapery` 関数を試してみよう。


```{r, fig.align='center', eval=F}
drapery(m.gen, 
        labels = "studlab",
        type = "pval", 
        legend = FALSE)
```


```{r, fig.align='center', echo=F, fig.width=12, fig.height=8}
par(bg="#FFFEFA")
drapery(m.gen, 
        labels = "studlab",
        type = "pval", 
        legend = FALSE,
        bg = "#FFFEFA")
```

結果として得られるプロットは、各効果量の $p$-値曲線を含み、すべて逆 V 字の形をしている。太線はランダム効果モデルによる平均効果を表した。プロットで見られる斜線部分は予測区間で、プール効果の信頼区間よりもかなり広い。

$p$ 値関数の「ピーク」は、メタ分析における効果量の正確な値を表している。y軸を下に行くに従って、$p$ 値は小さくなり、信頼区間は広くなり、破線の水平線で示される従来の有意閾値に到達することになる。

$p$ がすでに非常に小さい（<0.01）ときに太線が x 軸上でゼロになることから、プロットに基づいて、プール効果量がゼロより大きいことをかなり確信できることがわかる。

Rücker et al. [-@rucker2020beyond] は、ドレーパリープロットは主にフォレストプロット**に加えて**使用すべきであると推奨している。なぜなら、フォレストプロットは、結果を再現するために必要な効果量情報を含んでいないことがある。

$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block, type='boxquestion'}
**知識を試そう！**

\vspace{4mm}

1. フォレストプロットの主要な構成要素は何か？

\vspace{-2mm}

2. メタ分析でフォレストプロットを提示するメリットは何か？

\vspace{-2mm}

3. フォレストプロットの限界は何か、ドレーパリープロットはこの限界をどのように克服しているのか。

\vspace{4mm}


**問題の解答は、本書の巻末 [Appendix A](#qanda6) にある。**

```


<br></br>


## 要約

* メタ分析の結果は、フォレストプロットで可視化するのが一般的である。

* フォレストプロットは、各研究の効果量と信頼区間をグラフ化したもので、総合効果の計算値も表示される。さらに、プールに使用された効果量データも含まれる。

* フォレストプロットには、各研究が受けた品質評価など、他の種類の情報を追加することも可能である。


<!--chapter:end:08-forestplots-ja.Rmd-->

# サブグループ解析  {#subgroup}

---

<img src="_figs/fassade.jpg" />

<br></br>

<span class="firstcharacter">C</span>
hapter \@ref(heterogeneity)  では、研究間異質性の概念と、それがメタ分析においてなぜ重要であるかについて説明した。また、外れ値解析や影響度解析の一環として、どの研究が観察された異質性に寄与しているかを特定するための手法も学んだ。この分析では、純粋に統計学的な立場からメタ分析にアプローチする。データ中のかなりの異質性を「測定」し、その結果、統計的特性に合わない研究（すなわち、外れ値や影響力のある研究）を除外して、モデルの頑健性を向上させる。

\index{Outlier}\index{外れ値}
\index{Influential Case}
\index{Heterogeneity}\index{異質性}

この方法は、**post hoc** な手続きと見なすことができる。外れ値や影響力の分析は、データを見た**後**に行われ、多くの場合、見つけた結果の**ために**行われるのである。また、データそのもの以外のものには注意を払わない。影響力分析の方法論は、ある研究がモデルの予測に適切に沿わないことを教えてくれるとしても、それが**なぜ**なのかは教えてくれない。原因は、この研究がわずかに異なる研究手法や治療法を用いているからかもしれない。しかし、このことは研究の影響力だけではわからないのである。 

ある治療法の効果を調べるためにメタ分析を行うとする。その結果、全体としてその治療には効果がないことがるとする。しかし、大きな治療効果が認められた研究が3つあるとする。これらの研究を影響度分析で検出することは可能だろうが、なぜその研究が影響力があるのかはわからない。この3つの研究では、他のすべての研究で使用された治療法とわずかに異なる治療法が使用され、この小さなディテールが治療効果に大きな影響を与えたということがあり得るのである。これは画期的な発見だろう。しかし、外れ値解析や影響度解析だけではできない発見である。

\index{Subgroup Analysis}\index{サブグループ解析}
\index{Moderator Analysis}

このことから、データから特定の異質性パターンを見出すことができる異なるアプローチが必要であることは明らかである。**サブグループ解析**は、**モデレータ分析**としても知られており、これを行うための一つの方法である。ある種の研究が、なぜ他の研究よりも低い効果や高い効果をもたらすのかを説明し、特定の仮説を検証することが可能である。 

Chapter \@ref(analysis-plan) で学んだように、サブグループ検定は **a priori** で定義されるべきである。メタ分析を始める前に、観察された効果量に影響を与える可能性のあるさまざまな研究特性を定義し、それに従って各研究をコーディングする必要がある。効果量が異なる理由は無数にあるが、分析の文脈上、重要なものに限定すべきである。 

例として、ある種の薬が他の薬より高い効果をもたらすかどうかを調べることがでlきる。あるいは、フォローアップ期間が短い研究と長い研究を比較することもできる。また、研究が実施された文化的地域によって、観察された効果が異なるかどうかを調べることも可能である。メタ分析では、その分野に特化した専門知識があると、その分野の他の科学者や実務者に実際に関連する質問を見つけることができることがある。

サブグループ解析の背景にある考え方は、メタ分析が平均的な効果量を計算するだけでなく、エビデンスのばらつきを調べるツールにもなり得るということである。サブグループ解析では、異質性を単に厄介なものとしてではなく、科学的仮説によって説明できるか否かという興味深い変動としてとらえる。最良の場合、これは私たちを取り巻く世界の理解を深めるものとなる。そうでなくとも、少なくとも将来の意思決定の指針となる実用的な洞察を生み出すものとなる。

この章では、サブグループ解析の背後にある統計モデルと、 _R_ で直接サブグループ解析を行う方法について説明する。

<br></br>

## 固定効果（複数）モデル  {#fixed-effect-plural}

---

\index{Fixed-Effects (Plural) Model}

サブグループ解析では、メタ分析に含まれる研究は、1つの全体的な集団から生じているのではないと仮定する。その代わりに、異なる**サブグループ**に分類され、各サブグループが独自の真の全体効果を持つと仮定する。研究の目的としては、サブグループ間の効果量に差がないという帰無仮説を棄却することとある。

サブグループ解析の計算は、2つの部分からなる。まず、各サブグループでの効果をプールする。その後、統計的検定 を用いて、各サブグループの効果を比較する [@borenstein2013meta] 。

<br></br>

### サブグループにおける効果のプール化

---

最初の部分は、サブグループなしのメタ分析（Chapter \@ref(fem-rem)）と同じ基準が適用されるので、かなり簡単である。もし、サブグループ内のすべての研究が同じ集団から発生し、1つの共有された真の効果を持つと仮定すると、固定効果モデルを使用することが可能である。前に述べたように、研究をより小さなグループに分割しても、実際にはこの仮定が成立しないことがよくある。

\index{Random-Effects Model}\index{ランダム効果モデル}

したがって、代替案は、ランダム効果モデルを使用することである。これは、サブグループ内の研究は、推定したい平均値を持つ母集団から抽出されると仮定する。通常のメタ分析との違いは、各サブグループごとに別々のランダム効果メタ分析を実施することである。論理的には、この結果、各サブグループ $g$  のプール効果 $\hat\mu_g$  が得られる。

\index{Heterogeneity}\index{異質性}

各サブグループはそれぞれ個別のメタ分析を受けるので、$\tau^2$  異質性の推定値もサブグループごとに異なる。しかし実際には、個々の異質性の値 $\hat\tau^2_g$  は、サブグループ間でプールされた $\tau^2$  に置き換えられることが多いようである。 

つまり、すべてのサブグループが研究間の異質性の**共通の**推定値を共有すると仮定することになる。これは、実用的な理由で行われることがほとんどである。サブグループ内の研究数が少ない場合、例えば $k_g \leq 5$ [@borenstein2011introduction, chapter 19] の場合、$\tau^2$  の推定値が不正確になる可能性がある。この場合、1つのサブグループにおける研究間異質性の非常に不正確な推定値に頼るよりも、すべてのサブグループで使用するプール版 $\tau^2$  を計算する方がよいだろう。


<br></br>

### サブグループ効果の比較  {#comparing-the-subgroup-effects}

---

次のステップでは、$G$  のサブグループ間に **真の**差があるかどうかを評価する。この仮定は、サブグループが異なっていること、つまり、少なくとも1つのサブグループが研究の異なる集団の一部であることを意味する。

これをテストするエレガントな方法は、サブグループのプール効果が、実は**1つの大規模研究**の**観察された効果量**に過ぎないというふりをすることである [@borenstein2011introduction、chap. 19 参照]。例えば、$G=3$  のサブグループ解析を行う場合、3つの大きな研究の観察された効果量（および標準誤差）を計算したふりをするのである。 

このようにサブグループを見ると、通常のメタ分析の異質性を評価するときに直面する質問と非常に似ていることがわかる。効果量の差が、サンプルエラーによってのみ存在するのか、それとも効果量の**真の**差によって存在するのかを知りたいと思っている。 

\index{Cochran's \textit{Q}}

したがって、サブグループの差が、サンプル誤差だけでは説明できないほど大きいかどうかを判断するために、$Q$  の値を使用する。サブグループ効果が**観察された**効果量であると仮定して、$Q$  の値を計算する。この観察された $Q$  の値は、$\chi^2$  の分布と仮定した場合の期待値と比較され、この場合は自由度 $G-1$ である（Chapter \@ref(cochran-q)）。 

 $Q$  の観測値が期待値よりかなり大きい場合、$Q$ 検定の $p$ -値は有意になる。これは、サブグループ間の真の効果量に差があることを示す。この $Q$  検定は、**オムニバス検定** である。これは、すべてのサブグループの効果量が等しいという帰無仮説を検定し、少なくとも2つのサブグループ、またはそれらの組み合わせが異なる場合に有意であることを示すものである。 

通常、サブグループ内の研究はランダム効果モデルに従ってふるまうと仮定するが、プールされたサブグループレベルでは状況は異なるように見える。Borenstein and Higgins [-@borenstein2013meta] は、多くの分野で、分析するために選択したサブグループは、可能なサブグループの「宇宙」からランダムに抽出したものとは見なせず、調査したい特性の**固定**レベルを表していると論じている。例として、雇用形態を挙げる。雇用形態には、"employed" と "unemployed" という2つの固定されたサブグループがある。同じことが、例えば、特定の併存疾患を持つ患者と持たない患者における研究にも当てはまる。 

\index{Fixed-Effects (Plural) Model}
\index{Random-Effects Model}\index{ランダム効果モデル}

Borenstein and Higgins は、サブグループ解析のためのモデルを**固定効果（複数）モデル**と呼んでいる。「複数」という言葉がついているのは、標準的な固定効果モデルとの区別するためである。固定効果（複数）モデルは、固定効果モデルとランダム効果モデルの両方の特徴を含むハイブリッドな生き物と見ることが可能である。ランダム効果モデルと同様に、データにはサブグループが存在するため、真の効果量は1つではないと仮定する。 

ただし、サブグループは、サブグループの全宇宙からのランダムな抽選とは見なさない。サブグループの水準は固定で、**網羅的** であり、一般化が必要ないことを意味する。これは、私たちがサブグループデータを生成するプロセスを固定効果「複数」モデルと呼ぶ理由を明確にする：なぜなら、**複数**の真の効果量が存在するが、真の効果量は、**固定**と仮定されるサブグループレベルを表しているからである。

Borenstein ら [-@borenstein2011introduction, chapter 19] は、「固定」という言葉が統計学では二つの意味を持つため、少し混乱しているように見えるかもしれないと論じている。従来のメタ分析では、「固定効果」という言葉は「共通効果」と同義に使われる。しかし、サブグループ解析の文脈では、「ランダムではない」ことを強調するために「固定効果」という言葉を使う。固定効果は、一般化することを目的とする包括的な分布の単なるランダムな現れではなく、変数が入ることができる**現実**かつ**唯一**のカテゴリである。 

Figure \@ref(fig:subgroups)  は、サブグループ内の研究がランダム効果モデルに従うと仮定して、固定効果（複数）モデルを可視化する。


```{r subgroups, message = F, out.width = '90%', echo = F, fig.align='center', fig.cap="サブグループ内でランダム効果モデルを想定した固定効果（複数）モデルの可視化。"}
library(OpenImageR)
knitr::include_graphics('images/subgroups_sep.png')
```

```{block, type='boxinfo'}
**水準が固定されたサブグループ変数の例**

\vspace{4mm}

* **年齢層**: 小児, 若年成人 (young adults), 成人, 高齢者

\vspace{2mm}

* **文化的背景**: 西洋, 非西洋

\vspace{2mm}

* **対照群**: 代替療法, 最小限治療, 治療なし

\vspace{2mm}

* **アウトカム測定手法**: 自己報告, 専門家判断

\vspace{2mm}

* **研究の質**: high, low, unclear.

\vspace{2mm}

* **種**: plants, animals.

\vspace{2mm}

* **セッティング**: 学校, 病院, 家庭

\vspace{4mm}

サブグループの具体的な選択と定義は、メタアナリシスの目的と範囲に基づいて適合させることができ、またそうすべきであることに注意。
```


\index{Mixed-Effects Model}\index{混合効果モデル}
\index{Meta-Regression}\index{メタ回帰}\index{メタ回帰}

固定効果（複数）モデルは、ランダム効果（サブグループ内）と固定効果（サブグループは固定されていると仮定されているため）の両方を含むので、文献上では**混合効果モデル**としても知られている。Chapter \@ref(pooling-props) ですでにこの用語に触れている。たとえば、割合をプールするために使用できる異なるタイプの（一般化）混合効果モデルについて議論してきた。 

サブグループ解析に使用するモデルは、メタ分析でよく使用される他の手法と大きく関連している。 Chapter \@ref(metareg)  では、サブグループ解析が単なる**メタ分析**の特殊なケースであり、そのために混合効果モデルも使用することを示す予定である。 

\index{Multilevel Meta-Analysis}

さらに、サブグループの水準が固定であると仮定できない可能性もある。効果が観察された場所によって、効果の大きさが異なるかどうかを評価したいと想像してみよう。ある研究はイスラエルで、ある研究はイタリアで、ある研究はメキシコで、ある研究は中国本土で、効果を評価してきたとする。世界にはたくさんの国があり、国を水準数の固定された因子とはみなすことはできないため、 「ランダム」な選択を含んでいることにする。 

この場合、サブグループを固定的にモデル化するのではなく、ランダム効果として国ごとのばらつきを推定するようにすることが理にかなっている。これは、Chapter \@ref(multilevel-ma)  で扱う**マルチレベル・モデル**につながる。 

<br></br>

## サブグループ解析の限界と落とし穴  {#limits-subgroup}

---

\index{Power}\index{検出力}\index{検出力}

直感的には、サブグループ解析は、効果緩和因子を検出するのに非常に優れたツールであると考えるかもしれない。結局のところ、メタ分析の目的は、利用可能なすべてのエビデンスを調査することである。これは、メタ分析で分析される個体の総数は、通常、一次研究のそれを桁違いに上回ることを意味した。 

しかし、残念ながら、この方法では、サブグループの違いを検出するための**統計的検出力**は必ずしも高くはない。これにはいくつかの理由がある [@hedges2004power]。 

* まず、サブグループ解析では、サブグループ内の結果は通常ランダム効果モデルを使用してプールされることを覚えておこう。サブグループ内の研究間異質性が大きい場合、プール効果の精度が低下する（すなわち、標準誤差が増加する）ことになる。しかし、サブグループの効果推定値が非常に不正確な場合、これは、それらの信頼区間が大きく重なることを意味する。結果的に、これはサブグループ間の有意差を見つけることを難しくする--たとえ差が存在するとしてもである。

* 同じように、サブグループ解析で検出したい効果は、通常のメタ分析よりもはるかに低いため、統計的検出力も低くなりがちである。例えば、あるアウトカムを**自己報告**と**専門家の評価**で評価する研究間で、効果に差があるかどうかを調べるとした。たとえ差があったとしても、それは非常に小さいものだろう。治療群と対照群の間に有意差を見出すことはしばしば可能である。しかし、**研究間**の効果量の差を検出することは、差が小さいため、通常より多くの統計的検出力が必要とされ、より困難である。

* 上記の点から、重要な注意事項がある： **エビデンスの欠如は、欠如のエビデンスではない**。もし、サブグループ間の効果量に**差がない**としても、それは自動的にサブグループが**同等の**アウトカムをもたらすということにはならない。上で述べたように、私たちのサブグループ解析が、効果の真の差を確認するのに必要な統計的検出力を持たないかもしれない様々な理由があるのである。この場合、サブグループが同じ効果を持つと言うのは重大な誤訳である--私たちは、差が存在するかどうか単に知らないのである。このことは、ある治療法が他の治療法よりも優れているかどうかを評価したい場合に、特に問題となる。企業を含む一部の利害関係者は、しばしば治療の同等性を示すことに既得権益を有している。しかし、サブグループ解析は、通常、これを証明する適切な方法ではない。 

* 事前に**サブグループ検出力分析**を行うことで、サブグループ解析において統計的検出力が問題となるかどうかを確認することが可能である。このような分析では、サブグループ解析で検出できる最小の効果量の差を確認することが可能である。各種ツールの Chapter \@ref(power-subgroup)  では、 _R_ でどのようにサブグループ検出力分析を行うことができるかを説明している。しかし、検出力分析は、せいぜい有用な診断として見られるだけで、私たちの分析の検出力が十分に高く、サブグループが同等であることを示す証明にはならないことに注意してみよう。Schwarzer ら [@schwarzer2015meta, chapter 4.3] は、一般的な経験則として、サブグループ解析は、メタ分析が少なくとも $K=$  10 件の研究を含むときにのみ意味をなすと言及している。 


サブグループ解析のもう一つの重要な限界は、純粋に観察的であることである [@borenstein2013meta]。メタ分析には、参加者が治療群または対照群のいずれかにランダムに割り付けられたランダム化比較試験（RCT）しか含まれていないことが多い。このようなRCTは、適切に実施されれば、研究で観察された群間差を治療が**引き起こした**というエビデンスを提供することが可能である。これは、評価されたアウトカムに影響を与える可能性のあるすべての関連変数が、2つのグループで等しいことがある。唯一の違いは、一方のグループが治療を受け、もう一方のグループが受けなかったということである。 

サブグループ解析は、ランダム化された研究のみからなる場合でも、因果関係を示すことができない。サブグループ解析で、ある種の治療が他の治療より効果的であることがわかったとした。この発見が偽りかもしれない理由は無数にある；たとえば、治療Aを調査した研究では、治療Bを調査した研究とは別の対照群を使用していた可能性がある。これは、両方の治療が同じように有効である可能性があり、治療タイプが方法論の因子と**交絡** (confound) するので、違いを見ているだけだということである。この例は、サブグループ解析の結果を常に批判的に評価する必要があることを強調するものである。

最後の重要な落とし穴は、サブグループの定義の仕方である。しばしば、**集合的な情報**に基づいて研究をサブグループに分類したくなることがある。Schwarzer ら [@schwarzer2015meta, chapter 4.3] は、よくある例として、研究の平均年齢を挙げている。例えば、高齢者（65歳以上）と一般成人との間で効果が異なるかどうかを評価したいとする。そこで、報告された平均年齢が65歳以上か以下かによって、研究をこの2つのカテゴリに分類する。 

もし、平均年齢の高いサブグループで効果が高いことがわかれば、直感的に、高齢者ほど効果が高いことを示していると考えるかもしれない。しかし、この推論には深い欠陥がある。一次研究の**平均**年齢が65歳以上である場合、それよりも**若い**個人の割合がかなり含まれている可能性がある。**その逆もまた然り**で、**平均**年齢が65歳**より低い**場合でも、65歳**より上**の人が多く含まれている可能性は十分にあるのである。 

つまり、「高齢者」サブグループに見られる高い効果は、実際には65歳未満の個人によって**のみ**もたらされる可能性がある。逆に、「若い」サブグループでは、低い効果は65歳以上の研究対象者によってもたらされた可能性がある。 

このことは、逆説的な状況をもたらす。すなわち、全体レベルでは、平均年齢が高い研究ほど効果が高いことがわかる。しかし、個人レベルではその逆で、年齢が上がるにつれて効果は**低く**なる。

\index{Ecological Bias}

今述べたシナリオは、いわゆる**生態学的バイアス** [@thompson2002should; @piantadosi1988ecological] によって引き起こされるものである。これは、個人（**ミクロ**）レベルの関連を予測するために、集合体（**マクロ**）レベルの関係を利用したいときに発生するものである。 

生態学的バイアスを回避する最善の方法は、サブグループ解析やメタ回帰において、集計情報を**決して**、使用しないことである。しかし、ある研究の **すべての** 個人が1つのカテゴリに分類されるとわかっている場合は、状況が違ってくる。例えば、18歳未満の青少年**のみ**を対象としたいくつかの研究と、成人（18歳以上）**のみ**を対象としたいくつかの研究があれば、生態学的バイアスのリスクはほぼ排除される。しかし、効果の違いは、参加者の年齢ではなく、交絡変数によって引き起こされた可能性が残っている。

```{block, type='boxinfo'}
**サブグループ解析: やって良いことと悪いこと**

\vspace{4mm}

1. サブグループ解析は統計的検出力に依存するため、研究数が小さい場合は通常実施する意味がない（つまり $K$ < 10）。

\vspace{1mm}

2. サブグループ間の効果量に差がない場合、これは自動的にサブグループが**同等な**結果をもたらすことを意味するものでは**ない**。

\vspace{1mm}

3. サブグループ解析は純粋に**観察的**なものなので、効果の違いは交絡変数によっても引き起こされる可能性があることを常に念頭に置いておく必要がある。

\vspace{1mm}

4. サブグループ解析において、集合的な研究情報を使用することは、生態学的なバイアスをもたらす可能性があるため、良くない考えである。

```

<br></br>

##  _R_ のサブグループ解析  {#subgroup-R}

---

\index{meta Package}

 _R_ で学んだことを実行する時が来た。**{meta}** パッケージを使ってサブグループ解析を行うのは比較的簡単である。**{meta}** のすべてのメタ分析関数において、  `subgroup` 引数を指定することが可能である^[古いバージョンの**{meta}** （バージョン5.0-0以前）では、この引数は `byvar` と呼ばれている]。これは、どの効果量がどのサブグループに該当するかを関数に伝え、サブグループ解析を実行する。引数  `subgroup` には、`character`、`factor`、`logical`、`numeric` の変数を指定することが可能である。唯一気をつけなければならないのは、同じサブグループに属する研究は絶対に同じラベルを持つということである。 

この例では、再び `m.gen` メタ分析オブジェクトを使用する。メタ分析の計算に使用した `ThirdWave`  データセットには、サブグループ情報を持ついくつかの列が含まれている。ここでは、バイアスのリスクが高い研究と低い研究の間で効果量に差があるかどうかを調べたい。バイアスリスクの情報は、`RiskOfBias` 列に格納されている。 

まず、この列を見てみよう。このコードでは、データセットの最初の数行だけが表示されるように  `head`  関数を使用している。

```{r}
# 研究名と 'RiskOfBias' 列、最初のデータを表示
head(ThirdWave[,c("Author", "RiskOfBias")])
```

データセット内の各研究は、バイアスのリスク評価を指定するラベルを持っていることがわかる。`metagen` を使用してメタ分析を計算した際、この情報は内部的に `m.gen` オブジェクトに保存された。サブグループ解析を行うには、`update.meta` 関数を使用して `m.gen` オブジェクトを指定し、`subgroup` 引数を使用してデータセットのどの列にサブグループラベルが含まれるかを指定する。 

前回、サブグループ解析は、サブグループ間で共通の推定値（$\tau^2$  ）の有無で実施できることも取り上げた。これは、**{meta}** で  `tau.common`  を  `TRUE`  または  `FALSE`  に設定することで制御することが可能である。とりあえず、各サブグループでの研究間異質性分散の別々の推定値を使用することにしよう。 

この例では、固定効果（複数）モデルを適用し、サブグループ内の研究はランダム効果モデルを使用してプールされると仮定する。`m.gen` にランダム効果モデルの結果が含まれているので、（`comb.fixed` を `FALSE`、`comb.random` を `TRUE` に設定したので）何も変更する必要はない。元のメタ分析はランダム効果モデルを用いて行われたため、`update.meta` は自動的に、サブグループ内の研究もランダム効果モデルを用いてプールすることを想定している。 

したがって、出来上がったコードは次のようになる。


```{r, eval=FALSE}
update.meta(m.gen, 
            subgroup = RiskOfBias, 
            tau.common = FALSE)
```

```
## Review:     Third Wave Psychotherapies
## 
## Number of studies combined: k = 18
## 
##                         SMD           95%-CI    t  p-value
## Random effects model 0.5771 [0.3782; 0.7760] 6.12 < 0.0001
## 
## Quantifying heterogeneity:
##  tau^2 = 0.0820 [0.0295; 0.3533]; tau = 0.2863 [0.1717; 0.5944]
##  I^2 = 62.6% [37.9%; 77.5%]; H = 1.64 [1.27; 2.11]
## 
## Test of heterogeneity:
##      Q d.f. p-value
##  45.50   17  0.0002
## 
## Results for subgroups (random effects model):
##                     k    SMD           95%-CI  tau^2    tau     Q   I^2
## RiskOfBias = high   7 0.8126 [0.2835; 1.3417] 0.2423 0.4922 25.89 76.8%
## RiskOfBias = low   11 0.4300 [0.2770; 0.5830] 0.0099 0.0997 13.42 25.5%
## 
## Test for subgroup differences (random effects model):
##                     Q d.f. p-value
## Between groups   2.84    1  0.0917
## 
## Details on meta-analytical method:
## - Inverse variance method
## - Restricted maximum-likelihood estimator for tau^2
## - Q-profile method for confidence interval of tau^2 and tau
## - Hartung-Knapp adjustment for random effects model
```


この出力では、`Results for subgroups` と呼ばれる新しいセクションが表示される。出力のこの部分は、各サブグループで別々にプール効果量を示している。バイアスのリスクが高い研究が $k=$ 7件、バイアスのリスクが低い研究が11件であることがわかる。推定された研究間の異質性はかなり異なっており、バイアスのリスクの高い研究では $I^2=$  77%であるが、リスクの低い研究では26%にすぎない。

また、サブグループの効果量も異なっている。 $g=$  0.43 で、バイアスリスクの低い研究の効果推定値は、バイアスリスクの高い研究よりも小さい。バイアスのかかった研究は治療効果を過大評価する可能性が高いので、このことはよく見られる所見である。 

しかし、その差は統計的に有意なのだろうか？`Test for subgroup differences` には、$Q$-検定を示している 結果があるので、これで確認することができる。この例では、2つのサブグループがあり、自由度1に基づいている。この検定の $p$-値は 0.09 で、従来の有意水準より大きいが、それでも傾向レベルの差を示している。

また、両方のサブグループで**共通の** $\tau^2$  推定値を仮定した場合の結果も確認することができる。`tau.common` を `TRUE` に設定するだけである。

```{r, eval=F}
update.meta(m.gen, subgroup = RiskOfBias, tau.common = TRUE)
```


```
## [...]
##                     k    SMD           95%-CI  tau^2    tau     Q   I^2
## RiskOfBias = high   7 0.7691 [0.2533; 1.2848] 0.0691 0.2630 25.89 76.8%
## RiskOfBias = low   11 0.4698 [0.3015; 0.6382] 0.0691 0.2630 13.42 25.5%
## 
## Test for subgroup differences (random effects model):
##                    Q d.f. p-value
## Between groups  1.79    1  0.1814
## Within groups  39.31   16  0.0010
## 
## Details on meta-analytical method:
## - Inverse variance method
## - Restricted maximum-likelihood estimator for tau^2 
##   (assuming common tau^2 in subgroups)
## [...]
```

この出力では、推定された研究間異質性分散が $\tau^2=$  0.069 で、両方のサブグループで同じであることがわかる。２つの $Q$ -検定が提示される。すなわち、**between** groups の異質性 （実際のサブグループ）と **within-subgroup** の異質性（サブグループ内の異質性）である。 

通常のメタ分析と同様に、後者は単にサブグループに過剰な変動があることを示している ($p=$  0.001)。サブグループ差の検定でも、バイアスリスクが低い研究と高い研究の間に有意な差がないことが示された ($p=$  0.181)。

ここで、$\tau^2$ が独立しているか、あるいは共通のであるかを仮定して結果を探った。両サブグループの異質性が等しいと仮定する十分な理由がなく、また、各サブグループに最低 $k=$ 7 件の研究があることから、$\tau^2$  の別々の推定が適切であると考えられる。しかし、少なくともこの例では、どちらのアプローチでも結果の解釈は同じようなものだとわかった。

```{block2, type='boxreport'}
**サブグループ解析の結果を報告**

\vspace{2mm}

サブグループ解析の結果は、通常、各サブグループにおける推定効果と異質性、およびサブグループの差の検定の $p$ 値を表示した表で報告される。


```

```{r, echo=F}
library(kableExtra)
m.gen.sg = update.meta(m.gen, 
            subgroup = RiskOfBias, 
            tau.common = FALSE)

dat = data.frame(g = round(m.gen.sg$TE.random.w, 2),
                 g.ci = paste0(round(m.gen.sg$lower.random.w,2),"-", 
                               format(round(m.gen.sg$upper.random.w,2), nsmall = 2)),
                 p = c("0.009", format.pval(m.gen.sg$pval.random.w[2], eps = 0.001)),
                 i2 = round(m.gen.sg$I2.w, 2),
                 ci.i2 = paste0(format(round(m.gen.sg$lower.I2.w, 2), nsmall=2), "-", round(m.gen.sg$upper.I2.w, 2)),
                 p.sg = c(" ", " "))

dat = rbind(c("", "", "", "", "", 0.092), dat)

rownames(dat) = c("Risk of Bias", "- High", "- Low")
colnames(dat) = c("$g$", "95\\%CI", "$p$", "$I^2$", "95\\%CI", "$p$<sub>subgroup</sub>")

kable(dat, booktabs = T, digits = 2, escape = FALSE) %>% 
  kable_styling(latex_options = c("scale_down"),
                bootstrap_options = c("condensed", "striped"))

# kable_styling(font_size = 7)


```

```{block2, type='boxempty'}
複数のサブグループ解析が行われた場合は、表にさらに行を追加することができる。
```

$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block, type='boxquestion'}
**知識を試そう！**

\vspace{4mm}

1. 影響度分析や外れ値分析ではわからないことのうち、何がサブグループ解析ではわかることがあるか？

\vspace{-2mm}

2. サブグループ解析の背景にあるモデルが、なぜ固定効果（複数）モデルと呼ばれるのか。

\vspace{-2mm}

3. メタ分析の一環として、ある教育研修プログラムの効果が、実施された学区によって異なるかどうかを調べたいと考えている。この問いに答えるために、固定効果（複数）モデルを用いたサブグループ解析は適切か？

\vspace{-2mm}

4. あなたの友人が、合計9つの研究を含むメタ分析を行った。これらの研究のうち5つが1つのサブグループに分類され、4つが他のサブグループに分類されている。彼女は、サブグループ解析を行うことに意味があるかどうかをあなたに尋ねている。あなたならどうするか？

\vspace{-2mm}

5. メタ分析で、分析した治療法が男性よりも女性でより効果的であると著者が主張しているものがあった。この知見は、研究対象者に含まれる女性の割合に基づいて研究をサブグループに分けたサブグループ解析に基づいている。この知見は信頼できるか、またその理由は？

\vspace{4mm}


**問題の解答は、本書の巻末 [Appendix A](#qanda7) にある。**

```

<br></br>

## 要約

* メタ分析の不均一性を評価する方法はいろいろあるが、これらのアプローチでは、データに過剰な変動が見られる**理由**を知ることはできない。サブグループ解析では、ある研究の真の効果量が他の研究よりも高い、または低い理由についての仮説を検証することが可能である。

* サブグループ解析では、通常、**固定効果（複数）モデル**を仮定する。サブグループ内の研究は、ほとんどの場合、ランダム効果モデルを用いてプールされる。その後、全体のサブグループの結果に基づいた $Q$ -検定を使用して、グループが有意に異なるかどうかを判断する。 

* サブグループ解析モデルは、異なるカテゴリ自体が固定されていると仮定されているため、「固定効果」モデルと呼ばれる。サブグループの水準は、可能なカテゴリの宇宙からのランダムな抽選とは見なされない。それらは、サブグループ変数が取り得る唯一の値を表す。

* サブグループ解析を計算する場合、サブグループ内の結果をプールするために、研究間の異質性の推定値を別々にするか、共通にするかを決めなければならない。

* サブグループ解析は万能ではない。サブグループの差を検出するのに必要な統計的検出力が不足していることが多い。したがって、サブグループの差について有意でない検定は、自動的にサブグループが同等の結果をもたらすことを意味するものでは**ない**。

<!--chapter:end:09-subgroup-ja.Rmd-->

# メタ回帰  {#metareg}

---

<img src="_figs/airplanes.jpg" />

<br></br>

\index{Subgroup Analysis}

<span class="firstcharacter">前</span>
章では、メタ分析の「ツール」に新しい手法としてサブグループ分析を追加した。前章で学んだのは、サブグループ解析では、1つの全体的な効果を見つけることから解析の焦点をずらすという点である。その代わりとして、データ中の異質性のパターンとその原因を調査することができるのである。 

\index{Meta-Regression}

また、サブグループ解析は**メタ分析**の特殊な形態であることを述べた。「回帰」という言葉を聞いたことがあるかと思われる。回帰分析は、最も一般的な統計手法の1つで、さまざまな分野で使用されている。最も単純な形では、回帰モデルは、ある変数 $x$  の値を使って、別の変数 $y$  の値を予測しようとするものである。通常、回帰モデルは、$x$ と $y$ の両方の値が測定された個人またはサンプルからなるデータに基づいている。

\index{Sampling Error}

メタ回帰では、このロジックは**全ての研究**に適用される。変数 $x$  は、研究の特徴、たとえば、実施された年などを表す。この情報に基づいて、メタ回帰モデルは、研究の効果量である $y$  を予測しようとする。しかし、予測される変数として効果量が使用されると、より複雑になる。 

Chapter \@ref(what-is-es)  ですでに、観察された効果量 $\hat\theta$  は、その標準誤差によって、研究の真の効果のおおよそ**正確な**推定量になりうることを学んだ。「通常の」メタ分析では、研究に大小の重みを与えることによって、これを考慮に入れている。メタ回帰では、ある研究のサンプル誤差が他より低いとき、その推定値はより「真実」に近いと仮定できるため、モデルはこれらの研究に注意を払う必要がある。

\index{Mixed-Effects Model}

メタ回帰は、**混合効果モデル**を仮定することによって、これを実現する。このモデルは、観察された研究がサンプルエラーや研究間の異質性によって、真の全体効果から逸脱するという事実を説明する。しかし、より重要なのは、1つ以上の変数 $x$  、真の効果量の違いを予測するために使用することである。サブグループ分析も混合効果モデルに基づいていることは、すでに前章で述べたとおりである。この章では、もう少し掘り下げて、なぜサブグループ分析とメタ回帰が本質的に関連しているのかを議論する。

メタ回帰は、それなりの限界はあるものの、メタ分析において非常に強力なツールとなり得る。また、非常に汎用性が高い。たとえば、**多重メタ回帰**は、1つだけでなく、複数の予測変数とそれらの交互作用を含めることができる。本章の後半では、多重メタ回帰と、 _R_ を用いたメタ回帰の実施方法について説明する。

<br></br>

## メタ回帰モデル  {#the-metareg-model}

---

過去に、参加者を分析単位とする一次研究のデータを使って、すでに回帰を行ったことがあるだろう。メタ分析では、通常、各参加者の個別のデータは得られず、集約された結果に頼るしかない。これが、**研究レベル**の予測因子でメタ回帰を実行しなければならない理由である。 

また、一次試験よりもはるかに大きなサンプルで分析を行っても、メタ回帰が有用となるだけのデータポイントが得られない可能性があることを意味する。 Chapter \@ref(limits-subgroup) で、$K<$ 10件の時、サブグループ解析が意味をなさないことが多いことを取り上げた。Borenstein ら [-@borenstein2011introduction, chapter 20] は、このガイドラインはメタ回帰モデルにも適用できるかもしれないが、鉄則と見なすべきではないと言及している。

従来の回帰では、人物 $i$の値 $y_i$ を、**予測因子**（または**共変量**） $x_i$ と回帰係数 $\beta$ を使って推定したい。したがって、標準的な回帰式は次のようになる。

\begin{equation}
\hat{y_i} = \beta_0 + \beta_1x_i
(\#eq:mr1)
\end{equation}

メタ回帰では、予測したい変数 $y$  は、研究 $k$  の観察された効果量 $\hat\theta_k$  である。**メタ回帰**の式は、正規回帰モデルの式に似ている。

\begin{equation}
\hat\theta_k = \theta + \beta x_{k} + \epsilon_k+\zeta_k
(\#eq:mr2)
\end{equation}

この式は、2つの追加項、$\epsilon_k$ と $\zeta_k$ を含んでいることに注意されたい。同じ項がランダム効果モデルの式（ Chapter \@ref(rem)  ）にもあり、2種類の独立した誤差を意味する。1つ目の $\epsilon_k$ は、研究の効果量が真の効果から逸脱するサンプル誤差である。 

2つ目の誤差、$\zeta_k$ は、研究の真の効果量でさえ、効果量の包括的な分布からサンプルされているに過ぎないことを表している。これは、私たちのデータには研究間の異質性が存在することを意味し、これは異質性分散 $\tau^2$ によって捕捉される。

\index{Random-Effects Model}
\index{Fixed-Effect Model}
\index{Mixed-Effects Model}

上記の式は、**固定**効果（$\beta$  係数）と**ランダム**効果（$\zeta_k$）を含むので、メタ回帰で使用されるモデルは、**混合効果モデル**と呼ばれることも多い。概念的には、このモデルは Chapter \@ref(comparing-the-subgroup-effects)  で説明した混合効果モデルと同じで、サブグループ解析がどのように機能するかを説明したものである。

<br></br>

### カテゴリカル予測変数のメタ回帰

---

\index{Dummy Variable}

実際、前述のように、サブグループ分析は、カテゴリカル予測変数のメタ回帰にほかならない。そのようなカテゴリカル変数は、たとえば、**ダミー・コーディング** によって含めることができる。


\begin{equation}
  D_g=\begin{cases}
    0: & \text{Subgroup A}\\
    1: & \text{Subgroup B.}
  \end{cases}
  (\#eq:mr3)
\end{equation}


サブグループ分析をメタ回帰の形で指定するには、共変量 $x_k$ を $D_g$ に置き換えるだけでよい。

\vspace{2mm}

\begin{equation}
\hat\theta_k = \theta + \beta D_g +\epsilon_k+\zeta_k.
(\#eq:mr4)
\end{equation}

\vspace{2mm}

この式を理解するためには、左から右へ読む必要がある。メタ回帰モデルの目的は、他の統計モデルと同様、観測されたデータがどのように生成されたかを説明することである。私たちの場合、これはメタ分析におけるいくつかの研究（$k$）の観察された効果量 $\hat\theta_k$ である。上の式はレシピのように機能し、観察された効果を生み出すためにどの材料が必要かを教えてくれる。 

まず、$\theta$ は回帰モデルにおける**切片**として機能する。$\theta$ の値は、サブグループAの真の全体効果量と同じである。この理由を見るために、次の「成分」である項 $\beta D_g$  を見る必要がある。この項の $\beta$  の値は、サブグループAとサブグループBの間の効果量の差 $\theta_{\Delta}$  を表している。 $\beta$  の値は、研究がサブグループA ( $D_g = 0$ ) またはサブグループB ( $D_g = 1$ ) のどちらに属しているかによって 0 または 1 のどちらかになる $D_g$ を掛け合わされたものである。 

ゼロを掛けるとゼロになるので、サブグループAの研究を扱っているときは、$\beta D_g$  の項は方程式から完全に外れる。一方、$D_g=1$ 、1を掛けると、$\beta$ が方程式に残り、$\theta$  、サブグループBの全体的な効果量が得られる。基本的に、ダミー予測変数は **2** 式を **1** に統合する方法である。これは、各サブグループの式を個別に書き出すと、簡単にわかる。

\vspace{2mm}

\begin{equation}
  D_g=\begin{cases}
    0: & \text{$\hat\theta_k = \theta_A + \epsilon_k+\zeta_k$}\\
    1: & \text{$\hat\theta_k = \theta_A + \theta_{\Delta} +\epsilon_k+\zeta_k$}
  \end{cases}
  (\#eq:mr5)
\end{equation}

\vspace{2mm}

このように書くと、この式は、実際には、サブグループAとサブグループBの2つのモデルを含んでいることが明らかになる。モデル間の主な違いは、$\beta$ （上の式では $\theta_{\Delta}$  と表記）の値によって、第2サブグループの効果が上下に「シフト」されることである。

```{r subgroups2, message = F, out.width = '70%', echo = F, fig.align='center', fig.cap='Meta-regression with a categorical predictor (subgroup analysis).'}
library(OpenImageR)
knitr::include_graphics('images/subgroups2_sep.png')
```

これは、サブグループ分析が通常の回帰と同じように動作することを明確にするもので、ある変数 $x$  を使って $y$  の値を予測する。特別なのは、$\beta x_k$  が連続的ではなく、ある研究が特定のサブグループに属するかどうかに応じて、予測に追加する固定値であるということである。この固定値 $\beta$  は、2つのサブグループ間の効果量の差の推定値である。


<br></br>

### 連続予測因子によるメタ回帰  {#metareg-continuous}

---

\index{Weight}

しかし、「メタ回帰」というと、普通は**連続**変数を予測変数としたモデルを思い浮かべる。そこで、8.2式に示す一般的なメタ回帰の式に戻る。ここでも、前に説明した回帰の用語が使われているが、少し違う目的を持っている。$\theta$ 項は再び切片を表すが、今度は $x = 0$ のときに予測される効果量を表す。 

切片に、$\beta x_k$ 項が加えられる。この部分は、**回帰傾き**を生成する。つまり、連続変数 $x$ と**回帰重み** $\beta$ が掛け算され、共変量値の予測効果を低くしたり高くしたりする。 

メタ回帰モデルの目的は、研究の**予測**効果量と**真の**効果量の差を最小化する $\theta$ と $\beta$  の値を見つけることである（ Figure \@ref(fig:subgroups3)  を参照）。

```{r subgroups3, message = F, out.width = '70%', echo = F, fig.align='center', fig.cap='連続変数予測因子と４つの研究のメタ回帰'}
library(OpenImageR)
knitr::include_graphics('images/subgroups3_sep.png')
```


メタ回帰式をよく見てみると、2種類の項が含まれていることがわかる。いくつかの項には添え字（$k$）があり、他の項には添え字がない。添え字（$k$）は、ある値が研究ごとに**異なる**ことを示す。ある項が添え字（$k$）を含んでいない場合、それはすべての研究で同じである。

```{r, message = F, out.width = '45%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/metareg_form_sep.png')
```

メタ回帰では、$\theta$  と $\beta$  の両方が不変、または固定である。予測変数の変動と観察された効果に基づいて、**回帰線**の形で、データの根底にある**固定パターン**を「抽出」しようとするのである。メタ回帰モデルがデータによく当てはまる場合、推定されたパラメータ $\theta$ と $\beta$ は、モデルが**今まで見たことのない**研究の効果量を予測するのに使うことができる（$x$  がわかっていればの話であるが）。 

$\epsilon_k$ と研究間異質性 $\zeta_k$ の両方を考慮すると、メタ回帰は、観察された効果量だけでなく、関心のあるすべての研究の「宇宙」に対して、うまく**一般化する**モデルを見つけようとするものである。


<br></br>

### モデルの適合性を評価 {#metareg-model-fit}

---

メタ回帰モデルの重要な点は、効果量のプールに使用する「通常の」ランダム効果モデルの拡張とみなすことができる点である。ランダム効果モデルは、傾き項を含まないメタ回帰モデルに過ぎない。傾きがないので、ランダム効果モデルは、各研究について単純に**同じ値**を予測する。つまり、プールされた効果量の推定値 $\mu$ であり、これは切片と同じである。

\index{Ordinary Least Squares (OLS)}
\index{Weighted Least Squares (WLS)}

最初のステップでは、メタ回帰の計算は、したがってランダム効果メタ分析のものとよく似ており、研究間異質性 $\tau^2$ が Chapter \@ref(tau-estimators)  で説明した方法（例えば、DerSimonian-Laird 法または REML 法）のいずれかを使って推定される。次のステップでは、固定重み $\theta$ と $\beta$ が推定される。通常の線形回帰モデルは、**通常の最小2乗** (ordinary least squares, OLS) 法を用いて、データに最もよく適合する回帰直線を見つける。メタ回帰では、**重み付き最小2乗** (weighted least squares, WLS)と呼ばれる修正された方法が使用され、より小さな標準誤差を持つ研究がより高い重みを与えられるようにする。 

最適解が見つかったら、新しく追加された回帰項が効果量の異質性の一部を説明しているかどうかを確認することができる。メタ回帰モデルがデータによく適合している場合、真の効果量は、プール効果量 $\hat\mu$ と比較して回帰直線からの偏差が小さくなる。この場合、予測因子 $x$ は、メタ分析における異質性分散の一部を**説明**する。

```{r, message = F, out.width = '100%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rem_mem_sep.png')
```

したがって、メタ回帰モデルの適合性は、それが異質性分散のどれだけを説明するかをチェックすることによって評価することができる。混合効果モデルに含まれる予測変数は、**残渣** (residual)、または説明されない異質性分散の量を最小化する必要があり、これは、$\tau^2_{\text{unexplained}}$  で示される。 

回帰分析では、モデルによって説明される変動の割合を定量化するために、$R^2$  指数が一般的に使用される。類似の指数である $R^2_{*}$  もメタ回帰で計算することができる。ここでは、観測されたデータ点ではなく、**真の効果量** を扱うので、メタ回帰の $R^2$  は、従来の回帰で使われるものと若干異なることを示すために、アスタリスク（$*$）を追加している。 $R^2_*$  の式は次のようになる。

\begin{equation}
R^2_* = 1- \frac{\hat\tau^2_{\text{unexplained}}}{\hat\tau^2_{\text{(total)}}}
(\#eq:mr6)
\end{equation}

$R^2_*$ は、メタ回帰の傾きでさえ説明できない異質性分散の残渣量を使用し、それをメタ分析で最初に発見した異質性の合計で割る。この割合を1から引くと、予測変数によって説明される研究間の異質性のパーセンテージが得られる。 

また、$R^2_*$ を定式化する別の方法がある。それは、混合効果モデルが、最初のランダム効果プーリングモデルと比較して、異質性の分散をどれだけ**低減**させるかをパーセントで表すと言うことができる。この結果、次のような式になる。

\begin{equation}
R^2_* =  \frac{\hat\tau^2_{\text{REM}}-\hat\tau^2_{\text{MEM}}}{\hat\tau^2_{\text{REM}}}
(\#eq:mr7)
\end{equation}

この式で、$\hat\tau^2_{\text{REM}}$  はランダム効果プーリングモデルで見つかった研究間異質性の量を表し、$\hat\tau^2_{\text{MEM}}$  は混合効果メタ回帰モデルの（残）分散（すなわち、真の効果量に関する「予測誤差」）を表す。

\index{Wald 型検定}

通常、私たちは回帰モデルで説明される異質性の量に興味があるだけでなく、私たちの予測因子 $x$  の回帰重量が有意であるかどうかにも興味がある。もしそうであれば、$x$  が研究の効果量に影響を及ぼしていると確信できる。従来の回帰でもメタ回帰でも、回帰重みの有意性は、一般的に **Wald-type** 検定で評価される。これは、$\beta$  の推定値をその標準誤差で割ることによって、検定統計量 $z$  を計算することを含む。

\begin{equation}
z = \frac{\hat\beta}{SE_{\hat\beta}}
(\#eq:mr8)
\end{equation}

 $\beta = 0$  という帰無仮説のもとでは、この $z$ -統計量は、標準正規分布に従う。これは、対応する $p$ -値を計算することができ、予測変数が有意であるかどうかを決定するものである。

しかし、$z$-統計量に基づく検定は、予測変数の有意性を評価する唯一の方法ではない。通常のメタ分析モデルのように、$t$-分布に基づく検定統計量になる Knapp-Hartung 調整も使用できる（ Chapter \@ref(knapp-hartung)  を参照）。以前学んだように、Knapp-Hartung 法は、偽陽性のリスクを減らすので、使用することが推奨される。

<br></br>

##  _R_ のメタ回帰について  {#metareg-R}

---

 **{meta}** パッケージには、メタ回帰を行うための関数  `metareg`  が含まれている。この  `metareg`  関数は、入力として  **{meta}**  メタ分析オブジェクトと共変量名のみを必要とする。

この例では、再び `ThirdWave` データセット（ Chapter \@ref(pre-calculated-es)  参照）に基づいた `m.gen` メタ分析オブジェクトを使用する。メタ回帰を用いて、研究の**出版年**がその効果量を予測するのに使えるかどうかを調べたいと思われる。デフォルトでは、`ThirdWave`  データセットには出版年を格納する変数がないので、この情報を格納する新しい `numeric`  変数を作成する必要がある。そのため、この情報を含む新しい `numeric`  変数を作成する必要がある。ここでは、すべての研究の出版年を `ThirdWave`  データセットに現れるのと同じ順序で単純に連結している。この変数を  `year`^[この例で使用している出版年はテキトウで、説明のためだけに使用している。] という名前で保存する。

```{r}

year <- c(2014, 1998, 2010, 1999, 2005, 2014, 
          2019, 2010, 1982, 2020, 1978, 2001,
          2018, 2002, 2009, 2011, 2011, 2013)
```

これで、メタ回帰を実行するために必要な情報はすべて揃った。`metareg` 関数では、最初の引数にメタ分析オブジェクトの名前 `m.gen` を指定し、2番目の引数に予測変数の名前 `year` を指定する。結果は `m.gen.reg` という名前になる。


```{r}
m.gen.reg <- metareg(m.gen, ~year)

```

では、その結果を見てみよう。

```{r, eval=F}
m.gen.reg
```

```
## Mixed-Effects Model (k = 18; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.019 (SE = 0.023)
## tau (square root of estimated tau^2 value):             0.1371
## I^2 (residual heterogeneity / unaccounted variability): 29.26%
## H^2 (unaccounted variability / sampling variability):   1.41
## R^2 (amount of heterogeneity accounted for):            77.08%
## 
## Test for Residual Heterogeneity:
## QE(df = 16) = 27.8273, p-val = 0.0332
## 
## Test of Moderators (coefficient 2):
## F(df1 = 1, df2 = 16) = 9.3755, p-val = 0.0075
## 
## Model Results:
## 
##         estimate     se   tval   pval    ci.lb    ci.ub 
## intrcpt   -36.15  11.98  -3.01  0.008  -61.551  -10.758  ** 
## year        0.01   0.00   3.06  0.007    0.005    0.031  ** 
## 
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

\index{I$^2$, Higgins \& Thompson's}

ここでわかることを見ていこう。最初の行では、意図したとおりに混合効果モデルがデータに適合されたことが出力されている。次の数行は、モデルによって説明される異質性の量に関する詳細である。残差異質性分散（予測変数によって説明されない分散）の推定値が、$\hat\tau^2_{\text{unexplained}}=$  0.019である。 

出力には、$I^2$ もある。これは、予測変数の包含後、データの変動の29.26%が残りの研究間異質性に帰着することができることを教えてくれる。通常のランダム効果メタ分析モデルでは、$I^2$ 異質性が 63% であることがわかっていた。これは、予測変数が真の効果量における差のかなりの量を「説明する」ことができたということになる。 

最後の行では、$R^2_*$ の値が表示され、この例では 77% となっている。これは、真の効果量の差の77%が出版年によって説明できることを意味し、非常に大きな値である。

次のセクションは、`Test for Residual Heterogeneity` を含み、本質的には、すでに以前知った $Q$-検定である（ Chapter \@ref(cochran-q)  を参照）。ここでは、予測変数で説明されない異質性が有意であるかどうかを検定する。$p$ = 0.03 であることから有意である。しかし、私たちは $Q$-検定（Chapter \@ref(cochran-q)）の限界を知っているので、この結果にはあまり依存しない方がよいだろう。

次の部分は、`Test of Moderators` を示している。この検定も有意であることがわかる ($p$ = 0.0075)。これは、私たちの予測因子である出版年が、実際に研究の効果量に影響を与えることを意味する。

最後のセクションでは、推定された回帰係数の詳細を説明する。最初の行は、切片（`intrcpt`）の結果を示している。これは、予測因子である出版年がゼロの場合に期待される効果量（私たちの場合：Hedges' $g$）である。この例では、少し不自然なシナリオを表している。これは、0年に実施された研究の予測効果を示しており、$\hat{g}=$ -36.15となっている。優れた統計モデルは現実を完璧に表現している必要はなく、ただ**有用**であればよいということを改めて思い起こさせるものとなっている。 

私たちが主に注目するのは2行目の係数である。このモデルの `year` の回帰重みの推定値が0.01であることがわかる。これは、1年増えるごとに、研究の効果量 $g$ が0.01ずつ増加することを意味する。したがって、研究の効果量は時間とともに増加していると言えるだろう。95%信頼区間の範囲は 0.005 から 0.3 であり、効果は有意であることがわかる。 

重要なのは、各回帰係数( `tval` )に対応する $t$-統計量も提示されていることである。これは、信頼区間と $p$ -値を計算するために、Knapp-Hartung 法が使用されたことを示す。最初のメタ分析モデルでもこの調整法を使用したので、 `metareg` はここでも自動的にこの調整法を使用してきた。そうでなければ、$z$ 値と Wald 型信頼区間が提供されるはずであった。

\index{Bubble Plot}

**{meta}** パッケージでは、 `bubble` 関数を用いてメタ回帰を可視化することができる。これは、推定回帰勾配と各研究の効果量を示す**バブルプロット** (bubble plot) を作成する。研究の重みを示すために、バブルは異なる大きさを持ち、大きければ大きいほど重みがあることを表す。 

バブルプロットを作成するためには、メタ回帰オブジェクトを `bubble` 関数に接続するだけである。研究ラベルも表示させたいので、`studlab` を `TRUE` に設定する。 

```{r, fig.width=8, fig.height=7, out.width="60%", fig.align="center", eval=F}
bubble(m.gen.reg, studlab = TRUE)
```


```{r bubble, fig.width=8, fig.height=7, out.width="60%", fig.align="center", echo=F}
par(bg="#FFFEFA")
bubble(m.gen.reg, studlab = TRUE)
```

\index{Risk of Bias}

完全性を期すために、前章のサブグループ分析（Chapter \@ref(subgroup-R)）を、今度はメタ回帰の枠組みで繰り返してみることもできる。これは、カテゴリ予測因子としてバイアスのリスク・アセスメントを使用することを意味する。変数  `RiskOfBias` はすでに `ThirdWave`  のデータセットに含まれているので、この情報を追加オブジェクトに保存する必要はない。単純に `metareg` 関数を再度実行すれば良いのであるが、今回は関数の2番目の引数として  `RiskOfBias` を使用する。

```{r, eval=F}
metareg(m.gen, RiskOfBias)
```

```
## [...]
## R^2 (amount of heterogeneity accounted for):            15.66%
## 
## Test for Residual Heterogeneity:
## QE(df = 16) = 39.3084, p-val = 0.0010
## 
## Test of Moderators (coefficient 2):
## F(df1 = 1, df2 = 16) = 2.5066, p-val = 0.1329
## 
## Model Results:
## 
##               estimate    se   tval    pval  ci.lb ci.ub 
## intrcpt           0.76  0.15   5.00  0.0001   0.44  1.09  *** 
## RiskOfBiaslow    -0.29  0.18  -1.58  0.1329  -0.69  0.10      
## [...]

```

出力では、$R^2_*$  の値が15.66%で、`year` の値よりかなり小さいことがわかる。以前の結果と一致して、バイアス・リスク変数が有意な効果量予測因子でないことがわかる ($p$  = 0.13)。 

モデル結果の下で、`metareg` が自動的に `RiskOfBias` をダミー変数に変換していることがわかる。サブグループ "high risk" のプール効果を表す切片の推定値は、$g$ = 0.76 である。バイアスのリスクが**低い**研究を表す回帰係数の推定値は -0.29 である。 

このサブグループの効果量を得るには、切片に回帰重みを加える必要があり、その結果、$g=$  0.76 - 0.29 $\approx$ 0.47 となる。これらの結果は、$\tau^2$  の共通の推定値を仮定したサブグループ分析の結果と同じである。 

<br></br>

## 多重メタ回帰  {#multiple-metareg}

---

\index{Risk of Bias}

前回は、メタ回帰モデルで**一つの**の予測因子 $\beta x_k$  を使用するシナリオのみを検討してきた。この例では、研究の効果量が出版された年に依存するかどうかを調べる。しかし今度は、報告された効果量が、研究が掲載された科学雑誌の**名声**にも依存していると仮定しよう。高い評価を得ている雑誌に掲載された研究が、より高い効果を報告している可能性があると考えている。なぜなら、一流の雑誌では、選ばれた研究は「画期的」な発見をしていることがほとんどだからである。

一方、評判の良い雑誌は一般的に**質の高い**研究を掲載しているというのももっともな話である。もしかしたら、より高い効果量と関連するのは、より良い研究の質だけだろう。そこで、ジャーナルの評判が本当に高い効果と関連しているかどうかを確認するために、この関係が、一流のジャーナルが高品質のエビデンスを出版する可能性が高いという事実によって**交絡**していないことを確認する必要がある。つまり、ジャーナルの名声と効果量の関係を調査する際には、研究の質を**コントロール**する必要がある。

これや他の多くの研究課題は、**多重メタ回帰**を使用して対処することができる。多重メタ回帰では、効果の変動を説明するために、1つだけでなく複数の予測変数を使用する。複数の予測変数を使用できるようにするには、前のメタ回帰式（式8.2参照）を修正して、次のようにする必要がある。

\begin{equation}
\hat \theta_k = \theta + \beta_1x_{1k} + ... + \beta_nx_{nk} + \epsilon_k + \zeta_k
(\#eq:mr10)
\end{equation}

この式は、メタ回帰モデルに $n-1$ より多くの予測変数 $x$ を追加して、多重メタ回帰に変えることができることを示す。この式の3つの点は、理論的には、望むだけの予測変数を追加できることを象徴している。しかし、現実にはもっとやっかいなことが多い。以下では、多重メタ回帰のいくつかの重要な落とし穴と、どのようにすれば頑健で信頼できるモデルを構築できるかを説明する。その前に、多重メタ回帰のもう一つの重要な特徴である**交互作用** (interaction) について説明する。

<br></br>

### 交互作用  {#interact}

---

\index{Interaction (Regression)}

ここまでは、モデル内に複数の予測変数 $x_1, x_2, \dots x_n$  があり、それらの回帰重み $\beta$  と共に加算される場合のみを考えていた。しかし、多重メタ回帰モデルは、このような**加算**関係に限定されるわけではない。また、予測変数の**交互作用** もモデル化することができる。交互作用とは、ある予測変数（例： $x_1$  ）と推定効果量との間の**関係**が、別の共変量（例： $x_2$  ）の異なる値で**変化する**ことを意味する。

2つの予測因子とそれらが効果量とどのように関連するかをモデル化したいとする：出版年 ($x_1$) と研究の質 ($x_2$) である。研究の質は次のようにコード化される。

\begin{equation}
  x_2=\begin{cases}
    0: & \text{low}\\
    1: & \text{moderate}\\
    2: & \text{high}
  \end{cases}
  (\#eq:mr11)
\end{equation}

出版年と研究の質の間に相互作用がないと仮定した場合、$x_1$  と $x_2$  の両方に回帰の重み $\beta$  を与え、数式でその項を一緒に**追加**することによって、メタ回帰モデルを構築することができる。

\begin{equation}
\hat \theta_k = \theta + \beta_1x_{1k} + \beta_2x_{2k} + \epsilon_k + \zeta_k
(\#eq:mr12)
\end{equation}

しかし、$x_1$  と $x_2$  の関係がもっと複雑だとしたらどうだろうか。先ほどの例のように、より新しい出版年がより高い効果と正に関連している可能性がある。しかし、すべての研究がこのような傾向を示すとは限らない。もしかしたら、質の高い研究で顕著に増加し、質の低い研究の結果は時間の経過とともにほとんど変わらなくなるだろう。効果量 ($\hat\theta_k$)、出版年 ($x_1$)、研究の質 ($x_2$)の間のこの想定された関係は、次のように可視化することができる。


```{r metareg2, message = F, out.width = '60%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/metareg2_col_sep.png')
```

このグラフは、交互作用の典型的な例を示している。回帰の傾きの急さは、別の予測変数の値に依存することがわかる。質の高い研究では、回帰線の傾きが非常に急で、発表年と効果の間に強い関係があることを示しているが、低質な研究では状況が異なる。このサブグループの回帰直線はほとんど水平で、出版年は結果に全く、あるいはわずかにマイナスの影響を与えることを示している。 

この例は、交互作用の強みの1つである、予測因子の影響がすべての研究で同じかどうか、あるいは他の特性によって緩和されているかどうかを調べることができることを示している。 

メタ回帰で相互作用を評価するためには、モデルに**交互作用項** を追加する必要がある。私たちの例では、これは私たちのモデルでテストしたい交互作用 $x_{1k}x_{2k}$ を捕捉する3番目の回帰重み $\beta_3$  を追加することで達成できる。これは、次の数式を与える。

\begin{equation}
\hat \theta_k = \theta + \beta_1x_{1k} + \beta_2x_{2k} + \beta_3x_{1k}x_{2k}+ \epsilon_k + \zeta_k
(\#eq:mr13)
\end{equation}

線形多重メタ回帰モデルは、このような単純な構成要素で構成されているだけであるが、様々な用途に使用することができる。しかし、 _R_ を用いた多重メタ回帰のフィッティングを始める前に、まずその限界と落とし穴について考えておく必要がある。 


<br></br>

### 多重メタ回帰にありがちな落とし穴  {#limits-metareg}

---

多重メタ回帰は、適切に適用されれば非常に有用であるが、ある種の注意点がある。実際には（多重）メタ回帰は不適切な使い方や解釈が多く、結果の妥当性が低いという意見もある [@higgins2004controlling]。多重メタ回帰モデルを当てはめる際に注意しなければならない点がいくつかあるので、以下に説明する。

<br></br>

#### 過適合: 信号のないところに信号を見いだす

---

\index{Overfitting}

メタ回帰モデル（複数）のリスクをより良く理解するためには、**過適合** (overfitting) という概念を理解する必要がある。過適合とは、データに**あまりにも**近く適合するような統計モデルを構築した場合に起こる。簡単に説明すると、手元のデータはうまく予測できるが、将来のデータはうまく予測できない統計モデルを構築してしまうということである。 

これは、モデルが、データの変動が真の「シグナル」に由来すると仮定したときに起こるもので、実際にはランダムなノイズしか捉えていない [@iniesta2016machine]。その結果、モデルは**偽陽性**の結果を生成する。つまり、何もないところに関係性を見出すのである。


```{r overfitting, message = F, out.width = '80%', echo = F, fig.align='center', fig.cap="過適合モデルと頑健適合モデルの予測。"}
library(OpenImageR)
knitr::include_graphics('images/overfitting_col_sep.png')
```

\index{Ordinary Least Squares (OLS)}
\index{Maximum Likelihood}

モデル適合のために、回帰は通常の最小2乗法や最尤推定などの**最適化**技術を利用する。すでに学んだように、メタ回帰は普通の最小二乗法の重み付きバージョンを使用するので（Chapter \@ref(metareg-model-fit)  参照）、これも例外ではない。 

「貪欲に」最適化すると、しかしながら、回帰アプローチが過適合に陥りやすい [@gigerenzer2004mindless]。残念ながら、従来の回帰手法からメタ回帰に移行すると、頑健でないモデルを構築するリスクはさらに高くなる。これにはいくつかの理由がある [@higgins2004controlling]。

1. メタ回帰では、含まれる研究の集約された情報しか使えないので、通常、データポイントの数は少ない。

2. メタ分析は、すべての利用可能なエビデンスを包括的に概観することを目的としているので、私たちの回帰モデルが未知のデータをどれだけ予測できるかを「テスト」できるような追加データは持っていない。

3. メタ回帰では、効果量の異質性が存在する可能性に対処しなければならない。２つの研究があり、両者の効果量が異なり、信頼区間が重なっていないケースを想像してみよう。２つの研究で異なる値を持つすべての変数が、効果量の差の説明となり得る。しかし、これらの説明のほとんどが偽の説明であることは明らかだろう。

4. 一般的なメタ回帰、特に多重メタ回帰は、予測変数の「遊び」を非常に簡単にする。データの異質性を説明するために、多数のメタ回帰モデルをテストして、より多くの予測変数を含めたり削除したりすることができる。このアプローチは魅力的で、実際によく見られる。メタ分析では、効果量が異なる理由の説明を見つけたいからである [@higgins2002statistical]。有意なモデルを見つけるまで無限にモデルの一部を変更することができるが、そのモデルは過適合である（つまり、ほとんど統計的ノイズをモデル化している）可能性が非常に高い。

メタ回帰モデルを構築する際に、過度の偽陽性を避けるためのガイドラインがいくつか提案されている。

\index{Parsimony}
\index{Analysis Plan}

* 調査された予測変数の数を最小にする。多重メタ回帰では、これは**倹約** (parsimony) の概念に変換される。つまり、メタ回帰モデルの適合を評価するとき、**少ない**予測変数で**良い**適合を達成するモデルを好む。赤池情報量規準やベイズ情報量規準のような推定量は、この決定を助けることができる。ここでの実践的な例で、これらのメトリックをどのように解釈するかを示す。

* 予測変数の選択は、メタ分析で答えたい、あらかじめ定義された科学的な関連性のある質問に基づいて行う必要がある。メタ分析モデルに含まれる予測因子（組み合わせ）を分析レポート（ Chapter \@ref(analysis-plan)  ）ですでに定義しておくことが重要である。分析計画に記載されていないメタ分析を実行することになったとしても、それで終わりではない。ただし、この場合は正直に、メタ分析報告書に、データを見た**後で**モデルの適合を決定したことを記載する必要がある。

* 研究数が少ない場合（これはよくある）、予測変数の有意性を計算したい場合は、Knapp-Hartung 調整を用いて、より頑健な推定値を得るべきである。

\index{Permutation}

* 再サンプルされたデータにおけるモデルの頑健性を評価するために、**置換**を使用することができる。この方法の詳細については後ほど説明する。

<br></br>

#### 多重共線性

---

\index{Multi-Collinearity}
\index{Overfitting}

**多重共線性**とは、回帰モデル中の1つ以上の予測変数が、他のモデル予測変数によって高い精度で予測されることである [@mansfiled1982detecting]。これは通常、モデル中に相関の高い２つ以上の独立変数があることを意味する。 

多重共線性の危険性のほとんどは、過適合の問題と関連している。高い共線性は、予測変数の係数推定値 $\hat\beta$  を不安定にさせ、データの小さな変化で大きく変化させることがある。また、モデルによって説明される分散の大きさ（ここでは $R^2_*$）も制限される。

メタ回帰における多重共線性は一般的である [@berlin1994advantages]。重回帰は低度の共線性を扱うことができるが、非常に高い相関を持つ予測変数をチェックし、必要ならコントロールする必要がある。多重共線性の有無を判断するための統合されたイエス・ノールールはない。 

粗雑ではあるが、しばしば効果的な方法は、モデルを適合する前に、非常に高い予測変数の相関（すなわち、$r \geq$  0.8）をチェックすることである。そして、多重共線性は、(1) 近い冗長な予測変数の１つを除去するか、(2) 予測変数を１つの単一変数に結合しようとするかのいずれかによって削減することができる。


<br></br>

#### 過適合のアプローチ

---

多重メタ回帰モデルを構築するとき、予測変数の選択と包含にさまざまなアプローチがある。ここでは、最も重要なものを、その長所と短所とともに議論する。

* **強制入力**. 強制入力法では、すべての関連する予測変数が同時に回帰モデルに強制入力される。 _R_ のほとんどの関数では、これはデフォルトの設定である。これは一般的に推奨される手順であるが、強制入力で使用するすべての予測変数は、やはり事前に定義された、理論に基づいた決定に基づいているべきであることに留意してみよう。


* **階層的**. 階層型重回帰は、明確に定義された科学的根拠に基づいて、予測変数を段階的に私たちの回帰モデルに含めることを意味する。まず、以前の研究で効果量の差に関係していた予測変数のみが、その重要性の順序で含まれる。このステップの後、既知の予測変数ではまだ捕捉されていない異質性をこれらの変数が説明するかどうかを調べるために、新しい予測変数を追加することができる。

\index{Step-Wise Regression}

* **ステップ・ワイズ**. ステップ・ワイズ入力とは、変数/予測変数が次々にモデルに追加されることを意味する。一見すると、これは階層回帰とよく似ているが、決定的な違いがある：ステップ・ワイズ回帰法は、**統計的基準**に基づいて予測変数を選択する。**フォワード選択** (forward selection) と呼ばれる手順では、データ中の最大の変動量を説明する変数が、最初の予測変数として使われる。そして、このプロセスを残りの変数について繰り返し、毎回、データ中の説明できない残留変動のほとんどを説明する変数を選択する。また、**後方選択** (backward selection) と呼ばれる手順もあり、まずすべての変数がモデルの予測変数として使用され、次にあらかじめ定義された統計的基準に基づいて、順次削除される。ステップ・ワイズ法の使用を推奨しない文献が多数ある [@chatfield1995model; @whittingham2006we]。上で示した重回帰モデルの一般的な落とし穴を思い出すと、これらの方法が偽の知見を持つ過剰適合モデルを生成する高いリスクを持つことが明らかになる。とはいえ、ステップワイズ法は今でも実務で頻繁に使われているので、これらの手続きが存在することを知っておくことは重要である。ただし、ステップワイズ法を使う場合は、主に探索的に行い、この手法の限界を念頭に置いておくことを勧める。

\index{Multi-Model Inference}

* **マルチモデル推論**. マルチモデル法は、分散の大部分を説明する1つの「最良」モデルを連続的に構築しようとしないので、段階的アプローチとは異なる。その代わりに、この手法では、予測変数の**すべての**可能な組み合わせがモデル化される。これは、いくつかの異なるメタ回帰が作成され、その後、評価されることを意味する。これは、すべての可能な予測変数の組み合わせと、それらがどのように機能するかを完全に調べることができる。共通の発見は、良いモデル適合をもたらす多くの異なる仕様があることである。そして、予測変数の推定係数は、適合したすべてのモデルにわたってプールされ、特定の変数が全体としてどのくらい重要であるかを推論することができる。

<br></br>

###  _R_ の多重メタ回帰 {#multiple-metareg-R}

---

\index{meta Package}
\index{metafor Package}

すべてのインプットの後、 _R_ を使用して最初の多重メタ回帰の適合を開始する時が来た。以下の例は、**{meta}**  パッケージを使用しない最初の例である。その代わりに **{metafor}** を見てみよう [@urviecht]。このパッケージは、メタ分析のための膨大で高度な機能を、素晴らしいドキュメントとともに提供している^[実際、メタ回帰を行うために、**{meta}** 関数も内部で **{metafor}** パッケージを使用している]。そこで、まず、**{metafor}** がインストールされており、ライブラリからロードされていることを確認する。

```{r, message=F}
library(metafor)
```

このハンズオンでは、 `MVRegressionData` データセットを使用する。これは「おもちゃ」のようなデータセットで、説明のためにシミュレートしたものである。

\index{dmetar Package}

```{block, type='boxdmetar'}
**"MVRegressionData" データセット**

\vspace{2mm}

`MVRegressionData` のデータセットも **{dmetar}** パッケージに直接含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(SuicidePrevention)` を実行すると、自動的に _R_ 環境にデータセットが保存される。これでデータセットが利用できる。もし、**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/MVRegressionData.rda)から _.rda_ ファイルとしてデータセットをダウンロードして作業ディレクトリに保存し、R Studio ウィンドウでクリックするとインポートすることができる。

```


まず、データフレームの構造を見てみよう。

```{r, message=F}
library(tidyverse)
library(dmetar)
data(MVRegressionData)

glimpse(MVRegressionData)
```

このデータセットには6つの変数があることがわかる。`yi` 列と `sei` 列は、特定の研究の効果量と標準誤差を格納する。この列は、前に使った `TE` 列と `seTE` 列と対応している。この変数名が、**{metafor}** が使用している標準的な表記方法である。`yi`  は（メタ）回帰で予測したい観測された効果量 $y_i$ を表し、`sei` は $SE_i$で、研究 $i$ の標準誤差を表す。 

他の4つの変数は、メタ回帰で使用される予測変数である。まず、`reputation` であるが、これは研究が掲載されたジャーナルの（平均値中心の）**インパクト・ファクター**である。インパクトファクターは、ジャーナルの論文がどれだけ頻繁に引用されるかを定量化し、ジャーナルの名声の代理として使用する。 

その他の変数は、0から10で評価される研究の質である `quality`  、（中央揃えでスケーリングされた）出版年である `pubyear`  、そして研究が行われた大陸である `continent` である。これらの変数は、`continent` を除き、すべて連続変数である。最後は、ヨーロッパと北アメリカの2つのレベルを持つカテゴリ変数である。 


<br></br>

#### 多重共線性の確認

---

\index{Multi-Collinearity}

前に述べたように、メタ回帰の係数推定が頑健 (robust) であることを確認するために、予測変数の多重共線性をチェックする必要がある。高い相関をチェックする簡単な方法は、すべての連続変数について**相互相関行列**を計算することである。これは、`cor`  関数を用いて行うことができる。

```{r}
MVRegressionData[,c("reputation", "quality", "pubyear")] %>% cor()
```

\index{PerformanceAnalytics Package}

 **{PerformanceAnalytics}**  パッケージ [@perfanalytics] には  `chart.Correlation`  という関数があり、これを使うと相関行列を可視化することができる。まず、 `PerformanceAnalytics` パッケージをインストールしてから、このコードを使用する必要がある。

```{r, eval = F}
library(PerformanceAnalytics)

MVRegressionData[,c("reputation", "quality", "pubyear")] %>% 
  chart.Correlation()
```

```{r, echo = F, message=F, fig.align="center", fig.width=5, fig.height=5, out.width="60%"}

library(PerformanceAnalytics)

MVRegressionData[,c("reputation", "quality", "pubyear")] %>% 
  chart.Correlation()
```

変数は確かに相関しているが、おそらくそのうちの1つを除外するほどではないだろうということがわかる。

<br></br>

#### 多重メタ回帰モデルの適合

---

\index{metafor Package}

さて、最初のメタ回帰モデルは、 **{metafor}** を使用して適合させることができる。以前は、高いジャーナルの評判がより高い効果量を予測するかどうか、またはこれが単に一流ジャーナルの研究がより高い品質を持つという事実によって引き起こされる思い込みであるかどうかを調べたいと思った。 

例えば、先行研究から研究の質が効果量を予測することがよく分かっていると仮定しよう。この場合、階層的回帰を実行することは理にかなっている。まず、既知の予測因子である「品質」を含め、次に「評判」がそれ以上の異質性を説明するかどうかをチェックする。これが正しい場合、一流雑誌の研究がより高い品質を持つ傾向があるという事実を**制御**しても、雑誌の評判は実際に高い効果と関連していると言うことができる。

そのために、 **{metafor}** の `rma` 関数を使用する。この関数はランダム効果メタ分析を実行し、モデレータが追加されると混合効果メタ回帰モデルへと拡張される。`rma` 関数は無数の引数を取ることができ、 _R_ コンソールで `?rma` を実行すると、その引数を調べることができる。しかし、通常はそのうちのいくつかを指定するだけでよい。

* 各研究の効果量が格納されているデータフレームの列。

* 各研究の効果量の標準誤差が格納されているデータフレームの列。

* **`data`**. メタ分析データを格納したデータフレーム名。

* **`method`**. 使用したい $\tau^2$  推定量。この引数に使用できるコードは、  **{meta}**  のものと同じである（例:  `"REML"` restricted maximum likelihood の略）。`"ML"`を使用することが推奨される。これは、後で異なるメタ回帰モデルを比較することができるからである。

* このパラメータは、メタ回帰モデルを定義する。まず、モデルを `~` (チルダ) で指定する。次に、含める予測変数を `+` で区切って追加する（例： `variable1 + variable2`  ）。2 つの変数の間の相互作用は、アスタリスクで表す（例： `variable1 * variable2`  ）。

* **`test`**. 回帰係数に適用したい検定である。デフォルトの `"z"` または `"knha"` (Knapp-Hartung method) から選択できる。

まず、予測因子として `quality` だけを用いてメタ回帰を実行してみよう。その結果を  `m.qual`  というオブジェクトに保存して、出力を調べてみる。

```{r, eval=F}
m.qual <- rma(yi = yi,
              sei = sei,
              data = MVRegressionData,
              method = "ML",
              mods = ~ quality,
              test = "knha")

m.qual
```

```
## Mixed-Effects Model (k = 36; tau^2 estimator: ML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.066 (SE = 0.023)
## tau (square root of estimated tau^2 value):             0.2583
## I^2 (residual heterogeneity / unaccounted variability): 60.04%
## H^2 (unaccounted variability / sampling variability):   2.50
## R^2 (amount of heterogeneity accounted for):            7.37%
## 
## Test for Residual Heterogeneity:
## QE(df = 34) = 88.6130, p-val < .0001
## 
## Test of Moderators (coefficient 2):
## F(df1 = 1, df2 = 34) = 3.5330, p-val = 0.0688
## 
## Model Results:
## 
##          estimate      se    tval    pval    ci.lb   ci.ub 
## intrcpt    0.3429  0.1354  2.5318  0.0161   0.0677  0.6181  * 
## quality    0.0356  0.0189  1.8796  0.0688  -0.0029  0.0740  . 
## 
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```


この出力では、予測変数  `quality`  の結果を  `Model Results`  の下で確認できる。トレンド・レベルでは有意であるが ($p<$  0.1)、回帰の重みは有意ではない ($p=$  0.069)。合計で、このモデルは異質性の $R^2_*=$ 7.37% を説明する。 

では、`reputation` を予測変数に含めるとどうなるか見てみよう。`mods` の入力に `+ reputation` を追加し、今回は出力を `m.qual.rep` として保存する。

```{r, eval=F}
m.qual.rep <- rma(yi = yi, 
                  sei = sei, 
                  data = MVRegressionData, 
                  method = "ML", 
                  mods = ~ quality + reputation, 
                  test = "knha")

m.qual.rep
```

```
## Mixed-Effects Model (k = 36; tau^2 estimator: ML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0.0238 (SE = 0.01)
## tau (square root of estimated tau^2 value):             0.1543
## I^2 (residual heterogeneity / unaccounted variability): 34.62%
## H^2 (unaccounted variability / sampling variability):   1.53
## R^2 (amount of heterogeneity accounted for):            66.95%
## 
## Test for Residual Heterogeneity:
## QE(df = 33) = 58.3042, p-val = 0.0042
## 
## Test of Moderators (coefficients 2:3):
## F(df1 = 2, df2 = 33) = 12.2476, p-val = 0.0001
## 
## Model Results:
## 
##             estimate      se    tval    pval    ci.lb   ci.ub 
## intrcpt       0.5005  0.1090  4.5927  <.0001   0.2788  0.7222  *** 
## quality       0.0110  0.0151  0.7312  0.4698  -0.0197  0.0417      
## reputation    0.0343  0.0075  4.5435  <.0001   0.0189  0.0496  *** 
## 
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

モデル結果のセクションに新しい行が表示され、予測変数 `reputation` の結果が表示されていることがわかる。モデルは、回帰の重みを 0.034 と推定し、これは非常に有意である ($p$  &lt; 0.001)。 

また、メタ回帰モデルは、全体としてかなりの量の異質性を説明していることがわかる。正確には、$R^2_*$  = 66.95% である。これは、研究の質でコントロールした場合でも、ジャーナルの評判がより高い効果量と関連していることを意味する。

\index{Analysis of Variance}
\index{Maximum Likelihood}
\index{Restricted Maximum Likelihood Estimator}\index{制限付き最尤推定}

しかし、2番目のモデルは本当に最初のモデルよりも適合度が高いのだろうか？これを評価するために、 `anova` 関数を使用し、比較したい2つのモデルを指定することができる。これは、制限付き最尤法（`"REML"`）の代わりに最尤法（`"ML"`）を用いて両方の混合効果モデルを適合させたからこそ可能なことであることに注意しておこう。


```{r, eval=F}
anova(m.qual, m.qual.rep)
```

```
##         df   AIC   BIC  AICc logLik   LRT   pval    QE tau^2    R^2 
## Full     4 19.86 26.19 21.15  -5.93              58.30  0.03          
## Reduced  3 36.98 41.73 37.73 -15.49 19.11 <.0001 88.61  0.06 48.32% 
```


この関数はモデルのテストを行い、`m.qual.rep` が `m.qual` よりも適合度が高いかどうかを評価するためのいくつかの統計情報を提供する。ここでは、`quality` と `reputation` の両方を含むフルモデルである `m.qual.rep` と、`quality` のみを含む縮小モデルとを比較する。

\index{Likelihood Ratio Test}

`anova` 関数は **尤度比検定**を実行し、その結果は `LRT` 列で見ることができる。この検定は非常に有意であり ($\chi^2_1=$  19.11, $p<$  0.001) 、フルモデルが本当に良い適合を提供することを意味する。 

\index{Akaike's Information Criterion}

もう1つの重要な統計量は  `AICc` 列で報告されていて、小さなサンプルで補正された赤池情報量規準（AIC）を提供する。前に述べたように、AICc は、過適合を避けるために、より多くの予測変数がある複雑なモデルにペナルティを課す。 

AIC の値が低いと、モデルの性能が良いということに注意を払うことが重要である。この出力では、より多くのパラメータがあるにもかかわらず、フルモデル (AICc = 21.15) が削減モデル (AICc = 37.73) よりも良いAIC値を持っていることがわかる。これらのことは、重回帰モデルが実際に私たちのデータに対して良い適合を提供することを示唆している。


<br></br>

#### モデリング交互作用

---

\index{Interaction (Regression)}

追加予測変数 `pubyear` (出版年) と `continent` との交互作用をモデル化したいとする。出版年と効果量の関係がヨーロッパと北米の研究で異なると仮定する。この仮定を `rma` 関数でモデル化するために、`mods` パラメータで予測変数を `*` と接続する必要がある。`anova` 関数を用いて直接モデルを比較したくないので、今回は `"REML"` (restricted maximum likelihood) $\tau^2$  予測因子を使用する。 

解釈を容易にするために、モデルを実行する前に `MVRegressionData` で `continent` 変数に因子ラベルを追加する。 

```{r, eval=F}
# 因子ラベルを 'continent' に追加
# 0 = Europe
# 1 = North America
levels(MVRegressionData$continent) = c("Europe", "North America")

# メタ回帰モデルを適合
m.qual.rep.int <- rma(yi = yi, 
                      sei = sei, 
                      data = MVRegressionData, 
                      method = "REML", 
                      mods = ~ pubyear * continent, 
                      test = "knha")

m.qual.rep.int
```

```
## Mixed-Effects Model (k = 36; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of residual heterogeneity):     0 (SE = 0.01)
## tau (square root of estimated tau^2 value):             0
## I^2 (residual heterogeneity / unaccounted variability): 0.00%
## H^2 (unaccounted variability / sampling variability):   1.00
## R^2 (amount of heterogeneity accounted for):            100.00%
## 
## Test for Residual Heterogeneity:
## QE(df = 32) = 24.8408, p-val = 0.8124
## 
## Test of Moderators (coefficients 2:4):
## F(df1 = 3, df2 = 32) = 28.7778, p-val < .0001
## 
## Model Results:
## 
##                       estimate    se  tval    pval  ci.lb ci.ub 
## intrcpt                    0.38  0.04  9.24  <.0001   0.30  0.47  *** 
## pubyear                    0.16  0.08  2.01  0.0520  -0.00  0.33    . 
## continentNorth America     0.39  0.06  6.05  <.0001   0.26  0.53  *** 
## pubyear:continent          0.63  0.12  4.97  <.0001   0.37  0.89  *** 
##    North America
## [...]
```

最後の行の `pubyear:continentNorth America` には、相互作用項の係数が格納されている。 **{metafor}** は、自動的に相互作用項だけでなく、「通常の」低次予測変数として `pubyear` と  `continent` の両方を含むことに注意しておこう（むしろ、注意すべき）。 

また、`continent` は因子であるため、`rma` はこれがダミーコード化された予測因子であることを検出し、北米のカテゴリーと比較するために、カテゴリー「ヨーロッパ」を $D_g$  = 0 の基準として使用したことに留意してみよう。この交互作用項は正の係数 (0.63) を持ち、非常に有意であることがわかる ($p<$  0.001)。 

これは、近年、効果量が増加していること、また、北米で行われた研究でより強くなっていることを示している。また、私たちがあてはめたモデルは、$R^2_*$  =100% の異質性を説明していることがわかる。 

なぜこうなったかというと、このデータが説明のためにシミュレーションされたためである。実際には、データの異質性をすべて説明することはほとんどない。むしろ、現実のデータでこのような結果を見つけたら、モデルを過剰に適合させたことになるかもしれないので、心配する必要がある。


<br></br>

#### 並び替え検定

---

\index{Permutation}

**並び替え** (pPermutation) とは、数値や物体を含む集合を取り出し、その集合から繰り返し要素を取り出して順番に並べる数学的な操作である。すでに順序のある数値の集合がある場合、これはデータの順序を並べ替える、つまり**シャッフル**する処理と同じである。 

例として、3つの数を含む集合 $S$  があるとする。 $S=\{1,2,3 \}$  この集合の可能な並べ換えの1つは $(2,1,3)$ 、別の並べ替えでは $(3,2,1)$ となる。並べ替えの結果は、両方とも前の3つの数字を含んでいるが、順番が違うことがわかる。

並び替えは**並び替え検定**にも使われるが、リサンプリング法の特別な種類である。大まかに言うと、リサンプリング法は、同じソースまたは生成プロセスからサンプルされた（少し）異なるデータを与えることによって、統計モデルの頑健性を検証するために使用される [@good2013permutation, chap. 3.1]。これは、モデルの係数が本当にデータの根底にある真のパターンを捉えているかどうか、あるいは、モデルを過適合させ、それによって、実際には統計的ノイズであるのに、データのパターンを誤って仮定していないかどうかをより良く評価する方法である。

並び替え検定は、メタ回帰が未知の効果量を予測する際にどのように実行されるかを評価できる予備の「テスト」データセットを持っている必要はない。このため、特に、並べ替え検定は、メタ回帰モデルの頑健性を評価するために推奨されている [@higgins2004controlling]。

メタ回帰モデルで並べ替え検定をどのように実行するかの詳細については、ここではあまり触れない。最も重要な部分は、元のデータ集合のすべての可能な並べ替え、またはランダムに選ばれた多くの並べ替えで得られた検定統計量に基づいて、私たちのモデルの $p$-値を再計算することである。 

ここで重要な指標は、並べ替えデータから得られる検定統計量が、元の検定統計量と**等しいか大きいか**、また**その頻度**である。例えば、並べ替えデータ1000個のうち50個で、検定統計量が元の検定統計量より大きいか等しいとすると、$p$ = 0.05となる。

メタ回帰モデルに対して並べ替え検定を行うには、**{metafor}** に内蔵されている `permutest` という関数を使用する。例として、以前適合した `m.qual.rep` モデルの結果を再計算してみよう。`permutest` 関数は `rma` オブジェクトと一緒に提供するだけである。並べ替え検定は、特に大きなデータセットの場合、計算量が多く実行に時間がかかる。

```{r, eval=F}
permutest(m.qual.rep)
```

```
## Test of Moderators (coefficients 2:3):
## F(df1 = 2, df2 = 33) = 12.7844, p-val* = 0.0010
## 
## Model Results:
## 
##             estimate      se    tval   pval*    ci.lb   ci.ub 
## intrcpt       0.4964  0.1096  4.5316  0.2240   0.2736  0.7193      
## quality       0.0130  0.0152  0.8531  0.3640  -0.0179  0.0438      
## reputation    0.0350  0.0076  4.5964  0.0010   0.0195  0.0505  *** 
## 
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```


すべての予測変数の結果を含むおなじみの出力が再び表示される。`pval*` 列を見ると、評判予測変数の $p$-値が $p$ &lt; 0.001から $p_*$  = 0.001 に減少していることがわかる。しかし、これはまだ非常に有意であり、予測変数の効果が頑健であることを示している。 

メタ回帰モデルの結果を報告する前に、必ずこの並べ換え検定を用いることが推奨されている [@higgins2004controlling]。

```{block, type='boximportant'}
**データが小さい場合の Permutation 検定**

\vspace{4mm}

モデルに含まれる研究数 $K$ が少ない場合、従来から使われている統計的有意性の閾値（つまり$p$ < 0.05）に到達できないことに注意。

メタ回帰モデルの場合、`permutest` を用いた並べ替え検定は、$K$ > 4 の場合のみ統計的有意に達することができる [@viechtbauer2015comparison] 。

```


<br></br>

#### マルチモデル推論  {#multimodel-inference}

---

\index{Multi-Model Inference}

私たちはすでに、**マルチ・モデル推論**と呼ばれる方法で、予測変数の全ての可能な組み合わせをモデル化することができることを述べた。これは、どの予測変数の組み合わせが最良の適合を提供するか、そして、どの予測変数が全体として最も重要であるかを調査することができる。マルチモデル推論を行うには、 `multimodel.inference` 関数を使用する^[このトピックに関する詳細な情報は、Wolfgang Viechtbauer が **{metafor}** ドキュメントの一部として書いている [vignette](https://www.metafor-project.org/doku.php/tips:model_selection_with_glmulti_and_mumin) は、情報が多いので参照されたい。]。

```{block, type='boxdmetar'}
**"multimodel.inference" 関数**

\vspace{4mm}

`multimodel.inference` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

\vspace{2mm}

1. 関数のソースコードにアクセスする [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R). 
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。
3. **{metafor}**, **{ggplot2}**, **{MuMIn}** パッケージがインストールされ、ロードされていることを確認する。

```


この関数では、以下のパラメータを指定する必要がある。

* **`TE`**. 各研究の効果量。データセットの効果量列の名前を引用符で囲んで指定する必要がある（例： `TE = "effectize"`）。

* **`seTE`**. 効果量の標準誤差。データセットの標準誤差列の名前を指定する必要があい（引用符で囲んで、例えば  `seTE = "se"`）。

* **`data`**. 効果量、標準誤差、メタ回帰予測変数が含まれるデータフレーム。

* **`predictors`**. マルチモデル推論に使用する予測因子を指定する文字の連結配列。予測因子の名前は、`data` に与えられたデータフレームの列名と同じでなければならない。

* **`method`**. 効果量のプーリングに使用するメタ分析モデル。固定効果モデルには `"FE"` が用いられる。`"DL"`, `"SJ"`, `"ML"`, `"REML"` など、複数のランダム効果モデルが利用可能である。`"FE"` を使用する場合、Knapp-Hartung 法は固定効果モデルで使用することを意図していないため、`test` 引数は自動的に `"z"` に設定される。デフォルトは `"REML"` である。

* **`test`**. 検定統計量と信頼区間を計算する際に利用する手法。デフォルトは  `"knha"`  で、Knapp-Hartung 調整を利用する。コンベンショナルな Wald タイプの検定は、この引数を `"z"` に設定することで計算される。 

* **`eval.criterion`**. 適合したモデルに適用する評価基準。`"AICc"` (デフォルト、 スモールサンプル補正した赤池情報量規準)、 `"AIC"` (赤池情報量規準)、または `"BIC"` (ベイズ情報量規準) のいずれかを指定することが可能である。

* **`interaction`**.	`FALSE` （デフォルト）に設定すると、予測変数間の交互作用は考慮されていない。このパラメータを `TRUE` に設定すると、すべての交互作用がモデル化される。

では、データセット  `MVRegressionData`  のすべての予測変数を使って、交互作用**なしで** マルチモデル推論を実行してみよう。`multimodel.inference` 関数を実行すると、特に予測変数の数が多い場合、時間がかかることに注意しておこう。

```{r, eval=F}
multimodel.inference(TE = "yi", 
                     seTE = "sei",
                     data = MVRegressionData,
                     predictors = c("pubyear", "quality", 
                                    "reputation", "continent"),
                     interaction = FALSE)
```

```
## Multimodel Inference: Final Results
## --------------------------
##  - Number of fitted models: 16
##  - Full formula: ~ pubyear + quality + reputation + continent
##  - Coefficient significance test: knha
##  - Interactions modeled: no
##  - Evaluation criterion: AICc 
## 
## 
## Best 5 Models
## --------------------------
## [...]
##    (Intrc) cntnn  pubyr   qulty   rpttn df logLik AICc delta weight
## 12       +     + 0.3533         0.02160  5  2.981  6.0  0.00  0.536
## 16       +     + 0.4028 0.02210 0.01754  6  4.071  6.8  0.72  0.375
## 8        +     + 0.4948 0.03574          5  0.646 10.7  4.67  0.052
## 11       +       0.2957         0.02725  4 -1.750 12.8  6.75  0.018
## 15       +       0.3547 0.02666 0.02296  5 -0.395 12.8  6.75  0.018
## Models ranked by AICc(x) 
## 
## 
## Multimodel Inference Coefficients
## --------------------------
##                          Estimate  Std. Error   z value  Pr(>|z|)
## intrcpt                0.38614661 0.106983583 3.6094006 0.0003069
## continentNorth America 0.24743836 0.083113174 2.9771256 0.0029096
## pubyear                0.37816796 0.083045572 4.5537402 0.0000053
## reputation             0.01899347 0.007420427 2.5596198 0.0104787
## quality                0.01060060 0.014321158 0.7402055 0.4591753
## 
## 
## Predictor Importance
## --------------------------
##        model importance
## 1    pubyear  0.9988339
## 2  continent  0.9621839
## 3 reputation  0.9428750
## 4    quality  0.4432826
```

$$~$$


```{r, echo=F, fig.height=2, fig.width=6, out.width="70%", fig.align="center"}
load("data/mmi.rda")
mmi$predictor.importance.plot + geom_hline(aes(yintercept = 0.8), size = 2, color = "black")
```

\index{Akaike's Information Criterion}

見どころ満載なので、順を追って出力を見ていこう。

* **`Multimodel Inference: Final Results`**. この部分は、適合したモデルについての詳細な情報を提供する。 $2^4 = 16$  可能なモデルの総数が適合したことがわかる。また、この関数はモデルの比較に補正済みAIC (`aicc`) を使用していることがわかる。

* **`Best 5 Models` **. ここに表示されているのは、AICc が最も低い5つのモデルで、低いものから高いものへとソートされている。予測変数は表の列に、モデルは行に表示される。数字（重み）または  `+`  記号（カテゴリ予測変数の場合）は、予測変数/相互作用項がモデルで用いられたことを示し、空のセルは、予測変数が省略されたことを示す。私たちは、 `TE ~ 1 + continent + pubyear + reputation` が最良の適合を示すことがわかる（AICc = 6.0）。しかし、他の予測変数の組み合わせは、この値に非常に近い。したがって、どのモデルが本当に「ベスト」モデルであるかを言うのは難しい。しかし、上位5つのモデルはすべて予測変数  `pubyear`  を含んでおり、この変数が特に重要である可能性を示唆している。

* **`Multimodel Inference Coefficients`**. ここでは、すべての予測変数の係数を、それらが出現するすべてのモデルにわたって集約して見ることができる。係数推定値は、  `pubyear`  ( $\hat\beta$  = 0.378)で最も大きく、これは以前の発見を裏付ける。近似信頼区間は、`Std.Error` に格納された値に 1.96 を掛けたものを、`Estimate` と引き算したり足したりすることで得ることができる。

* **モデル平均予測変数の重要度プロット**. このプロットでは、すべてのモデルで各予測変数の平均された重要度が表示される。再び、`pubyear` が最も重要な予測変数であることがわかる。次に、`reputation`、`continent`、`quality` が続く。

```{block, type='boxinfo'}
**マルチモデル推論の限界**

\vspace{2mm}

この例から、マルチモデル推論が、効果量の違いを予測するためにどの予測変数が重要であるかを包括的に把握するのに有効な方法であることが明らかになるはずである。

\vspace{4mm}

ステップ・ワイズ回帰法の問題のいくつかを回避しているとはいえ、この方法はまだ**探索的**と見なされるべきで、予測変数が分析する研究分野の効果量とどのように関連しているかについて予備知識がない場合に使用することができることに注意してください。

マルチモデル推論の結果に基づいてメタ回帰モデルを構築することにした場合、これを報告することが極めて重要です。なぜなら、そのようなモデルは **a priori** な仮説に基づくものではなく、このサンプルにおける統計的特性に基づいて構築されたものだからです。

```

$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block, type='boxinfo'}
**知識を試そう！**

\vspace{4mm}

1. 一次研究で用いられる従来の回帰分析と、メタ回帰の違いは何か？

\vspace{-2mm}

2. サブグループ解析とメタ回帰は密接な関係がある。メタ回帰の公式をどのようにサブグループデータに適応させることができるか。

\vspace{-2mm}

3. メタ回帰において、個々の研究に異なる重みを与えるためにどのような方法が用いられるか？

\vspace{-2mm}

4. データによく適合するメタ回帰モデルにはどのような特徴があるか？これを調べるには、どのような指標を用いればよいか？

\vspace{-2mm}

5. メタ分析の手法でサブグループ分析を計算する場合、$\tau^2$  の値をサブグループで別々にするか、共通にするか。

\vspace{-2mm}

6. （多重）メタ回帰の限界と落とし穴は何か。

\vspace{-2mm}

7. （複数の）メタ回帰モデルの頑健性を向上させるために利用できる方法を2つ挙げ、それが有用である理由を述べよ。


\vspace{4mm}


**問題の解答は、本書の巻末 [Appendix A](#qanda8) にある。**

```

<br></br>

## 要約

* メタ回帰では、従来の回帰手法を研究レベルのデータに適応させる。サブグループ分析は、カテゴリカル予測因子と共通の推定値 $\tau^2$ を持つメタ回帰の特別なケースと見なすことができる。

* メタ回帰モデルの目的は、データにおける真の効果量の違い（すなわち、研究間異質性分散 $\tau^2$ ）を**説明**することである。モデルがデータによく合っている場合、回帰直線からの真の効果の偏差は、プール効果からの最初の偏差よりも小さくなるはずである。この場合、説明できない異質性、つまり残差は小さくなる。これは、$R^2_*$ 指数によって捕捉され、モデルによって説明される異質性の変動のパーセンテージを知らせる。

*  **多重メタ回帰**では、2つ以上の予測変数が同じメタ回帰モデルで使用される。また、相互作用項を導入することで、ある変数の予測値が他の変数の異なる値に対して変化するかどうかを検定することも可能である。

* 多重メタ回帰は非常に汎用性の高い手法であるが、限界がある。多重メタ回帰は、真の関係ではなくランダムなノイズがモデル化されることを意味する、**オーバーフィット**モデルを非常に容易にする。予測変数の多重共線性は、私たちのモデルの妥当性に脅威を与えるだろう。

* メタ回帰モデルが頑健であることを保証するために、いくつかのアプローチがある。例えば、**定義された**理論的根拠に基づいてのみモデルを適合させたり、並べ替え検定を使用したりすることができる。マルチモデル推論は、探索的アプローチとして使用することができる。この方法は、潜在的に重要な予測因子を指摘することができ、将来の研究で検証すべき仮説を導き出すために使用することができる。 





<!--chapter:end:10-metareg-ja.Rmd-->

# 出版バイアス  {#pub-bias}

---

<img src="_figs/pub_bias.jpg" />

<br></br>

<span class="firstcharacter">前</span>
章を振り返ってみると、すでにメタ分析の幅広い技術をカバーしていることがわかる。効果量をプールする方法を学んだだけでなく、発見の頑健性を評価する方法、異質性のパターンを検査する方法、効果に差がある理由についての仮説を検証する方法についても学んだ。

これらのアプローチはすべて、メタ分析から有効な結論を引き出すのに役立つ。しかし、これはデータの性質に関するある暗黙の前提の上に成り立っているが、まだそれに挑戦していない。すなわち、メタ分析を行う際、収集したデータが**包括的**であること、あるいは少なくとも調査中の研究分野を**代表**するものであることを前提としている。 

Chapter \@ref(study-search)  で、メタ分析は通常、研究分野を適切に説明する単一の効果量を導き出すために、利用可能な**すべての**エビデンスを含めようとすることを述べた。統計学的な観点からは、研究がいくつか欠けていても許容できるだろうが、それはこれらの研究が偶然に「省かれた」場合のみである。

残念ながら、多くの場合、メタ分析では既存のエビデンスをすべて網羅することはできない。さらに悪いことに、いくつかの研究は、収集したデータから完全に「ランダムに」して欠落しているわけではないと考えられる理由も十分にある。この世界は不完全であり、科学的実践を支配するインセンティブや「ルール」もまた不完全である。つまり、ある研究がメタ分析に含まれるかどうかを決定するシステム的なバイアスが存在するのである。

この問題の良い例が、あまり知られていない薬物療法研究の逸話にある。1990年代には、抗うつ薬（**選択的セロトニン再取り込み阻害薬**、SSRIなど）がうつ病患者に有効であることは周知の事実と考えられていた。エビデンスの多くは、抗うつ薬とプラセボを比較した薬物療法の臨床試験のメタ分析によって得られている。抗うつ薬の市場は何十億ドルもの価値があり、着実に成長していることを考えると、抗うつ薬の効果に関する疑問は重要なものである。 

このことは、Irving Kirsch ら [-@kirsch2002emperor] が書いた「**The Emperor's New Drugs**」という論文が引き起こした論争を理解するのに役立つだろう。この論争では、結局、物事はそれほど明るくないのではないかと論じた。

Kirsch らは、「情報公開法」を利用して、製薬会社が米国食品医薬品局に提供していた未発表の抗うつ剤試験データを入手した。そして、この未発表のデータも考慮すると、プラセボと比較した抗うつ薬の効果はせいぜいわずかであり、臨床的には無視しうるものであることを発見した。Kirsch らは、企業が好ましい知見を持つ研究のみを発表し、「期待はずれ」のエビデンスを持つ研究は非公開にしたためだと主張した [@kirschemperorbook]。

\index{Publication Bias}\index{出版バイアス}

その後、論争が起こり、Kirsch の主張は今日に至るまで論争の的となっている。この例を選んだのは、どちらかを選ぶためではなく、欠落した研究がメタ分析の推論の妥当性にもたらす潜在的な脅威を説明するためである。メタ分析の文献では、このような問題は通常、**出版バイアス** (publication bias) という用語で要約されている。 

\index{File Drawer Problem}

出版バイアスの問題は、メタ分析におけるすべての知見が、その根拠となるデータと同程度のものでしかないことを明確に示している。メタ分析の技術は、手元にあるデータでしか機能しない。したがって、収集したデータに歪みがあると、どんなに優れた統計モデルでも固有のバイアスを再現してしまうだけなのである。この基本的な注意点については、本書の一番最初に「ファイルの引き出し」問題（Chapter \@ref(pitfalls)）を取り上げたときに、すでに取り上げていたことを思い出すだろう。実際、「ファイルの引き出し問題」と「出版バイアス」という言葉は、しばしば同義的に使われる。

出版バイアスや関連する問題がメタ分析の結果に及ぼす影響は甚大である。治療の効果を過大評価したり、否定的な副作用を見落としたり、実際には無効である理論の信奉を強めたりする原因となり得るのである。 

そこで本章では、出版バイアスが知見を歪めてしまう様々な形について議論した。また、メタ分析担当者として、データにおける出版バイアスのリスクを調査するために使用できるいくつかのアプローチ、およびそもそも出版バイアスをどのように軽減できるかを見ていこう。

<br></br>

## 出版バイアスとは何か？  {#types-of-pub-biases}

---

ある研究が出版される確率がその結果に影響される場合、出版バイアスが存在する [@duval2005publication, chapters 2 and 5]。研究結果が統計的に有意である場合、あるいは初期仮説を確認する場合、その研究が世に出る可能性が高いというエビデンスが広く存在する [@schmucker2014extent; @scherer2018full; @chan2014increasing; @dechartres2018association]。 

適格な研究を検索する場合、通常、何らかの形で公表されているエビデンス、例えば、査読付き論文、プレプリント、書籍、その他のアクセス可能な報告書などに制約されることになる。出版バイアスがある場合、これはデータセットに含まれていない研究があることを意味するだけでなく、含まれていない研究に好ましくない知見を持つものである可能性が高いということを意味している。 

メタ分析の手法を用いれば、母集団における平均的な効果量の偏りのない推定値を求めることが可能である。しかし、サンプルそのものが歪んでいれば、統計学的に「正しい」効果推定値であっても、現実を代表するものではない。これは、氷山の大きさを推し量るのに、その先端しか測っていないようなもので、たとえ水面からの高さを完璧に測ることができたとしても、その結果は必然的に間違っているのである。

\index{Reporting Bias}\index{報告バイアス}
\index{Citation Bias}
\index{Time-Lag Bias}
\index{Multiple Publication Bias}
\index{Language Bias}
\index{Outcome Reporting Bias}

出版バイアスは、実は多くの**報告バイアス**のうちの1つに過ぎない。メタ分析 [@page2020investigating] で得られるエビデンスを歪める要因も、他にもいくつかある。

* **引用バイアス** (Citation bias): たとえ出版されたとしても、否定的な結果や結論の出ていない研究は、関連する文献に引用される可能性が低くなる。そのため、例えば参考文献検索などで発見することが難しくなる。

* **タイムラグバイアス** (Time-lag bias): 肯定的な結果を得た研究は、好ましくない結果を得た研究よりも早く発表されることが多い。つまり、最近行われた研究で肯定的な結果を得たものはすでに入手可能であることが多いが、有意でない結果を得たものはそうでないことが多い。

* **多重投稿バイアス** (Multiple publication bias): 「成功した」研究の結果は、複数の論文で報告される可能性が高く、そのうちの少なくとも1つを見つけることが容易になる。複数の論文にまたがって研究結果を報告するやり方は、「サラミスライス」とも呼ばれる。

* **言語バイアス** (Language bias): ほとんどの分野で、エビデンスが発表される主な言語は英語である。他の言語による出版物は、特に研究者自身が翻訳しなければ内容を理解できない場合、発見されにくい。英語の研究が他の言語で発表されたものと系統的に異なる場合、これもまたバイアスを引き起こす可能性がある。

* **アウトカムバイアス** (Outcome reporting bias): 多くの研究、特に臨床試験では、関心のあるアウトカムを複数測定する。これを悪用して、肯定的な結果が得られたアウトカムだけを報告し、仮説を確認できなかったアウトカムは削除する研究者もいる。これもバイアスにつながる。厳密に言えば、研究は発表されているのに、その（好ましくない）結果は報告されていないため、メタ分析ではまだ見落とされていることになる。

\index{Questionable Research Practice (QRP)}

非報告バイアスは、既存のエビデンスを見つけにくくするシステム的な要因として捉えることができる。しかし、たとえ関連する知見をすべて含めることができたとしても、この結果には欠陥があるだろう。また、研究者が知見を分析・報告する際に適用した**疑問のある研究手法** (questionable research practices, QRP) により、バイアスが存在する可能性もある [@simonsohn2020specification]。 


\index{P-Hacking}

「研究者の自由度」という概念については、以前すでに触れた（Chapter \@ref(pitfalls)）。QRP は、研究者がこの自由度を乱用して、結果を望ましい方向に「曲げる」行為と定義することができる。残念ながら、何が QRP を構成するのかについて明確なコンセンサスはない。しかし、一般的に提案されているいくつかの例がある。 

最も顕著な QRP のひとつが **p-hacking** で、従来の有意水準である $p<$ 0.05 に達するまで分析を微調整するものである。これには、外れ値の除去、サブグループの分析、欠損データの処理などが含まれる。 

\index{HARKing}

別の QRP は **HARKing**  [@kerr1998harking] といって、**結果が判明した後に仮説を立てること**である。HARKing の一つは、探索的分析における発見が、研究の a priori な仮説であったかのように装うことである。例えば、研究者が、データセットに対して様々なテストを実行し、有意であったすべてのテストについて仮説を「発明」することがある。これは重大な欠陥のあるアプローチで、研究の偽発見率を高め、偽の発見のリスクを増加させる（など、問題は他にもある）。もう一つのタイプの HARKing は、データによってサポートされなかったすべての仮説を取り下げることであり、これは最終的にアウトカム報告バイアスにつながる可能性がある。

<br></br>

## メタ分析における出版バイアス  {#addressing-pubbias}

---

出版バイアス、報告バイアス、QRP がメタ分析の妥当性に強く有害な影響を与えることは明らかである。バイアスの正確な大きさ、あるいはバイアスが存在するかどうかを知ることは、通常、事実上不可能であるため、これらは大きな課題となっている。 

\index{Study Search}
\index{Open Science Framework (OSF)}

メタ分析では、QRP と同様に、出版・報告バイアスによる歪みのリスクをある程度軽減する手法を適用することが可能である。そのアプローチには、研究探索に関連するものもあれば、統計的な手法もある。 

* **研究検索**: Chapter \@ref(study-search)  で、適格な研究を検索するプロセスについて説明してきた。出版バイアスが存在する場合、このステップは非常に重要である。なぜなら、出版された文献を検索しても、すべてのエビデンスを完全に代表していないデータが得られる可能性があることを意味する。学位論文、プレプリント、政府報告書、会議録などを含む**灰色文献**も検索することで、これに対抗することが可能である。幸いなことに、事前登録も多くの分野で一般的になってきている。これにより、ICTRP や **OSF Registries** などの研究登録（ Chapter \@ref(study-search)  の Table \@ref(tab:bibdatabases)  を参照）を検索して、未発表データのある研究を探し、著者に（まだ）公開されていないデータを提供してもらえるか尋ねることが可能である^[Mahmood and colleagues [-@mahood2014searching] には、包括的なグレー文献検索の方法とそれに伴う課題の詳細説明が掲載されている。この論文は、オンラインでオープンにアクセスすることができる]。灰色文献検索は退屈で嫌になるだろうが、努力する価値はある。灰色文献や未発表の文献を含めることで真の効果の過大評価を避けることができることは、大規模な研究でわかっている [@mcauley2000does]。

* **統計的手法**: 統計的手法によって出版物の有無を調べることも可能である。これらの方法はいずれも出版バイアスを直接同定することはできないが、それを示すと思われるデータのある種の特性を調べることが可能である。また、出版バイアスを補正した場合の真の全体効果を定量化するために使用できる手法もある。 

\index{Small-Study Effect}

本章では、出版バイアスを評価・制御するための一般的な**統計的**手法を紹介する。まず、**小規模研究効果**に着目した方法から始める [@sterne2000publication; @schwarzer2015meta, chapter 5; @duval2005publication, chapter 5]。このアプローチに共通するのは、研究の精度と観察された効果量の関係を見ることで、出版バイアスの指標を見つけるという点である。


<br></br>

### 小規模研究効果測定法  {#small-study-effects}

---

メタ分析における出版バイアスを評価・補正する方法として、様々な小規模研究効果法がある。その多くは、長年にわたり従来からある手法である。名前にあるように、これらの手法は特に**小規模研究**に関係している。統計学的な観点からは、これは標準誤差が大きい研究に相当する。小規模研究効果法は、小規模な研究は出版バイアスの餌食になりやすいと仮定している。 

この前提は、3つの核となる考えに基づいている [@borenstein2011introduction、第30章参照]。

\index{File Drawer Problem}

1. 大規模な研究は、多くの資源と時間を投入するため、結果が有意であろうとなかろうと、出版される可能性が高い。

2. 中程度の規模の研究は、発表されないリスクが高くなる。しかし、統計的検出力が中程度であっても、有意な結果を得るには十分であることが多い。つまり、「好ましくない」（つまり有意でない）結果を出したために、出版されない研究もあるということである。

3. 小規模な研究は、発見が有意でないリスクが最も高く、そのため「ファイルの引き出し」に入ったままとなる。小規模な研究では、非常に大きな効果だけが有意となる。つまり、非常に大きな効果量を持つ小規模な研究のみが発表されることになる。

これらの仮定の背後にあるとされるメカニズムは、非常に単純であることがわかる。本質的には、有意な効果のみが公表されるため、出版バイアスが存在するということである。サンプルサイズが大きいほど有意な結果が得られる確率が高くなるので、出版バイアスは小規模な研究であるほど均等ではない影響がある。


<br></br>

#### ファネルプロット  {#funnel-plot}

---

\index{Funnel Plot}\index{ファンネルプロット}

このガイドの前半（Chapter \@ref(what-is-es)）で、研究のサンプルサイズと標準誤差が密接に関係していることを学んだ。効果量の標準誤差が大きいと、信頼区間が広くなり、効果が統計的に有意でない可能性が高くなる。したがって、小さな研究の効果は、大きな標準誤差を持つ研究に大きく影響すると仮定するのは賢明なことである。 

収集したデータが出版バイアスによって負担されたと仮定する。この場合、大きな標準誤差を持つ研究は、低い標準誤差を持つ研究よりも効果量が大きいと仮定することが可能である。これは、効果の小さい研究は有意でなく、出版の検討すらされなかった。結果として、メタ分析に含めるられることもない。

小規模研究の効果を調べるには、**ファネルプロット**が一般的である。ファンネルプロットは、x軸に観察された効果量を、y軸に標準誤差の指標をとってプロットしたものである。通常、ファンネルプロットのy軸は反転している（y軸上の「高い」値は、標準誤差が**低い**ことを表している）。 

出版バイアスがない場合、このようなプロットのデータポイントは、ほぼ対称的な逆さファンネル（漏斗のこと）を形成するはずである。これがファンネルプロットと呼ばれる所以である。プロットの上部にある研究（標準誤差が小さいもの）は、密接に並んでおり、プール効果量からそれほど離れていないはずである。プロットの下部では、標準誤差が大きくなるにつれて、漏斗が「開き」、効果量がプール効果量の左右に大きく散らばることが予想される。 

Chapter \@ref(what-is-es)  で効果量について学んだことや、Chapter \@ref(fem)（Figure \@ref(fig:funnel1)）で固定効果モデルについて議論したことを思い出すと、なぜ研究が漏斗を形成する必要があるのかがわかりやすくなる。標準誤差は、研究の**精度**を示している：標準誤差が小さくなればなるほど、観察された効果量は、真の効果量の良い推定量になると予想される。標準誤差が大きい場合、効果量は精度が低く、したがって母集団における実際の効果から大きく外れている可能性が高くなる。

では、ファネルプロットを作成し、より具体的にしていこう。メタ分析オブジェクトのファネルプロットを表示すには、 **{meta}** パッケージの  `funnel.meta`  関数を使用することが可能である。ここでは、メタ分析オブジェクト  `m.gen`  に対してファネルプロットを生成する。さらに2つの引数、  `xlim`  と  `studlab`  を指定する。最初の引数はプロットにおけるX軸の限界をコントロールし、後者は研究ラベルを含めるようにこの関数に指示する。`funnel` を実行した後に `title` 関数を呼び出すと、プロットにタイトルが追加される。 

コードは次のようになる。

\vspace{2mm}



```{r, message=F, fig.width=8, fig.height=6, out.width="85%", collapse = TRUE, results='hold', fig.align='center', eval = F}
# 'meta' パッケージをロード
library(meta)

# ファンネルプロットを作成
funnel.meta(m.gen,
            xlim = c(-0.5, 2),
            studlab = TRUE)

# タイトルを追加
title("Funnel Plot (Third Wave Psychotherapies)")

```


```{r, message=F, fig.width=8, fig.height=6, out.width="85%", collapse = TRUE, results='hold', fig.align='center', echo=F}
# Load 'meta' package
library(meta)

par(bg="#FFFEFA")
# Produce funnel plot
funnel.meta(m.gen,
            xlim = c(-0.5, 2),
            studlab = TRUE)

# Add title
title("Funnel Plot (Third Wave Psychotherapies)")

```

すでに説明したように、得られたファネルプロットは、x軸に各研究の効果量（標準化平均差として表現）、y軸に標準誤差（大から小へ）を示している。解釈を容易にするため、このプロットには、研究が従うと思われる理想的なファネルの形も含まれている。ファンネルの真ん中の縦線は、平均効果量を示している。`m.gen` を生成する際にランダム効果モデルを使用したので、ファネルプロットもランダム効果推定値を使用している。

少人数研究の影響がなければ、プロットに表示される漏斗で描かれる形状に沿うはずである。この例では、そうなっているだろうか？そうではない。標準誤差が小さい研究ほど、推定された真の効果の周りに集中していることがわかるが、パターンは全体的に非対称に見える。これは、プロットの右下に非常に高い効果量を持つ3つの小さな研究（Shapiro、Kang、Danitz-Orsillo によるもの）があるためである。 

しかし、これらの研究には、プロットの左下隅に相当するものがない。非常に高い効果を持つ研究と「均等になる」ような、非常に低い効果量や負の効果量を持つ小規模な研究は存在しないのである。もう一つ気になるのは、サンプルの中で最も精度の高い、de Vibe による研究が、漏斗パターンにうまく従っていないように見えることである。この効果量は、予想よりもかなり小さい。

全体として、このデータセットは、出版バイアスを示しそうな非対称のパターンをファネルプロットに示している。3つの小さな研究は、運良く有意になるのに十分な効果を見出したものであり、一方、同様の標準誤差を持ちながら、小さい方、つまり有意でない効果を持つ未発表の研究が存在しても、成功には至らなかったのだろう。


非対称パターンと統計的有意性の関係を調べるには、**等高線ファンネルプロット** (contour-enhanced funnel plot) [@peters2008contour] を作成するのが良い方法である（訳注：「等高線ファンネルプロット」は、「輪郭強調ファンネルプロット」と訳されることもある。）。等高線ファンネルプロットは、出版バイアスと他の非対称性を区別するのに役立つように、プロット内の各研究の有意水準を示す色を含んでいる。`funnel.meta` 関数では、`contour` 引数に希望の有意閾値を与えることで等高線を追加することが可能である。通常は、` 0.9 `, ` 0.95 `, ` 0.99 `で、それぞれ $p$ &lt; 0.1, 0.05, 0.01 に相当する。また、 `col.contour` 引数を使用すると、輪郭の色を指定することが可能である。最後に、プロットに凡例を追加するために、 `legend` 関数を使用することができ、異なる色の意味を指定することができる。`x`  と  `y`  引数を使用してプロット上に凡例を配置し、  `legend`  でラベルを指定し、 `fill`  引数を使用して塗りつぶしの色を追加することが可能である。 

この結果、以下のようなコードになる。 

```{r, fig.width=8, fig.height=6, out.width="82%", collapse=TRUE, fig.align='center', eval=F}
# 等高線の塗りつぶし色を定義
col.contour = c("gray75", "gray85", "gray95")

# ファンネルプロットを生成 (研究ラベルはなし)
funnel.meta(m.gen, xlim = c(-0.5, 2),
            contour = c(0.9, 0.95, 0.99),
            col.contour = col.contour)

# 凡例を追加
legend(x = 1.6, y = 0.01, 
       legend = c("p < 0.1", "p < 0.05", "p < 0.01"),
       fill = col.contour)

# タイトルを追加
title("Contour-Enhanced Funnel Plot (Third Wave Psychotherapies)")

```


```{r, fig.width=8, fig.height=6, out.width="75%", collapse=TRUE, fig.align='center', echo=F}
# Define fill colors for contour
col.contour = c("gray75", "gray85", "gray95")


par(bg="#FFFEFA")
# Generate funnel plot (we do not include study labels here)
funnel.meta(m.gen, xlim = c(-0.5, 2),
            contour = c(0.9, 0.95, 0.99),
            col.contour = col.contour)

# Add a legend
legend(x = 1.6, y = 0.01, 
       legend = c("p < 0.1", "p < 0.05", "p < 0.01"),
       fill = col.contour)

# Add a title
title("Contour-Enhanced Funnel Plot (Third Wave Psychotherapies)")

```

ファネルプロットは、3つの陰影領域を含んでいることがわかる。 $p<$ 0.05 と $p<$  0.01 の領域に特に興味がある。なぜなら、この領域に入る効果量は、伝統的に有意とみなされている。 

等高線領域を追加すると、3つの小さな研究は、大きな標準誤差があるにもかかわらず、すべて有意な効果を示していることがわかる。同じような標準誤差を持つ研究で、有意でないものが1つだけある。対称性を高めるためにプロットの左下隅にある欠落した研究を「インプット」すると、これらの研究はプロットの非有意領域に位置することになる。 

大規模な研究については、少しパターンが異なるようである。 $p>$  0.05 の研究がいくつかあり、効果の分布はあまり偏っていないことがわかる。しかし問題なのは、厳密には有意ではないものの、1つの研究を除くすべての研究が有意性閾値に非常に近い（すなわち、0.1 $> p >$  0.05 の領域にある）ことである。これらの研究は、元の論文では単に効果量の計算が違っていて、それが有意な結果につながった可能性がある。あるいは、傾向レベルで有意な効果を見出すことが、すでに研究を発表するのに十分な説得力を持っていたのだろう。

まとめると、等高線ファンネルプロットによる検証では、非対称性があるのではないか、それは出版バイアスによって引き起こされたのではないかという当初の直感を裏づけるものであった。しかし、結論を急がず、ファンネルプロットを慎重に解釈することが大事である。出版バイアスは、ファネルプロットの非対称性の原因として考えられる多くの理由のうちの1つに過ぎないことを念頭に置かなければならない。

\index{Fidelity, Treatment}

```{block, type='boxinfo'}
**ファネルプロットの非対称性とは**

\vspace{2mm}

出版バイアスは非対称のファネルプロットにつながるが、同様のパターンを生み出す他の、むしろ「良性」の原因もある [@page2020investigating] 。

\vspace{2mm}

* 非対称性は、研究間の異質性によって引き起こされることもある。ファネルプロットは、効果量の分散が研究のサンプリング誤差によって引き起こされると仮定しているが、研究が異なる真の効果の推定者である可能性を制御することはできない。

\vspace{2mm}

* 小規模な研究では、研究の手順が異なり、その結果、効果が高くなった可能性がある。例えば、臨床研究では、サンプルサイズが小さいと、すべての参加者が意図したとおりに治療を受けていることを確認するのが容易である。大規模な研究ではそうではないため、**治療忠実度** (treatment fidelity) が低くなり、その結果、効果も低くなる可能性がある。このような代替説明が妥当かどうかを評価するために、対象研究の特徴を検証することは意味がある。

\vspace{2mm}

* 質の低い研究では、バイアスリスクが高いため、効果量が大きくなる傾向があることは一般的に知られている。大規模な研究はより多くの投資を必要とするため、方法論もより厳密なものになる可能性がある。よって、出版バイアスがない場合でも、ファネルプロットの非対称性につながる可能性がある。

\vspace{2mm}

* 最後に、ファネルプロットの非対称性は、単に偶然に起こる可能性も十分にある。

```


\index{Egger's Test}

（等高線）ファンネルプロットを視覚的に検証して、結果が出版バイアスの影響を受けている可能性を示すいくつかの「レッドフラッグ」が投げ出されたことを確認した。 

しかし、ファネルプロットをはっきり見ただけで解釈することにも限界がある。結果が「非対称すぎる」場合の明確なルールはなく、ファネルプロットからの推論は常に主観的である。したがって、定量的な方法でファネルプロットの非対称性の存在を評価することが有用である。これは通常、次に説明する **Egger の回帰検定**によって達成される。

<br></br>

#### Egger の回帰検定  {#eggers-test}

---

Egger の回帰検定 [@egger1997bias] は、ファネルプロットの非対称性を検定する定量的手法としてよく利用されている。ファネルプロットの目視検証と同様に、小規模研究の効果を識別するだけで、出版バイアスが存在するかどうかを直接教えてくれるわけではない。この検定は、単純な線形回帰モデルに基づいており、その式は次のようになる。

\begin{equation}
\frac{\hat\theta_k}{SE_{\hat\theta_k}} = \beta_0 + \beta_1 \frac{1}{SE_{\hat\theta_k}}
(\#eq:pub1)
\end{equation}

この式における応答変数 $y$  は、メタ分析で観測された効果量 $\hat\theta_k$  を、標準誤差で割ったものである。結果の値は、$z$ -スコアと同等である。これらのスコアは、効果量が有意であるかどうかを直接教えてくれる。 $z \geq$  1.96 または $\leq$  -1.96 のとき、その効果は有意であることがわかる ( $p<$  0.05)。この応答変数は、研究の標準誤差の逆数に回帰され、それは研究の精度に相当する。 

しかし、Egger の検定を用いる場合、回帰重み $\beta_1$ の大きさや有意性にではなく、**切片** $\beta_0$  に関心がある。ファネルの非対称性を評価するためには、$\hat\beta_0$ のサイズを検査し、それがゼロから有意に異なるかどうかを調べる。この場合、Egger の検定は、ファネルプロットの非対称性を示す。

回帰切片の大きさが、なぜファネルプロットの非対称性について何かを伝えるのかを理解するために、少し時間をとろう。すべての線形回帰モデルにおいて、切片は他のすべての予測変数がゼロのときの $y$  の値を表している。モデルの予測変数は研究の精度なので、切片は精度がゼロの時（すなわち、研究の標準誤差が無限に大きい時）に期待される $z$ -スコアを示す。 

出版バイアスがない場合、期待される $z$ -スコアはゼロ付近に散らばるはずである。これは、標準誤差が極端に大きい研究は信頼区間も極端に大きくなり、$|z| \geq$  1.96という値になることはほぼ不可能である。しかし、出版バイアスの影響などでファンネルプロットが非対称になると、効果量が非常に大きい小規模な研究がかなり多くなり、$z$ 値が 1.96 以上の値を持つ精度の低い研究が驚くほど多くなることが予想される。この歪みにより、精度がゼロの時の $y$ の予測値はゼロより大きくなり、結果として有意な切片となる。 

以下のプロットは、Egger の検定の基礎となる回帰の勾配と切片に対するファネルプロットの非対称性の影響を示している。



```{r eggers_alt, echo=F, out.width="50%", message=F, warning=F, fig.width=6, fig.height=5, eval=F}
library(ggplot2)

load("data/m.egdat.rda")
load("data/m.egdat.bias.rda")

funnel(m.egdat, xlab = "Effect Size")
title("Funnel Plot (No Asymmetry)")

m.egdat$data %>% 
  mutate(y = .TE/.seTE, x = 1/.seTE) %>% 
  ggplot(aes(y = y, x = x)) + 
  xlim(c(0, 110)) +
  #ylim(c(0, 110)) +
  geom_point(fill = "grey", pch=21) + 
  geom_smooth(method = "lm", se = F, fullrange = T, color = "black") + 
  theme_minimal() +
  ylab("Scaled Effect Size (z)") +
  xlab("Inverse Standard Error (Precision)") +
  annotate("text", x = 3, y = 33, label = bquote(hat(beta)[0]~"="~0.21), hjust = "left",
           cex = 6) +
  annotate(geom = "curve", x = 0, y = 0.21, xend = 5, yend = 30, 
           curvature = .3, arrow = arrow(length = unit(2, "mm")), linetype = "dashed") +
  ggtitle("Regression Line (No Asymmetry)") + 
  theme(plot.title = element_text(color="black", size=14, face="bold",
                                  hjust = 0.5),
        plot.margin = margin(1.08, 1, 1.08, 1, "cm"),
        plot.background = element_rect(fill = "#FFFEFA", color = "#fbfbfb"),
        panel.background = element_rect(fill = "#FFFEFA")) # 'nearly-white' used to keep knitr from cropping


meta::funnel.meta(m.egdat.bias, xlab = "Effect Size")
title("Funnel Plot (Asymmetry)")

m.egdat.bias$data %>% 
    mutate(y = .TE/.seTE, x = 1/.seTE) %>% 
    ggplot(aes(y = y, x = x)) + 
    xlim(c(0, 9)) +
    ylim(c(0,6)) +
    geom_point(fill = "grey", pch=21) + 
    geom_smooth(method = "lm", se = F, fullrange = T, color = "black") + 
    theme_minimal() +
    ylab("Scaled Effect Size (z)") +
    xlab("Inverse Standard Error (Precision)") +
    annotate("text", x = 0.8, y = 0.5, label = bquote(hat(beta)[0]~"="~2.85), hjust = "left",
             cex = 6) +
    annotate(geom = "curve", x = 0, y = 2.85, xend = 0.7, yend = 0.7, 
             curvature = .3, arrow = arrow(length = unit(2, "mm")), linetype = "dashed") +
    ggtitle("Regression Line (Asymmetry)") +
    theme(plot.title = element_text(color="black", size=14, face="bold",
                                hjust = 0.5),
      plot.margin = margin(1.08, 1, 1.08, 1, "cm"),
      plot.background = element_rect(fill = "#feffff", color = "#fbfbfb"),
      panel.background = element_rect(fill = "#feffff")) # 'nearly-white' used to keep knitr from cropping



```


```{r eggers, echo=F, out.width="50%", message=F, warning=F, fig.width=6, fig.height=5}
library(OpenImageR)
knitr::include_graphics('images/eggers-1_sep.png')
knitr::include_graphics('images/eggers-2_sep.png')
knitr::include_graphics('images/eggers-3_sep.png')
knitr::include_graphics('images/eggers-4_sep.png')
```


\index{tidyverse Package}

このような回帰モデルを `m.gen` のデータに当てはめると、どのような結果が得られるか見てみよう。 _R_  を使って、 `m.gen` の元データを取り出し、応答変数 `y`  と予測変数  `x`  を計算することが可能である。以下のコードでは、パイプ( Chapter \@ref(data-transform) )と  **{tidyverse}**  の一部である  `mutate`  関数を使用してこれを行う。その後、**l**inear **m**odel function  `lm`  を使って、$z$  のスコア  `y`  を精度  `x`  に回帰している。パイプの最後の部分では、結果の  `summary`  を要求している。

```{r, eval = F}
# パッケージをロード
library(tidyverse)

m.gen$data %>% 
  mutate(y = TE/seTE, x = 1/seTE) %>% 
  lm(y ~ x, data = .) %>% 
  summary()

```

```
## [...]
## 
## Coefficients:
##             Estimate Std. Error t value Pr(>|t|)    
## (Intercept)   4.1111     0.8790   4.677 0.000252 ***
## x            -0.3407     0.1837  -1.855 0.082140 .  
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
## 
## [...]
```

結果、この回帰モデルの切片は、$\hat\beta_0$  = 4.11であることがわかる。これはゼロより有意に大きく（ $t$  = 4.677, $p<$  0.001）、ファネルプロットのデータが実際に非対称であることを示している。全体として、これは小規模研究の効果があるという最初の発見を裏づけるものである。しかし、繰り返しになるが、このパターンが出版バイアスに起因しているかどうかは不明である。

Egger の切片検定を行うより便利な方法は、 **{meta}** にある  `metabias`  関数を使用することである。この関数はメタ分析オブジェクトを入力として必要とし、  `method.bias`  引数を  `"linreg"`  に設定する必要がある。この関数を  `m.gen`  に適用すると、以前と同じ結果が得られる。

```{r}
metabias(m.gen, method.bias = "linreg")
```

```{block2, type='boxreport'}
**Egger 検定の結果を報告**

\vspace{2mm}

Egger の検定では、通常、切片の値、その95%信頼区間、$t$ 値と $p$ 値を報告すれば十分である。**{dmetar}**パッケージでは、`eggers.test` という便利な関数が含まれている。この関数は `metabias` のラッパーであり、Eggerの検定の結果をレポートに適した形式で提供する。**{dmetar}** がインストールされていない場合は、この関数のソースコード [online](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/eggers.test.R) を参照。以下はその例である。

`eggers.test(m.gen)`

$~$            | `Intercept` | `ConfidenceInterval` | `t`        | `p`
-------------- | ----------- | -------------------- | ---------- | ---
`Egger's test` | `4.111`     | `2.347-5.875`        | `4.677`    | `0.00025`

```



\index{Standardized Mean Difference}\index{標準化平均差}

`m.gen` で使われている効果量の指標は、スモールサンプルバイアス補正 SMD (Hedges' $g$ ) である。SMD で Egger 検定を実行すると、偽陽性の結果が膨らむ可能性があると議論されている [@pustejovsky2019testing]。これは、研究の標準化平均差と標準誤差が独立していないためである。 

このことは、群間 SMD の標準誤差を計算するための式（式3.18、Chapter \@ref(b-group-smd)  ）を見れば簡単にわかる。この式は SMD そのものを含んでおり、観察された効果の値が小さくても大きくても研究の標準誤差が変化することを意味している（つまり、SMD とその標準誤差の間には人為的な相関がある）。 

Pustejovsky and Rodgers [-@pustejovsky2019testing] は、標準化平均差のファネルプロットの非対称性を検定する際に、標準誤差の修正版を使用することを提案している。標準誤差の式の最初の部分だけが使用され、観察された効果量が式から脱落することを意味している。したがって、式は次のようになる。


\begin{equation}
SE^*_{\text{SMD}_{\text{between}}}= \sqrt{\frac{n_1+n_2}{n_1n_2}}
(\#eq:pub2)
\end{equation}

ここで、$SE^*_{\text{SMD}_{\text{between}}}$  は標準誤差の修正版である。この修正版を使ったときに、Egger の検定が同じ結果を与えるかどうかを確認するのはよい考えだろう。次のコードでは、最初のデータセットに各研究の各群のサンプルサイズを追加し、適合された標準誤差を計算し、それを使って分析を再実行する。 

```{r}
# 実験群 (n1) と対照群 (n2) のサンプルサイズを追加
n1 <- c(62, 72, 44, 135, 103, 71, 69, 68, 95, 
        43, 79, 61, 62, 60, 43, 42, 64, 63)

n2 <- c(51, 78, 41, 115, 100, 79, 62, 72, 80, 
        44, 72, 67, 59, 54, 41, 51, 66, 55)

# 修正標準誤差を表示
ThirdWave$seTE_c <- sqrt((n1+n2)/(n1*n2))

# 修正標準誤差で 'metagen' を再実行し、メタ分析オブジェクトを取得
m.gen.c <- metagen(TE = TE, seTE = seTE_c,
                   studlab = Author, data = ThirdWave, sm = "SMD", 
                   fixed = FALSE, random = TRUE, 
                   method.tau = "REML", hakn = TRUE, 
                   title = "Third Wave Psychotherapies")

# Egger 検定
metabias(m.gen.c, method = "linreg")

```


正確な数値は異なるものの、結果の解釈は同じであることがわかる。このことは、以前発見したことが確からしいことを示している。


```{block2, type='boxinfo'}
**`metabias` で直接 Pustejovsky-Rodgers 法を使う**

最新の **{meta}** では、 `metabias` 関数に、Pustejovsky and Rodgers によって提案された補正標準誤差の式で Eggers の検定を行うオプションも用意されている。このオプションは `method.bias` を `"Pustejovsky"` に設定することで使用でる。

ただし、これは **{meta}** メタ分析オブジェクトが、実験グループとコントロールグループのサンプルサイズをそれぞれ `n.e` と `n.c` という要素で既に含んでいる場合にのみ可能である。`metagen` オブジェクトを使用する場合（上記の例のように）、通常はこのようなことはないため、手動で追加する必要がある。例として、再び `m.gen` メタ分析オブジェクトを使用してみよう。

`m.gen$n.e = n1; m.gen$n.c = n2`

`metabias(m.gen, method.bias = "Pustejovsky")`

なお、この設定では、`metabias` は Egger の検定を行うために式 \@ref(eq:pub5) を使用するが、これは先に示した式 \@ref(eq:pub1) と等価である。主な違いは、`metabias` がモデルの予測因子として補正標準誤差を用い、重みとして含まれる効果量の逆分散を用いる点である。

しかし、今回の例では、式 \@ref(eq:pub1) の両辺に補正された標準誤差を使用している。つまり、上記のようなアプローチと `method.bias` を `"Pustejovsky"` に設定した場合の結果は完全に一致するわけではない。

```

<br></br>

#### Peters の回帰検定  {#peters-test}

---

\index{Peter's Test}

効果量と標準誤差の依存性は、標準化された平均差にのみ適用されるわけではない。この数学的な関連性は、（対数）オッズ比（Chapter \@ref(or)）やリスク比（Chapter \@ref(rr)）などの二値アウトカムデータまたは割合（Chapter \@ref(props)）に基づく効果量にも存在する。 

二値効果量データを使用したときの偽陽性のリスクの増大を避けるために、Peters ら [@peters2006comparison] が提案した別のタイプの回帰検定を使用することが可能である。Peters の検定の結果を得るために、対数変換された効果量をサンプルサイズの逆数に回帰させる。

\begin{equation}
\log\psi_k =  \beta_0 + \beta_1\frac{1}{n_k}
(\#eq:pub3)
\end{equation}

この式において、$\log\psi_k$  は二値アウトカムデータに基づく任意の対数変換効果量（例えば、オッズ比）を表し、$n_k$ は研究 $k$  の総サンプルサイズである。

\index{Weighted Least Squares (WLS)}

重要なことは、回帰モデルを当てはめるとき、各研究 $k$  には、そのサンプルサイズとイベントカウントに応じて、異なる重み $w_k$   が付けられることである。この結果、**重み付け**線形回帰となり、メタ回帰モデル（Chapter \@ref(metareg-model-fit)）と似ている（同一ではない）。重みの式 $w_k$  は次のようなものである。

\begin{equation}
w_k = \frac{1}{\left(\dfrac{1}{a_k+c_k}+\dfrac{1}{b_k+d_k}\right)}
(\#eq:pub4)
\end{equation}

ここで、$a_k$ は治療群でのイベント数、$c_k$ は対照群でのイベント数である。 $b_k$ と $d_k$  はそれぞれ治療群と対照群での非イベントの数である（ Chapter \@ref(rr)  を参照)。Eggers の回帰検定とは対照的に、Peters の検定は、切片の代わりに $\beta_1$  を使って、ファネルプロットの非対称性を検定した。統計的検定が $\beta_1 \neq 0$  を明らかにするとき、データに非対称性が存在すると仮定することが可能である。

`metabin` （Chapter \@ref(pooling-or-rr)）または `metaprop` （Chapter \@ref(pooling-props)） 関数を用いて二値アウトカムに基づくメタ分析を計算した場合、 `metabias` 関数を用いて Peters 検定 を実施することが可能である。適合するメタ分析オブジェクトを用意し、 `method.bias` の引数に `"peters"` を指定するだけでよい。Chapter \@ref(pooling-or-rr) で作成した `m.bin` オブジェクトで、ファネルプロットの非対称性を確認してみよう。 

覚えているだろうが、このメタ分析ではリスク比を要約の指標として使った。

```{r}
metabias(m.bin, method.bias = "peters")
```

出力の構造は、Eggers の検定と同じであることがわかる。出力は、結果が  `サンプルサイズに基づく回帰検定`のものであることを示し、Peters の方法が使用されたことを意味した。検定は有意ではなく ($t$  = -0.08, $p$  = 0.94)、ファンネルプロットは非対称ではないことを示している。

```{block, type='boximportant'}
**ファネルプロット非対称性検定の統計的検出力**

\vspace{2mm}

メタ分析に十分な数の研究が含まれている場合のみ、ファネルプロットの非対称性を検定することが推奨される。研究数が少ない場合、Eggers の検定や Peters の検定の統計的検出力が、実際の非対称性を検出するのに十分でないことがある。一般に、$K \geq 10$ のときだけ検定を行うことが推奨されている [@sterne2011recommendations] 。

デフォルトでは、メタアナリシスの研究数がこれより少ないと `metabias` はエラーを出す。しかし、関数内の `k.min` 引数をより小さい数字に設定することで、これを防ぐことができる（推奨はしない）。

```


<br></br>

#### Duval & Tweedie トリム＆フィル方式  {#duval-and-tweedie}

---

\index{Trim and Fill Method}

メタ分析において、小規模研究の効果を調べる（そして検定する）方法をいくつか学んだ。データに出版バイアスが存在する可能性があることを知ることは良いことであるが、主に関心を持っているのは、そのバイアスの**大きさ**である。出版バイアスが推定値をわずかに歪めただけなのか、それとも知見の解釈を変えるほど大規模なものなのかを知りたい。

つまり、真の効果量の**バイアス補正**推定値を算出する方法が必要なのである。しかし、出版バイアスを直接測定することができないことをすでに学んだ。出版バイアスを**指摘**する可能性のある代理として、小規模研究の効果を使うことしかできない。 

したがって、出版バイアス**そのもの**ではなく、補正された効果推定値を得るために小規模研究の影響を補正することができるだけである。効果量の非対称性が実際に出版バイアスによって引き起こされた場合、この不均衡を補正することで、**すべての**エビデンスを考慮したときに真の効果をよりよく表す推定値が得られる。

ファネルプロットの非対称性を調整する最も一般的な方法の1つが、**Duval &amp; Tweedie トリム＆フィル法** [@duval2000trim] である。この方法の背後にある考え方は単純で、ファネルプロットが対称になるまで「欠損」効果を埋め込むというものである。そして、得られた「拡張」データセットのプール効果量は、小規模研究の効果を補正する際の推定値を表した。これは、効果の「トリム」 (trim) と「フィル」 (fill) を含む簡単なアルゴリズムによって達成される [@schwarzer2015meta、5.3.1章]。

* **トリム**. まず、このメソッドはファネルプロット内のすべての外れ値研究を識別する。先ほどの例では、これらはプロットの右側に散在しているすべての小規模な研究である。いったん識別されると、これらの研究は **トリム**、つまり分析から取り除かれ、プールされた効果は、これを除いて再計算される。このステップは、通常、固定効果モデルを使用して実行される。

* **フィル**. 次のステップでは、再計算されたプール効果が、すべての効果量の中心と仮定される。トリムされた各研究について、漏斗の反対側でその結果を反映するように、1つの効果量が追加される。たとえば、再計算された平均効果が0.5で、トリムされた研究の効果が0.8であれば、ミラーされた研究は0.2の効果を与えられる。これをすべてのトリムされた研究で行うと、ファネルプロットはほぼ対称的に見える。トリムされた効果量と帰属された効果量を含むすべてのデータに基づいて、平均効果量が再計算される（通常、ランダム効果モデルを使用する）。その結果は、補正されたプール効果量の推定値として使用される。

トリム＆フィル法に関する重要な注意点は、研究間の異質性が大きい場合、信頼できる結果が得られないことである [@peters2007performance; @terrin2003adjusting; @simonsohn2014p]。研究が1つの真の効果を共有していない場合、大規模な研究でも平均的な効果から大きく乖離している可能性がある。つまり、出版バイアスの影響を受けている可能性が低いにもかかわらず、そのような研究もトリムされて埋められることになる。これでは、無効な結果になることは容易に想像がつく。 

**{meta}** にある  `trimfill`  関数を使用するとトリム＆フィルアルゴリズムをデータに適用することが可能である。この関数は非常にわかりやすいデフォルト値を持っているので、メタ分析オブジェクトと一緒に提供するだけで十分である。この例では、再び `m.gen`  オブジェクトを使用する。しかし、その前に、まず、このメタ分析で観察された $I^2$ 異質性の量を確認してみよう。

```{r}
m.gen$I2
```


$I^2$  = 63%で、この分析における異質性はかなりのものであることがわかる。異質なデータセットにおけるトリム＆フィル法の限界を考慮すると、これは問題であることがわかる。 

そのため、2つのトリム＆フィル分析を行う。1つは全研究を対象とした分析で、もう1つは Chapter \@ref(outliers)  (すなわち、研究3と16)。その結果を `tf` と `tf.no.out`  に保存する。



```{r}
# 全ての研究を使用
tf <- trimfill(m.gen)

# 外れ値を外して解析
tf.no.out <- trimfill(update(m.gen, 
                             subset = -c(3, 16)))

```

まず、全研究を対象とした1つ目の分析を見てみよう。

```{r, eval=F}
summary(tf)
```

```
## Review:     Third Wave Psychotherapies
##                              SMD             95%-CI %W(random)
## [...]
## Filled: Warnecke et al.   0.0520 [-0.4360;  0.5401]        3.8
## Filled: Song & Lindquist  0.0395 [-0.4048;  0.4837]        4.0
## Filled: Frogeli et al.    0.0220 [-0.3621;  0.4062]        4.2
## Filled: Call et al.      -0.0571 [-0.5683;  0.4541]        3.8
## Filled: Gallego et al.   -0.0729 [-0.5132;  0.3675]        4.0
## Filled: Kang et al.      -0.6230 [-1.2839;  0.0379]        3.3
## Filled: Shapiro et al.   -0.8277 [-1.4456; -0.2098]        3.4
## Filled: DanitzOrsillo    -1.1391 [-1.8164; -0.4618]        3.3
## 
## Number of studies combined: k = 26 (with 8 added studies)
## 
##                         SMD           95%-CI    t p-value
## Random effects model 0.3428 [0.1015; 0.5841] 2.93  0.0072
## 
## Quantifying heterogeneity:
##  tau^2 = 0.2557 [0.1456; 0.6642]; tau = 0.5056 [0.3816; 0.8150];
##  I^2 = 76.2% [65.4%; 83.7%]; H = 2.05 [1.70; 2.47]
## 
## [...]
## 
## Details on meta-analytical method:
## - Inverse variance method
## - Restricted maximum-likelihood estimator for tau^2
## - Q-profile method for confidence interval of tau^2 and tau
## - Hartung-Knapp adjustment for random effects model
## - Trim-and-fill method to adjust for funnel plot asymmetry
```

トリムとフィルの手順で、合計8件の研究が追加されたことがわかる。トリムとフィルの研究には、すでに検出した外れ値だけでなく、比較的高い効果を持つ他のいくつかの小さな研究も含まれている。移植された効果量はすべて非常に低く、大きくマイナスなものも複数あることがわかる。出力はまた、補正された効果の推定値を提供し、それは $g=$  0.34である。これはまだ有意であるが、最初に `m.gen` に対して計算した $g=$  0.58という効果よりはるかに低いものである。 

では、外れ値を取り除いた解析結果と比較してみよう。

```{r, eval=F}
summary(tf.no.out)
```

```
## Review:     Third Wave Psychotherapies
## [...]     
## 
## Number of studies combined: k = 22 (with 6 added studies)
## 
##                         SMD           95%-CI    t p-value
## Random effects model 0.3391 [0.1904; 0.4878] 4.74  0.0001
## 
## Quantifying heterogeneity:
##  tau^2 = 0.0421 [0.0116; 0.2181]; tau = 0.2053 [0.1079; 0.4671];
##  I^2 = 50.5% [19.1%; 69.7%]; H = 1.42 [1.11; 1.82]
## [...]
```

$g=$ 0.34では、結果はほぼ同じである。全体として、トリム＆フィル法は、このメタ分析における $g=$ 0.58 のプール効果は、小規模研究の効果により過大評価されていることを示している。実際には、効果はかなり小さいと思われる。この過大評価は出版バイアスに起因する可能性が高いが、確実ではない。他の説明も可能であり、このことはトリム＆フィル推定が無効である可能性がある。

最後に、インプットされた研究を含むファネルプロットを作成することも可能である。`funnel.meta` 関数を `trimfill` の出力に適用するだけである。以下のコードでは、トリム＆フィルの両方の分析（外れ値あり、なし）に対して、等高線ファネルプロットを作成している。`par` 関数を使用すると、両方のプロットを並べて表示すことが可能である。

\vspace{4mm}

```{r, fig.width=12, fig.height=5, eval=F}

# 等高線の塗りつぶし色を定義
contour <- c(0.9, 0.95, 0.99)
col.contour <- c("gray75", "gray85", "gray95")
ld <- c("p < 0.1", "p < 0.05", "p < 0.01")

# 'par' を使って１行に表示
par(mfrow=c(1,2))

# 等高線ファンネルプロット（全てのデータ）
funnel.meta(tf, 
            xlim = c(-1.5, 2), contour = contour,
            col.contour = col.contour)
legend(x = 1.1, y = 0.01, 
       legend = ld, fill = col.contour)
title("Funnel Plot (Trim & Fill Method)")

# 等高線ファンネルプロット（外れ値は除去）
funnel.meta(tf.no.out, 
            xlim = c(-1.5, 2), contour = contour,
            col.contour = col.contour)
legend(x = 1.1, y = 0.01, 
       legend = ld, fill = col.contour)
title("Funnel Plot (Trim & Fill Method) - Outliers Removed")

```

```{r, fig.width=12, fig.height=5, echo=F}

# Define fill colors for contour
contour <- c(0.9, 0.95, 0.99)
col.contour <- c("gray75", "gray85", "gray95")
ld <- c("p < 0.1", "p < 0.05", "p < 0.01")

# Use 'par' to create two plots in one row (row, columns)
par(mfrow=c(1,2),
    bg="#FFFEFA")

# Contour-enhanced funnel plot (full data)
funnel.meta(tf, 
            xlim = c(-1.5, 2), contour = contour,
            col.contour = col.contour)
legend(x = 1.1, y = 0.01, 
       legend = ld, fill = col.contour)
title("Funnel Plot (Trim & Fill Method)")

# Contour-enhanced funnel plot (outliers removed)
funnel.meta(tf.no.out, 
            xlim = c(-1.5, 2), contour = contour,
            col.contour = col.contour)
legend(x = 1.1, y = 0.01, 
       legend = ld, fill = col.contour)
title("Funnel Plot (Trim & Fill Method) - Outliers Removed")

```

この二つのファネルプロットでは、インプットされた研究は塗りつぶしの色がない円で表されている。


<br></br>

#### PET-PEESE  {#pet-peese}

---

\index{PET-PEESE}
\index{Standardized Mean Difference}\index{標準化平均差}

Duval &amp; Tweedieのトリム＆フィル法は比較的古く、間違いなく小規模研究の効果を調整する最も一般的な方法の1つである。しかし、前述したように完璧とは言い難いアプローチであり、プール効果のバイアス補正版を推定する唯一の方法というわけではない。近年、**PET-PEESE** [@stanley2014meta; @stanley2008meta] という手法が、特に SMD がアウトカムとして頻繁に使われる研究分野（例えば、心理学や教育研究）で、ますます人気が出てきている。これまでのすべての手法と同様に、PET-PEESE は、出版バイアスの潜在的な指標とみなされる小規模研究の効果に狙いを定めている。

PET-PEESE は、実際には、**精密効果検定**（precision-effect test, PET）と**標準誤差付き精密効果推定**（precision-effect estimate with standard error, PEESE）の2つの手法を組み合わせたものである。まず、前者から説明しよう。PET 法は、研究の効果量をその標準誤差に回帰させるという単純な回帰モデルに基づいている。


\begin{equation}
\theta_k =  \beta_0 + \beta_1SE_{\theta_k}
(\#eq:pub5)
\end{equation}


Peters の検定と同じように、重み付き回帰を使用する。研究の重み $w_k$  は、分散の逆数として計算される--通常の（固定効果）メタ分析と同じである。

\begin{equation}
w_k = \frac{1}{s_k^2} 
(\#eq:pub6)
\end{equation}


注目すべきは、PET 法で使用される回帰モデルは、Eggers の検定のものと同等であることである。主な違いは、PET 式では、$\beta_1$  係数がファネルの非対称性を定量化し、Eggers の検定では、これが切片によって示されることである。 

\index{Limit}

しかし、PET 法を用いる場合、$\beta_1$  で測定されるファネルの非対称性には関心がなく、切片 $\beta_0$  に関心がある。これは、上の式で、切片がいわゆる**限界効果** (limit effect) を表していることがある。この限界効果は、**標準誤差が0**の研究の期待効果量である。これは、サンプル誤差なしに測定された観察された効果量に相当する。すべてが同じであれば、サンプリング・エラーなしで測定された効果量 $\epsilon_k$  は、真の全体的な効果そのものを表すことが分かっている。 

PET 法の背後にある考え方は、予測因子として標準誤差を含めることによって、小規模研究の効果を**制御**することである。理論的には、これは、すべての小規模研究の効果に対する補正後のメタ分析における真の効果を表す切片 $\beta_0$ につながるはずである。

\begin{equation}
\hat\theta_{\text{PET}} = \hat\beta_{0_{\mathrm{PET}}}
(\#eq:pub7)
\end{equation}

PEESE 法の式は、非常によく似ている。唯一の違いは、**2乗** 標準誤差を予測変数として使用することである（すなわち、効果量の分散 $s_k^2$  ）。

\begin{equation}
\theta_k =  \beta_0 + \beta_1SE_{\theta_k}^2
(\#eq:pub8)
\end{equation}


研究重みの計算式 $w_k$  は変わらないが。標準誤差の二乗の背後にある考え方は、小規模の研究は、特に**非常に**過剰に推定された効果を報告しやすいということである。この問題は、高い統計的検出力を持つ研究では、それほど顕著にはならないことが推測される。 

PET 法は、$\beta_0$  が捉えた真の効果が**ゼロ**のときに最もよく機能するのに対し、PEESE は真の効果が**ゼロでない**ときによりよい性能を示す。Stanley and Doucouliagos  [-@stanley2014meta] は、それぞれの長所をバランスさせるために、両方の方法を結合することを提案してきた。その結果生まれたアプローチがPET-PEESE 法である。PET-PEESE は、PET または PEESE の切片 $\beta_0$  を、補正された真の効果の推定値として使用する。 

PET と PEESE のどちらを使用するかは、PET 法で計算された切片のサイズに依存する。 $\beta_{0_{\text{PET}}}$  が、$\alpha$  = 0.05 の片側検定で、ゼロより有意に大きい場合、PEESE の切片を真の効果量推定値として使用する。PET の切片が0より有意に大きくない場合、PET 推定値のままである。 

 _R_ で回帰モデルを実装する場合、ほとんどの場合、両側検定で係数の有意性を検定するのが通例である（つまり、$\beta$  の重みが0と有意に異なるかどうかを、方向に関係なく検定する）。 $\alpha$  = 0.05で片側検定を仮定すると、$p$  &lt; 0.1、および $\beta_0$  の推定値がゼロより大きいとき、すでに切片が有意であるとみなす^[後者の条件 ( $\hat\beta_0$  &gt; 0) は、正の効果量が好ましい結果（たとえば、正の効果量は介入が有効だったことを意味する）である場合にのみ適用される。負の効果量（たとえば、SMD = -0.5）が有利なアウトカムを表す場合、片側検定は反対方向になるはずである。これは、PETの切片の $p$ -値が0.1より小さく、切片推定値が0より**小さい**とき、PEESEが使用されることを意味する]。


したがって、PET-PEESE によって推定される真の効果量を求めるルールは次のようになる。  


\begin{equation}
  \hat\theta_{\text{PET-PEESE}}=\begin{cases}
    \mathrm{P}(\beta_{0_{\text{PET}}} = 0) <0.1~\mathrm{and}~\hat\beta_{0_{\text{PET}}} > 0: & \hat\beta_{0_{\text{PEESE}}}\\
    \text{else}: & \hat\beta_{0_{\text{PET}}}.
  \end{cases}
  (\#eq:pub9)
\end{equation}

この if-else のロジックを理解するのはやや難しいが、実際の例で説明すると分かりやすいだろう。`m.gen` メタ分析オブジェクトを使用して、PET-PEESEの真の効果量の推定値を見てみよう。

現在、 **{meta}** における PET-PEESE の素直な実装はないので、線形モデル関数  `lm`  を使用して独自のコードを記述する。しかし、PET と PEESE モデルを適合させる前に、まず、データフレームに必要なすべての変数を準備する必要がある。このデータフレームを `dat.petpeese` と呼ぶ。最も重要な変数は、もちろん、標準化平均差である。最初に `metacont` または `metagen` を使用してメタ分析を実行しても、各研究の計算されたSMDは、常にメタ分析オブジェクトの `TE` の下に格納される。

```{r}
# Build data set, starting with the effect size
dat.petpeese <- data.frame(TE = m.gen$TE)
```

\index{Standardized Mean Difference}\index{標準化平均差}

次に、効果量の標準誤差が必要である。PET-PEESE では、Pustejovsky and Rodgers [-@pustejovsky2019testing, Chapter \@ref(eggers-test) を参照] が提案した修正標準誤差 を使用するとよい^[James Pustejovsky もこの方法を[ブログ記事](https://www.jepusto.com/pet-peese-performance/)で推奨していて、この代替方法を「SPET-SPEESE」と呼んでいる]。 

そこで、効果量そのものと相関がないように、修正標準誤差 `seTE_c`  を算出するために適応された式を使用する。また、この変数を `dat.petpeese`  に保存する。さらに、PEESEの予測因子として必要なので、**2乗**標準誤差を含む変数 `seTE_c2` を追加する。


```{r}
# 実験群ｎ (n1) と対照群 (n2) のサンプルサイズ
n1 <- c(62, 72, 44, 135, 103, 71, 69, 68, 95, 
        43, 79, 61, 62, 60, 43, 42, 64, 63)

n2 <- c(51, 78, 41, 115, 100, 79, 62, 72, 80, 
        44, 72, 67, 59, 54, 41, 51, 66, 55)

# 修正標準誤差を計算
dat.petpeese$seTE_c <- sqrt((n1+n2)/(n1*n2))

# 修正標準誤差の二乗（分散）を追加
dat.petpeese$seTE_c2 <- dat.petpeese$seTE_c^2
```

最後に、各研究の逆分散重み付け `w_k` を計算する必要がある。ここで、分散の推定値を得るために、二乗修正標準誤差も使用する。

```{r}
dat.petpeese$w_k <- 1/dat.petpeese$seTE_c^2
```

これで、 `dat.petpeese` には、PET と PEESE の重み付き線形回帰モデルを適合させるために必要なすべての変数が含まれるようになった。次のコードでは、両方のモデルを適合し、`summary`  関数を使用して推定係数を直接表示する。以下が得られた結果である。


```{r}
# PET
pet <- lm(TE ~ seTE_c, weights = w_k, data = dat.petpeese)
summary(pet)$coefficients

# PEESE
peese <- lm(TE ~ seTE_c2, weights = w_k, data = dat.petpeese)
summary(peese)$coefficients
```

PET と PEESE のどちらを使うべきかを判断するため、まず PET 法の結果を見る必要がある。限界推定値は、$g$  = -1.35 であることがわかる。この効果は有意であるが ($p$  &lt; 0.10) 、ゼロよりかなり小さいので、PET 推定値を使用すべきことがわかる。 

しかし、$g$ = -1.35 では、バイアス補正効果の PET の推定値はあまり信頼できない。これは、現実には、研究対象の介入タイプは関心のあるアウトカムに対して非常に負の効果を持つ。つまり、実際には非常に有害であることを示す。これは非常に考えにくいことである。「善意の」介入に効果がないことはありうるが、本当に危険な介入を見つけることは非常にまれである。 

実は、この結果に見られるのは、PET-PEESE の一般的な限界である。観測された効果量はすべて正符号であるにもかかわらず、補正された効果量は大きく負になっている。出力の2番目の部分を見ると、PEESE についても同じことが言えますが、その推定値はわずかに負であることがわかる（ $g=$ -0.44）。 

このような場合、切片を真の効果量の点推定値として解釈しないことが最善である。PET-PEESE は、スモールサンプル効果を補正した場合、研究中の介入タイプは**効果なし**であることを示すと簡単に言うことが可能である。これは基本的に、実際に推定された負の効果量を解釈するのではなく、$\hat\theta_{\mathrm{PET-PEESE}}$  をゼロに設定することを意味する。 

```{block, type='boximportant'}
**PET-PEESE の限界**

\vspace{2mm}

PET-PEESE は、系統的にプール効果量を過剰に修正するだけでなく、出版バイアスが全くない場合でも、真の効果を**過大評価**することがある。全体的に、PET-PEESE法は、含まれる研究の数が少ない場合 ($K$ < 20)、あるいは研究間の異質性が非常に高い場合 ($I^2$ > 80%)、悪いパフォーマンスを示すことが分かっている [@stanley2017limitations]。

研究間の異質性が非常に高い残念ながら、研究数が少なく異質性の高いメタアナリシスはよく見られる。このため、PET-PEESE の適用範囲は限定されており、小規模研究の影響を調整する**唯一の**方法として使用することは勧められない。しかし、この方法が存在し、どのように適用できるかを知っておくことは、一部の研究分野でますます一般的になってきているため、良いことである。

```


```{block2, type='boxinfo'}
**PET-PEESE で、`lm` の代わりに `rma.uni` を使う**

この実践例では、PET-PEESE を実装するために、`lm` 関数と研究の重みを使用した。この方法は、頻繁に使用されているが、全く問題がないわけではない。

`lm` によって実装された重み付き回帰モデルと、例えば `rma.uni` によって採用されたメタ回帰モデルとの間には、わずかだが決定的な違いがある。`lm` が**乗法誤差モデル**を使用するのに対し、メタ分析の関数は通常**加法誤差モデル**を使用する。この違いについての技術的な詳細はここでは触れない。このトピックについては、Wolfgang Viechtbauer が書いた素晴らしい [vignette](https://www.metafor-project.org/doku.php/tips:rma_vs_lm_lme_lmer) に詳しい情報が載っている。

主なポイントは、サンプリング誤差分散に比例定数を仮定した `lm` モデルは、メタ分析データには完全に適していないことである。これは、少なくとも感度分析として、`lm` の代わりに `rma.uni` を使って PET-PEESE を実装することが示唆されています。現実的には、以下のように `rma.uni` にモデレータ変数として $SE_{\theta_k}^{(2)}$ を追加して実行することになる。

`rma.uni(TE, seTE^2, mods = ~seTE, data = dat, method = "FE")`.

```

<br></br>

#### Rücker の限界メタ分析法  {#rucker-ma}

---

\index{Limit}

調整効果量の推定値を算出するもう一つの方法は、Rücker らが提案した**限界メタ分析** (limit meta-analysis) を行うことである [-@rucker2011treatment] （訳注：limit meta-analysis は、日本語の訳語はないようである。）。この方法は、PET-PEESE よりも高度で、より複雑な計算を必要とする。そのため、ここではこの方法の背景にある一般的な考え方を理解することに重点を置き、その後の重い作業は _R_ に任せることにする。

Rücker の方法の背後にある考え方は、小規模研究の効果によるバイアスを明示的に考慮したメタ分析モデルを構築することである。（ランダム効果）メタ分析の式は、次のように定義可能である。

\begin{equation}
\hat\theta_k = \mu + \epsilon_k+\zeta_k
(\#eq:pub10)
\end{equation}

ここで、$\hat\theta_k$ は研究 $k$ の観察された効果量、$\mu$ は真の全体効果量、$\epsilon_k$  はサンプル誤差、$\zeta_k$ は研究間異質性による偏差を定量化したものである。 

限界メタ分析では、このモデルを拡張し、小規模研究の効果がある場合、研究の効果量と標準誤差は独立していないという事実を考慮する。これは、出版バイアスが特に小規模な研究に影響すること、そして、小規模な研究は大規模な研究よりも大きな効果量を持つことを知っているために仮定されている。Rücker 法では、このバイアスは、新しい項（ $\theta_{\text{Bias}}$  ）をモデルに導入することによって追加される。これは、$\theta_{\text {Bias}}$ が $\epsilon_k$  および $\zeta_k$ と相互作用すると仮定している。そして、$\epsilon_k$  が増加するにつれて、より大きくなる。適応された式は次のようになる。


\begin{equation}
\hat\theta_k = \mu_* + \theta_{\text{Bias}}(\epsilon_k+\zeta_k)
(\#eq:pub11)
\end{equation}

この式では、$\mu_*$  はもはや全体的な真の効果量を表すのではなく、「標準的な」ランダム効果メタ分析では直接的に相当するものがないグローバル平均であることに注意することが重要である（ $\theta_{\text{Bias}} =$  0 以外の場合）。 

次のステップは、PET-PEESE（前章参照）の背後にある考え方に似ている。上の式を使って、研究の効果量の推定がだんだん正確になり、個々のサンプル誤差 $\epsilon_k$  がゼロに近づくと仮定する。これによって、最終的に $\epsilon_k$ が方程式から脱落する。

\begin{equation}
\mathrm{E}(\hat\theta_k) \rightarrow \mu_{*} + \theta_{\text{Bias}}\zeta_k ~ ~ ~ ~ \text{as} ~ ~ ~ ~ \epsilon_k \rightarrow 0.
(\#eq:pub12)
\end{equation}

この式では、 $\epsilon_k$ が 0 に近づくにつれて、$\mathrm{E}(\hat\theta_k)$ は $\hat\theta_k$ の**期待値**を示す。ここで作った式は、「限界メタ分析」の一つであり、 大きな標準誤差を持つ研究の歪んだ影響を取り除いた、調整された効果の推定値を提供するものである。$\zeta_k$ は、通常群間異質性分散 $\tau^2$ （あるいはその平方根である標準偏差 $\tau$）によって表されるので、これを使って式中の $\zeta_k$ を置き換えれば、この式となるわけである。

\begin{equation}
\hat\theta_{*} =  \mu_* + \theta_{\mathrm{Bias}}\tau
(\#eq:pub13)
\end{equation}

ここで、$\hat\theta_*$  は、小規模研究の影響を調整した後の**プールされた**効果量の推定値を表している。Rücker の方法は、最尤法を用い、真の効果量の「縮約」推定値 $\hat\theta_*$ などを使い、この式のパラメータを推定することが可能である。さらに、この式を用いて、個々の研究 $k$ ごとに縮約効果量推定値 $\hat\theta_{{*}_k}$ を得ることも可能である。

\begin{equation}
\hat\theta_{{*}_k} =  \mu_* + \sqrt{\dfrac{\tau^2}{SE^2_k + \tau^2}}(\hat\theta_k - \mu_*)
\end{equation}

ここで、$SE^2_k$  は、$k$  の二乗標準誤差（すなわち、観察された分散）を表し、$\hat\theta_k$  は、もともと観察された効果量である^[この式は、式 9.11 のより単純化したバージョンから導き出すことができる。この方法の技術的な説明は、Rücker ら [-@rucker2011treatment] の式2.4から式2.6にある]。 

\index{metasens Package}

PET-PEESE と比較した Rücker の限界メタ分析法の利点は、異質性分散 $\tau^2$  が明示的にモデルに含まれていることである。もう一つのより実用的な利点は、 _R_ で  `limitmeta`  関数を使用して、この方法を直接適用できることである。この関数は  **{metasens}**  パッケージに含まれている [@metasens]。 

 **{metasens}** と **{meta}** は同じ研究者グループによって開発されたので、通常は非常にシームレスに連携して動作する。例えば、 `m.gen` メタ分析のリミットメタ分析を行うには、 `limitmeta` の呼び出しの最初の引数としてそれを与えるだけでよいのである。 

```{r, echo=F, message=F}
library(metasens)
```

```{r, message=F, eval=F}
# 'metasens' をライブラリからロード
library(metasens)

# 限界メタ分析を実行
limitmeta(m.gen)
```

```
## Results for individual studies 
## (left: original data; right: shrunken estimates)
## 
##                           SMD        95%-CI      SMD        95%-CI
## Call et al.              0.70 [ 0.19; 1.22]    -0.05 [-0.56; 0.45]
## Cavanagh et al.          0.35 [-0.03; 0.73]    -0.09 [-0.48; 0.28]
## DanitzOrsillo            1.79 [ 1.11; 2.46]     0.34 [-0.33; 1.01]
## de Vibe et al.           0.18 [-0.04; 0.41]     0.00 [-0.22; 0.23]
## Frazier et al.           0.42 [ 0.13; 0.70]     0.13 [-0.14; 0.42]
## Frogeli et al.           0.63 [ 0.24; 1.01]     0.13 [-0.25; 0.51]
## Gallego et al.           0.72 [ 0.28; 1.16]     0.09 [-0.34; 0.53]
## Hazlett-Stevens & Oren   0.52 [ 0.11; 0.94]    -0.00 [-0.41; 0.40]
## Hintz et al.             0.28 [-0.04; 0.61]    -0.05 [-0.38; 0.26]
## Kang et al.              1.27 [ 0.61; 1.93]     0.04 [-0.61; 0.70]
## Kuhlmann et al.          0.10 [-0.27; 0.48]    -0.29 [-0.67; 0.08]
## Lever Taylor et al.      0.38 [-0.06; 0.84]    -0.18 [-0.64; 0.26]
## Phang et al.             0.54 [ 0.06; 1.01]    -0.11 [-0.59; 0.36]
## Rasanen et al.           0.42 [-0.07; 0.93]    -0.25 [-0.75; 0.25]
## Ratanasiripong           0.51 [-0.17; 1.20]    -0.48 [-1.17; 0.19]
## Shapiro et al.           1.47 [ 0.86; 2.09]     0.26 [-0.34; 0.88]
## Song & Lindquist         0.61 [ 0.16; 1.05]     0.00 [-0.44; 0.44]
## Warnecke et al.          0.60 [ 0.11; 1.08]    -0.09 [-0.57; 0.39]
## 
## Result of limit meta-analysis:
## 
##  Random effects model     SMD            95%-CI     z     pval
##     Adjusted estimate -0.0345 [-0.3630; 0.2940] -0.21   0.8367
##   Unadjusted estimate  0.5771 [ 0.3782; 0.7760] -0.21 < 0.0001
## [...]
```

出力は、まず、各研究の元の推定値（左）と縮約された推定値（右）を示している。調整済み効果量は、観察された効果量よりもかなり小さくなっていることがわかる。現在ではマイナスになっているものも複数ある。出力の第2部では、調整されたプール効果推定値が表示されている。これは、$g=$  -0.03、小規模研究の影響を補正した場合、全体的な効果がほぼゼロであることを示している。 

もし、小規模研究の効果が本当に出版バイアスによるものであるなら、この結果は残念である。最初の発見は完全に偽りで、選択的な出版によって治療が実際には有効でないという事実が隠されていたことを意味するからである。しかし、繰り返しになるが、出版バイアスがこのデータにおける小規模研究の効果の唯一の原動力であったと証明することは難しい。

\index{Funnel Plot}\index{ファンネルプロット}

限界メタ分析のファネルプロットを作成することも可能である。 `limitmeta` の結果を  `funnel.limitmeta` 関数に渡すだけで、`funnel.meta` によって生成されたものと全く同じように見える。唯一の違いは、プロットに**灰色のカーブ**が追加されることである。この曲線は、Y軸の標準誤差がゼロのときの調整済み平均効果量を示しているが、標準誤差が増加するにつれて、小規模研究の効果によるバイアスが増加することを表している。 

`limitmeta` オブジェクトのファンネルプロットを生成する際に、 `shrunken` 引数を `TRUE` に設定することで、縮約した研究レベルの効果量推定値を含めることも可能である。以下は、これらのプロットを生成するコードである。 


```{r, fig.width=6, fig.height=5, out.width="50%", collapse=TRUE, results='hold', eval = F}
# limitmeta オブジェクトを作成
lmeta <- limitmeta(m.gen)

# カーブ付きファンネル
funnel.limitmeta(lmeta, xlim = c(-0.5, 2))

# カーブと縮約研究推定値のファンネル
funnel.limitmeta(lmeta, xlim = c(-0.5, 2), shrunken = TRUE)
```


```{r, fig.height=5, fig.width = 13, collapse=TRUE, results='hold', echo=F}
# Create limitmeta object
lmeta <- limitmeta(m.gen)

par(mfrow = c(1,2),
    bg="#FFFEFA")
# Funnel with curve
funnel.limitmeta(lmeta, xlim = c(-0.5, 2))

# Funnel with curve and shrunken study estimates
funnel.limitmeta(lmeta, xlim = c(-0.5, 2), shrunken = TRUE)
```

`limitmeta` は標準化平均差を用いたメタ分析にのみ適用できるわけではなく、  **{meta}**  メタ分析オブジェクトであればどのようなものでも使用できる。例として、リスク比を要約指標とする `m.bin` の調整済み効果量を確認してみよう。

```{r, eval=F}
limitmeta(m.bin)
```

```
## Result of limit meta-analysis:
## 
##  Random effects model     RR           95%-CI    z     pval
##     Adjusted estimate 2.2604 [1.8066; 2.8282] 7.13 < 0.0001
##   Unadjusted estimate 2.0217 [1.5786; 2.5892] 7.13 < 0.0001
```

この分析では、元の推定値と修正後の推定値はほぼ同じであることがわかる。これは、Peters の検定（Chapter \@ref(peters-test)）で、このメタ分析では小規模研究の効果は小さいとされていることを考えると、あまり驚くことではない。

<br></br>

### P 曲線 {#p-curve}

---

\index{P-Curve}\index{P-曲線}

これまで、小規模研究の効果を見ることで出版バイアスのリスクを評価する様々なアプローチについて説明してきた。実施方法は異なるが、これらの方法はすべて、選択的な報告によって研究の効果量がそのサンプルサイズに依存するという考えに基づいている。標準誤差が大きい（つまり精度が低い）研究は、大規模な研究よりも平均効果量が大きいと仮定する。これは、非常に高い効果量を持つ小規模な研究だけが発表され、その他の研究はファイルの引き出しに入ったままになっていることがある。

この「理論」は確かに直感的だが、やや的外れであるという意見もある。小規模研究法は、出版バイアスが**効果量**によって引き起こされると仮定したが、より現実的なスタンスは、$p$ -**値**によって作動すると言えるだろう。実際、研究結果は、$p<$  0.05 である場合にのみ、出版する価値があるとみなされる。 

先に述べたように、研究は**人間**によって行われるため、私たちの生活の他の多くの部分と同様に、金と名声に影響される。"significant $p$, or no PhD" という悪名高いフレーズは、この問題を非常によく捉えている。研究者は、$p$ - 0.05より小さい値を「出す」ようにという大きな外圧にさらされている。研究者は、この有意水準が、自分の研究が出版されるかどうか、また、それが「成功」したとみなされるかどうかを決定することができることを知っているのである。このようなインセンティブは、ネガティブで有意でない知見が出版された文献からますます消えていく理由を説明するだろう [@fanelli2012negative]。

小規模研究法は、出版バイアスの背後にあるメカニズムを**間接的に**捉えていると言えるだろう。確かに、報告が選択されることによって、より小さな研究がより高い効果を持つようになることがある。しかし、これは、非常に高い効果によって、$p<$  0.05の検定統計量を得る機会が増えるから正しいだけである。小規模研究の効果測定法では、$p=$  0.049 の研究と、$p$ -値が0.051 の研究の間にはほとんど差がない。しかし、実際には、この小さな違いが、研究者にとって大きな意味を持つ。 

\index{P-Value}\index{P-値}
\index{P-Hacking}
\index{Questionable Research Practice (QRP)}
\index{Small-Study Effect}

以下では、出版バイアスの主な要因として $p$-値に着目した **p-曲線** (p-curve) という手法を紹介する [@simonsohn2014p; @simonsohn2014es; @simonsohn2015better]。この方法の特徴は、**有意な**効果量と、その $p$ -値がどのように分布しているかに限定されていることである。これにより、メタ分析データの背後に真の効果があるかどうかを評価することができ、それがどの程度大きいかを推定することが可能である。重要なのは、小規模研究効果法ではできない、$p$ -hacking のような疑わしい研究手法も明示的にコントロールできることである。 

\index{Trim and Fill Method}

P 曲線は比較的新しい手法である。これは、近年社会科学に影響を与えた「複製の危機」に対応して開発された [@ioannidis2005most; @open2015estimating; @mcnutt2014reproducibility]。この危機は、一見確立されたように見える研究結果の多くが、実は系統的に再現できないという不都合なものであるという観察に端を発している。このため、出版バイアスを検出する方法に新たな関心が寄せられるようになった。メタ分析では、選択的な報告を適切にコントロールできないため、すでに出版された文献に存在するバイアスを単純に再現している可能性がある。 

P 曲線は、標準的な出版バイアス法、特に Duval &amp; Tweedie trim-fill 法の欠点に対応して開発されたものでもある。Simonsohnら [-@simonsohn2014es] は、trim-and-fill 法は通常**小さな**下方修正をもたらすだけで、分析データの背後に真の効果が全くないという事実を見過ごすことが多いことを発見してきた。

P 曲線はその名の通り、$p$ -値の曲線に基づくものである。 $p$ -曲線はヒストグラムのようなもので、メタ分析において、$p<$  0.05, $p<$  0.04, $p<$  0.03, というような研究数を示している。p-曲線法は、この $p$ -値のヒストグラムの形状は、研究のサンプルサイズに依存するという考えに基づいており、さらに重要なことは、このデータの背後にある**真の**効果量に依存していることである。 

これを説明するために、9つのメタ分析の結果をシミュレートしてみる。パターンを明確にするために、これらの架空のメタ分析には、それぞれ膨大な数の $K=$ 10$^{\text{5}}$ 件の研究が含まれている。9つのシミュレーションのそれぞれで、個々の研究に対して異なるサンプルサイズ（ $n=$  20から $n=$  100の範囲）と、異なる真の効果量（ $\theta=$  0から0.5の範囲）を仮定しよう。メタ分析では、すべての研究が1つの真の効果量を共有し、効果が固定効果モデルに従うと仮定する。そして、シミュレーションで有意なすべての効果量の $p$ -値を取り、ヒストグラムを作成する。その結果は、以下のプロットで見ることが可能である。

\vspace{2mm}

```{r pcurve, fig.width=12, fig.height=9, message=F, echo=F, out.width="80%", fig.align="center", fig.cap="異なるサンプルサイズと効果量の P-曲線。"}
library(dplyr)
library(rlang)

# Define helpers
pdist = function(x, lower.tail) pnorm(x, lower.tail=lower.tail)

plotter = function(x, var){
  
  x %>% filter(!!enquo(var) < 0.05) %>% pull(!!enquo(var)) %>% 
    hist(breaks = 20, plot = F) -> h
  h$density = h$counts/sum(h$counts)*100
  plot(h, freq = F, main = NULL, ylab = "Percentage", 
       xlab = bquote(italic("p")~"value"), col = "gray")
  
  d = strsplit(deparse(substitute(var)), "_") %>% unlist() %>% nth(2)
  n = strsplit(deparse(substitute(var)), "_") %>% unlist() %>% nth(3)
  d = as.numeric(d)/10
  title(bquote(theta~"="~.(d)~~~"n = "~.(n)))
  
} 


# # Simulate
# dat = list()
# for (i in 1:1e5){
#   
#   dat.inner = list()
#   for (n in c(20, 50, 100)){
#   
#   z = mean(rnorm(n, 0, 1))*sqrt(n)
#   dat.inner[[paste0("s_0_", n)]] = z
#   
#   z = mean(rnorm(n, .2, 1))*sqrt(n)
#   dat.inner[[paste0("s_2_", n)]] = z
#   
#   z = mean(rnorm(n, .5, 1))*sqrt(n)
#   dat.inner[[paste0("s_5_", n)]] = z
#   }
#   
#   dat[[i]] = unlist(dat.inner)
# }
# 
# do.call(rbind, dat) %>% 
#   apply(., 2, function(x) 2*pmin(pdist(x, TRUE), pdist(x, FALSE))) %>% 
#   data.frame() -> simdat.p

load("data/simdat.p.rda")


par(mfrow = c(3,3), cex.main = 2, bg="#FFFEFA")
simdat.p %>% plotter(s_0_20)
simdat.p %>% plotter(s_0_50)
simdat.p %>% plotter(s_0_100)
simdat.p %>% plotter(s_2_20)
simdat.p %>% plotter(s_2_50)
simdat.p %>% plotter(s_2_100)
simdat.p %>% plotter(s_5_20)
simdat.p %>% plotter(s_5_50)
simdat.p %>% plotter(s_5_100)

```

\vspace{2mm}

一番上の段は、真の効果がない場合の有意な $p$ -値の分布を示している。このパターンは、個々の研究のサンプルサイズがどんなに大きくても、すべてのシミュレーションで同じであることがわかる。３つの研究の $p$ 値は、等しく分布しているように見える。$p=$  0.04というかろうじて有意な値は、$p=$  0.01と同じぐらいありそうである。このような平坦な $p$ -曲線は、このデータに基礎的な効果がないとき、すなわち、$\theta = 0$  の**帰無仮説**が真であるときに出現する。 

この場合、$p$-値は**一様**分布に従うと仮定される。すべての $p$ -値は他のものと同じように可能性がある。帰無仮説（ $\theta = 0$  ）が真であるとき、偶然に有意な効果量を見つけることは可能である。これは、**偽陽性**、つまり、$\alpha$  エラーになる。しかし、これはありえないことで、私たちは**どのようにありえないか**を正確に知っている。効果量がゼロの時は一様に分布しているので、$p$ -値の5%は0.05より小さいと予想される。これはまさに、帰無仮説を棄却するための仮説検定でよく使われる $\alpha=$  0.05の有意性閾値なのである。

$p$-曲線は、2段目と3段目で全く違って見える。これらの例では、帰無仮説は否定され、データには真の効果が存在する。このため、$p$ -値の分布は**右に歪んだ**状態になる。このデータが真の効果を捉えている場合、非常に有意な（例えば、$p=$  0.01）効果量は、ほとんど有意でない効果（例えば、$p=$  0.049）よりも可能性が高くなる。この右に歪んだ状態は、真の効果量と研究サンプルサイズが大きくなるにつれて、ますます顕著になる。 

しかし、メタ分析では、検出力が極端に低い研究（すなわち、$\theta=$  0.2の小さな効果を検出することを目的としながら、$n=$  20人の参加者しか含まない）でも、右に歪んだ $p$ -曲線が出現することがわかる。このことから、$p$ -曲線は、真の効果量の変化に対して非常に敏感であることが明らかになった。真の効果量が存在する場合、$p$-値が有意である分布を見るだけで、それを検出できることがよくある。

さて、研究者が $p$-hack したとき、$p$-曲線がどのように見えるか想像してみてみよう。通常、アナリストが $p$-hacking を使い始めるのは、結果が有意ではないが、それに **近い** と判断されたときである。そして、$p$ -値が0.05より小さくなるまで分析の詳細が調整される。それはすでに結果を公表するのに十分な値なので、それ以降、$p$ -hackingは行われない。 $p$ -ハッキングが広く行われると、$p$ -曲線が**左に歪む**ことになるのは想像に難くない。 $p$ -0.05をわずかに下回る値が過剰に表現され、非常に有意な結果が過小に表現される。 

まとめると、$p$ -曲線は、出版バイアスと $p$ -hacking の存在を評価するための診断ツールとして使用できることがわかる。次に、経験的な $p$-曲線に基づく統計検定のコレクションである p-曲線**曲線**について説明する。重要なのは、これらのテストはどれも出版バイアスそのものに焦点を当てていないことである。その代わりに、この方法は、このデータに**明らかな価値**があるかどうかを見つけ出そうとするものである。これは間違いなく、メタ分析で最も関心のあることである。推定した効果が偽りのものでなく、選択的な報告によって引き起こされた人工物であることを確認したいのである。P-曲線は、まさにこの懸念に対応するものである。P-曲線は、発見が現実に存在する効果によってもたらされているのか、あるいは、大げさに言えば、「音と怒りの物語、何の意味もない」のかをチェックすることを可能にした。 

<br></br>

#### 証拠能力の検定

---

\index{Power}\index{検出力}\index{検出力}

証拠能力の有無を評価するために、p-曲線は2種類の検定を用いる：**右歪度の検定**と**33%検出力の検定**である（後者は $p$ -曲線の平坦性の検定と見なすことができる）。まず、右歪度の検定から始める。すでに学んだように、$p$-曲線の右歪度は、研究のサンプルサイズとその真の根本的な効果の関数である。したがって、メタ分析の $p$ -曲線が有意に右歪んでいることを確認できるテストは非常に有用である。有意な $p$ -値の分布に有意な右に歪んでいる場合、これは結果が本当に真の効果によって引き起こされていることを示すだろう。 

<br></br>

##### 右歪度の検定

---

\index{Binomial Test}

右歪度を検定するために、p-曲線法ではまず**二項検定**を用いる。この検定は、二項分布に従うデータに対して使用することが可能である。二項分布は、2つのカテゴリに分けられるデータ（例：成功/失敗、表/裏、イエス/ノー）に対して仮定することができ、$p$  は結果の1つの確率を示し、$q = 1-p$  は他の結果の確率を示す。 

二項検定を使用するために、$p$ -曲線を2つのセクションに分割しなければならない。これは、&lt;0.025である $p$ -値の数と、次に&gt;0.025である有意な $p$ -値の数をカウントすることによって行う。 $p$ -曲線の値は0から0.05の範囲にあるので、基本的には**x**-軸の中央をカットオフとして使用する。 $p$ -曲線が確かに右に歪んでいる場合、2つのグループの $p$ -値の数が異なることが予想される。これは、0.025より小さい結果を得る確率 $p$  は、0.025より大きい値を得る確率 $q$  よりもかなり高いからである。 

$p$ -曲線に8つの値があり、そのうちの7つが0.025以下であると想像してみよう。 _R_  の `binom.test` 関数を使って、$p$ -値の小ささと高さが等しく起こりうるという帰無仮説のもとで、そのようなデータを見つけることがどの程度可能かをテストすることが可能である^[帰無仮説のもとでは、&lt; 0.025 という結果を得る真の確率 $p$  は $\pi=$  0.5 だと仮定している。私たちの目標は、$k=$ 8 件の有意な研究があるときに、$n=$ 7 件以上の高い有意な研究が得られる確率を計算することである。この確率、片側二項検定の $p$ -値は、この公式を使って求めることが可能である。$$\text{P}(X\geq k) = \sum_{k=7}^{8}\frac{n!}{k!(n-k)!}p^k(1-p)^{n-k}$$ ここで $p=$ 0.5、エクスクラメーション記号（!）は階乗であることを示す。 シグマ記号（Σ）は全て足すことを表す。つまり $k=$ 7 から順に $k=n$ まで足す。]。
 

小さい $p$ -値は大きい $p$ -値よりも頻度が高いと仮定しているので、  `alternative` 引数を `"greater"`  に設定することで、片側検定を使用することが可能である。

```{r}
k <- 7   # p<0.025 である研究数
n <- 8   # 有意な研究数
p <- 0.5 # k (ヌル仮説) の推定確率

binom.test(k, n, p, alternative = "greater")$p.value
```

二項検定が有意であることがわかる（$p<$  0.05）。この例では、$p$ -値 が、低い値より高い値の方が有意に多いことを意味する。全体として、これは $p$ -曲線が右に歪んでおり、真の効果があることを示している。

二項検定の欠点は、$p$ -値が実際には連続的であるにもかかわらず、二項化することを要求することである。情報の損失を避けるために、データを二項に変換することを必要としない検定が必要である。 

P-曲線は、各 $p$ -値に対して $p$ -値を計算することによってこれを実現し、各研究のいわゆる $pp$ -値が得られる。 $pp$ -値は、$p$ -曲線が平坦なとき（すなわち、真の効果がないとき）、$p$  と少なくとも同じ高さの値を得る可能性を示している。これは、有意な値のみを考慮した場合の $p$  の値の確率を示す。 $p$ -値は一様分布に従うので、$\theta = 0$ , $pp$ -値は、$[0,1]$  の範囲に投影する有意な $p$ -値にほかならない。連続アウトカム尺度の場合、これは $p$ -値に20を乗じることで達成される。例えば、$p = 0.023\times20 = 0.46 \rightarrow pp$  。

\index{Fisher's Method}
\index{Stouffer's Method}
\index{History of Meta-Analysis}

 $k$  メタ分析で有意な各研究の $pp_k$ -値を用いて、**Fisher の方法**で右歪度を検定することが可能である。この方法は、20世紀初頭に R. A. Fisher によって開発されたメタ分析の「古風な」タイプである（Chapter \@ref(history) を参照）。Fisherの方法は、いくつかの研究からの $p$ -値を集約し、少なくとも1つが真の効果を測定しているかどうかを検定することが可能である（すなわち、提出された $p$ -値の分布が右に歪んでいるかどうかを検定する）。これは、$pp$ -値を対数変換し、すべての研究 $k$  の結果を合計し、-2 を掛けることを必要とする。 

結果として得られる値は、$2 \times K$  の自由度を持つ $\chi^2$  分布 ( Chapter \@ref(cochran-q)  参照) に従う検定統計量となる ( $K$  は $pp$ -値の総数)^[新しいバージョンの p-曲線では、右歪度の検定に Fisher 法 [@simonsohn2015better] の代わりに **Stouffer' 法** が使われている。両方の方法は密接に関連しているが、Stouffer 法は $p$-値の代わりに $z$-scoreに基づいている。]。


\begin{equation}
\chi^2_{2K} = -2 \sum^K_{k=1} \log(pp_k)
(\#eq:pub14)
\end{equation}

Fisher の方法を簡単な例で試してみよう。 $p$ -曲線が5つの $p$ -値を含んでいると想像してみよう。  $p=$  0.001, 0.002, 0.003, 0.004 および 0.03とする。右歪度を検定するために、まず、これらの $p$ -値を $pp$ -値に変換しなければならない。

```{r}
p <- c(0.001, 0.002, 0.003, 0.004, 0.03)
pp <- p*20

# pp 値を表示
pp
```

式9.15を用いると、このコードで $\chi^2$  の値を算出することができる。


```{r}
chi2 <- -2*sum(log(pp))
chi2
```

この結果、$\chi^2=$  25.96 となる。5 件の研究が含まれているので、自由度は $\text{d.f.} =2\times5=10$  となる。この情報を使って、効果がない/右に歪んでいないという帰無仮説のもとで、このデータがどれだけの確率で成り立っているかをチェックすることが可能である。これは _R_ で `pchisq`  関数を用いて行うことが可能である。 $\chi^2$  の値と d.f. の数を指定する必要がある。

```{r}
pchisq(26.96, df = 10, lower.tail = FALSE)
```

これは、$p$-値が 0.0026 であることを意味する。これは、帰無仮説が非常にありそうにないことを意味し、したがって棄却される。 $\chi^2$ 検定の有意な値は、この例では、$p$ -値が実際に右に歪んでいることを教えてくれる。これは、このデータの背後に証拠能力があるという仮定の証拠と見ることが可能である。 


<br></br>

##### 平坦度テスト

---

\index{Power}\index{検出力}\index{検出力}

右歪度の検定が、有意な $p$ -値の分布が真の全体効果を表しているかどうかを決定するために使用できることを確認する。問題は、この検定がデータの**統計的検出力**に依存することである。したがって、右歪度検定が**有意でない**とき、これは自動的に証拠能力がないことを意味するわけではない。本当に効果がないのか、あるいは、たとえデータが実際に右に歪んでいても $p$ -曲線における値の数が $\chi^2$  検定を有意にするには少なすぎるのか、という2つのことが考えられる。  

したがって、右歪度の検定が有意でないことの説明として、検出力の欠如を除外しなければならない。右歪度の検定の帰無仮説は、「証拠能力がない」というものである。検定では、基本的に、経験的な $p$-曲線が平坦で**ない**ことを示すことによって、この帰無仮説を棄却しよう。 

ここで、この論理を逆転させて、$p$-曲線が平坦で**ある** ことを示さなければならない。これは帰無仮説を変更することで可能である。効果がないのではなく、新しい帰無仮説は、$p$ -曲線は**小さい**効果を含み、結果として**わずかに**右に歪んでいると仮定する。平坦性の検定では、$p$ -曲線が**わずかに**右に歪んでいないことを示すことが目標になる。あるいは、別の言い方をすれば、$p$ -曲線が、非常に、非常に小さな効果に対して私たちが期待するものよりも、著しく平坦であることを確認したい。このような場合、手元のデータでは非常に小さな効果さえも否定され、証拠能力が全くない可能性が高いと言える。

\index{t-Distribution}\index{t-分布}

P曲線解析は、33%の検出力の検定を通してこれを達成する。このアイデアは、真の効果が非常に小さい場合の各有意な研究 $k$  の**期待** $pp$ -値（すなわち、$p$  の確率）を構築することである。非常に小さいというのは、研究のサンプルサイズを用いて、33%の検出力で検出できる効果量という意味である。 

この33％という閾値はある程度恣意的なもので、p-曲線の発明者が実質的に無視できる程度の効果を示す大まかな指標として選んだものである。33% 検出力 $pp$ -値がどのように決定されるかの統計的な詳細は割愛するが、アウトカム尺度によって非中心分布 $F$ , $t$ , $\chi^2$  などの**非中心**分布の使用を伴うことは知っておく必要がある^[本書で使用する  _R_ のp-曲線関数では、効果量はまず $z$ スコアに変換される（式 $z = \frac{\hat\theta}{SE_{\hat\theta}}$ を使用する）。33% の検出力検定の期待値 $pp$ -値を計算するために、 d.f. = 1 の非心分布 $\chi^2$  が使用される。これは、$\chi^2_1$ と $z$（より正確には: $z^2$ ）の分布が等しいので可能である。]。


以下、p曲線（Chapter \@ref(p-curve-es)）を用いた効果量推定について、非心分布の概念をより詳細に説明する。

要約すると、平坦性検定では、まず、有意な $p$ -値ごとに、33%の検出力で検出できる効果に基づく $pp$ -値を計算する。もし、33%検出力の推定値が私たちの $p$ -値の分布によく合うなら、33%検出力の $pp$ -値は一様分布になる。ちょうど、$p$ -値が、データが帰無仮説 $\theta = 0$  によく合うとき、一様分布に従うのと同じである。したがって、右歪度検定で使ったのと同じ方法を適用できるが、今回は、計算に 33% の検出力 $pp$ -値を使用する。 

唯一の違いは、帰無仮説を棄却することに特に注目しないことである。これは、少なくとも小さな効果がデータに存在するという概念を否定している。無視できるほど小さな効果があるか、あるいは全く効果がないかのいずれかである。 

<br></br>

##### P-曲線の結果の解釈  {#interpretation-p-curve-results}

---

ここまで、経験的に $p$ -曲線を分析することができるいくつかの検定を取り上げた。統計的な概念のいくつかが理解しにくいと感じても、あまり心配しないでみよう。p-曲線の背後にある方法論を把握するのに時間がかかるが、次の実践的な例はこの点で必ず役に立つ。最も重要なのは、p-曲線検定の背後にある**アイデア**と、その結果がどのように解釈されるかを理解することである。このセクションでは、後者に焦点を当てる。

p-曲線を解釈するとき、私たちは4つの検定結果を意味づけしなければならない。二項右歪度検定と平坦度検定、および $pp$ -値に基づく右歪度検定と平坦度検定のものである。さらに悪いことに、p-曲線解析は、まだカバーしていない2つの追加検定を含んでいる。 **half** $p$  _curve_ に基づく右歪度検定と平坦度検定である。これらの検定は、前にカバーした $pp$ -値に基づく検定と同じであるが、高い $p$ -値（すなわち、$p<$  0.025）にのみ適用されている。 

\index{P-Hacking}

half $p$ -curve 検定は、**ambitious** $p$ **-hacking** [@simonsohn2015better] に対するセーフガードとして導入されたものである。可能性は低いが、研究者が $p$ -有意性が高くなるまで結果をハッキングしている可能性がある。しかし、この場合、$p$ -曲線の形状が歪む可能性がある。つまり、真の効果がない場合でも、左ではなく、わずかに右に歪んで見えるだろう。half $p$ -curve に基づく検定は、これを制御することが可能である。なぜなら、野心的な $p$ -ハッカーでさえ、真の効果がない限り、**非常に**高い $p$ -値（たとえば $p<$  0.01）を得ることはますます困難になることがある。定義上、半分の $p$ -曲線は0.025より小さい値しか含まないので、二項検定は実行されない。

p-曲線の結果を解釈するとき、私たちは本質的に2つの質問に答えようとする。1つ目は、$p$ -曲線は、証拠能力の存在を示しているか？これは、右歪度の検定を使用して評価することが可能である。証拠能力の存在を確認できない場合、2番目の質問に移る。これは、平坦度検定で評価することができる。具体的には、以下のガイドラインを用いることができる [@simonsohn2015better]。

* **固有値の存在**: 右歪度検定が半分の $p$ -曲線で有意である ( $p<$  0.05) **または**右歪度検定の $p$ -値が半分と完全な曲線の**両方**で&lt;0.1&gt;である。

* **証拠となる値がない、または不十分である**: 完全曲線に対する平坦度検定は $p<$ 0.05 で有意である **または** 半曲線に対する平坦度検定 **および** 二項検定は $p<$  0.1 で有意である。

```{block, type='boxinfo'}
**「ノーノー」ケースの解釈**

\vspace{2mm}

どのP曲線分析も、最終的には3つの結果のいずれかに帰結する。右歪度検定が有意であるとき、我々は証拠能力があると結論づける。右歪度検定が有意でなく、平坦度検定が有意なとき、これは証拠能力がない（または効果がとてもとても小さい）ことを示します。

最後の3つ目の結果は、最も厄介である。適切な表現がないので、「ノーノー」ケースと呼んでいる。これは、証拠能力があることも、ないことも確認できない場合である（つまり、右歪度の検定も、平坦度の検定も有意ではない）。

\vspace{2mm}

解釈としては、「ノーノー」の場合、真の効果があることを確認できないが、比較的小さな効果も否定できないことを意味している。

この3つ目の結果は、$p$ 曲線に含まれる研究数が少ない場合によく起こり、確かにやや期待はずれである。この結果は、$p$-曲線を見ただけでは真の効果が存在するかどうかわからない、物事を明確にするためにもっと証拠が必要であることを伝えることが多い。

```

<br></br>

#####  _R_ のP曲線解析

---

ここまでで、p-曲線分析の背後にある理論について多くを学んだので、そろそろ実世界の例でこの技術を適用し始める時期が来ている。幸運なことに、p-曲線の発明者である Simonsohn、Simmons、Nelson は、以前に説明したすべてのテストを自動的に行い、関連する結果を返すアプリケーションを開発してきた。この**p-曲線アプリ**は、[オンライン](http://p-curve.com/) でも見ることが可能である。 
 _R_ で p-曲線を使用するには、 `pcurve` 関数に頼ることが可能である。この関数はアプリの動作をエミュレートするもので、特に **{meta}**  パッケージで作成されたメタ分析オブジェクトのために設計されている。 

```{block, type='boxdmetar'}
**"pcurve" 関数**

\vspace{2mm}

\index{dmetar Package}

`pcurve` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

\vspace{2mm}

1. 関数のソースコードに [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R) でアクセスする。
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。
3. **{stringr}** と **{poibin}** パッケージがインストールされ、ロードされていることを確認する。

```


\index{Outlier}\index{外れ値}

関数 `pcurve` の使い方は簡単である。この関数に、以前に作成した  **{meta}**  メタ分析オブジェクトを渡すだけでよい。この例では、  `metagen` 関数 ( Chapter \@ref(pre-calculated-es) ) で作成した `m.gen` メタ分析オブジェクトを再び使用する。 

しかし、分析を実行する前に、以前に特定した2つの外れ研究（研究3と研究16、Chapter \@ref(outliers)  参照）を削除している。これがなぜ良いアイデアなのかは後で説明する。

```{r, fig.align="center", fig.width=6, fig.height=5, out.width="70%", eval=F}
library(dmetar)
library(meta)

# m.gen から外れ値を外して update
m.gen_update <- update.meta(m.gen, subset = -c(3, 16))

# p-曲線解析を実行
pcurve(m.gen_update)

```

\vspace{4mm}

```
## P-curve analysis 
##  ----------------------- 
## - Total number of provided studies: k = 16 
## - Total number of p<0.05 studies included into the 
##   analysis: k = 9 (56.25%) 
## - Total number of studies with p<0.025: k = 8 (50%) 
##    
## Results 
##  ----------------------- 
##                     pBinomial  zFull pFull  zHalf pHalf
## Right-skewness test     0.020 -3.797 0.000 -2.743 0.003
## Flatness test           0.952  1.540 0.938  3.422 1.000
## Note: p-values of 0 or 1 correspond to p<0.001 and p>0.999, 
## respectively.   
##
## Power Estimate: 66% (31.1%-87.8%)
##    
## Evidential value 
##  ----------------------- 
## - Evidential value present: yes 
## - Evidential value absent/inadequate: no
```

\vspace{4mm}

```{r, echo=F, fig.align="center", fig.width=7, fig.height=6, out.width="68%"}
library(poibin)
library(stringr)

source("data/pcurve.bw.R")

par(bg="#FFFEFA")
p <- pcurve(m.gen_update)

```

p曲線解析の結果と、観測された $p$ -曲線のプロットの2つが出力される。 

出力は、メタ分析が $k=$ 9件の有意な効果を含み、それが $p$ -曲線に含まれることを教えてくれる。研究（ $k=$  8）のほとんどは、非常に有意な結果（すなわち、$p<$  0.025）であった。`Results` セクションには、分析の主なアウトカムが記載されている。3つの右歪度検定すべてが有意であることがわかる：二項検定 ( `pBinom` ; $p=$  0.02), 完全な $p$-曲線 $pp$ -値の検定 ( `pFull` ; $p<$  0.001) と half $p$-曲線に基づく検定 ( `pHalf` ; $p=$  0.003)^[出力から、 完全および half $p$ の統計出力は、 $z$ スコアと関係があることがわかる。出力では、完全および半分の の曲線に基づく検定統計量も有意であることがわかる。これは、 `pcurve` 関数が Fisher 法ではなく Stouffer 法を用いて結果を集計しているためである。この章の脚注6で述べたように、両手法は密接に関連している。]。

Chapter \@ref(interpretation-p-curve-results)  で設定した基準を適用すると、このデータには証拠能力があることがわかる。次の行では、$p$ が 0.938 から 1 までで、3つの平坦性検定が**有意でない**ことがわかる。これは、非常に論理的に、証拠能力がないわけでも不十分なわけでもないことを教えてくれる。同じ解釈は、出力の `Evidential value` セクションでも提供されている。 

この関数による $p$-曲線は、３種類の線を描く。 実線は、データに基づく経験的な $p$ -曲線。破線は、33%の検出力を仮定して期待される $p$ -値の分布。点線は、効果がないときに期待される一様な分布を表している。実線は目に見えて右に歪んでおり、ちょうど研究が真の効果を測定しているときに期待されるようなものである。 

全体として、これらの結果は、証拠能力の存在を示し、真の非ゼロ効果があることを示している。出版バイアスがメタ分析の結果に影響を及ぼしていることは、まだ否定できない。しかし、p-曲線の結果に基づいて、私たちが見つけたプール効果は完全に偽りのものではなく、選択的な報告によって生み出された単なる「蜃気楼」でもないと結論づけることができる。 

興味深いことに、この知見は、いくつかの少量調査効果法を用いて得られた結果とあまり一致していない。PET-PEESE ( Chapter \@ref(pet-peese) ) と限界メタ分析法 ( Chapter \@ref(rucker-ma) ) はともに、補正平均効果を約0と推定してきた^[注意深く見ると、小規模試験効果法では外れ値が除去されておらず、これが異なる結果の原因となっている可能性があることを認識されただろう。この可能性を確認するために、統計的外れ値を除いたPET-PEESEと限界メタ分析を再実行したところ、以前とほぼ同じ結果になる。 _R_ で検証されたい。]。 

<br></br>

#### P 曲線効果量推定値  {#p-curve-es}

---

メタ分析に証拠能力があるかどうかを判断するために、経験則に基づく $p$ -曲線の分析がどのように利用できるかを学習してきた。しかし、この方法を用いて決定的な結果を得ても、私たちの洞察はやや限定的なものにとどまるだろう。データに真の効果があることを知ることは非常に有用であるが、この真の効果がどの程度大きいかを知ることができれば、さらによいだろう。幸いなことに、p-曲線はこの問題にも役立ってくれる。研究のサンプルサイズがわかっていれば、$p$ -曲線の形状に最も合う真の効果量を探すことが可能である。 

\index{t-Distribution}\index{t-分布}

これがどのように実現可能なのかを理解するために、まず、**非心分布** (non-central distribution) の概念と、それが効果量にどのように関係するかを議論する必要がある。非心分布とは何かを例証するために、間違いなく最も一般的な統計的検定である2標本 $t$ -検定から始める。 $t$ -検定は、2つのグループの平均が異なるかどうかを調べるためによく使われる。 

$t$ -検定における帰無仮説は、両平均値 $\mu_1$ と $\mu_2$  は同一であり、したがって、それらの差はゼロであるということである。帰無仮説が真であるとき、$t$ 統計量は、**中心** $t$ -分布に従うと仮定する。中心 $t$ -ディストリビューション分布は、標準正規分布に似ている。帰無仮説は差がないと仮定しているので、$t$ -分布はゼロを中心とする。

\index{Non-Centrality Parameter}

帰無仮説が正しくないとき、この中心 $t$ -分布は、現実をよく表していないことになる。平均値の間に真の差があるとき、$t$-値がゼロの周りに中心を持つことは期待できない。その代わりに、$t$ 統計は、**非心** $t$ -分布に従う。この非心分布は通常非対称であり、より広い広がりを持つ傾向がある。 

しかし、最も重要なことは、その中心がゼロから「シフト」していることである。このシフトの大きさは、**非心パラメータ** $\delta$  によって制御される。 $\delta$  が高いほど、非中心分布のピークがゼロから離れることになる。 

下のグラフはこの挙動を表している。左側には、$t$ -分布の中心、$\delta=$  0が表示されている。右側には、$t$ -分布の非心、$\delta=$  5が表示されている。右の曲線は対称性が低く、5付近でピークになることがわかるが、対称的で中心的な $t$ -分布の中心は0になっている。

\vspace{8mm}

```{r, echo=F, message=F, warning=F, out.width="70%", fig.align="center", fig.width=6, fig.height=3}
library(ggplot2)
bw = function(b, x) { b/bw.nrd0(x) }
set.seed(123)

df = data.frame(type = rep(c("ncp0", "ncp2"), each = 1e4),
                value = c(rt(1e4, 9, 0), rt(1e4, 9, 5)))

ggplot(df, aes(x = value, fill = type, color = type)) + 
  geom_vline(xintercept = 0, linetype = "dashed") +
  geom_density(alpha = 0.5, adjust=bw(1.5, df$value)) +
  xlim(c(-5,13)) +
  xlab(bquote(italic(t)["d.f. = 9"])) +
  ylab(bquote("P("~italic(t)~")")) +
  theme_classic() +
  theme(legend.position = "none") +
  scale_fill_manual(values=c("gray40", "gray77")) +
  scale_color_manual(values=c("gray30", "gray67")) +
  annotate("text", x = 2, y = 0.33, 
           label = bquote("Central"~italic(t)~"distribution ("~delta~"= 0 )"), 
           hjust = "left") +
  annotate(geom = "curve", x = 1.9, y = 0.32, xend = 0.9, yend = 0.28, 
           curvature = .1, arrow = arrow(length = unit(2, "mm"))) +
  annotate("text", x = 5.8, y = 0.23, 
           label = bquote("Non-central"~italic(t)~"distribution ("~delta~"= 5 )"), 
           hjust = "left") +
  annotate(geom = "curve", x = 8, y = 0.22, xend = 6.5, yend = 0.16, 
           curvature = .1, arrow = arrow(length = unit(2, "mm"))) +
  theme(panel.background = element_rect(fill = "#FFFEFA",
                                        size = 0),
        plot.background = element_rect(fill = "#FFFEFA",
                                       size = 0))



```


\vspace{4mm}

左の中心分布は帰無仮説が正しい場合の期待値 $t$ -値を示しているのに対し、右は **対立仮説** が正しい場合の期待値 $t$ -値を示している。 

別の考え方として、左の曲線は効果が**ない**ときの $t$ -分布を、右の曲線は効果が**ある**ときの分布を表していると言うことが可能である。中央の分布は、たとえば SMD が0であることを表し、中央でない分布は、SMD = 1.3 の効果に対する期待値 $t$ -値の分布を表す（この値は仮のもの）。効果量が大きいと（つまり、2つのサンプル間の差が大きいと）、非心パラメータ $\delta$  は高くなり、非心分布は0からますます離れていくだろう。 

先ほど述べたように、非心 $t$ -分布は、$t$ -検定において対立仮説をモデル化するために用いることが可能である。しかし、統計の教科書に非心分布が載っているのは珍しいことで、それは通常、非心分布は**必要**ないためである。統計的仮説検定では、通常、対立仮説は**非特異的**である。2サンプル $t$ -kentei 
を計算するとき、帰無仮説（「群間に差がない」）にしか興味がない。データが帰無仮説にうまく当てはまらないとき、これを棄却し、**何らかの**効果が存在すると結論づける。 

このような検定における対立仮説は、帰無仮説の反対で、2つのサンプル間の平均差が**ゼロではない**ことであり、効果がこのサイズまたはこのサイズであることではないのである。

\index{Power}\index{検出力}\index{検出力}

具体的な対立仮説が必要になるのは、通常、統計的検定の**検出力**を計算するときだけである。実験を行う場合、**偽陰性**の確率が20％以下になるように十分なサンプルサイズを計画するのが通例である。適切なサンプルサイズを用いることで、真の効果が存在する場合に、それを確実に検出できるようにしたいのである。このように、統計的検定が真の効果を発見する確率が、その統計的検出力である。これは、1マイナス偽陽性の確率と定義され、$\beta$ としても知られている。 

$t$ -検定に必要なサンプルサイズを計算するために、非心 $t$ -分布が必要である。なぜなら、それは効果があるときの $t$ -値の期待される振る舞いを示すからである。サンプルサイズを計算するために、また真の効果量について値を仮定する必要がある。なぜなら、それは非心パラメータ $\delta$  に影響し、したがって非心分布の形状に影響を与えるからである。 


これらの断片をまとめると、非心 $t$ -分布の形状、したがって統計的検出力は、2つのものだけで制御されることがわかる：サンプルサイズと、真の根本的な効果である。同じことが、$p$ -曲線の形状にも当てはまる。その右歪度は、サンプルサイズとデータの真の効果に依存する。これは重要な観察で、$p$ -曲線内の研究のサンプルサイズがわかれば、その真の効果量も推定できることを意味する。 

p-曲線がどのようにこれを実現するかを見るために、小さな例を見てみよう。独立2サンプル $t$ -検定（両群の分散が等しいと仮定）の場合、$t$  の値は、群間平均差 $\text{MD}_{\text{between}}$  をその標準誤差 $SE_{\text{MD}_{\text{between}}}$ で割ったものに等しくなる。


\begin{equation}
t_{\text{d.f.}}= \frac{\text{MD}_{\text{between}}}{SE_{\text{MD}_{\text{between}}}}
(\#eq:pub15)
\end{equation}

群間平均差と標準誤差の式（Chapter \@ref(b-group-md) の式 3.14 と式 3.15 参照）を入れると、次の式になる。

\begin{equation}
t_{n_{1}+n_{2}-2} = \frac{\hat\mu_{1}-\hat\mu_{2}}{s_{\text{pooled}}\sqrt{\dfrac{1}{n_1}+\dfrac{1}{n_2}}}
(\#eq:pub16)
\end{equation}

この式から、$t$  の自由度は、両群のサンプルサイズを合わせたもの ($n_1+n_2$) から2を引いたものと定義されることがわかる。 

この式を使って、一次研究で報告されたデータから $t$ -値を計算することが可能である。ある研究で、実験群に $n_1=$  30人、対照群に $n_2=$  20人の参加者がいたとする。この研究では、第1群と第2群の平均がそれぞれ13と10で、両群の標準偏差が5であったと報告されている。このデータに基づいて、次のコードを使って $t$  を計算することができる。 


```{r}
# 平均差を計算
md <- 13-10

# 平均差の標準誤差を計算
n1 <- 30
n2 <- 20
s1 <- s2 <- 5
s_pooled <- sqrt((((n1-1)*s1^2) + ((n2-1)*s2^2))/
                   ((n1-1)+(n2-1)))

se <- s_pooled*sqrt((n1+n2)/(n1*n2))

# t-値を計算（分散の等しい２ーサンプル t 検定と同じ）
md/se

```

結果は、$t_{48} =$ 2.078 である。この結果は、両者の平均が同一であり、影響がないという帰無仮説を支持するか？ 

この質問に答えるには、 `pt` 関数を使用することができる。この関数は、d.f. = 48 **かつ**帰無仮説が真であると仮定するとき、$t$-値 が 2.078 より大きいことを発見する確率を与える。この確率は、片側 $t$-検定の $p$ -値に等しい。 

```{r}
pt(2.078, df = 48, lower.tail = F)
```
結果は、$p=$  0.02 で、検定が有意であることを意味する。したがって、実験群の効果がゼロ（または負）であるという帰無仮説を棄却する。その結果、対立仮説を受け入れる：実験群に有利な正の効果がある（より高いスコアがより良いアウトカムを表すと仮定）。 

$t$  検定の帰無仮説の基礎となる中心 $t$ -分布は、私たちの経験的データにはあまり合わないことがわかっている。また、非心 $t$ -分布が私たちのデータによく合うことも分かっている。しかし、どちらなのかは分からない。今のところ、どの真の効果量、したがって、どの非心パラメータ $\delta$ が、経験的な $t$ -値が引き出された母集団を本当に表しているかを推測することができるだけである。 

最初の推測として、発見の背後にある真の効果量は、標準化平均差 $\theta=$  0.6であると仮定することが可能である。これは、中〜大の効果があったために、$t=$ 2.078 となったことを意味する。この $\theta$ の値に基づいて、非心性パラメータは次の式で計算される。

\begin{equation}
\delta = \frac{\theta}{\sqrt{\dfrac{n_{1}+n_{2}}{n_{1}n_{2}}}}
(\#eq:pub15)
\end{equation}

ここで、$n_1$  と $n_2$  は両グループのサンプルサイズである。この例では、非心性パラメータ $\delta$  を次のコードで計算することができる。


```{r}
theta <- 0.6
delta <- theta/sqrt((n1+n2)/(n1*n2))

# Show delta
delta
```

$\delta=$  2.078 の時の非心分布 $t$ -分布がどのように見えるかを見るために、少しシミュレーションをしてみよう。`rt` 関数を用いて、自由度48の100万個のランダムな $t$ -値を2回描く。1回は非心パラメータを0と仮定したとき（これは効果がないというヌル値に等しい）、もう1回は先ほど計算した $\delta$ の値（つまり、真の効果は SMD = 0.6 ）を用いて描く。 

次に、パイプと `hist` 関数を使って、 _R_  に両シミュレーションのヒストグラムを描かせる。 


```{r, eval=F, fig.align="center", fig.width=6, fig.height=4, out.width="75%"}
# '1 with 6 zeros' can also be written as '1e6' in R
rt(n = 1e6, df = 48, ncp = 0) %>% 
  hist(breaks = 100, 
       col = "gray50",
       xlim = c(-4,8), 
       ylim = c(0, 40000),
       xlab = "t-value",
       main = NULL)

rt(n = 1e6, df = 48, ncp = delta) %>% 
  hist(breaks = 100, 
       col = "gray95",
       xlim = c(-4,8), 
       ylim = c(0, 40000), 
       add = T)
```

これが結果のプロットである。

```{r, echo=F, fig.align="center", fig.width=6, fig.height=4, out.width="75%"}

par(bg="#FFFEFA")
# '1 with 6 zeros' can also be written as '1e6' in R
rt(n = 1e6, df = 48, ncp = 0) %>% 
  hist(breaks = 100, 
       col = "gray50",
       xlim = c(-4,8), 
       ylim = c(0, 40000),
       xlab = "t-value",
       main = NULL)

rt(n = 1e6, df = 48, ncp = delta) %>% 
  hist(breaks = 100, 
       col = "gray95",
       xlim = c(-4,8), 
       ylim = c(0, 40000), 
       add = T)
```


その中で、左側に中心の $t$-分布（効果なし）、右側に非心分布（ $\theta=$  0.6）を見ている。すでに適度な大きさのサンプル（ $N=$  50 ）があるので、非心分布は、前の図よりも右に歪んでいないように見える。それでも、私たちの仮定した対立仮説の分布は右にシフトし、$\delta$  の値でピークになることがはっきりわかる。 

もちろん、中心的な疑問は、この代替分布が本当に正しい分布であり、真の効果が実際には $\theta=$  0.6 であるとき、$t_ **{48}** =$  2.078 より大きい値を得る可能性はどの程度あるのだろうかということである。この質問を検証するために、再び  `pt`  関数を使用することができるが、今回は想定した非心性パラメータ $\delta$  も提供する。この情報は  `ncp`  引数を用いて追加することが可能である。どのような結果が得られるか、確認してみよう。

```{r}
# t=2.078 を使用
pt(2.078, df = 48, ncp = delta, lower.tail = FALSE)
```

指定された対立仮説のもとで、私たちの結果より大きな値を得る確率は、およそ50％であることがわかる。これは、約半分の値が、私たちが見つけた $t$ -値より高く、残りの半分は低いと予想されることを意味する。全体として、これは自由度48と真の効果0.6を仮定した非心 $t$ -分布が、私たちの発見を非常によく近似していることを示している。この研究の真の母集団効果は、SMD = 0.6である可能性が非常に高いと思われる。

今行ったステップは、本質的に、p-curve が真の効果量を決定するために使用するものでもある。 $p$ -曲線におけるすべての有意な $p$ -値について、$t$  より大きい値を得る確率を計算する。 

1.ある効果量／非中心性パラメータ。 

2. $p$ -値は、$x$  自由度（これは研究のサンプルサイズから導き出せる）に基づくこと。  

3. 有意な値( $p<$  0.05 )のみが $p$ -曲線に含まれることを知る。

この結果、重要な研究ごとに $pp$ -値が設定されることになる。 $k$  。先ほど説明したことに基づいて、研究の $pp$-値の式は次のように表すことが可能である $k$ : 

\begin{equation}
pp(t_k) = \mathrm{P}(t>t_k~\vert~\delta,~\text{d.f.},~p<0.05)
(\#eq:pub16)
\end{equation}

\index{Kolmogorov-Smirnov Test}

研究の自由度は通常知られているので、式中の唯一の未知数は、$\delta$  、したがって真の効果量 $\theta$  である。しかし、正しい真の効果量/ $\delta$ -値を仮定すると、$pp$ -値の分布が**一様**になることが分かっているので、この真の効果量を**見つけることが可能である**。私たちの知見が帰無仮説に合致するとき $p$ -値が一様分布に従うように、結果が **正しい**非心分布（すなわち、点対立仮説）に合致するとき $pp$ -値は一様に分布するのである。 

したがって、私たちは、たくさんの可能な**効果量の候補**を試し、得られた $\delta$ -値を上記の式に差し込み、得られた $pp$ -値の歪度を評価すればよいのである。そして、$pp$ -値の一様分布に最も近い効果量候補が、真の効果の推定値を表す。P-curve は、いわゆる Kolmogorov-Smirnov (KS) 検定の $D$  距離メトリックを使用して、$pp$  分布が一様分布からどのくらい逸脱しているかを把握する。 

\index{Cohen's \textit{d}}

P-曲線の効果推定法は `pcurve` 関数にも実装されている。これを利用するには、  `effect.estimation`  引数を  `TRUE`  に設定する必要がある。また、各研究のサンプルサイズである  `N`  を指定する必要がある。最後に、効果量の候補の探索空間を  `dmax`  と  `dmin`  を用いて制御することが可能である。ここでは、Cohen's $d=$  0 と 1 の間の効果量を検索するように `pcurve` に指示する。`dmin` は常に 0 以上でなければならないことに注意してみよう--p-曲線が検出できる最小値は効果なしである。 


```{r, eval=F}
# 実験群(n1) と対照群 (n2) のサンプルサイズを追加
# 研究３と６のサンプルサイズを削除
n1 <- c(62, 72, 135, 103, 71, 69, 68, 95, 
        43, 79, 61, 62, 60, 43, 64, 63)

n2 <- c(51, 78, 115, 100, 79, 62, 72, 80, 
        44, 72, 67, 59, 54, 41, 66, 55)

# 効果推定ありで P 曲線分析を実行
pcurve(m.gen_update, 
       effect.estimation = TRUE,
       N = n1+n2, 
       dmin = 0,
       dmax = 1)

```


```
## P-curve analysis 
##  ----------------------- 
## [...]
##    
## P-curve's estimate of the true effect size: d=0.389  
```


\vspace{4mm}

```{r, echo=F, fig.width=6, fig.height=5, fig.align="center", out.width="45%"}
source("data/pcurve.bw.es.R")


m.gen_update <- update.meta(m.gen, subset = -c(3, 16))

n1 <- c(62, 72, 135, 103, 71, 69, 68, 95, 
        43, 79, 61, 62, 60, 43, 64, 63)

n2 <- c(51, 78, 115, 100, 79, 62, 72, 80, 
        44, 72, 67, 59, 54, 41, 66, 55)

par(bg="#FFFEFA")
pcurve.bw.es(m.gen_update, 
             effect.estimation = TRUE,
             N = n1+n2, 
             dmin = 0,
             dmax = 1) -> d
```

出力には、真の効果量の推定値と効果量探索の結果を示すプロットという2つの新しい要素が含まれる。プロットでは、効果量の候補が滑らかなV字型の勾配を形成し、それは効果量 $d=$  0.389でピークに達した。この時点で、計算された $pp$  分布と一様分布（Y軸の $D$  の値で表される）との差は最小であり、これは真の効果の最良推定値を表していることを意味する。 

重要なことは、p-曲線の効果量の推定は、このプロットのようなV字型のときだけ信頼できるということである。他の不規則な形状は、p-curveが最小値を発見していない可能性を示している。滑らかな下降線を持つプロットは、探索空間が単に狭すぎることを示すだろう。この場合、より高い `dmax` 値で分析を再実行することは理にかなっている。

全体として、p-曲線の推定値 $d=$  0.389 は、メタ分析で見つけたプール効果（外れ値を除くと $g=$  0.45）よりもいくらか低い。しかし、それでも十分に大きく、前回の発見、すなわち、研究には証拠能力があるということと一致する。 

```{block, type='boxreport'}
**P-曲線解析結果の報告**

\vspace{4mm}

p 曲線解析の結果を報告する際には、少なくとも3つの右歪度検定と平坦性の検定の$p$値、およびこれらの結果をどのように解釈したかを記載するとよい。真の効果の大きさが推定されたときは、これも含めるべきである。結果は、次のような表にまとめることができる。
```

```{r, echo=F}
library(kableExtra)

dat = data.frame(pBinomial = c("0.020", "0.952"),
                 zFull = c(-3.797, 1.540),
                 pFull = c("<0.001", "0.938"),
                 zHalf = c(-2.743, 3.422),
                 pHalf = c("0.003", ">0.999"),
                 present = c("yes", "yes"),
                 absent = c("no", "no"),
                 d = c(0.39, 0.39))

rownames(dat) = c("Right-Skewness Test", "Flatness Test")
colnames(dat) = c("$p_{\\text{Binomial}}$", "$z_{\\text{Full}}$", "$p_{\\text{Full}}$", "$z_{\\text{Half}}$",
                  "$p_{\\text{Half}}$", "present", "absent", "$\\hat{d}$")

kable(dat, booktabs = T, digits = 2, escape = FALSE) %>% 
  kable_styling(latex_options = c("scale_down"), 
                bootstrap_options = c("condensed")) %>% 
  add_header_above(c(" " = 2, "Full Curve" = 2, "Half Curve" = 2, "Evidential Value" = 2, " ")) %>% 
  collapse_rows(columns = c(7:9), latex_hline = "major", valign = "middle") %>%
kable_styling(font_size = 14)


```

```{block, type='boxempty'}
p-曲線の開発者は、各解析について、結果が論文のどの部分から抽出され、どのように報告されたかを記述した**開示表**を作成することを強く推奨している。このような開示表の例は、他のいくつかの実用的なガイドラインと一緒に、Simonsohn ら [-@simonsohn2014p] に記載されている。

```


```{block, type='boximportant'}
**P-曲線と群間異質性**

\vspace{4mm}

P-曲線解析から外れ値の研究を除外した理由については、まだ説明する義務があります。外れ値も含めたメタ分析では、研究間の異質性が $I^2=$ 63% となり、非常に大きな値となった。これは、研究間の異質性が高い場合、p曲線は真の効果量を推定するのに頑健な方法ではないことが分かっているので問題である。

\vspace{2mm}

そこで Van Aert ら [-@aert2016conducting] は、異質性が小から中程度の場合にのみ p-曲線を使用することを提案している。彼らは p 曲線が適用できるかどうかを判断する経験則として、$I^2=$ 50%という閾値を提案した。メタ分析における研究間の異質性がこれよりも高い場合の回避策の一つは、例で行ったように、外れ値を含まない効果量をp曲線で表す。さらに良い解決策は、意味のある研究のサブグループが存在する場合、そのサブグループで別の分析を行うことである。

```


<br></br>

### 選択モデル  {#selection-models}

---

\index{Selection Model}

最後に取り上げるのは、いわゆる**選択モデル**と呼ばれる出版バイアスの手法である。選択モデルは以前から選択的出版の影響を調べるために提案されていたが [@hedges1992modeling; @iyengar1988selection; @hedges1996estimating; @hedges1984estimation] 、特にここ数年でその適用への関心が高まっている [@mcshane2016adjusting; @carter2019correcting] 。  

上で取り上げた出版バイアス法は、すべて何らかの「理論」に基づいており、選択的出版がメタ分析の結果になぜ、どのように影響するかを説明するために使用される。例えば、Small-study Effect法は、研究の非出版リスクはサンプルサイズと効果量に比例すると仮定した。P曲線は、$p$-値 0.05 が「魔法の閾値」として機能するという考えに基づいている。 $p \geq$  0.05 の結果は、一般的に統計的に有意な発見よりも、このデータで見つからない可能性がはるかに高いのである。 

選択モデルは、これらの方法を一般化したものと見ることが可能である。このモデルは、出版バイアスが結果に影響を与えたと考えられるあらゆる種類のプロセスをモデル化することが可能である。つまり、選択モデルは、出版バイアスの発生に関する非常に単純な仮説、または非常に洗練された仮説に基づいてデータをモデル化するために使用することができるのである。 

すべての選択モデルの背後にある考え方は、ある研究がその結果に応じて出版（すなわち「選択」）される確率を、多くの場合非常に理想化された方法で予測する分布を指定することである。通常、この結果は研究の $p$ -値で、選択モデルは、$p$  の値を変化させたときの出版確率を返す関数のように見ることが可能である。いったんこのような選択関数が定義されると、選択的出版による想定バイアスを「除去」して、真の効果量の補正推定値を導き出すために使用することが可能である。 

しかし、この補正された効果は、私たちが定義した選択モデルが本当に正しい場合にのみ、適切なものとなる。私たちは常に、私たちのモデルがデータにうまく適合しているように見えても、選択過程を説明する多くの方法のうちの一つに過ぎないことを心に留めておかなければならない。出版バイアスがどのような過程を経て私たちの結果を形成したかは、必然的に未知のままである。しかし、選択モデルは、出版がデータに影響を与えたかどうか、そしてより重要なことに、出版がどのようにデータに影響を与えたかを広く評価するために非常に役立つ。 

\index{Step Function}

この章では、**ステップ関数**に基づく2種類の（かなり単純な）選択モデルを取り上げる。そこで、まずステップ関数とは何かを明らかにする。 


<br></br>

#### ステップ関数選択モデル  {#step-function-selmodels}

---

選択モデル分析を行うには、**効果量モデル**と**選択モデル**の2つの要素が必要である。この2つのモデルは、ある入力値 $x$  を使って、その値の確率を返す **関数** と考えることができる。

式 $f(x_k)$ で示される効果量モデルは、ランダム効果モデルに等しい。漢族された効果量 $\hat\theta_k$ は、平均効果 $\mu$ の周りを、サンプリング誤差と群間異質性 $\tau^2$ から偏差した正規分布に従う。$\mu$ と研究の標準誤差 $\tau^2$ と効果量が正規分布に従うことを知っていれば、出版バイアスがないと仮定して、効果量の値 $x_k$ をどの程度かを $f(x_k)$ は予測する。

しかし、出版バイアスがあるとき、効果量分布と、 $f(x)$ 自体が現実をうまく現さなくなっている。出版の選択により、いくつかの研究はデータの中で過剰に代表されている。おそらく、驚くほど効果量が高く、サンプルサイズは小さい。このため、知らずして、プールモデルに高い重みを与えてしまっている。よって、いくつかの研究は他の研究よりも高い確率で入っていること、そしてその研究には高い「重み」が与えられていることを考慮した、より現実的な $f(x)$ を導き出す必要がある。

\index{Weight}\index{重み}

これを、**重み関数** (weight function) $w(p_k)$ で行う。重み関数は、ある研究 $k$ の $p$ 値から選択確率を与える。これを使って、出版バイアスメカニズムを組み込んだ修正版の $f(x_k)$ を定義する。$f^*(x_k)$ は、以下の式で表される [@vevea2005publication]。


\begin{equation}
f^*(x_k) = \frac{w(p_k)f(x_k)}{\int w(p_k) f(x_k) dx_k}
(\#eq:pub17)
\end{equation}

ここで、分数の分母は $w(p_k) f(x_k)$ の積分である。式中の重み関数 $w(p_k)$ は、仮定選択モデルを表す。

\index{Step Function}

$w(p_k)$ は、技術的にはどのような形式にもなるが、よく現されるのは**ステップ関数**である [@hedges1996estimating]。$w(p_k)$ をステップ関数とすると、同じセグメントに入る $p_k$ 値（例えば 0.05 未満の全ての $p$ 値）は、等しい確率で選択される。この区間別選択確率は $\omega_i$ と現され、区間ごとに変わる。$p$ 値が取りうる値をいくつかのセグメントに分け、それぞれの選択確率を $\omega_1$, $\omega_2$, ..., $\omega_c$ とする。

セグメントの幅は、**カットポイント**（ここでは $a_i$  で示す）によって決まる。カットポイントの数と正確な値は、自由に選ぶことが可能である。例えば、$w(p_k)$ が4つのセグメント(従って4つのカットポイント)を含むとき、その内部構造を次のように定義することができる。

\begin{equation}
  w(p_k) =\begin{cases}
    \omega_1~~~\text{if}~~~0 \leq p_k \leq a_1 \\
    \omega_2~~~\text{if}~~~a_1 \leq p_k \leq a_2 \\
    \omega_3~~~\text{if}~~~a_2 \leq p_k \leq a_3 \\
    \omega_4~~~\text{if}~~~a_3 \leq p_k \leq a_4~~~(\text{where}~~~a_4=1).
  \end{cases}
  (\#eq:pub18)
\end{equation}

任意の $p$ 値に対して、上記の関数は、私たちの値が入る $p$ -値の区間に基づいて、特定の選択確率 $\omega$  （訳注：$\omega$ は、「オメガ」と読み、$w$ と似ているが異なる文字である。）を返すことがわかる。これをより具体的にするために、カットポイント $a_i$ と選択確率 $\omega_i$ に実際の値を記入した選択モデルを定義してみる。 

例えば、メタ分析における出版バイアスのメカニズムは、3つのカットポイントで記述できると仮定可能である。まず、$a_1=$  0.025がある。この値は、片側 $p$-値が 0.025、両側 $p$-値が 0.05 に相当する。 $\omega_1$ これはほとんどの研究で使われている従来の有意水準なので、$p$-値 のより小さい $a_1=$ 0.025 の選択確率はすべて100％であると仮定するのは理にかなっている。結局のところ、結果が陽性だった研究をファイルの引き出しに入れる理由はないのである。次に定義するカットポイントは、$a_2=$ 0.05である。この範囲の結果については、選択確率を80%とする。それでもまだ高いが、明らかに有意な結果と比べると低くなる。次に、$a_2=$  0.05 から $a_3=$  0.5 までの大きな区間を指定し、この区間では選択確率が60%になるようにする。最後に、非常に高い $\geq$ 0.5 の $p$-値の研究については、$\omega_4=$ 35% とさらに低い確率を定義する。 

その結果、以下の Figure \@ref(fig:stepcurve)  に描かれているような選択モデルが生まれる。 


\vspace{2mm}

```{r stepcurve, warning = FALSE, message=F, echo=F, fig.align="center", out.width="56%",fig.cap="ステップ関数に基づいた選択モデル。", fig.width=6, fig.height=4.5}
library(ggplot2)

df = data.frame(x = c(0, 0.025, 0.05, 0.5, 1),
                y = c(1, 0.8, 0.6, 0.35, 0.35))


ggplot(data = df, aes(x = x, y = y)) +
  geom_step(cex = 1) +
  geom_vline(xintercept = 0.025, linetype = "dotted", color = "gray30") +
  geom_vline(xintercept = 0.05, linetype = "dotted", color = "gray30") +
  geom_vline(xintercept = 0.5, linetype = "dotted", color = "gray30") +
  geom_vline(xintercept = 1, linetype = "dotted", color = "gray30") +
  annotate("text", x = 0.10, y = 1.03, label = bquote(a[1]~"="~0.025), hjust = "left",
           color = "gray30") +
  annotate(geom = "curve", x = 0.095, y = 1.04, xend = 0.025, yend = 1.05, 
           curvature = .2, arrow = arrow(length = unit(2, "mm")), linetype = "solid",
           color = "gray30") +
  annotate("text", x = 0.15, y = 0.76, label = bquote(a[2]~"="~0.05), hjust = "left",
           color = "gray30") +
  annotate(geom = "curve", x = 0.145, y = 0.77, xend = 0.05, yend = 0.85, 
           curvature = .2, arrow = arrow(length = unit(2, "mm")), linetype = "solid",
           color = "gray30") +
  annotate("text", x = 0.6, y = 0.80, label = bquote(a[3]~"="~0.50), hjust = "left",
           color = "gray30") +
  annotate(geom = "curve", x = 0.59, y = 0.79, xend = 0.5, yend = 0.73, 
           curvature = .2, arrow = arrow(length = unit(2, "mm")), linetype = "solid",
           color = "gray30") +
  annotate("text", x = 0.86, y = 0.62, label = bquote(a[4]~"="~1), hjust = "right",
           color = "gray30") +
  annotate(geom = "curve", x = 0.87, y = 0.61, xend = 1, yend = 0.55, 
           curvature = .2, arrow = arrow(length = unit(2, "mm")), linetype = "solid",
           color = "gray30") +
  theme_classic() +
  ylab(bquote("Probability of Selection ("~omega~")")) +
  xlab("p-value") + 
  scale_x_continuous(breaks = c(0, 0.025, 0.05, 0.5, 1), expand = c(0, 0), limits = c(0, 1.05),
                     labels = c("0", "0.025", "0.05", "0.5", "1")) +
  scale_y_continuous(expand = c(0,0), limits = c(0, 1.1), 
                     labels = c("0%", "25%", "50%", "75%", "100%")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1),
        plot.background = element_rect(fill = "#FFFEFA", color = "#fbfbfb"),
        panel.background = element_rect(fill = "#FFFEFA"))
  
```


ステップ関数に基づく選択モデルを定義する場合、通常、カットポイント $a_i$  のみを指定する。これがこのモデルにおける唯一の固定パラメータで、選択確率 $\omega = \omega_1, \omega_2, \dots, \omega_c$  はデータから推定する。そして、式9.20の式に基づいて、選択モデルをデータに当てはめることが可能である。このとき、最尤法を使って、$\omega$  を共同で推定し、さらに、$\mu$  と $\tau^2$  の補正推定値（異なる選択確率を考慮したもの） $\omega$  を推定する。その結果、$\mu$  の補正された推定値は、想定される出版バイアスのメカニズムを制御した場合の真の平均効果量を表している。 

以前は、選択確率 $\omega$  を0%から100%までのパーセンテージで表現していた。しかし、選択モデルをあてはめるときには、$\omega_i$  は絶対的な選択確率としてではなく、選択の**相対的な尤度** という観点から推定される。これは、ステップ関数の最初の区間に基準値1を与えて、$\omega$  の他のすべての値は、この基準群との**関係で**選択の尤度を表すということである。たとえば、2番目の区間で $\omega_2$ =0.5 と推定すると、この区間の研究は、最初の区間（$\omega_1 = 1$）と比較して、選択される可能性が半分しかなかったことを意味する。 

もちろん、真の平均効果 $\mu$ の補正された推定値は、選択モデル自体が適切である場合にのみ正確となる。その目安は、選択モデル・パラメーターの尤度比検定（LRT）が有意であることである。この検定は、選択がなく、相対選択尤度がすべての区間で同一である（すなわち、$\omega_1 = \omega_2 = \dots = \omega_c$  ）という帰無仮説に基づく。しかし、この有意性検定は、しばしば反保守的な結果を出すことが分かっている[@hedges1996estimating]ことに注意しなければならない。つまり、その結果は慎重に解釈されるべきである。 

理論的には、選択モデルで使用するカットポイント $a_i$ の数は **ad libitum** （自由）に選択することが可能である。しかし、カットポイントを追加するごとに、$\omega_i$  の値を追加で推定しなければならない。メタ分析の規模にもよるが、これはすぐに、各区間で利用可能な研究がわずかである、という問題につながる。これは、各 $\omega_i$  を適切に推定することをますます困難にしている。したがって、多くのカットポイントを持つ複雑な選択モデルは、研究の数が多いときにのみ適用できる（つまり、$K \geq$  100）。 

\index{Three-Parameter Selection Model}

残念ながら、ほとんどのメタ分析では、少数の研究しか含まれていない。これは、非常に少ないカットポイントを持つ単純な選択モデルしか適用できないことを意味する。このような単純なモデルの1つの変形が、次に説明する**3パラメータ選択モデル**である。このモデルは、含まれる研究の数が少ない場合にも適用できるという利点がある（例： $K=$  15--20）。 


<br></br>

##### ３パラメータ選択モデル  {#three-param-selmodel}

---

３パラメータモデルは、カットポイントが1つしかない選択モデルである[@mcshane2016adjusting]。真の効果 $\mu$  、研究間異質性分散 $\tau^2$  、第2区間の相対尤度 $\omega_2$ の3パラメータだけを推定する必要があるので、 **3パラメータ** モデルと呼ばれている^[この区間は、選択尤度を1に固定した参照区分として機能するので、$\omega_1$  を推定する必要はない。]。

3パラメータ選択モデルにおいて、単一のカットポイント $a_1$  は0.025に設定され、これは片側 $p$ -値が0.05であることと等しくなっている。これは、$p$ -値の範囲を、統計的に有意とみなせるものと、有意でないものの2つのビンに分割するものである。したがって、$\omega_2$  は、有意でない結果が出版用に選択される確率を表している^[P 曲線（Chapter \@ref(p-curve)）は、特殊なタイプの3パラメータ選択モデルとして見ることが可能である。これも $p$ -値0.05を選択のカットポイントとして使用したが、有意な結果（選択確率が100％と仮定される）にのみ焦点を当てる。また、$\tau^2$  はゼロであると仮定される。これは、p-曲線では、データから実際に推定されるパラメータは1つだけ、すなわち真の効果量 $\mu$ であることを意味する。]。


\index{metafor Package}

 **{metafor}** パッケージの  `selmodel`  関数を使うと、 _R_  に様々な種類の選択モデルを当てはめることが可能である^[この文章を書いている時点では、  `selmodel`  関数は  **{metafor}**  の **開発版** からしか利用することができない。開発版の **{metafor}** は、まず **{remotes}** パッケージをインストールし、次のコードを実行することでダウンロード可能である。`remotes::install_github("wviechtb/metafor") `。その後、ライブラリから **{metafor}** を呼び出すと、`selmodel` 関数が使用できるようになる。なお、これを読んでいる頃には、すでに `selmodel` 関数は  **{metafor}** の標準バージョンに統合されている可能性が高いので、開発版のインストールは必要ない]。また、3パラメータの選択モデルにも使用することが可能であるので、これから試してみよう。前回と同様に、例として `ThirdWave` データセットを使用する。 

`selmodel` 関数は  **{metafor}**  の `rma` 関数によって作成されたメタ分析オブジェクトのみを受け取る（Chapter \@ref(multiple-metareg-R) を参照）。したがって、まずオブジェクトを作成する必要がある。`rma`  の呼び出しでは、  **{meta}**  の  `metagen`  関数 ( Chapter \@ref(pre-calculated-es) ) で使用したものと同じ設定を使用する。 


```{r, message=F}
library(metafor)

# 新しいオブジェクトの名前を 'm.rma' に設定
m.rma <- rma(yi = TE,        
             sei = seTE,
             data = ThirdWave,
             slab = Author,
             method = "REML",
             test = "knha")
```

`m.rma` オブジェクトを使用して、`selmodel` を使用して 3 パラメータの選択モデルを適合させることが可能である。関数にステップ関数を適用することを伝えるために、 `type` 引数を `"stepfun"` に設定する必要がある。引数 `steps` にはカットポイントを指定する。このモデルでは $a_1$ =0.025 となる。結果を見てみよう。

\vspace{4mm}

```{r, eval=F}
selmodel(m.rma,
         type = "stepfun",
         steps = 0.025)
```

```
## [...]
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   0.5893  0.1274  4.6260  <.0001  0.3396  0.8390  *** 
## 
## Test for Selection Model Parameters:
## LRT(df = 1) = 0.0337, p-val = 0.8544
## 
## Selection Model Results:
## 
##                      k  estimate      se    pval   ci.lb   ci.ub 
## 0     < p <= 0.025  11    1.0000     ---     ---     ---     ---    
## 0.025 < p <= 1       7    1.1500  0.8755  0.8639  0.0000  2.8660    
## 
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

`Model Results` の下で、選択モデルの真の平均効果量の推定値が $g=$  0.59 (95%CI: 0.34-0.84) であることを見ることが可能である。興味深いことに、この推定値は、以前に得たプール効果量( $g=$  0.58)とほぼ同じである。 

全体として、これはメタ分析が有意でない結果の低い選択確率によって実質的にバイアスされたことを**示さない**ことを示している。この結果は、 `Test of Selection Model Parameters` によって裏付けられ、有意ではない（$\chi^2_1=$  0.034, $p=$  0.85）ことから、$\omega_1$  と $\omega_2$  は互いに有意な差がないことを物語っている。 

`Selection Model Results`の下に、両方のビンにおける相対的な選択尤度の推定値が表示されている。 $\omega_2=$  1.15で、2番目のセグメントの選択確率が1番目のセグメントよりわずかに高いことがわかる。実質的な出版バイアスがある場合は、その逆で、有意でない結果の相対選択尤度は、有意な発見と比較してかなり**低く**なることが予想される。

感度分析として、$a_1$ を 0.025 から 0.05 に変更し、分析を再実行することが可能である。カットポイントを0.05に設定するということは、0.05と0.10の間の両側 $p$ -値は、0.05以下の値と同様に「出版可能」であると仮定することである。例えば、「傾向レベル」で有意な結果が選ばれる可能性がある、あるいは、元の研究の中には、研究グループの違いを評価するために片側検定を使っているものがある、などの可能性がある。このカットポイントの変更で結果が変わるかどうか見てみよう。

```{r, eval=F}
selmodel(m.rma,
         type = "stepfun",
         steps = 0.05)
```


```
## [...]
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   0.3661  0.1755  2.0863  0.0370  0.0222  0.7100  * 
## 
## Test for Selection Model Parameters:
## LRT(df = 1) = 3.9970, p-val = 0.0456
## 
## Selection Model Results:
## 
##                    k  estimate     se   pval   ci.lb   ci.ub 
## 0    < p <= 0.05  15    1.0000    ---    ---     ---     ---      
## 0.05 < p <= 1      3    0.1786 0.1665 <.0001  0.0000  0.5050  *** 
## 
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
```

\vspace{2mm}

興味深いことに、異なるパターンが見られる。新しい平均効果量推定値は、$g=$  0.37で、以前より小さくなっている。さらに、尤度検定は有意で、区間が異なることを示している。$\omega_2=$  0.18 で、選択尤度（両側） $p>$  0.1 は、（僅かに）有意な $p$ -値のものよりもずっと低いと見ることが可能である。 

このことは、プール効果が選択的な報告によってわずかに歪められている可能性を示している。特に、**明らかに**有意でない結果を示した研究がファイル引き出しに収められたためである。


<br></br>

##### 固定重み選択モデル  {#fixed-weights-selmodel}

---

先ほど説明した3パラメータ選択モデルでは、カットポイント $a_1$  を1つだけ指定し、選択尤度はモデルによって自由に推定することが可能である。前述したように、３パラメータ・モデルが1つのカットポイントしか使わないということは、比較的少ない研究のメタ分析にも適用可能である。これは、モデルがいくつかのビンにおいて「研究を使い果たす」可能性が低いことがある。 

しかし、選択尤度 $\omega_i$  をデータから推定する必要がなければ、選択モデルの大きなサンプルサイズの必要性を回避することができる。単に各区間の固定値 $\omega_i$  を与えて、課されたモデルのもとで $\mu$  の推定値がどうなるかをチェックすればよい。このアプローチは、より複雑な選択モデル（つまり、より多くのカットポイントを持つモデル）を適合させることができる一方で、欠点もある。 

このような**固定重み選択モデル**を課す場合、あらかじめ指定された $\omega_i$  の値がすべて正しいと単純に仮定することになる。しかし、モデルが適切でない場合、平均効果の推定値が信用できなくなることを意味する。したがって、固定ウェイトモデルは、想定した選択プロセスが適用された場合、真の効果量がどのように見えるか**を確認する方法と見なすべきである。 

Vevea and Woods [-@vevea2005publication] は、このようなマルチカットポイント、固定重みの選択モデルがどのように見えるかの例をいくつか示している。下のプロットは、中程度の選択と厳しい選択を表すステップ関数の2つの例を示している。 

\vspace{4mm}

```{r, echo=F, fig.width=4, fig.height=4, fig.align="center", out.width="55%"}
df = data.frame(x = rep(c(0.005, 0.01, 0.05, 0.10, 0.25, 0.35, 0.50, 0.65, 0.75, 0.90, 0.95, 0.99, 0.995, 1), 2),
                y = c(1, 0.99, 0.95, 0.80, 0.75, 0.65, 0.60, 0.55, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50, 1, 
                      0.99, 0.90, 0.75, 0.60, 0.50, 0.40, 0.35, 0.30, 0.25, 0.10, 0.10, 0.10, 0.10),
                Selection = c(rep("moderate", 14), rep("severe", 14)))


ggplot(data = df, aes(x = x, y = y, fill = Selection, color = Selection, linetype = Selection)) +
  geom_step(cex = 1) +
  theme_classic() +
  scale_color_manual(values = c("gray15", "gray60")) +
  ylab(bquote("Probability of Selection ("~omega~")")) +
  xlab("p-value") + 
  scale_x_continuous(breaks = 1:20/20, expand = c(0, 0), limits = c(0, 1.05)) +
  scale_y_continuous(expand = c(0,0), limits = c(0, 1), 
                     labels = c("0%", "25%", "50%", "75%", "100%")) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  theme(legend.position="top",
        plot.background = element_rect(fill = "#FFFEFA", color = "#fbfbfb"),
        panel.background = element_rect(fill = "#FFFEFA"))
```

感度分析として、これらの選択モデルがメタ分析に適切であると仮定したときに、$\mu$  の推定値がどのように変化するかを確認することが可能である。これを行うには、上に表示されたモデルで使われたすべてのカットポイント、および各区間に与えられた尤度 $\omega_i$  を定義する必要がある。


```{r}
# カットポイントを定義
a <- c(0.005, 0.01, 0.05, 0.10, 0.25, 0.35, 0.50, 
       0.65, 0.75, 0.90, 0.95, 0.99, 0.995)

# それぞれの信頼区間の選択尤度を定義
# (moderate/severe selection)
w.moderate <- c(1, 0.99, 0.95, 0.80, 0.75, 0.65, 0.60, 
                0.55, 0.50, 0.50, 0.50, 0.50, 0.50, 0.50)
w.severe <- c(1, 0.99, 0.90, 0.75, 0.60, 0.50, 0.40, 0.35, 
              0.30, 0.25, 0.10, 0.10, 0.10, 0.10)

```

これらのパラメータが定義されると、  `selmodel`  を呼び出す際に使用することが可能である。新しいカットポイントは  `steps`  引数に、固定尤度は  `delta`  に与える必要がある。


```{r, eval=F}
# 中程度の選択を仮定し、モデルを適合
selmodel(m.rma, type = "stepfun", steps = a, delta = w.moderate)
```

```
## [...]
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   0.5212  0.0935  5.5741  <.0001  0.3380  0.7045  *** 
##
## [...]
```


```{r, eval=F}
# 高度の選択を仮定し、モデルを適合
selmodel(m.rma, type = "stepfun", steps = a, delta = w.severe)
```

```
## [...]
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   0.4601  0.1211  3.8009  0.0001  0.2229  0.6974  *** 
## [...]
```

中程度の選択を代表する選択モデルを課した場合、プール効果量の推定値は $g=$  0.52であることがわかる。厳しい選択過程を仮定すると、$g=$  0.46という少し低い効果が得られる。 

これらの結果は、選択的出版をコントロールした場合でも、観察された効果がかなり頑健であることを示している。しかし、重要なのは、これらの推定値が有効なのは、私たちが規定した選択モデルが現実を代表している場合のみであるということである。 

```{block, type='boxinfo'}
**その他の選択モデル関数**

\vspace{2mm}

この例では、選択モデルの基礎となるステップ関数のみを取り上げた。しかし、選択過程をモデル化するために使える関数はこれだけではないことに注意する必要がある。`selmodel` 関数には、例えば、半正規分布、ロジスティック分布、負指数分布など、 **連続** 分布に基づいた関数もいくつか含まれている。これらのモデルは、 `type` 引数の仕様を変更することで選択することができる。

使用できるモデルについてすべて説明することはこのガイドの範囲外だが、 `selmodel` 関数のドキュメントが素晴らしいイントロダクションを提供している。このドキュメントには、 **{metafor}** がロードされた後に、 _R_ で `?selmodel` を実行することでアクセスすることができる。

```

<br></br>

## どの方法を使うべきか？  {#pub-bias-which-method}

---

以上で、出版バイアスの統計的手法に関する考察を終えたい。この章はかなり長くなってしまったが、なぜこれほど多くの異なるアプローチについて議論したのかと聞きたいのではないだろうか。1つの方法を選び、その方法で出版バイアスのリスクを評価し、次に進むだけでは十分ではないのだろうか？ 

短い答えは「ノー」である。出版バイアスの手法は依然として非常に活発な研究テーマであり、多くの研究が長年にわたってさまざまなアプローチの性能を評価してきました [例： @simonsohn2014es; @stanley2017limitations; @aert2016conducting; @mcshane2016adjusting; @rucker2011treatment; @terrin2003adjusting; @peters2007performance]。残念なことに、まだ明確な勝者は現れていない。それどころか、どの出版バイアス法も他のすべての方法を一貫して凌駕しているというエビデンスもある [@carter2019correcting]。 

出版バイアスの方法が異なると、結果が大きく異なることはよくあることで、実際によくあることである。この章の実践的な演習は、その好例である。毎回同じデータセットを使用してきたが、真のバイアス補正効果の推定値は、実質的にゼロから $g=$  0.59まで幅があった。このことは、手法の選択が結果、ひいては結論に大きな影響を与える可能性があることを強調している。いくつかの方法は、小規模研究の影響をコントロールするとプール効果が完全に消失することを示したが、他の方法は、最初の発見をほぼ裏付けるものであった。

この問題に対処するため、出版バイアスを評価する際には、常に**複数の**手法を用いることを勧める。どの方法がこのデータに最も適しているか、その結果が信頼に足るかどうかを知ることは、不可能ではないにしても、しばしば困難なことである。前述したように、選択的な報告がどの程度結果に影響を及ぼしているのか、正確なところは常に不明である。しかし、いくつかの出版バイアスの手法を適用することで、信頼できる真の効果の**範囲**に近いものを作り出すことが可能である。 

\index{PET-PEESE}
\index{P-Curve}\index{P-曲線}
\index{Three-Parameter Selection Model}

この範囲の大きさは、私たちの解釈を導くために使用することが可能である。例えば、PET-PEESE、p-曲線、３パラメータ選択モデルの両方が、最初のプール効果に近い推定値を得た場合、発見の頑健性に対する信頼性が高まる。しかし、各手法が一致しないことが判明した場合は、そうではない。これは、出版バイアスや小規模研究の影響がより不確実であることを意味し、プールされた効果の信頼性も同様に不確実である。

いずれにせよ、出版バイアス法の結果は、常に慎重に解釈されるべきである。出版バイアス分析の結果が論争に発展した例もある--たとえば、文献 "ego-depletion" [@friese2019ego] 。出版バイアスをコントロールする最善の方法は、未出版のエビデンスを適切に検索し、出版方法を全面的に変更することであることを心に留めておくことが重要である。私たちメタ分析者が思いつく出版バイアスの統計的「証明」は、どれもせいぜい弱いものである。

どの方式を適用するかを決定しやすくするために、各方式の長所と短所の簡単な概要を作成した（ Table \@ref(tab:pubtab)  参照）。 

```{r pubtab, echo=F, message=F}
library(kableExtra)
library(dplyr)
library(stringr)

dat = read.csv("data/pubbias_procon-ja.csv")

dat$長所 = str_replace_all(dat$長所, "BREAK", "")
dat$短所 = str_replace_all(dat$短所, "BREAK", "")

colnames(dat)[1] = " "
# dat[1,1]<- c("Duval & Tweedie  Trim-and-Fill")

kable(dat %>% mutate_all(linebreak), "html", booktabs = T, escape = FALSE, 
      align = "l", longtable = T, 
      caption = "出版バイアスを補正し真の効果量を推定する方法。長所と短所の概要。") %>% 
  kable_styling(latex_options = c("repeat_header"), 
                bootstrap_options = c("condensed", "striped"),
                font_size = 15) %>% 
  row_spec(0, bold=TRUE) %>% 
  column_spec(1, width = "2cm", bold = T) %>% 
  column_spec(2, width = "4cm") %>% 
  column_spec(3, width = "5cm") %>%
  column_spec(1, italic= FALSE) 

```


この表には統計的な考察と実際的な考察の両方が含まれており、包括的でも最終的でもないと見るべきだろう。出版バイアスの方法は現在進行中の研究分野であり、より多くのエビデンスが確立されれば、状況は違ってくる可能性がある。 

\index{Outlier}\index{外れ値}
\index{Heterogeneity}\index{異質性}
\index{I$^2$, Higgins \& Thompson's}

最後に、研究間異質性が高い場合に許容できる結果を提供する方法は、現在のところ存在しないことに留意が必要である [@aert2016conducting、すなわち $I^2 \approx$  75%]。つまり、異質性が非常に高いメタ分析の出版バイアス分析は、完全に避けるのが最善である。外れ値を含まない解析やより均質なサブグループでの解析は、しばしば実用的な回避策として使用できるが、一般的な問題を解決するものではない。 

$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block, type='boxquestion'}
**知識を試そう！**

\vspace{4mm}

1. 「出版バイアス」という言葉はどのように定義できるか？なぜメタ分析で問題になるのか？

\vspace{-2mm}

2. 他にどのような報告バイアスがあるか？少なくとも3つ挙げて説明しなさい。

\vspace{-2mm}

3. 疑わしい研究慣行（QRP）を2つ挙げ、どのようにメタ分析の妥当性を脅かすかを説明しなさい。

\vspace{-2mm}

4. 小規模研究効果法の基本的な前提を説明しなさい。

\vspace{-2mm}

5. データが小規模研究の効果を示すことがわかったとき、自動的に出版バイアスがあることを意味するか？

\vspace{-2mm}

6. p-曲線は、メタ分析に含まれるすべての研究の真の効果を推定するのか、それとも「有意な」効果量を持つすべての研究の真の効果だけを推定するのか、どちらか？

\vspace{-2mm}

7. どの出版バイアス法が一番性能が良いか。


\vspace{4mm}



**問題の解答は、本書の巻末 [Appendix A](#qanda9) にある。**

```

<br></br>

## 要約

* 出版バイアスは、ある研究が出版された文献の中で体系的に欠落している場合に発生し、その結果、私たちのメタ分析においても発生した。厳密には、出版バイアスは、ある研究が出版される確率がその結果に依存する場合に発生した。しかし、その他にも様々な**報告バイアス**が存在した。これらの報告バイアスも、ある知見がメタ分析に採用される可能性に影響を及ぼした。例えば、引用バイアス、言語バイアス、アウトカムバイアスなどである。

* また、例えば疑わしい研究の実施（QRP）などにより、**発表**されたエビデンスに偏りがある可能性もある。よくあるQRPは、$p$ -hackingとHARKingの2つで、どちらもメタ分析で効果を過大評価するリスクを高める可能性がある。

* 多くの出版バイアス法は、**小規模研究効果**という考えに基づいている。これらのアプローチは、驚くほど高い効果量を持つ小規模な研究だけが有意な結果を得て、それゆえ出版用に選択されると仮定している。これは、非対称のファンネルプロットをもたらし、出版バイアスの徴候となり得る。しかし、そうである必要はない。小規模研究の効果には、さまざまな「良性」の原因が考えられる。

* 比較的新しい手法である**p-curve**は、データ中の有意な効果( $p<$  0.05 )のパターンを見るだけで、証拠能力をコントロールできるという考えに基づいている。これは、真の効果の有無の検定に使用でき、その大きさを推定することができる。 

* **選択モデル**は非常に汎用性の高い手法で、様々な出版バイアスのプロセスをモデル化するために使用することが可能である。しかし、想定したモデルが適切である場合にのみ有効な結果が得られ、しばしば非常に多くの研究を必要とした。非常にシンプルな選択モデルである3パラメータモデルも、小規模なデータセットに使用することが可能である。

* 出版バイアスの手法は、他の手法を常に凌駕するものではない。したがって、常に**複数の**手法を適用し、補正後の効果量を慎重に解釈することが推奨される。未発表のエビデンスの徹底的な検索は、現在の統計的アプローチよりもはるかに優れた方法で出版バイアスのリスクを軽減する。 

<!--chapter:end:11-publication-bias-ja.Rmd-->

# (PART) 高度な分析  {-}

# 「マルチレベル」メタ分析  {#multilevel-ma}

---

<img src="_figs/multilevel_felder.jpg" />

<br></br>

\index{Multilevel Meta-Analysis}

<span class="firstcharacter">高</span>
度な分析へようこそ。このガイドの前のパートでは、ほとんどすべてのメタ分析に非常に関連すると思われるトピックに深く潜ってみよう。この背景を踏まえて、より高度なテクニックに進む。

以下の方法は、数学的な基礎がより複雑である、あるいは _R_ での実装であるため、「高度」であるとみなした。しかし、このガイドの前の章を読んでいれば、この後に続く内容を理解し、実装するのに十分な能力を備えているはずである。以下のトピックの多くは、それ自身の本に値するものであり、ここで取り上げるものは、簡単な紹介としてのみ考慮されるべきである。ここで取り上げた内容は、あくまでも簡単な紹介と考えていただきたい。 

最初の章では、「マルチレベル」メタ分析というトピックを扱う。なぜ「マルチレベル 」という言葉をカギカッコで囲むのか、不思議に思われるだろう。ある研究を「マルチレベル」メタ分析と表現することは、暗に「標準的な」メタ分析に比べて特別なものであることを示している。 

しかし、これは正しくはない。あらゆるメタ分析モデルは、結果をプールするために、データのマルチレベル構造を前提にしている [@pastor2018multilevel]。前の章で、私たちはすでに何度かマルチレベル（メタ分析）モデルを、知らないうちに使っている。 

マルチレベルメタ分析というと、すぐに思いつくのは**３レベルメタ分析モデル**ではないだろうか。このモデルは、確かに私たちが既に知っている固定効果モデルやランダム効果モデルとは多少異なる。そこで、この章では、まず、なぜメタ分析が自然にデータのマルチレベル構造意味をするのか、そして、従来のメタ分析をどのようにして3レベルモデルに拡張できるのかを説明する。また、いつものように、このようなモデルを _R_ でどのように適合させることができるかを、実際の例を使って見ていこう。 

<br></br>

## メタ分析の多階層性  {#multilevel-nature}

---

メタ分析がなぜデフォルトでマルチレベルになるのかを知るために、Chapter \@ref(rem)  で説明したランダム効果モデルの式に戻ってみよう。

\begin{equation}
\hat\theta_k = \mu + \epsilon_k + \zeta_k
(\#eq:mlm1)
\end{equation}

\index{Sampling Error}\index{サンプル誤差}

ランダム効果モデルで $\epsilon_k$ と $\zeta_k$ （「ゼータ」と読む） という項が導入されているのは、2つの変動源があると仮定しているからだと説明してきた。1つ目は、個々の研究のサンプルエラー( $\epsilon_k$ )によるもので、これにより効果量推定値が真の効果量から乖離することになる $\theta_k$ . 

2つ目の $\zeta_k$ は、研究間の異質性を表している。この異質性は、ある研究の真の効果量 $k$  が、やはり真の効果量**の包括的な**分布の一部に過ぎないという事実によって引き起こされる。この分布は、個々の真の効果量 $\theta_k$  が引き出されたところことがある。したがって、ランダム効果モデルにおける私たちの目的は、$\mu$  で示される真の効果量の分布の平均を推定することである。

 $\epsilon_k$ と $\zeta_k$ の2つの誤差項は、メタ分析データにおける「参加者」レベル（レベル1）と「研究」レベル（レベル2）の2つのレベルに対応している。以下の Figure \@ref(fig:multilevel1)  は、この構造を象徴している。 

\vspace{2mm}

```{r multilevel1, message = F, out.width = '100%', echo = F, fig.align='center', fig.cap="Multilevel structure of the conventional random-effects model."}
library(OpenImageR)
knitr::include_graphics('images/multilevel-model_col_sep.png')
```

\vspace{2mm}

最下層（レベル1）には、参加者（研究分野によっては、患者、検体など）がいる。これらの参加者は、より大きな単位であるメタ分析に含まれる研究の一部である。この上にある研究の層は、私たちの第２レベルを構成している。 

メタ分析を行う場合、レベル1のデータは通常すでに「プール」された形で届く（例えば、論文の著者は生データの代わりに研究サンプルの平均と標準偏差を提供してくれる）。しかし、レベル2（研究レベル）のプールは、メタ分析の一部として実行されなければならない。伝統的に、このようなタイプのデータは**ネスト**と呼ばれ、参加者が研究内に「ネスト」されていると言うことが可能である。

\index{Random-Effects Model}\index{ランダム効果モデル}

ここで、ランダム効果モデルの式 \@ref(eq:mlm1) に戻ってみよう。この式は暗黙のうちにメタ分析データのマルチレベル構造を記述している。これをより明確にするために、式を2つに分割し、それぞれが2つのレベルのうちの1つに対応するようにする必要がある。そうすると、次のような結果が得られる。 


\vspace{4mm}

**レベル1（参加者）モデル：**

\begin{equation}
\hat\theta_k = \theta_k + \epsilon_k 
(\#eq:mlm2)
\end{equation}

\vspace{2mm}

**レベル2（研究）モデル：**

\begin{equation}
\theta_k = \mu + \zeta_k
(\#eq:mlm3)
\end{equation}

\vspace{2mm}

すでにお気づきかもしれないが、最初の式の $\theta_k$ を2番目の式の定義に置き換えればよい。そうすると、先ほどのランダム効果モデルの式とまったく同じ式が得られる。固定効果モデルもこのように書くことが可能である。$\zeta_k$ をゼロに設定するだけである。明らかに、私たちのメタ分析モデルは、すでにマルチレベルの特性を 「内蔵」している。これは、私たちのデータでは、参加者が研究内でネストされていると仮定しているので、この特性を示している。

このように、メタ分析には多階層構造が備わっていることがわかる。データを生成した特定のメカニズムをよりよく捉えるために、この構造をさらに拡張することが可能である。そこで、**３レベルモデル** [@cheung2014modeling; @assink2016fitting] の出番となる。

\index{Unit-of-Analysis Problem}\index{分析単位問題}

統計的独立性は、メタ分析で効果量をプールするときの中心的な前提条件の一つである。効果量の間に依存関係がある（効果量に相関がある）場合、異質性を人為的に減少させ、その結果、偽陽性の結果につながる可能性がある。この問題は**解析単位エラー**として知られており、以前すでに取り上げた（Chapter \@ref(unit-of-analysis)  参照）。効果量の依存性は、様々な原因から生じる可能性がある [@cheung2014modeling]。

* **個々の研究の著者によって導入された依存性**: 例えば、研究を実施する科学者が複数のサイトからデータを収集したり、複数の介入を一つの対照群と比較したり、同じアウトカムを測定するために異なる質問票を使用したりすることがある。これらのシナリオのすべてにおいて、報告されたデータには何らかの依存性があると考えることが可能である。

* **メタ分析者自身によって導入される依存性**: 例として、ある心理メカニズムに注目したメタ分析を考えてみよう。このメタ分析には、世界の異なる文化圏（例えば、東アジアと西欧社会）で行われた研究が含まれている。心理メカニズムの種類によっては、同じ文化圏で行われた研究の方が、異なる文化圏で行われた研究よりも結果が似ていることもあり得る。

メタ分析モデルの構造に第3の層を組み込むことで、このような依存性を考慮することがでく。例えば、異なる質問票に基づく効果量が研究内でネストされているモデルが考えられる。あるいは、研究が文化圏にネストされているモデルを作成することもできる。これにより、次の図に示すような3階層のメタ分析モデルが構築される。

\vspace{2mm}

```{r multilevel2, message = F, out.width = '100%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/multilevel-model2_col_sep.png')
```

\vspace{2mm}

\index{Cluster Effect}

３レベルのモデルには3つのプール段階があることがわかる。まず、研究者自身が、一次研究の個々の参加者の結果を「プール」し、集約した効果量を報告する。次に、レベル2において、これらの効果量は、$\kappa$（「カッパ」と読む）で示されるいくつかの**クラスター**内にネストされている。これらのクラスタは、個々の研究（すなわち、多くの効果量が1つの研究にネストされている）、または研究のサブグループ（すなわち、多くの研究が1つのサブグループにネストされており、各研究は1つの効果量にのみ寄与する）のいずれかである可能性がある。 

最後に、集計されたクラスタ効果をプールすると、全体の真の効果量 $\mu$  になる。概念的には、この平均効果は、固定効果モデルまたはランダム効果モデルでプールされた真の効果 $\mu$ （「ミュー」と読む）に非常に近いものである。しかし、その違いは、私たちのデータにおける依存効果量を明示的に考慮したモデルに基づいている点にある。 

３レベルモデルの式は、これまでと同じレベル表記で書き表すことができる。最大の違いは、2つの数式ではなく、3つの数式を定義する必要があることだ。

\vspace{4mm}

**レベル1モデル：**

\begin{equation}
\hat\theta_{ij} = \theta_{ij} + \epsilon_{ij}
(\#eq:mlm4)
\end{equation}

\vspace{2mm}

**レベル2モデル：**

\begin{equation}
\theta_{ij} = \kappa_{j} + \zeta_{(2)ij}
(\#eq:mlm5)
\end{equation}

\vspace{2mm}

**レベル3モデル：**

\begin{equation}
\kappa_{j} = \mu + \zeta_{(3)j}
(\#eq:mlm6)
\end{equation}

\vspace{2mm}

ここで、$\hat\theta_{ij}$  は、真の効果量 $\theta_{ij}$  の推定値である。 $ij$  という用語は、「クラスタ $j$  にネストされているある効果量 $i$  」と読み替えることができる。パラメータ $\kappa_{j}$  はクラスタ $j$  の平均効果量であり、$\mu$  は全体的な平均母集団効果である。前と同じように、これらの数式をつなぎ合わせて、数式を1行に減らすことができる。

\begin{equation}
\hat\theta_{ij} = \mu + \zeta_{(2)ij} + \zeta_{(3)j} + \epsilon_{ij}
(\#eq:mlm7)
\end{equation}

ランダム効果モデルとは異なり、この式には**2つの**不均質性項が含まれていることがわかる。一つは $\zeta_{(2)ij}$で、これはレベル２の**クラスタ内** (within-cluster) 異質性である（つまり、 クラスタ $j$ 内の**真の**効果量は、平均 $\kappa_j$ の分布に従う）。もう一つは $\zeta_{(3)j}$ で、これはレベル３の**クラスタ間** (within-cluster) 異質性である。結果、３レベルメタ分析適合モデルでは、異質性分散 $\tau^2$ は一つではなく、レベル2用とレベル3用の２つ推計しなければならない。 

\index{meta Package}
\index{metafor Package}

 **{metafor}** パッケージは、特にメタ分析的な３レベルモデルの適合に適している。これは、（制限付き）最尤法を用いて行う。以前は、メタ分析の実行に主に **{meta}** パッケージの関数を使用していた。なぜなら **{meta}**  の方が若干専門的でなく、初心者に適しているためである。しかし、Chapter \@ref(multiple-metareg-R)  で見たように、 **{metafor}**  パッケージも、データを正しく準備すればかなり使いやすくなっている。具体的にどのように **{metafor}** を使って _R_ の３レベルモデルに適合させるかは、次のセクションのトピックになる。 


<br></br>

##  _R_ で３レベルのメタ分析モデルを適合  {#multilevel-R}

---

前述したように、３レベルのメタ分析モデルを適合させるためには、 **{metafor}** パッケージが必要である。そのため、まずライブラリからロードする必要がある。


```{r, message=F, warning=F}
library(metafor)
```


この例では、 `Chernobyl` データセットを使用する。このデータセットは、[1986年のチェルノブイリ原発事故 ](https://www.britannica.com/event/Chernobyl-disaster) [@moller2015strong] によって引き起こされた電離放射線（「核汚染」）とヒトの突然変異率の相関を調べた実際のメタ分析に緩く基づいている。 

\index{dmetar Package}

```{block, type='boxdmetar'}
**"Chernobyl" データセット**

\vspace{2mm}

`Chernobyl` データセットは **{dmetar}** パッケージに含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(TherapyFormats)` を実行すると、自動的に _R_ 環境にデータセットが保存される。これでデータセットが使用できるようになる。

\vspace{2mm}

**{dmetar}** がインストールされていない場合は、[Internet](https://www.protectlab.org/meta-analysis-in-r/data/Chernobyl.rda) から _.rda_ ファイルとしてデータセットをダウンロードし、作業ディレクトリに保存してから、R Studio ウィンドウでクリックしてインポートすることが可能である。

```

```{r, message=F, warning=F}
# Load data set from 'dmetar'
library(dmetar)
data("Chernobyl")
```


データの一般的な構造を見るために、  `head`  関数を使用すよう。これは、先ほどグローバル環境にロードしたデータフレームの最初の6行を表示する。

```{r, message=F, warning=F, eval=F}
head(Chernobyl)
```
```
##                       author  cor   n    z se.z var.z radiation es.id
## 1 Aghajanyan & Suskov (2009) 0.20  91 0.20 0.10  0.01       low  id_1
## 2 Aghajanyan & Suskov (2009) 0.26  91 0.27 0.10  0.01       low  id_2
## 3 Aghajanyan & Suskov (2009) 0.20  92 0.20 0.10  0.01       low  id_3
## 4 Aghajanyan & Suskov (2009) 0.26  92 0.27 0.10  0.01       low  id_4
## 5     Alexanin et al. (2010) 0.93 559 1.67 0.04  0.00       low  id_5
## 6     Alexanin et al. (2010) 0.44 559 0.47 0.04  0.00       low  id_6
```

\index{Fisher's \textit{z}}

このデータセットには8つの列がある。最初の列は  `author`  で、研究の名前が表示されている。`cor` 列は放射線被曝と突然変異率の（未変換の）相関を示し、`n` はサンプルサイズを示す。`z` ,  `se.z` ,  `var.z`  列は Fisher- $z$  で変換した相関（ Chapter \@ref(pearson-cors)  ）とその標準誤差および分散である。`radiation` 列はモデレーターとして機能し、効果量を全体的に放射線被曝量の低い (low) サブグループと高いサブグループに分割する。`es.id` 列には、各効果量（すなわち、データフレームの各行）の識別用 ID を格納している。 

このデータセットで特徴的なことは、 `author` に繰り返し入力されていることである。これは、このメタ分析におけるほとんどの研究が、1つ以上の観察された効果量に貢献しているからである。いくつかの研究では、突然変異を測定するためにいくつかの方法を用いたり、複数のタイプの指標となる人物（例えば、被曝した両親とその子孫）を用いたりしており、これらすべてが研究ごとに複数の効果をもたらす。 

この構造を見ると、私たちのデータセットの効果量が独立していないことは明らかである。これらはネスト構造になっており、様々な効果量が1つの研究にネストされている。したがって、私たちのデータにおけるこれらの依存性を適切にモデル化するために、３レベルのメタ分析に適合させることは良いアイデアだろう。

<br></br>

### モデルの適合

---

３レベルのメタ分析モデルは、 **{metafor}** の  `rma.mv`  関数を使用して適合させることが可能である。以下は、この関数の最も重要な引数のリストと、それらの引数の指定方法である。

* **`yi`**. 計算された効果量を含むデータセットの列の名前。この例では、これは  `z`  である。Fisher- $z$  で変換された相関は、"未変換 "の相関よりも数学的特性が優れていることがある。

* **`V`**. 計算された効果量の **分散** を含む、データセットの列の名前。この場合、 `var.z` となる。また、効果量の**2乗**標準誤差を使用することも可能である。 $SE_k^2 = v_k$  。 

* **`slab`**. **{meta}** の  `studlab`  と同様に、研究ラベルを含むデータセットの列の名前。

* **`data`**. データセットの名前。

* **`test`**. 回帰係数に適用する検定。`"z"` (デフォルト) と `"t"` （推奨; Knapp-Hartung 法に類似した検定を使用）から選択することが可能である。

* **`method`**. モデルのパラメータを推定するために用いる手法。REML（推奨；制限付き最尤法）とML（最尤法）の両方が利用可能。他のタイプの研究間不均一性推定量（例えば Paule-Mandel）はここでは適用できないことに注意しておこう。

しかし、最も重要な議論は、**`random`**である。間違いなく、最も厄介なものでもある。この引数では、（ネストされた）ランダム効果を定義する数式を指定する。3レベルモデルの場合、式は常に  `~ 1`  で始まり、縦棒  `|`  が続く。縦棒の後ろでは、グループ化変数（研究、測定、地域など）に**ランダム効果**を割り当てる。このグルーピング変数は、各グループに異なる効果（すなわち切片）を仮定するようにモデルに指示すので、しばしば **ランダム化切片** と呼ばれる。 

3レベルモデルでは、2つのグループ化変数がある。1つはレベル2で、もう1つはレベル3である。私たちは、これらのグルーピング変数がネストになっていると仮定する。すなわち、レベル2でのいくつかの効果が一緒になって、レベル3でのより大きなクラスタを構成している。 

このようなネストしたランダム効果を仮定するために、 `rma.mv` に特別な方法を指示すことが可能である。これは、スラッシュ（ `/` ）を使用して、上位と下位のグループ化変数を分離するものである。の左側には、レベル3（クラスタ）変数を入れる。右側には、大きなクラスタにネストされた低次の変数を入れる。したがって、式の一般的な構造は次のようになる: `~ 1 | cluster/effects_within_cluster` . 

この例では、個々の効果量（レベル2； `es.id` で定義）は、研究（レベル3； `author` で定義）内にネストされていると仮定している。この結果、以下の式が得られる: `~ 1 | author/es.id`。完全な  `rma.mv`  関数呼び出しは次のようになる。

\vspace{2mm}

```{r}
full.model <- rma.mv(yi = z, 
                     V = var.z, 
                     slab = author,
                     data = Chernobyl,
                     random = ~ 1 | author/es.id, 
                     test = "t", 
                     method = "REML")
```

出力には  `full.model`  という名前を付けることとした。結果の概要を表示すには、 `summary`  関数を使用する。

```{r, eval=F}
summary(full.model)
```
```
## Multivariate Meta-Analysis Model (k = 33; method: REML)
## [...]   
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed        factor 
## sigma^2.1  0.1788  0.4229     14     no        author 
## sigma^2.2  0.1194  0.3455     33     no  author/es.id 
## 
## Test for Heterogeneity:
## Q(df = 32) = 4195.8268, p-val < .0001
## 
## Model Results:
## 
## estimate      se    tval    pval   ci.lb   ci.ub 
##   0.5231  0.1341  3.9008  0.0005  0.2500  0.7963  *** 
## [...]
```

まず、「分散成分」 (Variance Components) を見てみよう。ここでは、モデルの各レベルについて計算されたランダム効果分散を見ることが可能である。最初の  `sigma^2.1`  は、レベル3の**クラスタ間**分散 (**between** cluster variance) を示している 。この例では、これは従来のメタ分析における研究間異質性分散 $\tau^2$  に相当する（クラスタがこのモデルにおける研究を表しているため）。 

2番目の分散成分  `sigma^2.2`  は、**クラスタ内**の分散 (**within** cluster variance)  （レベル2）を示している。`nlvls` の列では、各レベルのグループの数を示している。レベル3は14グループあり、$K=$  14件の研究に相当する。2行目に示すように、これらの14の研究は、33の効果量を含む。 

\index{esc Package}

`Model Results` の下に、プール効果の推定値がある。 $z=$  0.52 (95%CI: 0.25--0.80)である。解釈を容易にするために、効果を正規の相関に変換することが推奨される。これは、 **{esc}**  パッケージの  `convert_z2r`  関数を使用して行うことが可能である。

```{r}
library(esc)
convert_z2r(0.52)
```
この結果、約 $r \approx$  0.48 の相関が得られることがわかる。これは大きいといえるだろう。チェルノブイリの放射線被曝と突然変異率の間には、かなりの相関があるようだ。 

出力された「異質性の検定」は、私たちのデータにおける真の効果量の差を指摘している（ $p<$  0.001）。しかし、この結果は、あまり有益ではない。私たちは、私たちのモデルの各レベルによって捕捉された異質性の分散の正確な量に、より興味がある。異質性のどれだけが**研究内**の差（レベル2）に起因し、どれだけが**研究間**の差（レベル3）に起因しているかを知ることは良いことだろう。


<br></br>

### レベル間の分散分布

---

\index{I$^2$, Higgins \& Thompson's}

 $I^2$  [@cheung2014modeling] のマルチレベル版を計算することでこの疑問に答えることができる。従来のメタ分析では、$I^2$  はサンプリングエラーに起因しない変動量を表した（Chapter \@ref(i-squared) ;すなわち、研究間異質性）。3レベルモデルでは、この異質性の分散は2つの部分に分けられる：1つは**クラスタ内の**真の効果量の差に起因し、もう1つは**クラスタ間の**変動に起因するものである。したがって、レベル2またはレベル3のいずれかに関連する全変動のパーセンテージを定量化する2つの値（$I^2$）が存在する。 

\index{dmetar Package}

```{block, type='boxdmetar'}
**"var.comp" 関数**

\vspace{4mm}

`var.comp` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

\vspace{2mm}

1. 関数のソースコードにアクセスする [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R). 
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。
3. **{ggplot2}** パッケージがインストールされ、ロードされていることを確認する。

```


`var.comp`  関数は、フィットした  `rma.mv`  モデルのみを入力として必要とする。出力を  `i2`  に保存し、 `summary`  関数で結果を表示する。 

```{r}
i2 <- var.comp(full.model)
summary(i2)
```

出力では、3つのレベルのそれぞれに起因する全分散のパーセンテージが表示される。レベル1のサンプル誤差の分散は非常に小さく、およそ1％を占めるだけである。クラスタ内の異質性の分散である $I^2_{\text{Level 2}}$ の値ははるかに高く、合計で約40%になる。しかし、最も大きな割合を占めるのはレベル3である。クラスタ間（ここでは研究間）の異質性は、私たちのデータにおける全変動のうち、$I^2_{\text{Level 3}}=$ 59% を占めている。 

全体として、3番目のレベルではかなりの研究間異質性があることを示している。しかし、全体の分散の3分の1以上という大きな割合が、**研究内**の差によって説明できることもわかる。

また、この全分散の分布を視覚化することも可能である。`var.comp` の出力を `plot` 関数に代入するだけである。 


```{r, warning=F, message=F, fig.width=5, fig.height=5, out.width="55%", fig.align='center'}
plot(i2)
```

<br></br>

### モデルの比較

---

\index{Occam's Razor}

3レベルモデルの適合は、2レベルモデルよりもデータの変動をよりよく表す場合にのみ意味がある。２レベルモデルが３レベルモデルに匹敵する適合度を示すことがわかったら、**オッカムのカミソリ**を適用すべきである。というのも、３レベルモデルより２レベルモデルの方が複雑でなく、かつデータをうまく説明できることがある。

幸運なことに、 **{metafor}** パッケージは、３レベルモデルと1レベルを取り除いたモデルを比較することが可能である。これを行うには、再び  `rma.mv`  関数を使用した。しかし、今回は、1つのレベルの分散成分をゼロに設定した。これは、  `sigma2`  パラメータを指定することにより可能である。`c(level 3, level 2)`という一般的な形式のベクトルを用意する必要がある。このベクトルには、分散成分をゼロにする場合は `0` を記入し、データからパラメータを推定する場合は `NA` を使用する。 

この例では、個々の効果量を研究に入れ込むことでモデルが改善されたかどうかを確認することは理にかなっている。したがって、私たちは、研究間の異質性を表すレベル3分散がゼロに設定されたモデルを適合させる。これは、すべての効果量が独立であると仮定する（独立でないことは分かっている）単純なランダム効果モデルの適合と同じである。レベル3はゼロで一定なので、  `sigma2`  の入力は  `c(0, NA)`  となる。この結果、以下のように  `rma.mv`  が呼び出され、その出力が  `l3.removed`  という名前で保存される。

\vspace{2mm}


```{r, echo=F}
l3.removed <- rma.mv(yi = z, 
                     V = var.z, 
                     slab = author,
                     data = Chernobyl,
                     random = ~ 1 | author/es.id, 
                     test = "t", 
                     method = "REML",
                     sigma2 =  c(0, NA))

```


```{r,eval=F}
l3.removed <- rma.mv(yi = z, 
                     V = var.z, 
                     slab = author,
                     data = Chernobyl,
                     random = ~ 1 | author/es.id, 
                     test = "t", 
                     method = "REML",
                     sigma2 =  c(0, NA))

summary(l3.removed)
```

```
## [...]
## Variance Components:
## 
##             estim    sqrt  nlvls  fixed        factor 
## sigma^2.1  0.0000  0.0000     14    yes        author 
## sigma^2.2  0.3550  0.5959     33     no  author/es.id 
## 
## Test for Heterogeneity:
## Q(df = 32) = 4195.8268, p-val < .0001
## 
## Model Results:
## 
## estimate      se    tval    pval   ci.lb   ci.ub 
##   0.5985  0.1051  5.6938  <.0001  0.3844  0.8126  *** 
## [...]
```

\index{Analysis of Variance}\index{分散分析}

出力では、 `sigma^2.1` がゼロに設定されていることがわかる。全体の効果も変化している。しかし、この結果は3レベルモデルのものよりも良いのだろうか？これを評価するために、  `anova`  関数を使って両モデルを比較することが可能である。

```{r, eval=F}
anova(full.model, l3.removed)
```

```
##         df   AIC   BIC  AICc logLik   LRT   pval      QE 
## Full     3 48.24 52.64 49.10 -21.12              4195.82 
## Reduced  2 62.34 65.27 62.76 -29.17 16.10 <.0001 4195.82
```


２レベルの「縮小」モデルに比べ、「完全」（３レベル）モデルはより適合度が高いことがわかる。赤池情報量規準（Akaike Information Criterion, AIC）とベイズ情報量規準（Bayesian Information Criterion, BIC）は、このモデルの方が低く、良好な性能を示している。両モデルを比較した尤度比検定 (Likelihood Ratio Test, `LRT`) は有意であり ( $\chi^2_1=$  16.1, $p<$  0.001) 、同じ方向を向いている。 

3レベルモデルは、1つの追加パラメータを導入したが（すなわち、自由度が2ではなく3）、この追加された複雑さは正当化されるようだと言える。ネストのデータ構造のモデリングは、おそらく良いアイデアで、プール効果の推定値を改善してきた。

しかし、3階層構造を維持することには、たとえそれが有意に優れた適合性を提供しない場合であっても、しばしば正当な理由があることに留意してみよう。特に、3階層モデルが確かな理論的根拠に基づいていると考えられる場合には、3階層モデルを維持することは理にかなっている。 

例えば、複数の効果量を持つ研究がデータに含まれている場合、これらの効果が独立していることはありえないということが**わかる**。したがって、ネスティッドモデルを維持することは、データがどのように「生成」されたかをより適切に表現しているため、理にかなっている。もし、この例の anova の結果が2レベル解を支持していたなら、私たちは研究内の効果は**大きく**均質であると結論付けたことだろう。しかし、いずれにせよ、3レベルモデルの結果を報告しただろう。これは、3レベルモデルがデータ生成過程をよりよく表現していることを知っていることがある。 

クラスタ変数の重要性が不明確な場合、状況は多少異なる。たとえば、３レベル・モデルにおいて、レベル3のクラスタが異なる文化圏を表すとした。研究対象の現象が文化間の変化を示さないことがわかったら、3番目のレベルを削除して、代わりに２レベル・モデルを使用してもまったく問題ない。 

<br></br>

## 三階層モデルにおけるサブグループ解析  {#three-level-subgroup}

---

\index{Subgroup Analysis}\index{サブグループ解析}
\index{Moderator Analysis}

３レベルモデルが設定されると、全体効果の推定モデレータを評価することも可能になる。このガイドの前では、サブグループ解析が、ダミー・コード化された予測変数（ Chapter \@ref(the-metareg-model)  ）のメタ回帰モデルとして表現できることを発見してきた。同様にして、私たちは 「マルチレベル」モデルに回帰項を追加することができ、これは **３レベル混合効果モデル** につながる。


\begin{equation}
\hat\theta_{ij} = \theta + \beta x_i + \zeta_{(2)ij} + \zeta_{(3)j} + \epsilon_{ij}
(\#eq:mlm8)
\end{equation}

ここで、$\theta$  は切片、$\beta$  は予測変数 $x$  の回帰重みである。 $x_i$  をダミー ( Chapter \@ref(the-metareg-model) ) に置き換えると、サブグループ解析に使用できるモデルが得られる。 $x$  が連続的であるとき、上記の式は３レベルのメタ回帰モデルを表す。   

カテゴリまたは連続の予測変数は、  `rma.mv`  で  `mods`  引数を用いて指定することが可能である。この引数には、チルダ（ `~` ）で始まる数式と、その後に予測変数の名前を指定した。複数の予測変数（例：  `~ var1 + var2` ）を指定することで、多重メタ回帰を行うことも可能である。 

チェルノブイリの例では、サンプルに含まれる放射線の量（低、中、高）によって相関が異なるかどうかを確認したい。この情報は、データセットの  `radiation`  列で提供されている。このコードを使って3レベルモデレータモデルを適合させることがでく。

\vspace{2mm}

```{r, message=F, warning=F, eval=F}
mod.model <- rma.mv(yi = z, V = var.z, 
                    slab = author, data = Chernobyl,
                    random = ~ 1 | author/es.id, 
                    test = "t", method = "REML",
                    mods = ~ radiation)

summary(mod.model)
```

```
## [...]
## Test of Moderators (coefficients 2:3):
## F(df1 = 2, df2 = 28) = 0.4512, p-val = 0.6414
## 
## Model Results:
##                 estimate    se   tval  pval  ci.lb ci.ub 
## intrcpt             0.58  0.36   1.63  0.11  -0.14  1.32    
## radiationlow       -0.19  0.40  -0.48  0.63  -1.03  0.63    
## radiationmedium     0.20  0.54   0.37  0.70  -0.90  1.31    
## [...]
```

最初の重要な出力は  `Test of Moderators`  である。 $F_{2,28}=$  0.45、$p=$  0.64であることがわかる。これは、サブグループ間に有意な差がないことを意味した。 

`Model Results` はメタ回帰の枠組みで表示される。これは、サブグループ内のプール効果量を得るために、推定値を直接抽出することができないことを意味した。 

 $z$  最初の値である切片（ `intrcpt` ）は、全体の放射線被曝量が高い場合（ $z=$  0.58）の値を示している。低線量群および中線量群における効果は、切片の値にそれらの推定値を加えることによって求めることがでく。したがって、低線量被曝群における効果は $z$  = 0.58 - 0.19 = 0.39 であり、中線量被曝群における効果は $z$  = 0.58 + 0.20 = 0.78 である。 

```{block2, type='boxreport'}
**Reporting the Results of Three-Level (Moderator) Models**

\vspace{2mm}

When we report the results of a three-level model, we should at least mention the estimated variance components alongside the pooled effect. The `rma.mv` function denotes the random-effects variance on level 3 and 2 with $\sigma^2_1$ and $\sigma^2_2$, respectively. 

When we report the estimated variance, however, using $\tau^2_{\text{Level 3}}$ and $\tau^2_{\text{Level 2}}$ may be preferable since this makes it clear that we are dealing with variances of **true (study) effects** (i.e. heterogeneity variance). Adding the multilevel $I^2$ values also makes sense, since they are easier for others to interpret--provided we first explain what they represent. 

\vspace{2mm}

When you conducted a model comparison using `anova`, you may at least report the results of the likelihood ratio test. Results of moderator analyses can be reported in a table such as the one presented in Chapter \@ref(subgroup-R). Here is one way to report the results in our example:

> _"The pooled correlation based on the three-level meta-analytic model was $r=$ 0.48 (95%CI: 0.25-0.66; $p$ < 0.001). The estimated variance components were $\tau^2_{\text{Level 3}}=$ 0.179 and $\tau^2_{\text{Level 2}}=$ 0.119. This means that $I^2_{\text{Level 3}}=$ 58.22% of the total variation can be attributed to between-cluster, and $I^2_{\text{Level 2}}=$ 31.86% to within-cluster heterogeneity. We found that the three-level model provided a significantly better fit compared to a two-level model with level 3 heterogeneity constrained to zero ($\chi^2_1=$ 16.10; $p$< 0.001)."_

```

<br></br>

## ロバスト分散推定  {#rve}

---

前章では、**3階層メタ分析モデル**を紹介し、のデータにおける**効果量間の依存性**をモデル化するために、どのように使用できるかを説明してきた。前章で取り入れた階層型モデルは、効果量が完全に独立しているとする「従来の」メタ分析よりも、明らかに私たちのデータセットを**より良く表現**している。しかし、これはまだ**現実の単純化**である。実際には、効果量間の依存関係は、現在のネストモデルで捉えられるものよりも複雑であることが多いのである。

チェルノブイリのデータセットに戻ると、すでにこのことがわかる。このデータでは、ほとんどの研究が**複数の効果量**を提供しているが、その**理由**は研究によって異なっている。いくつかの研究では、**異なる対象集団**における放射線の影響を比較しており、そのため複数の効果量を報告している。また、**同じサンプル**に対して異なる方法を用いた研究もあり、これも複数の効果量が報告されていることを意味する。 

一つの研究の複数の効果量が同じサンプルに基づいている場合、それらの**サンプリングエラー**（Chapter \@ref(multilevel-nature) と Chapter \@ref(three-level-subgroup) の 式 10.7 and 10.8 における $\epsilon_ {ij}$）には**相関がある**と期待される。しかし、このことは、今回の３レベルモデルではまだ捉えられていない。上記のモデルは、クラスタ/研究内では、サンプル誤差の相関（つまり共分散）がゼロであることを仮定している。つまり、1つのクラスタまたは研究内では、効果量の推定値は**独立である**と仮定している。 

```{r multilevel3, message = F, out.width = '100%', echo = F, fig.align='center', fig.cap="In its original form, the three-level (hierarchical) model assumes that effect size estimates within studies or clusters are independent."}
library(OpenImageR)
knitr::include_graphics('images/multilevel-model3_col_sep.png')
```


このセクションでは、拡張された３レベル構造、いわゆる**相関・階層効果** (Correlated and Hierarchical Effects, CHE) モデル [@pustejovsky2021meta]に時間を割くこととする。以前の（階層的）3レベルモデルと同様に、CHEモデルは、ある共通点（例えば、同じ研究、作業グループ、文化的地域などに由来する）に基づいて、いくつかの効果量を**大きなクラスタ**に**結合**することが可能である。 

しかし、それに加えて、このモデルでは、クラスタ内のいくつかの効果量が**同じサンプルに基づいて**おり（例えば、複数の測定が行われたため）、したがってそれらのサンプル誤差は**相関している**ことを明示的に考慮しているのである。特に、データの依存性構造が**複雑**であったり、**部分的にしか知られていない**場合、[@pustejovsky2021meta]^[Pustejovsky and Tipton [-@pustejovsky2021meta] も CHE モデルが適切か、いつ適切かを決定するための決定木を提供している(【図1】( https://link.springer.com/content/pdf/10.1007/s11121-021-01246-3.pdf) 参照)。CHE モデルがデータに対して最適な仮定を提供するか、あるいは他の作業モデルがより合理的かどうかをチェックする方法として、発見を目的として使用することが可能である。]。

CHE モデルとともに、メタ分析の文脈における**ロバスト分散推定** (Robust Variance Estimation, RVE) についても説明する [@hedges2010robust; @tipton2015small; @tipton2015small2]。これは、過去にメタ分析で従属効果量を扱うために頻繁に使用されてきた一連の方法である。RVEの中核は、いわゆる**サンドイッチ推定量**を中心に展開されている。この推定量は、CHEモデル（および他のメタ分析モデル）と組み合わせて、ロバストな信頼区間と $p$-値を得るために使用することが可能である。選択したモデルが、データの複雑な**依存構造**を完全に**うまく捉えていない**場合でも、である。

そこで、最初の CHE モデルの適合の前に、**メタ分析 RVE の概要**と **サンドイッチ推定量** について、後者がなぜそのような魅力的な名前を持っているのかを探ってみよう。 

<br></br>

### サンドイッチ型分散推定量  {#sandwich}

---

発表されたメタ分析では、「ロバスト分散推定」という言葉が**特殊な使われ方**をしていることがあり、これが依存効果量を持つメタ分析データに**のみ適用できる**特殊な方法であると思われることがある。その逆である。ロバスト分散推定量は、もともと**従来の回帰モデル**のための手法として開発されたもので、**回帰重みの分散**を計算するために使われる $\hat\beta$  [@aronow2019foundations, chapter 4.2.2 など参照]. 

この推定量は、線形モデルの通常の仮定が満たされない場合でも、漸近的な標準誤差の推定値が得られるため、「ロバスト」推定量と呼ばれる ^[その一つが、**同質散布性** (homoskedasticity) と呼ばれる残差分散の均質性である。同質散布性は、係数分散の「古典的」推定値が有効であるために必要な他の仮定のうちの1つである。] 。回帰モデルにおける係数分散のロバスト推定は非常に重要である。分散推定値 ^[あるいはむしろその**平方根**で、これは係数の**標準誤差**を表す。 $\sqrt{V_{\hat\beta}}={SE}_{\hat\beta}$] は、$p$-値と同様に、推定回帰重量の周りの**信頼区間** を計算するために使われ、したがってモデルから引き出す推測に直接影響を持つ。 

ここで取り上げるロバスト分散推定量は、「通常の」回帰モデルで使用されるオリジナルの手法の**特別バージョン** に過ぎないのである。Hedges, Tipton and Jackson [-@hedges2010robust] は、**依存効果量** のある**メタ回帰** モデルに使用できる**適応型** のRVEを発表し、このアプローチはここ数年で拡張されている。 

これを理解するためには、まずメタ回帰の**式**をもう一度見てみる必要がある。概念的には、この式は Chapter \@ref(the-metareg-model)  で紹介した式 8.2 と非常によく似ている。それを単に**行列表記**で表示すだけですある^[本章では、メタ分析的 RVE を論じる際に、Hedges, Tipton and Jackson [-@hedges2010robust] とそのフォローアップ論文の表記法をほぼ踏襲した]。

\begin{equation}
\boldsymbol{T}_{j}=\boldsymbol{X}_{j}\boldsymbol{\beta} + \boldsymbol{u}_j +\boldsymbol{e}_j
(\#eq:mlm9)
\end{equation}


この式は、単純に、$\boldsymbol{T}$ のある **効果量** が、$\boldsymbol{X}$ のある**共変量**と関連した**回帰の重み** $\beta$  によって予測されることを教えてくれる。また、**サンプルエラー**（$\boldsymbol{e}_j$  で記号化）以外に、各研究の**ランダム効果**（$\boldsymbol{u}_j$  で表記）があり、それによって（混合効果）メタ回帰モデルを生成していることも教えてくれる。 

特別なのは、この式の添え字 $j$ である。これは、式中の**文字**が**太字** であることとともに、データセット中の各研究またはクラスタ $j$  が**複数の効果量** を提供する、または提供できることを示している。 $n_j$  は、ある研究 $j$  における効果量の数であるとする。そして、$j$  の効果量は、式で見る列ベクトルとして書き下すことが可能である。$\boldsymbol{T}_j = (T_{j,1}, \dots, T_{j,{n_j}})^\top$. 同様に、 $\boldsymbol{X}_j$ は $j$ の共変量を含む**デザイン行列**であり、

\begin{equation}
\boldsymbol{X}_j =
\begin{bmatrix}
 x_{1,1}    & \cdots & x_{1,p}    \\ 
 \vdots     & \ddots & \vdots     \\
 x_{n_j,1}  & \cdots & x_{n_j,p}
\end{bmatrix}
(\#eq:mlm10)
\end{equation}


ここで $p-1$ は共変量の総数である^[線形回帰モデルでは、**デザイン行列**（または**モデル行列**）には、回帰係数を推定するために使用されるすべての**共変量値**が含まれている。最も簡単な形では、デザイン行列は**共変量のデータフレーム**とみなすことができ、最初の列に1の列が追加される。この最初の列は、回帰の**切片** をモデル化するために使用される。メタ回帰で、3つの共変量があると仮定する。データ集合の4番目の研究が3つの効果量に寄与する場合、そのデザイン行列は: $$\boldsymbol{X}_4 = \begin{bmatrix} 1  & 4.5 & 0 & 2  \\  1  & 7.3 & 1 & 2 \\ 1  & 2.4 & 0 & 2 \end{bmatrix}$$]。推定したい回帰係数のベクトル $\boldsymbol{\beta} = (\beta_1, \dots, \beta_{p})^\top$ には、**添字 $j$ は含まれていない**。なぜなら、回帰係数は全ての研究で同じと仮定されているからである。 

全体として、この表記は、研究が複数の効果量に貢献できる場合、私たちのデータは、いくつかの小さなデータセットを**積み重ねたように見える**ことを強調している。 $J$  は、私たちのデータにおける研究またはクラスターの合計数である。

\begin{equation}
\begin{bmatrix}
 \boldsymbol{T}_1 \\
 \boldsymbol{T}_2 \\
 \vdots \\
 \boldsymbol{T}_J
\end{bmatrix}
=
\begin{bmatrix}
 \boldsymbol{X}_1 \\
 \boldsymbol{X}_2 \\
 \vdots \\
 \boldsymbol{X}_J
\end{bmatrix}
\boldsymbol{\beta}
+
\begin{bmatrix}
 \boldsymbol{u}_1 \\
 \boldsymbol{u}_2 \\
 \vdots \\
 \boldsymbol{u}_J
\end{bmatrix}
+
\begin{bmatrix}
 \boldsymbol{e}_1 \\
 \boldsymbol{e}_2 \\
 \vdots \\
 \boldsymbol{e}_J 
\end{bmatrix}.
(\#eq:mlm11)
\end{equation}

この式に基づいて、メタ回帰の係数 $\boldsymbol{\hat\beta}$ を推定することができる。信頼区間を計算し、係数の有意性検定を行うには、その**分散**の推定が必要である。これはロバストサンプリング分散推定量 $\boldsymbol{V_{\hat\beta}}$ を使って実現可能である。その式は次のようになる [@hedges2010robust; @pustejovsky2021meta, suppl. S1]。

\begin{equation}
\scriptsize\boldsymbol{V}^{\text{R}}_{\boldsymbol{\hat\beta}} =
\left(\sum^J_{j=1}\boldsymbol{X}_j^\top\boldsymbol{W}_j\boldsymbol{X}_j \right)^{-1} 
\left(\sum^J_{j=1}\boldsymbol{X}_j^\top\boldsymbol{W}_j \boldsymbol{A}_j\Phi_j \boldsymbol{A}_j \boldsymbol{W}_j \boldsymbol{X}_j \right)
\left(\sum^J_{j=1}\boldsymbol{X}_j^\top\boldsymbol{W}_j\boldsymbol{X}_j \right)^{-1} 
(\#eq:mlm12) 
\end{equation}


この式はかなり複雑に見えるので、細部まで理解する必要はないだろう。今重要なのは、**形式**と、その**「成分」**の一部である。

まず、この式が**三分木構造**であることがわかる。左右の括弧で囲まれた部品は、真ん中の部品を取り囲むように同じものが並んでいる。これは、外側の部分が「パン」で内側の部分が「肉」であるサンドイッチのように見え、**「サンドイッチ推定量」**と名付けられた所以である。この式の重要な「材料」は、$\boldsymbol{\Phi}_j$,  $\boldsymbol{W}_j$ and $\boldsymbol{A}_j$ の行列である。

- まず1つ目。$\boldsymbol{\Phi}_j=\text{Var}(\boldsymbol{u}_j +\boldsymbol{e}_j)$, は、$ n_j $ 行と $ n_j $ 列の**分散共分散行列** (variance-covariance matrix) である。これは、研究 $j$ の**真の依存構造**を表している [@pustejovsky2021meta, Suppl. S1]。残念ながら、効果量が研究内でどのように、どの程度相関しているかはほとんど知られておらず、私たちのメタ分析で**すべての**研究に関してこれを知ることはさらに困難である。したがって、このモデルでは、いくつかの単純化した仮定を置く必要がある^[Hedges, Tipton and Jacksonによるオリジナルのアプローチ [-@hedges2010robust] では、 $\boldsymbol{\Phi}_j$ は **cross-product of the model residuals** $\boldsymbol{\Phi}_j=\boldsymbol{e}_j{\boldsymbol{e}_j}^\top$ に置き換えられる。これはすぐに使うことができるからである。これは真の依存構造の粗い推定値であるが、メタアナリシスにおける研究数が多い場合には「最良の推定値」として機能する。]。CHE モデルは、例えば、効果量間の**既知の相関** (known correlation) $\rho$ があり、 $\rho$ は**全ての研究で同じ値**という仮定がある [「一定標本相関」の仮定、@pustejovsky2021meta]。

- $\boldsymbol{W}_j$  行列には、各効果量の **重み** が含まれている。前の章（ \@ref(fem) and \@ref(metareg-model-fit) 参照）で、効果量推定値の **精度** を考慮に入れてからプールする必要があることを既に学びんだ。これを行う最適な方法は、**分散の逆数**を取ることであり、これは、$\boldsymbol{W}_j = \boldsymbol{\Phi}^{-1}_j$   を意味する。先ほど述べたように、$\boldsymbol{\Phi}_j$  の真の値はほとんど知られていないので、私たちのモデルに基づく推定値、$(\boldsymbol{\hat\Phi}_j)^{-1}$ が使われる^[Hedges、Tipton、Jackson によるオリジナルのアプローチ [-@hedges2010robust] では、単純化対角重み行列を用いた別の方法を採用しているので、おおむね効率が良い].

- 最後の $\boldsymbol{A}_j$  は**調整行列**で、**メタ分析の研究数が少ない** [例えば40以下, @hedges2010robust; @tipton2015small] でも推定量が有効な結果を提供できるようにするものである。推奨されるアプローチは、bias-reduced linearization、つまり**"CR2" 法**に基づく行列を使うことである[@tipton2015small]^[CR2調整行列は次のようなものである。$$\scriptsize \boldsymbol{A}^{\text{CR2}}_j = \boldsymbol{W}_j^{-1/2}\left\{\boldsymbol{W}_j^{-1/2} \left[\boldsymbol{W}_j^{-1}-\boldsymbol{X}_j \left(\sum^J_{j=1}\boldsymbol{X}_j^\top\boldsymbol{W}_j\boldsymbol{X}_j \right)^{-1} \boldsymbol{X}_j^\top \right] \boldsymbol{W}_j^{-1/2}\right\}^{-1/2} \boldsymbol{W}_j^{-1/2}.$$ It entails taking the symmetric square root of the weight matrix $\boldsymbol{W}_j$.]。

<br></br>

### ロバスト分散推定を用いたCHEモデルの適合  {#fit-rve}

---

それでは、最初の相関・階層効果モデルを *R* で**適合**させ、同時に**ロバスト分散推定**を採用し、モデルの**誤指定**を防ぐ。前回と同様に、 **{metafor}** の  `rma.mv`  関数を使用してモデルを実行した。今回は、 **{clubSandwich}** パッケージ [@clubSandwich]が提供するいくつかの追加関数も必要である。そのため、必ずパッケージを**インストール**し、ライブラリから**ロード**してみよう。

```{r, eval=F}
library(clubSandwich)
```

上記のように、CHEモデルは、研究またはクラスター内の効果量が**相関**しており、この相関は研究内および研究間で同一であると仮定している。 

したがって、モデル内で使用する**相関係数**を定義する必要がある。今回のチェルノブイリのデータでは、相関が大きいと仮定して、$\rho$ =0.6としよう。これは推測に過ぎず、$\rho$  の値を変えながら**複数の感度分析**を行うことを強く勧める。

```{r, eval=F}
# constant sampling correlation assumption
rho <- 0.6
```

さて、この相関を利用して、各研究の仮定された**分散共分散行列**を計算することが可能である。これは、 **{clubSandwich}** の  `impute_covariance_matrix`  関数を使用して行う。

- `vi`の引数には、各効果量の*分散*（すなわち、標準誤差の二乗）を含むデータセットの変数名を指定した。
- `cluster` 引数は、各効果量を **study** または **cluster** に関連付ける変数を定義する。`Chernobyl` データセットでは、これは `author` である。 
- 引数  `r`  は、効果量間の**定数相関係数**を想定している。

```{r, eval=F}
# constant sampling correlation working model
V <- with(Chernobyl, 
          impute_covariance_matrix(vi = var.z,
                                   cluster = author,
                                   r = rho))
```

`V` で準備した分散共分散行列を用いて、`rma.mv` モデルの適合を行うことができるようになる。 Chapter \@ref(three-level-subgroup)  と同じメタ回帰モデルで、共変量として `radiation` を用いて解析するとする。 

最初の引数は `formula` オブジェクトで、効果量 `z` が切片 (`1`) と共変量 `radiation` によって予測されることを関数に渡した。`V` 引数には、先ほど作成した分散共分散行列のリストを渡す。また、 `sparse` 引数を `TRUE` に設定することで、計算を高速化することが可能である。 

引数 `random` と `data` だけが同じである。結果は  `che.model`  という名前で保存される。

```{r, eval=F}
che.model <- rma.mv(z ~ 1 + radiation,
                    V = V,
                    random = ~ 1 | author/es.id,
                    data = Chernobyl,
                    sparse = TRUE)
```

メタ回帰係数の**信頼区間** を計算するために、 **{clubSandwich}**  の  `conf_int`  関数を使用することが可能である。フィットしたモデルを指定し、 `vcov` で使用する**小サンプル調整** を指定するだけである。推奨通り、 `"CR2"` 調整を使用する ( Chapter \@ref(sandwich)  参照)。


```{r, eval=F}
conf_int(che.model, 
         vcov = "CR2")
```

```
##            Coef. Estimate    SE d.f. Lower 95% CI Upper 95% CI
##          intrcpt    0.584 0.578 1.00        -6.76         7.93
##     radiationlow   -0.190 0.605 1.60        -3.52         3.14
##  radiationmedium    0.207 0.603 1.98        -2.41         2.83
```

`Estimate` の点推定値は、Chapter \@ref(three-level-subgroup)  で得たものと同様であることがわかる。しかし、推定された標準誤差と信頼区間は、はるかに大きくなっている。また、`coef_test`関数を用いて、回帰重みの $p$ **値** を計算することが可能である。

```{r, eval=F}
coef_test(che.model, 
          vcov = "CR2")
```

```
##            Coef. Estimate    SE t-stat d.f. (Satt) p-val (Satt) Sig.
##          intrcpt    0.584 0.578  1.010        1.00        0.497     
##     radiationlow   -0.190 0.605 -0.315        1.60        0.789     
##  radiationmedium    0.207 0.603  0.344        1.98        0.764 
```

ロバスト分散推定を用いた場合、どの係数も有意ではないことがわかる^[デフォルトでは、  `cont_int`  と  `coef_test`  関数は **Satterthwaite-corrected** 自由度 [@tipton2015small2] を用いている。このデフォルト設定を維持することが推奨される]。 

```{block2, type='boxinfo'}
**ロバスト分散推定とモデルの誤同定**

読者の中には、なぜ私たちがロバスト分散推定を使ったモデルに大騒ぎするのか不思議に思われるかもしれない。その主な理由は、多変量・マルチレベルのモデルは、**簡単に誤った仕様になりうる**からである。CHE モデルでさえ、相関が研究内と研究間で同一であると仮定することで、やや粗雑なモデルであることをすでに学んだ。モデルがデータ中の複雑な依存関係を**適切に近似している**かどうかが**不明確**なことがよくある。

この点、ロバスト分散推定は、モデルの潜在的な**誤記定**に対して、私たちの**推論**（すなわち、我々が計算する信頼区間と$p$値）を**保護する**ことができるため、有用である。

```


```{block2, type='boxinfo'}
**{robumeta} パッケージ**

このセクションでは、相関・階層効果モデルと組み合わせたロバスト分散推定を取り上げた。このモデルは、他のいくつかの革新的な技術とともに、Pustejosky and Tiptonによって提案されている [-@pustejovsky2021meta]。

Hedges, Tipton and Jackson [-@hedges2010robust] による **"original" RVE approach** と、いくつかの小サンプルの拡張は、 **{robumeta}** パッケージ [@robumeta] を使って適用することができる。このパッケージは、Hedges, Tipton and Jackson　が最初に提案した2種類のモデル、**階層的**モデルと**相関効果**モデル（ただし両方を組み合わせたモデルは不可）を使ってメタ回帰を適合させることができる。 

```


<br></br>

## クラスターワイルドブートストラップ  {#cwb}

---

前章では、相関効果モデルと階層効果モデルの適合方法、ロバスト分散推定を用いた信頼区間と係数検定の計算方法について学んだ。 

もう一つの、そして時には私たちのモデルの係数を検定するのに有利な方法は、**ブートストラップ法**で、その特別な変種がいわゆる**クラスターワイルドブートストラップ**  [@joshi2021clusterwild] である。この方法は、メタ分析における**研究の総数** $J$  が**小さい**場合に適している。特に、（私たち自身の `チェルノブイリ` の例で見たように）小さなサンプルで**過度に保守的な結果**につながる可能性があるRVEと比較して、この方法は適している。

この方法は、いわゆる**多重対比仮説** を検定したいときにも有効である。多重対比仮説は、たとえば、ダミー・コード化されたカテゴリ共変量の全体効果を検定したい場合に必要である。 


```{block2, type='boxinfo'}
**Cluster Wild Bootstrapping Algorithm**
  
ワイルドブートストラップは、Null モデル（共変量を追加せずにフィットさせたモデル）の残差に基づく方法である。クラスターワイルドブートストラップでは、依存効果量を扱うために、例えば CR2 法に基づく調整行列 $\boldsymbol{A}_j$ を用いて残差を変換する（Chapter \@ref(sandwich) 参照）。ワイルドブートストラップの一般的なアルゴリズムは以下のようなものである [@joshi2021clusterwild]。
  
1. 元のデータからフルモデルを計算し、目的の検定統計量（$t$ 値または $F$ 値）を導出する。
2. 元のデータに基づいてヌルモデルを適合し、その残差 $\boldsymbol{e}$ を抽出する。
3. 各研究またはクラスター $j$ について、分布^[本ガイドで使用している **R** パッケージの **{wildmeta}** では、このために **Rademacher** 分布を使用しています]からランダムな値を引き、$j$ の残差にこのランダムな値をかけます。
4. 元のデータに基づく Null モデルの予測値に変換された残差を加えることで、新しいブートストラップされた効果量を生成する。
5. ブートストラップされた効果量値を用いて，再度フルモデルを適合させ，再度検定統計量を計算する。

そして、ステップ3から5を $R$ 回繰り返す。Boostrap $p$値は、boostrap検定統計量が元データに基づくものより**極端**であった回数の**割合**として導出される。

```


ブートストラップを用いて多重対比仮説を検定するには、 **{wildmeta}**  パッケージ [@wildmeta]を使用することが可能である。このパッケージは、次の例のためにインストールし、ライブラリからロードする必要がある。さらに、 **{tidyverse}** の関数を用いて、 `Chernobyl` データセットに新しい変数を生成し、そこに各研究の年号を保存する。


```{r, eval=F}
# {wildmeta} と {tidyverse} をロードすること
library(wildmeta)
library(tidyverse)

# year という変数を追加
Chernobyl$year <- str_extract(Chernobyl$author, 
                              "[0-9]{4}") %>% as.numeric()
```

次に、この変数をメタ回帰モデル  `rma.mv`  の **新しい予測変数** として使用した。これは、単に最初の引数で  `year`  を数式に追加し、共変数をセンタリング、スケールするために  `scale`  関数を適用した。また、この式ではもう一つ、切片の  `1`  を  `0`  に変更している。これは切片がないことを意味し、「年」の予測値は放射線のレベルごとに **層別** される^[この変更は、放射線のレベルごとの **表示** に影響を与える：一つのレベルを基準群として回帰重みを得るのではなく、各レベルについて3つの別々の効果量推定値がプールされる]。この結果を  `che.model.bs`  として保存する。

```{r, eval=F}
che.model.bs <- rma.mv(z ~ 0 + radiation + scale(year),
                       V = V,
                       random = ~ 1 | author/es.id,
                       data = Chernobyl,
                       sparse = TRUE)
```


ブートストラップを始める前に、実施したい検定について**線形対比**を定義する必要がある。例えば、変数  `radiation`  の **全体的なモデレーション効果** を検定したいとする。これを行うには、 **{clubSandwich}** の  `constrain_equal`  関数を使用して、検定のための制約行列を作成する必要がある。帰無仮説は、変数  `radiation`  の3つのレベルの間で効果が等しいというもので、 `constraints`  引数を  `1:3`  にセットする。さらに、 `coefs`  引数には先ほどフィットしたモデルの係数を指定した。結果は  `rad.constraints`  という名前で保存される。

```{r, eval=F}
rad.constraints <- constrain_equal(constraints = 1:3,
                                   coefs = coef(che.model.bs))
rad.constraints
```
```
##      [,1] [,2] [,3] [,4]
## [1,]   -1    1    0    0
## [2,]   -1    0    1    0
```


 **{wildmeta}** の  `Wald_test_cwb` 関数を用いて、多重対比仮説のブートストラップ $p$ -値を計算することができる。フィットしたフルモデル、制約行列、使用したいスモールサンプル調整の種類、そしてブートストラップ複製の数である  `R`  を指定する必要がある。検出力が向上するため、**高い複製数**（例：1000以上）を使用することを勧める。この例では、2000回を使用し、結果を `cw.boot` として保存する。繰り返しの回数にもよるが、この処理は終了までに**数分かかることがある**。

```{r, eval=F}
cw.boot <- Wald_test_cwb(full_model = che.model.bs,
                         constraints = rad.constraints,
                         adjust = "CR2",
                         R = 2000)
cw.boot
```

```
##           Test Adjustment CR_type Statistic    R  p_val
## 1 CWB Adjusted        CR2     CR0   Naive-F 2000 0.3595
```

モデレータの検定の結果、$p$ -値は0.36で、**有意ではない**ことがわかる。私たちは以前、Chapter \@ref(three-level-subgroup)  の放射強度のモデレータ分析でも同様の所見を得た。

`plot` 関数を使用すると、すべてのブートストラップ複製における検定統計量の**密度** を可視化することも可能である。 


```{r, eval=F}
plot(cw.boot, 
     fill = "lightblue", 
     alpha = 0.5)
```

```{r, fig.width=5, fig.height=3, out.width="75%", fig.align='center', echo=F, message=FALSE, warning=FALSE}
library(wildmeta)
load("data/cw.boot.rda")
plot(cw.boot, fill = "lightblue", alpha = 0.5) +
  ggplot2::theme(plot.background = element_rect(fill = "#FFFEFA",
                                                color = "#FFFEFA"),
                 panel.background = element_blank(),
                 panel.border = element_blank())
```



\qed

<br></br>

## 演習問題

```{block, type='boxquestion'}
**知識を試そう！**

\vspace{4mm}

1. なぜ「マルチレベル」モデルではなく「３レベル」モデルと言う方が正確なのか？

\vspace{-2mm}

2. ３レベルメタ分析モデルはいつ有用か？

\vspace{-2mm}

3. 効果量依存性の一般的な原因を2つ挙げなさい。

\vspace{-2mm}

4. マルチレベル $I^2$ の統計量はどのように解釈すればよいか。

\vspace{-2mm}

5. モデレータ変数の効果を取り入れるために、どのように３レベルモデルを拡張することができるのか？

\vspace{4mm}


**問題の解答は、本書の巻末 [Appendix A](#qanda10) にある。**

```


$$\tag*{$\blacksquare$}$$

<br></br>

## 要約

* すべてのランダム効果メタ分析は、マルチレベルモデルに基づいている。３レベル目が追加された場合、３レベルメタ分析モデルと呼ばれる。このようなモデルは、**クラスタ化**した効果量データの取り扱いに適している。 

* ３レベルモデルは、従属効果量に使用することがでく。例えば、1つの研究が複数の効果量に寄与している場合、これらの結果が独立しているとは通常仮定できない。３レベルモデルは、効果量がより大きなクラスタ（研究など）に **ネスト**されていると仮定することで、この問題を制御する。

* 従来のメタ分析とは異なり、３レベルモデルでは、クラスタ内のランダム効果分散と、クラスタ間の不均一分散の2つの不均一性分散を推定することが可能である。

* ３レベルモデルを用いて、カテゴリまたは連続予測変数を検定することも可能である。これは、３レベル混合効果モデルをもたらす。 

<!--chapter:end:12-mlma-ja.Rmd-->

# 構造方程式モデリングメタ分析  {#sem}

---

<img src="_figs/semtitle_leaf.jpg" />

<br></br>

<span class="firstcharacter">前</span>
章で、メタ分析モデルにはマルチレベル構造が内在していることを示した。この性質を利用して、例えば、従来のメタ分析を３レベルモデルに拡張することができる。 

\index{Analysis of Variance}
\index{Subgroup Analysis}

統計的手法に関しては、よく別々の箱に入れられることがあるが、これは非常におかしなことである。研究や実務では、統計のそれぞれの手法は無関係なものとして扱われることが多いが、実際はそうではない。例えば、**分散分析**（ANOVA）とカテゴリ予測変数の線形回帰は本質的に同じことを行なっていると教えると、多くの社会科学の学生はたいてい驚く^[ANOVA は $y_{ij} = \mu + \tau_i + \epsilon_{ij}$  モデルに基づいている、ここで $\tau_i$ は $i$ th要因レベル/治療の効果、そして $\epsilon_{ij}$  は（説明できない）ランダムエラーによる偏差を示している [@montgomery, chapter 3.2]。これは線形回帰モデルの特殊なケースにほかならない。主な違いは、$\tau_i$  が **effect-coded** であることである（たとえば、治療変数が-1 と1のいずれかであり、カテゴリ治療効果の合計が0になる： $\sum_{i={1}^{a} \tau_i = 0$ )。一方、線形回帰モデルでは、カテゴリカル予測変数は通常ダミー・コード化（たとえば、0と1）される]。2つの方法が異なる文脈で使われ、別個のものとして教えられてきたときに、このようになることがある。



\index{Structural Equation Model}

この例と同じように、マルチレベルモデルを**構造方程式モデル**（Structural Equation Model, SEM）の特殊な形態として捉え始めたのはごく最近のことである [@mehta2005people; @bauer2003estimating] 。すでに学んだように、すべてのメタ分析はマルチレベルモデルに基づいている。結果として、プール効果量が潜在（または未観測）変数として扱われる構造方程式モデルとしてメタ分析を扱うことが可能である [@cheung2015meta, chapter 4.6]。要するに、メタ分析はマルチレベルモデルなので、構造方程式モデルとしても表現できるのである。

\index{Multivariate Meta-Analysis}
\index{Factor Analysis}

これは、これまで取り上げられてきた種類のメタ分析を構造方程式モデリングの観点から概念化できることを意味するだけではない。SEM を使って、より複雑なメタ分析モデルを構築することもできるようになるのである。**メタ分析的**な SEM を用いて、**因子分析的**なモデルを検証したり、アウトカムを複数含む**多変量メタ分析**を実行することが可能である（これらは、応用例の一部に過ぎない）。 

メタ分析 SEM は、利用可能なすべてのエビデンスを考慮した上で、文献中のあるモデルが実際に成り立っているかどうかを評価したい場合に役立つ。逆に、ある理論がエビデンスに裏付けられていないかどうか、あるいはさらに興味深いことに、その理論がサブグループにしか適用されないかどうかをチェックするためにも使用することが可能である。

メタ分析的な SEM の手法を適用するには、もちろん構造方程式モデリングに基本的に慣れていることが前提になる。そこで次のセクションでは、構造方程式モデリングの背後にある一般的な考え方と、そのメタ分析的な拡張について簡単に説明する。 

<br></br>

## メタ分析構造方程式モデリングとは？  {#what-is-meta-sem}

---

構造方程式モデリングは、**顕在**（観測）変数と**潜在**変数の関係に関する仮説を検定するために用いられる統計手法である [@kline2015principles, chapter 1]。潜在変数は、観測されないか、**観測可能**のどちらかである。例えば、パーソナリティは、例えば、アンケートの様々な項目を通して間接的にしか測定できない構成要素である。SEM では、顕在変数と潜在変数の間の仮定された関係（「構造」）が、測定された顕在変数を用いて、その測定誤差を考慮しながらモデル化される。

SEM 分析は、「従来の」統計的仮説検定（例えば、$t$-検定など）とは多少違う点がある。通常、統計的検定は、$H_0: \mu_1 = \mu_2$（ここで、$\mu_1$ と $\mu_2$ は2つのグループの平均）のような**帰無仮説**に対する検定を伴う。このような検定では、研究者は、帰無仮説を**棄却**することを「目的」とし、これによって、2つのグループが異なると結論づけることができることがある。しかし、SEM では、特定の構造モデルが事前に提案され、適合度が十分であれば、このモデルを**受け入れる**ことを「目的」とする [@cheung2015meta, chapter 2.4.6]。


<br></br>

### モデル仕様

---

一般に、SEM は一連の**行列**によって指定され、数学的に表現される。行列は、 _R_  の  `data.frame`  オブジェクトのように、行と列を含む単純な表と考えることができる（実際、ほとんどのデータフレームは、`as.matrix` 関数を用いて簡単に行列に変換することが可能）。視覚的には、SEM は**パス図**として表現することができる。このようなパス図は、通常、非常に直感的であり、その解釈も簡単である。したがって、まず最初に SEM を**視覚的に**示し、その後、行列表記に移行しよう。

<br></br>

#### パス図

---

\index{Path Diagram}

パス図は、SEM をグラフィカルに表現したものである。パス図の描き方について完全なコンセンサスは得られていないが、いくつかの規約がある。ここでは、パス図の主な構成要素と、それらが表現するものを紹介した。

```{r, echo=F, message=F, warning=F}
library(kableExtra)
library(dplyr)

df = data.frame(Symbol = c("$\\square$", "$\\circ$", "$\\triangle$", "$\\rightarrow$", "$\\leftrightarrow$"),
                Name = c("長方形", "円", "三角形", "矢印", "二重矢印"),
                Description = c("観測変数。", "潜在（非観測）変数",
                                "切片 (fixed vector of 1s).", "予測。矢印の末端の変数が、先端の変数を予測する。Predictor $\\rightarrow$ Target。",
                                "（共）変量。双方向の矢印が2つの変数（長方形/円）を結ぶ場合、2つの変数間の共分散・相関を意味する。双方向矢印が1つの変数の上にループを形成している場合、その変数の分散を意味する。"))


kable(df %>% mutate_all(linebreak), "html", booktabs = T, escape = FALSE, longtable = T) %>% 
  kable_styling(latex_options = c("repeat_header"),
                bootstrap_options = c("condensed",
                                      "striped")) %>% 
  column_spec(3, width = "13cm")

```

例として、単純な線形（「非メタ分析」）回帰モデルのパス図を作成してみよう。このモデルでは、$y$ を $x$ で予測したい。モデル式は次のようなものである。

\begin{equation}
y_i = \beta_0 + \beta_1x_i + e_i
(\#eq:sem1)
\end{equation}

さて、この数式を「分解」してみよう。このモデルにおいて、$x_i$ と $y_i$  は観測された変数である。観測されない（潜在）変数はない。$y$ の真の母平均は回帰切片 $\beta_0$  であり、$\mu_x$ は $x$ の母平均を示す。観測された予測変数の分散 $x$ は $\sigma^2_x$ で示される。 $x$ が $y$ の完全な予測因子でない場合、$y$ に関連する残留誤差分散 $\sigma^2_{e_y}$  がある程度存在することになる。以下の通り、2つの回帰係数がある。$\beta_0$ は切片で、$\beta_1$  は $x$ の傾きである。

これらの構成要素を用いて、線形回帰モデルのパス図を作成すると、以下のようになる。 

```{r regression_path, message = F, out.width = '43%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/regression_path_sep.png')
```

また、このグラフモデルを出発点として、回帰モデルの式を組み立て直すことができる。このモデルから、$y$ は、$x \times \beta_1$ と $1 \times \beta_0$ という二つの要素に影響されていることが推測できる。 この二つの要素を足し合わせると、再び先ほどの $y$ の式にたどり着く。

<br></br>

#### 行列表現

---

SEM を行列で表現する方法はいくつかある [@joreskog2006lisrel; @muthen2012mplus; @mcardle1984some]。ここでは、**Reticular Action Model** (RAM) の定式化に焦点を当てることにする  [@mcardle1984some]。なぜなら、この後に紹介する **{metaSEM}** パッケージでは、この式が使用されているからである。RAM は4つ行列を使用する。$\boldsymbol{F}$、$\boldsymbol{A}$、$\boldsymbol{S}$、$\boldsymbol{M}$ という4つ行列を使用する。 $\boldsymbol{M}$  行列は、今回取り上げるメタ分析的SEMに適合させる必要はないので、ここでは省略した[より広範な紹介は @cheung2015meta を参照]。 

先ほどの線形回帰モデルに、残りの $\boldsymbol{A}$ , $\boldsymbol{F}$ , $\boldsymbol{S}$  行列を指定する。この3つ行列は、すべて同じ行と列数で、モデルで持っている変数 $x$ と $y$ に対応している。したがって、回帰モデルの一般的な行列構造は、常に次のようになる。


```{r, message = F, out.width = '18%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/M1.png')
```


<br></br>

**$\boldsymbol{A}$ 行列: 一方向矢印**

$\boldsymbol{A}$ 行列は、パス・モデル中の非対称（単一方向）矢印を表す。この行列は、矢印が始まる変数の**列**のエントリを検索し ( $x$ )、次に矢印が終わる変数行列の**行**のエントリを検索することによって埋めることが可能である ( $y$ )。矢印の値 $\beta_1$ は、選択された列と行が行列の中で交差する場所に置かれる ( $i_{y,x}$ )。このモデルには、変数間の他のパスがないので、残りのフィールドを0で埋める。したがって、例の $\boldsymbol{A}$ 行列は次のようになる。


```{r, message = F, out.width = '20%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/M2.png')
```

<br></br>

**$\boldsymbol{S}$ 行列: 一方向矢印**

$\boldsymbol{S}$ 行列は、含まれる変数について推定したい（共）分散を表している。予測変数である $x$ については、分散 $\sigma^2_x$ を推定する必要がある。予測変数 $y$  については、予測誤差の分散 $\sigma^2_{e_y}$ を知りたい。したがって、$\boldsymbol{S}$ をこのように指定する。

```{r, message = F, out.width = '20%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/M4.png')
```

<br></br>

**$\boldsymbol{F}$  行列: 一方向矢印**

$\boldsymbol{F}$  行列は、モデルで**観測された**変数を指定することが可能である。変数が観測されたことを指定するために、単に行列のそれぞれの対角フィールドに1を挿入する。このモデルでは、$x$ と $y$  の両方が観測されているので、両方の対角フィールドに 1 を挿入する。

```{r, message = F, out.width = '20%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/M3.png')
```

\index{Maximum Likelihood}

これらの行列が設定されると、SEM のパラメータを推定することができ、指定されたモデルがどれだけデータに適合しているかを評価することができるようになる。これにはいくつか行列代数と最尤推定によるパラメータ推定が含まれるが、数学的な細かい説明はここでは省略する。このステップの背後にある詳細を理解することに興味がある場合は、@cheung2015meta の4.3章を参照。 


<br></br>

### SEMの観点からのメタ分析

---

ここで、メタ分析モデルと SEM に関する知識を組み合わせて、メタ分析を構造方程式モデル [@cheung2008model] として定式化しよう。

はじめに、ランダム効果モデルの式に戻りよう。前回、メタ分析モデルがマルチレベル構造に従っていることをすでに説明してきたが（Chapter \@ref(multilevel-nature)）、これは次のようなものである。

\vspace{2mm}

**レベル 1**

\begin{equation}
\hat\theta_k = \theta_k + \epsilon_k
(\#eq:sem2)
\end{equation}


\vspace{2mm}

**レベル 2**

\begin{equation}
\theta_k = \mu + \zeta_k
(\#eq:sem3)
\end{equation}

最初のレベルでは、研究 $k$ で報告された効果量 $\hat\theta_k$ が、真の効果量 $\theta_k$  の推定値であると仮定する。観測された効果量が真の効果から乖離しているのは、サンプリングエラー $\epsilon_k$、分散 $\widehat{\text{Var}}(\hat\theta_k)=v_k$ で表されるからである。

\index{Random-Effects Model}
\index{Fixed-Effect Model}

ランダム効果モデルでは、各研究の真の効果量でさえ、レベル2の真の効果量の母集団からしか抽出されないと仮定する。この真の効果量の母集団の平均 $\mu$  が推定したいものであり、プール効果量を表す。これを推定するためには、真の効果量の分散 $\widehat{\text{Var}}(\theta)=\tau^2$ （つまり、研究間異質性）も推定する必要がある。固定効果モデルはランダム効果モデルの特殊なケースで、$\tau^2$ がゼロであると仮定される。

このモデルを SEM グラフとして表現することは、非常に簡単である。レベル1のパラメータを潜在変数として、観察している効果量がどのように生まれたかを「説明」する [@cheung2015meta, chapter 4.6.2]。


```{r, message = F, out.width = '45%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/REM_SEM_sep.png')
```

グラフィカルなモデルでは、ある研究 $k$ の観察された効果量 $\hat\theta_k$  は、2つのアームによって「影響」されていることがわかる。
２つのアームとは、分散 $v_k$ を持つサンプルエラー $\epsilon_k$、および分散 $\tau^2$ を持つ真の効果量 $\theta_k$ である。

<br></br>

### ２段階メタ分析 SEM アプローチ

---

上記では、SEM の観点から（ランダム効果）メタ分析モデルを定義してみた。これは理論的には面白いが、このモデルは以前取り上げたメタ分析手法と比較して能力が高いわけでも低いわけでもない。単に、ランダム効果モデルを仮定して効果量をプールすることを記述しているだけである。

メタ分析 SEM の汎用性を本当に生かすには、２段階アプローチが必要である [@tang2016testing; @cheung2015meta, chapter 7]。**２段階構造方程式モデリング**（Two-Stage Structural Equation Modeling, TSSEM）では、まず、各研究の効果量をプールする。通常、これらの効果量は、モデリングに使用する複数の変数間の相関である。 各研究 $k$ の相関は、ベクトル $\boldsymbol{r_k} = (r_1, r_2, \dots, r_p)$ で現される。ここで、 $p$ は、（ユニークな）相関の総数である。通常のランダム効果モデルと同様に、サンプリングエラー $\epsilon_k$ と研究間の異質性 $\zeta_k$（「ゼータ・k」と読む）により、研究 $k$  で観測された各相関は真の平均相関 $\rho$（「ロー」と読む）から乖離すると仮定する。 

$\boldsymbol{r_k}$ が1つの研究に含まれる**複数の**相関を表すことを考慮すると、ランダム効果モデルの式は次のようになる。


\begin{align}
  \boldsymbol{r_k} &= \boldsymbol{\rho} + \boldsymbol{\zeta_k} + \boldsymbol{\epsilon_k} \notag \\ 
  \begin{bmatrix} r_1 \\ r_2 \\ \vdots \\ r_p \end{bmatrix} &=
  \begin{bmatrix} \rho_1 \\ \rho_2 \\ \vdots \\ \rho_p \end{bmatrix} +
  \begin{bmatrix} \zeta_1 \\ \zeta_2 \\ \vdots \\ \zeta_p \end{bmatrix} +
  \begin{bmatrix} \epsilon_1 \\ \epsilon_2 \\ \vdots \\ \epsilon_p \end{bmatrix} (\#eq:sem4)
\end{align}


\index{metaSEM Package}

このモデルを用いて、**プール**相関のベクトル $\boldsymbol{r}$  を計算することが可能である。この最初のプール化ステップにより、研究間の効果の異質性を評価し、ランダム効果モデルまたはサブグループ分析を使用すべきかどうかを判断することが可能である。**{metaSEM}** パッケージで使用されている最尤法に基づくアプローチのおかげで、部分的にデータが欠損している研究であっても、このステップに含めることが可能である。

\index{Weighted Least Squares (WLS)}

次に、第二段階として、**加重最小二乗法**（ Chapter \@ref(metareg-model-fit)  参照）を用いて、指定した構造方程式モデルを当てはめる。指定したモデル $\rho(\hat\theta)$ の関数は、以下の式で表される [@cheung2009two; @cheung2015meta, chapter 7.4.2]。


\begin{equation}
F_{\text{WLS}}(\hat\theta) =  (\boldsymbol{r} - \rho(\hat\theta))^\top \boldsymbol{V}^{-1} (\boldsymbol{r} - \rho(\hat\theta))
(\#eq:sem5)
\end{equation}

ここで、$\boldsymbol{r}$  はプール相関ベクトルである。この式の重要な部分は、$\boldsymbol{V}^{-1}$（「ブイ・インバース」と読む）で、これは $\boldsymbol{r}$  の共分散を含む逆行列である。この行列は、重み付けに使用される。重要なのは、この第2ステップの式は、ランダム効果モデルでも固定効果モデルでも同じである。なぜなら、研究間の異質性が存在する場合は、第1ステップですでに考慮されているからである。

<br></br>

## 多変量メタ分析  {#multivariate-ma}

---

\index{Multivariate Meta-Analysis}

メタ分析 SEM の最初の事例を紹介しよう。まずは、SEM 法を使った**多変量メタ分析**から始めたい。多変量メタ分析では、1つ以上の効果を同時に推定しようとする。このようなメタ分析は、主なアウトカムが1つだけでなく、複数あるような研究テーマを研究している場合に有効である。 

ある種の治療の効果を調べることを想像してみよう。この治療法では、ほとんどの専門家が重要とみなし、したがってほとんどの研究で評価される2種類のアウトカムが存在する可能性がある。多変量メタ分析では、1つのモデルで両方のアウトカムに対する効果量を**共同で**推定することで、この問題に対処することができる。この多変量解析のアプローチでは、2つのアウトカム間の相関を考慮することも可能である。これは、一方のアウトカムで高い効果量を持つ研究が、もう一方のアウトカムでも高い効果量を持つかどうかを判断するために使用することができる。あるいは、2つのアウトカムに負の関係があるか、まったく関係がないかがわかるだろう。

\index{metaSEM Package}

なお、多変量メタ分析は、SEMの枠組み以外でも実行可能となる [@schwarzer2015meta, chapter 7; @mvmeta]。しかし、ここでは、SEMの観点からそれらを実行する方法を紹介した。この例と次の例では、Mike Cheung [-@metasem]によって開発されたメタ分析SEMのための壮大なパッケージである **{metaSEM}** を使用することになる。いつものように、まず、 **{metaSEM}** パッケージをインストールし、ライブラリからロードする必要がある。


```{r, message=F, warning=F}
library(metaSEM)
```

\index{dmetar Package}

今回の例でも、 **{dmetar}** の  `ThirdWave`  データセットを使用する（ Chapter \@ref(pre-calculated-es)  を参照）。デフォルトでは、このデータセットには1つのアウトカム、知覚されたストレスに対する効果しか含まれていない。さて、このメタ分析のほとんどの研究が、もう1つの重要なメンタルヘルス関連のアウトカムである**不安**に対する効果も測定していると想像してみよう。したがって、多変量メタ分析を使用して、ストレスと不安に対する効果、および両者がどのように互いに関連しているかを共同で推定することが可能である。

したがって、先に進むために両方のアウトカムのデータが含まれる新しいデータフレームを作成する必要がある。まず、各研究で報告された不安に対する効果（Hedges' $g$ と表す）、およびその標準誤差を含むベクトルを定義する。また、各研究で報告されたストレスと不安の間の**共分散**を含むベクトルも定義する必要がある。1つの研究では、不安のアウトカムを評価していないので、情報がないことを示すために、3つのベクトルで `NA` を使用する。

```{r, message=F, warning=F}
# 不安の効果(Hedges g) を定義
Anxiety <- c(0.224,0.389,0.913,0.255,0.615,-0.021,0.201, 
             0.665,0.373,1.118,0.158,0.252,0.142,NA, 
             0.410,1.139,-0.002,1.084)

# 不安の効果の標準偏差
Anxiety_SE <- c(0.193,0.194,0.314,0.165,0.270,0.233,0.159,
                0.298,0.153,0.388,0.206,0.256,0.256,NA,
                0.431,0.242,0.274,0.250)

# ストレスと不安の共変量
Covariance <- c(0.023,0.028,0.065,0.008,0.018,0.032,0.026, 
                0.046,0.020,0.063,0.017,0.043,0.037,NA, 
                0.079,0.046,0.040,0.041)

```

そして、このデータを `ThirdWave` の情報と合わせて、`ThirdWaveMV` という新しいデータフレームを作成する。このデータセットには、効果量の**分散**である `Stress_var` と `Anxiety_var` を設定する。分散は、標準誤差を二乗することで得られる。 

```{r, message=F, warning=F, echo=F}
ThirdWaveMV <- data.frame(Author = ThirdWave$Author,
                          Stress = ThirdWave$TE,
                          Stress_var = ThirdWave$seTE^2,
                          Anxiety = Anxiety,
                          Anxiety_var = Anxiety_SE^2,
                          Covariance = Covariance)

```

```{r, message=F, warning=F, eval=F}
ThirdWaveMV <- data.frame(Author = ThirdWave$Author,
                          Stress = ThirdWave$TE,
                          Stress_var = ThirdWave$seTE^2,
                          Anxiety = Anxiety,
                          Anxiety_var = Anxiety_SE^2,
                          Covariance = Covariance)

format(head(ThirdWaveMV), digits = 2)

```

```
##            Author Stress Stress_var Anxiety Anxiety_var Covariance
## 1     Call et al.   0.71      0.068   0.224       0.037      0.023
## 2 Cavanagh et al.   0.35      0.039   0.389       0.038      0.028
## 3   DanitzOrsillo   1.79      0.119   0.913       0.099      0.065
## 4  de Vibe et al.   0.18      0.014   0.255       0.027      0.008
## 5  Frazier et al.   0.42      0.021   0.615       0.073      0.018
## 6  Frogeli et al.   0.63      0.038  -0.021       0.054      0.032

```


見てわかるように、新しいデータセットには、ストレスと不安の両方の効果量が、それぞれのサンプル分散と一緒に含まれている。`Covariance` 列は、各研究で測定されたストレスと不安の間の共分散を格納している。

実際の研究でよくある問題は、2つのアウトカム間の共分散（または相関）がオリジナルの研究で報告されていないことである。この場合、アウトカム間の相関に関する合理的な仮定に基づいて、共分散を**推定**する必要がある。 

各研究の共分散がまだわかっていないとしよう。どのように推定できるだろうか？良い方法は、2つのアウトカム間の相関を評価した過去の文献を探すことで、今扱っているのと同じようなコンテキストで探すことができると最適である。例えば、臨床試験の介入後テストにおいて、ストレスと不安は非常に高い相関があり、$r_{\text{S,A}} \approx$ 0.6であると文献で見つけたとしよう。この想定される相関に基づいて、ある研究 $k$ の共分散を次の公式を使って近似可能である [@schwarzer2015meta, chapter 7]。

\begin{equation}
\widehat{\text{Cov}}(\theta_{1},\theta_{2}) = SE_{\theta_{1}} \times SE_{\theta_{2}} \times \hat\rho_{1, 2}
(\#eq:sem6)
\end{equation}

今回のデータを使って、$r_{\text{S,A}} \approx$ 0.6とすると、この式は _R_ で次のように実装可能である。

```{r}
# SE = sqrt(var) より、分散の２乗根を使用
cov.est <- with(ThirdWaveMV, 
                sqrt(Stress_var) * sqrt(Anxiety_var) * 0.6)
```

なお、このように共分散を計算する場合、想定する相関の選択によって結果に大きな影響を与えることがある。したがって、（1）常に想定した相関係数を報告し、（2）感度分析を行い、選んだ相関によって結果がどう変わるかを検証することが強く望まれる。 

<br></br>

### モデルの指定

---

多変量メタ分析モデルを指定するために、プログラム的に TSSEM 手順（前章参照）に従う必要はないし、RAM 行列を指定する必要もない。このような比較的単純なモデルであれば、 **{metaSEM}** の `meta` 関数を使用すれば、たった1ステップでメタ分析 SEM を適用することが可能である。`meta` を使用するには、3つの必須引数を指定するだけである。

* **`y`**. 効果量データを含むデータセットの列である。多変量メタ分析では、`cbind` を用いて、効果量を含む列を結合する必要がある。 

* **`v`**. 効果量の分散を含むデータセットの列。多変量メタ分析では、`cbind`  を用いて、対象とする分散列を結合する必要がある。また、効果量間の共分散を含む列も含める必要がある。引数の構造は `cbind(variance_1, covariance, variance_2)` である。

* **`data`**. 効果量と分散が格納されたデータセット。

適合したモデルを `m.mv` という名前で保存する。ひとつ重要な点として、 `meta` を実行する前に、**{meta}** パッケージがロードされて**いない**ことを確認しておこう。**{meta}** と **{metaSEM}** の関数は同じ名前を持って流物がいくつかあり、 _R_ でコードを実行するときにエラーにつながる可能性がある。`detach` 関数を使ってパッケージを "unload" することが可能である。 

したがって、まず、**{meta}** を確実にアンロードし、それからモデルの適合を行う。結果として得られる `m.mv` オブジェクトは、`summary` を用いて検証したい。

```{r, message=F, warning=F, echo=F}
m.mv <- meta(y = cbind(Stress, Anxiety), 
             v = cbind(Stress_var, Covariance, Anxiety_var),
             data = ThirdWaveMV)
```


```{r, fig.width=5, fig.height=5, eval=F}
detach(package:meta, unload = TRUE)

m.mv <- meta(y = cbind(Stress, Anxiety), 
             v = cbind(Stress_var, Covariance, Anxiety_var),
             data = ThirdWaveMV)

summary(m.mv)

```

```
## [...]
## Coefficients:
##            Estimate Std.Error lbound ubound z value Pr(>|z|)    
## Intercept1    0.570     0.087  0.399  0.740  6.5455  5.9e-13 ***
## Intercept2    0.407     0.083  0.244  0.570  4.9006  9.5e-09 ***
## Tau2_1_1      0.073     0.049 -0.023  0.169  1.4861   0.1372    
## Tau2_2_1      0.028     0.035 -0.041  0.099  0.8040   0.4214    
## Tau2_2_2      0.057     0.042 -0.025  0.140  1.3643   0.1725    
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
## [...]
## 
## Heterogeneity indices (based on the estimated Tau2):
##                              Estimate
## Intercept1: I2 (Q statistic)   0.6203
## Intercept2: I2 (Q statistic)   0.5292
## 
## Number of studies (or clusters): 18
## [...]
## OpenMx status1: 0 ("0" or "1": The optimization is considered fine.
## Other values may indicate problems.)
```

<br></br>

### 結果の評価

---

\index{Maximum Likelihood}

SEM モデルが最尤法を使って適合していることを考えると、まず出力の最後にある `OpenMx status` を最初にチェックする。最尤推定は最適化手順であり、手元のデータに対する最適解が見つかるまで、パラメータが繰り返し変更される。しかし、特に複雑なモデルでは、何度繰り返しても最適解に到達しないことがある。その場合、最尤法は停止して、これまでに近似したパラメータ値を出力した。しかし、このようなモデルの構成要素の値は間違っている可能性が高く、信用するべきではない。 

このモデルの `OpenMx status` は `0` であり、最尤推定がうまくいったことを示している。もし、このステータスが 0 または 1 以外であった場合、このコードを使ってモデルを再実行する必要がある。

```{r, eval=F}
rerun(m.mv)
```

この出力では、プールされた2つの効果量が `Intercept1` と `Intercept2`  として表示される。効果量は、`meta` の呼び出しに挿入した順番に番号が振られている。プールされた効果量は、$g_{\text{Stress}}$  = 0.57 および $g_{\text{Anxiety}}$  = 0.41であることがわかる。どちらの効果量も有意である。異質性指標では、$I^2$ の値も見ることが可能である。 $I^2_{\text{Stress}}$  = 62% と $I^2_{\text{Anxiety}}$  = 53%で、両方のアウトカムにかなりの研究間異質性があることがわかる。 

また、研究間異質性分散 $\tau^2$ の直接推定値も示されている。2つの推定値だけでなく、3つの推定値があることがわかる。この意味を理解するために、`m.mv` オブジェクトから「ランダム」な値を抽出することが可能である。

```{r}
tau.coefs <- coef(m.mv, select = "random")
```

次に、`vec2symMat` 関数を使用して、係数行列を作成する。行列の行と列には、変数名である  `Stress`  と  `Anxiety`  を付ける。

```{r}
# 行列を作成
tc.mat <- vec2symMat(tau.coefs)

# 列名と行名をつける
dimnames(tc.mat)[[1]] <- dimnames(tc.mat)[[2]] <- c("Stress", 
                                                    "Anxiety")

tc.mat
```

ここで、$\tau^2$ の3つの値の意味がよくわかる。これらは、行列の対角線上の研究間分散（異質性）を表している。他の2つのフィールドでは、行列はストレスと不安の間の推定共分散を示している。共分散は相関の未標準化バージョンに過ぎないので、`cov2cor` 関数を用いて、これらの値を相関に変換することが可能である。

```{r}
cov2cor(tc.mat)
```

極めて論理的に、行列の対角要素の相関は1であることがわかる。ストレスと不安に対する効果の相関は、$r_{\text{S,A}}$  = 0.45 である。これは興味深い発見で、治療法の知覚ストレスに対する効果と不安に対する効果との間に正の相関があることを示している。ストレスに対する効果が高い治療法は、不安に対する効果も高いようだと言うことが可能である。

\index{Wald 型検定}

`m.mv` の要約で示される信頼区間は Wald 型の区間であることに注意しておこう（Chapter \@ref(knapp-hartung)  を参照）。このような Wald タイプの信頼区間は、特に小さなサンプルでは不正確な場合がある  [@diciccio1996bootstrap]。したがって、**尤度に基づく**信頼区間を用いて、別の方法で信頼区間を構築することが重要である場合がある。`meta` 関数を再実行し、さらに `intervals.type = "LB"` を指定することで、これらの CI を得ることが可能である。 

```{r, eval = F}
m.mv <- meta(y = cbind(Stress, Anxiety), 
             v = cbind(Stress_var, Covariance, Anxiety_var),
             data = ThirdWaveMV,
             intervals.type = "LB")
```

`m.mv` の出力には、研究間異質性 $\tau^2$ のゼロでない推定値が含まれていることがすでにわかった。したがって、今適合したモデルは、ランダム効果モデルであると結論づけることが可能である。`meta` 関数は自動的にランダム効果モデルを使用する。出力された $I^2$  の値を考慮すると、これは確かに適切であると結論づけることが可能である。しかし、固定効果モデルを適用したい場合は、解析を再実行し、パラメータ ` RE.constraints = matrix(0, nrow=2, ncol=2)` を追加することで、適用することが可能である。これは、$\tau^2$  の値をすべて0に拘束する零行列を作成する。

\vspace{2mm}

```{r, eval = F}
m.mv <- meta(y = cbind(Stress, Anxiety), 
             v = cbind(Stress_var, Covariance, Anxiety_var),
             data = ThirdWaveMV,
             RE.constraints = matrix(0, nrow=2, ncol=2))
```


<br></br>

### 結果の可視化

---

多変量メタ分析モデルをプロットするには、`plot` 関数を使用する。また、プロットの外観を変更するために、いくつかの追加指定を行う。全てのスタイリングオプションを見たい場合は、コンソールに  `?metaSEM::plot.meta` を貼り付けて、Enterキーを押してみよう。

\vspace{2mm}

```{r, fig.width=5, fig.height=5, fig.align='center', out.width="60%", eval=F}
plot(m.mv, 
     axis.labels = c("Perceived Stress", "Anxiety"), 
     randeff.ellipse.col = "#014d64",
     univariate.arrows.col = "gray40", 
     univariate.polygon.col = "gray40",
     estimate.ellipse.col = "gray40",
     estimate.col = "firebrick")
```

```{r, fig.width=5, fig.height=5, fig.align='center', out.width="60%", echo=F}
par(bg="#FFFEFA")
plot(m.mv, 
     axis.labels = c("Perceived Stress", "Anxiety"), 
     randeff.ellipse.col = "#014d64",
     univariate.arrows.col = "gray40", 
     univariate.polygon.col = "gray40",
     estimate.ellipse.col = "gray40",
     estimate.col = "firebrick")
```


それでは、見ていこう。プロットには2つの軸がある：ストレスへの効果を示すx軸と、不安への効果を示すy軸である。また、両方のアウトカムに対するプール効果とその95%信頼区間が表示されている（黒い菱形で象徴されている）。 

\index{Prediction Interval}

プロットの中央には、両変数のプール効果が赤い菱形で示されている。小さい青い楕円は、私たちのプールされた効果の95%信頼区間を表し、大きい黒い楕円は、95%**予測**区間を表している（Chapter \@ref(het-measure-which)）^[これらの予測区間（または「もっともらしい値間隔」）は、**{meta}** および {metafor} が使用する式（Chapter \@ref(het-measure-which) の 5.7 式）と異なる式 [$\hat\mu \pm 1.96 \times \hat\tau$, @raudenbush2009pi] に基づき、わずかに狭い間隔になっている]。



最後に、黒丸は個々の研究を示し、破線の楕円は95%信頼区間を表す。

<br></br>

## 確証的因子分析  {#cfa}

---

\index{Factor Analysis}

確証的因子分析 (Confirmatory Factor Analysis, CFA) は、観測された変数が仮定された潜在変数にどのように関係するかを特定する一般的な SEM 手法である [@thompson2004exploratory, chapter 1.1 and 1.2]。CFA は、アンケートや他のタイプのアセスメントの心理測定特性を評価するためによく使用される。それは、研究者が、評価された変数が、測定しようとする潜在変数を本当に測定しているかどうか、および複数の潜在変数がお互いにどのように関係するかを決定することを可能にする。 

頻繁に使用されるアンケートについては、通常、異なるアンケート項目間の相関を報告する多くの実証研究が存在した。このようなデータは、メタ分析的な SEM に使用することが可能である。これにより、すべての利用可能なエビデンスに基づいて、どの潜在因子構造が最も適切であるかを評価することが可能である。

この例では、睡眠の問題についての（架空の）質問票の潜在的な因子構造を確認したいとした。この質問票は、睡眠の問題を特徴づける2つの異なる潜在変数を測定すると仮定される。**不眠症**と**弛緩**である。Koffel and Watson [-@koffel2009two] は、睡眠の苦情は、実際にこれらの2つの潜在因子によって記述され得ると主張した。 

メタ分析 CFA を実践するために、私たちが想像した睡眠アンケートを評価した11件の研究結果をシミュレートした。このデータセットを  `SleepProblems`  と名付けた。これらの研究のそれぞれには、私たちの質問票によって直接測定された睡眠に関する不満の症状間の相互相関が含まれている。これらの測定指標には、睡眠の質、睡眠潜時、睡眠効率、日中機能不全、**hypersomnia**（すなわち、寝過ぎ）が含まれる。最初の3つの症状は、いずれも不眠症を潜在変数として測定しているので関連があり、日中機能不全と過眠症は、倦怠感要因の症状なので関連があると推測される。

提案された構造をグラフィカルなモデルとして表現すると、次のようになる^[パス図のラベルは、後でモデルの関連コンポーネントを識別しやすくするために、多少「特異」であることに注意してみよう]。


```{r, message = F, out.width = '60%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/CFA_Graph-1_sep.png')
```

<br></br>

### データ準備

---

まず、モデルに使用する  `SleepProblems`  データを見てみよう。このデータセットは特殊な構造を持っている。それは  `list`  オブジェクトであり、 (1) 行列の  `list`  と (2) 数値ベクトルを含んでいる。リストは非常に汎用性の高い  _R_  オブジェクトであり、異なる要素を 1 つの大きなオブジェクトに結合することが可能である。リストは  `$`  演算子を用いて、データフレームのようにアクセスすることが可能である。`names` 関数を使用すると、リスト内のオブジェクトの名前を表示すことが可能である。

```{block, type='boxdmetar'}
**"SleepProblems" データセット**

\vspace{2mm}

`SleepProblems` データセットは **{dmetar}** パッケージに含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(TherapyFormatsGeMTC)` を実行すると、自動的にデータセットが _R_ 環境にセーブされる。これでデータセットが利用できるようになる。

\vspace{2mm}

もし、**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/SleepProblems.rda) から _.rda_ ファイルとしてダウンロードし、作業ディレクトリに保存した後、R Studio のウィンドウでクリックするとインポートすることが可能である。

```


```{r, message=F, warning=F}
data(SleepProblems)
names(SleepProblems)
```

このリストには、実際の  `data`  と、各研究のサンプルサイズである  `n`  の 2 つの要素が含まれていることがわかる。data ` オブジェクトはそれ自体が ` list ` であるため、 ` names` 関数を使用してそのコンテンツの名前を取得することも可能である。 

```{r, eval=F}
names(SleepProblems$data)
```

```
## [1] "Coleman et al. (2003)"  "Salazar et al. (2008)" 
## [3] "Newman et al. (2016)"   "Delacruz et al. (2009)"
## [5] "Wyatt et al. (2002)"    "Pacheco et al. (2016)"
## [...]
```

また、 `$` 演算子を使って  `data`  に含まれる特定の要素を表示すことも可能である。

```{r}
SleepProblems$data$`Coleman et al. (2003)`
```

`data` リストには11の要素があり、含まれる11の研究ごとに1つずつある。Coleman et al. (2003)の研究を詳しく見ると、データは5つの変数を持つ相関行列として格納されていることがわかる。行列の各行と列は、私たちの質問票で評価された睡眠の不定愁訴の症状の1つに対応した。 

Coleman et al. (2003)の研究では、各症状の組み合わせについて相関が報告されている。しかし、いくつかのフィールドで欠損値（ `NA` としてコード化）を持つ研究を使用することも可能である。これは、メタ分析SEMが、少なくともある程度は、欠損データを扱うことができることがある。

先に進む前に、このようなリストを自分で作成する方法を簡単に説明しよう。2つの研究の相関行列を抽出し、それをデータフレームとして  _R_  にインポートしたい。データフレームを `df1` と `df2`  と呼ぶとすると、以下の「レシピ」を使用して、さらなる解析に適した `list` オブジェクトを作成することが可能である。

\vspace{2mm}

```{r, eval=F}
# データフレームを行列に変換
mat1 <- as.matrix(df1)
mat2 <- as.matrix(df2)

# 行ラベルを定義
dimnames(mat1)[[1]] <- c("Variable 1", "Variable 2", "Variable 3")
dimnames(mat2)[[1]] <- c("Variable 1", "Variable 2", "Variable 3")

# リストに相関係数行列を結合
data <- list(mat1, mat2)
names(data) <- c("Study1", "Study2")

# 二つの研究のサンプルサイズを定義
n <- c(205, # N of study 1
       830) # N of study 2

# 行列とサンプルサイズを結合
cfa.data <- list(data, n)

```


<br></br>

### モデル仕様

---

CFA モデルを指定するためには、先に述べた RAM 指定と2段階メタ分析 SEM 手順を使用する必要がある。**{metaSEM}** パッケージは、2段階のそれぞれについて、`tssem1` と `tssem2` という別々の関数を含んでいる。最初の関数は、すべての研究の相関行列をプールし、2番目の関数は、提案されたモデルをデータに適合させる。


<br></br>

#### ステージ 1

---

最初の段階では、`tssem1` 関数を用いて相関行列をプールする。この関数では、4つの重要な引数を指定する必要がある。

* **`Cov`**. プールしたい相関行列の `list` を指定する。リスト内のすべての相関行列は、同一の構造を持っている必要があることに注意。

* **`n`**. 各研究のサンプルサイズを含む数値ベクトルで、`Cov`  に含まれる行列と同じ順序で並べられる。

* **`method`**. 固定効果モデル (`"FEM"`) またはランダム効果モデル (`"REM"`) を使用するかどうかを指定。

* **`RE.type`**. ランダム効果モデルを利用する場合、ランダム効果の推定方法を指定する。デフォルトは `"Symm"`  で、2つの変数間の共分散を含む、すべての $\tau^2$ の値を推定する。`"Diag"` に設定すると、ランダム効果行列の対角要素のみが推定される。これは、ランダム効果が独立であると仮定していることを意味する。`"Diag"`  を設定すると、モデルは非常に単純化されるが、推定しなければならないパラメータが少なくなるため、多くの場合、この方法が望ましい。これは変数の数が多い場合や研究の数が少ない場合に特に意味がある。

この例では、ランダム効果モデルを仮定し、`RE.type = "Diag"`  を使用する。モデルを `cfa1` として保存し、出力を取得するために `summary` 関数を呼び出す。
```{r, eval=T}
cfa1 <- tssem1(SleepProblems$data, 
               SleepProblems$n, 
               method="REM",
               RE.type = "Diag")

summary(cfa1)
```

```
[...]
Coefficients:
           Estimate Std.Error lbound  ubound z value Pr(>|z|)    
Intercept1    0.444     0.057  0.331   0.557   7.733  < 0.001 ***
Intercept2    0.478     0.042  0.394   0.561  11.249  < 0.001 ***
Intercept3    0.032     0.071 -0.106   0.172   0.459    0.645    
Intercept4    0.132     0.048  0.038   0.227   2.756    0.005 ** 
Intercept5    0.509     0.036  0.438   0.581  13.965  < 0.001 ***
Intercept6    0.120     0.040  0.040   0.201   2.954    0.003 ** 
Intercept7    0.192     0.060  0.073   0.311   3.170    0.001 ** 
Intercept8    0.221     0.039  0.143   0.298   5.586  < 0.001 ***
Intercept9    0.189     0.045  0.100   0.279   4.163  < 0.001 ***
Intercept10   0.509     0.023  0.462   0.556  21.231  < 0.001 ***
Tau2_1_1      0.032     0.015  0.002   0.061   2.153    0.031 *  
Tau2_2_2      0.016     0.008  0.000   0.032   1.963    0.049 *  
Tau2_3_3      0.049     0.023  0.003   0.096   2.091    0.036 *  
Tau2_4_4      0.019     0.010  0.000   0.039   1.975    0.048 *  
Tau2_5_5      0.010     0.006 -0.001   0.022   1.787    0.073 .  
Tau2_6_6      0.012     0.007 -0.002   0.027   1.605    0.108    
Tau2_7_7      0.034     0.016  0.001   0.067   2.070    0.038 *  
Tau2_8_8      0.012     0.006 -0.000   0.025   1.849    0.064 .  
Tau2_9_9      0.017     0.009 -0.001   0.036   1.849    0.064 .  
Tau2_10_10    0.003     0.002 -0.001   0.008   1.390    0.164    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
[...]

Heterogeneity indices (based on the estimated Tau2):
                              Estimate
Intercept1: I2 (Q statistic)    0.9316
Intercept2: I2 (Q statistic)    0.8837
Intercept3: I2 (Q statistic)    0.9336
Intercept4: I2 (Q statistic)    0.8547
Intercept5: I2 (Q statistic)    0.8315
Intercept6: I2 (Q statistic)    0.7800
Intercept7: I2 (Q statistic)    0.9093
Intercept8: I2 (Q statistic)    0.7958
Intercept9: I2 (Q statistic)    0.8366
Intercept10: I2 (Q statistic)   0.6486

[...]
OpenMx status1: 0 ("0" or "1": The optimization is considered fine.
Other values may indicate problems.)
```

`OpenMx status` を見ると、モデルの推定値が信頼できるものであることが確認可能である。結果をより消化しやすくするために、`coef` 関数を用いて固定効果（私たちの推定したプール相関）を抽出することが可能である。次に、`vec2symMat` を用いて係数から対称行列を作成し、解釈を容易にするために次元名を追加する。

\vspace{2mm}

```{r, echo=F, eval=F}
load("data/cfa1.rda")
```


```{r}
# Extract the fixed coefficients (correlations)
fixed.coefs <- coef(cfa1, "fixed")

# Make a symmetric matrix
fc.mat <- vec2symMat(fixed.coefs, diag = FALSE)

# 列名と行名をつける
dimnames(fc.mat)[[1]] <- c("Quality", "Latency", 
                           "Efficiency", "DTDysf", "HypSomnia")
dimnames(fc.mat)[[2]] <- c("Quality", "Latency", 
                           "Efficiency", "DTDysf", "HypSomnia")

# Print correlation matrix (3 digits)
round(fc.mat, 3)
```

\vspace{2mm}

これで、変数のプールされた相関行列を見ることが可能である。モデルの出力を見てみると、すべての相関係数が有意であることがわかる ( $p<$  0.05) ただし、1つだけ、睡眠の質と日中機能不全の相関は有意ではなかった。私たちの想定したモデルの観点からは、これらの変数が異なる因子に負荷されると予想されるので、これは理にかなっている。また、異なる推定値の $I^2$ 値が非常に大きい（65-93%）ことがわかる。  


<br></br>

#### ステージ 2

---

相関行列をプールした後、提案した因子モデルがデータにうまく適合しているかどうかを判断することになる。モデルを指定するために、今回は RAM 式を使用し、$\boldsymbol{A}$, $\boldsymbol{S}$, $\boldsymbol{F}$  という行列を指定する必要がある。これら行列の各フィールドを埋めるために、最初に空行列を構築することが最善であることがよくある。構造的には、私たちが定義したすべて行列は、観測変数だけでなく、仮定した潜在変数である `f_Insomnia` と `f_Lassitude` も含んでいる。ここでは、出発点としてゼロ行列を作成する方法を示した。

\vspace{2mm}


```{r, echo=F}
dims <- c("Quality", "Latency", "Efficiency", 
          "DTDysf", "HypSomnia", "f_Insomnia", "f_Lassitude")
```


```{r, eval=F}
# Create vector of column/row names
dims <- c("Quality", "Latency", "Efficiency", 
          "DTDysf", "HypSomnia", "f_Insomnia", "f_Lassitude")

# Create 7x7 matrix of zeros
mat <- matrix(rep(0, 7*7), nrow = 7, ncol = 7)

# 列名と行名をつける
dimnames(mat)[[1]] <- dimnames(mat)[[2]] <- dims
mat
```

```
##             Qlty Ltncy Effcncy DTDysf HypSmn f_Insmn f_Lsstd
## Quality        0     0       0      0      0       0       0
## Latency        0     0       0      0      0       0       0
## Efficiency     0     0       0      0      0       0       0
## DTDysf         0     0       0      0      0       0       0
## HypSomnia      0     0       0      0      0       0       0
## f_Insomnia     0     0       0      0      0       0       0
## f_Lassitude    0     0       0      0      0       0       0
```

<br></br>

$\boldsymbol{A}$ **行列**

$\boldsymbol{A}$ 行列では、モデルにおける非対称（つまり単一）矢印を指定する。各単一矢印は列変数から始まり、列が行変数のエントリと交差するところで終わる。矢印を表さない他のフィールドはすべて `0` で埋められる。 

$\boldsymbol{A}$ 行列に文字列を追加することで、矢印を「推定」しなければならないことを指定する。この文字列は、最適化手順の開始値（通常は 0.1 から 0.3 の間のどこか）で始まり、その後に `*`  が続く。記号の後に、その値のラベルを指定する。$\boldsymbol{A}$  行列の2つのフィールドが同じラベルを持つ場合、これはそのフィールドが同じ値を持つと仮定することを意味する。

この例では、すべての推定矢印の開始値を 0.3 とし、先に示した経路図に従ってフィールドにラベル付けを行う。 

\vspace{2mm}

```{r}
A <- matrix(c(0, 0, 0, 0, 0, "0.3*Ins_Q", 0          ,
              0, 0, 0, 0, 0, "0.3*Ins_L", 0          ,
              0, 0, 0, 0, 0, "0.3*Ins_E", 0          ,
              0, 0, 0, 0, 0, 0          , "0.3*Las_D",
              0, 0, 0, 0, 0, 0          , "0.3*Las_H",
              0, 0, 0, 0, 0, 0          , 0          ,
              0, 0, 0, 0, 0, 0          , 0
              ), nrow = 7, ncol = 7, byrow=TRUE)

# 列名と行名をつける
dimnames(A)[[1]] <- dimnames(A)[[2]] <- dims

```

最後のステップは、$\boldsymbol{A}$ 行列を `as.mxMatrix` 関数に入れて、ステージ2モデルで使用できるようにすることである。


```{r}
A <- as.mxMatrix(A)
```

<br></br>

$\boldsymbol{S}$ **行列**


$\boldsymbol{S}$ 行列では、推定したい分散を指定する。この例では、これらはすべての観測変数の分散と、2つの潜在要因の間の相関である。まず、潜在要因の自分自身との相関を1に設定した。さらに、観測された変数の分散は 0.2、相関は 0.3 という開始値を使用する。これらはすべてこのコードで指定することができる。

\vspace{2mm}

```{r}
# 分散を表す対角行列を作る
Vars <- Diag(c("0.2*var_Q", "0.2*var_L", 
               "0.2*var_E", "0.2*var_D", "0.2*var_H"))

# 潜在変数に対する行列を作成する
Cors <- matrix(c(1, "0.3*cor_InsLas",
                 "0.3*cor_InsLas", 1),
               nrow=2, ncol=2)

# 結合する
S <- bdiagMat(list(Vars, Cors))

# 列名と行名をつける
dimnames(S)[[1]] <- dimnames(S)[[2]] <- dims
```


そして、再び、`as.mxMatrix` を用いて行列に変換する。

```{r}
S <- as.mxMatrix(S)
```

<br></br>

$\boldsymbol{F}$ **行列**

最後に、$\boldsymbol{F}$  行列を指定するのは簡単である。観測された変数の対角要素には 1 を記入し、それ以外は 0 を使用する。さらに、行列の少なくとも 1 つの要素が 0 でない行だけを選択する（つまり、最後の 2 行は 0 しか含まれていないので削除する）。

```{r}
# 対角行列を作成
F1 <- Diag(c(1, 1, 1, 1, 1, 0, 0))

# ヌルでないだけを選択
F1 <- F1[1:5,]

# 行ラベルと列ラベルの指定
dimnames(F1)[[1]] <- dims[1:5]
dimnames(F1)[[2]] <- dims

F1 <- as.mxMatrix(F1)
```


<br></br>

### モデル適合

---

さて、いよいよ提案したモデルをプールされたデータに適合させる。これを行うには、 `tsem2` 関数を使用する。ステージ1のモデル `cfa1`、3つ行列、そして  `diag.constraints=FALSE` を指定するだけである（mediation モデルを適用しているわけではないため）。結果として得られるオブジェクトを `cfa2` として保存し、`summary` を用いてアクセスする。

\vspace{2mm}

```{r, eval=T}
cfa2 <- tssem2(cfa1, 
               Amatrix = A, 
               Smatrix = S, 
               Fmatrix = F1, 
               diag.constraints = FALSE)
summary(cfa2)
```

```
## [...]
## Coefficients:
##            Estimate Std.Error lbound ubound z value Pr(>|z|)    
## Las_D         0.688     0.081  0.527  0.848   8.409  < 0.001 ***
## Ins_E         0.789     0.060  0.670  0.908  13.026  < 0.001 ***
## Las_H         0.741     0.088  0.568  0.914   8.384  < 0.001 ***
## Ins_L         0.658     0.053  0.553  0.763  12.275  < 0.001 ***
## Ins_Q         0.613     0.051  0.512  0.714  11.941  < 0.001 ***
## cor_InsLas    0.330     0.045  0.240  0.419   7.241  < 0.001 ***
## ---
## Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1
## 
## Goodness-of-fit indices:
##                                                Value
## Sample size                                3272.0000
## Chi-square of target model                    5.2640
## DF of target model                            4.0000
## p value of target model                       0.2613
## [...]
## RMSEA                                         0.0098
## RMSEA lower 95% CI                            0.0000
## RMSEA upper 95% CI                            0.0297
## [...]
## OpenMx status1: 0 ("0" or "1": The optimization is considered fine.
## Other values indicate problems.)
```


`OpenMxの状態`が `0` であり、最適化がうまくいったことがわかる。出力では、Lassitude $\rightarrow$  Daytime Dysfunction (`Las_D`)の0.69のように、2つの潜在因子と観察された症状の間のパスの推定値が提供される。私たちはまた、モデルによると、2つの潜在的な要因の間に有意な相関があることがわかる。  $r_{\text{Ins,Las}}$  = 0.33. 

しかし、最も重要なことは、想定したモデルがどの程度データに適合しているかをチェックすることである。これは `Goodness-of-fit indices` を見ることによって達成可能である。適合度検定は、$\chi^2_4=$ 5.26, $p=$  0.26 で、**有意でない**ことがわかる。他の統計検定とは異なり、このアウトカムは、私たちのモデルがデータに**よく**適合するという帰無仮説を受け入れることを意味するので、望ましい結果である。 

\index{Root Mean Square Error of Approximation (RMSEA)}

さらに、**近似値の二乗平均平方根誤差** (Root Mean Square Error of Approximation, RMSEA) の値は 0.0098 であることがわかる。経験則では、RSMEAの値が0.05以下であれば、モデルはデータによく適合していると考えることができ、値が小さいほど適合度が高いことを示している [@rmsea]。したがって、この適合度指数も、モデルが私たちのデータによく適合していることを示している。 

```{block, type='boximportant'}
**代替モデル**

\vspace{2mm}

SEM 研究によくある問題は、研究者が自分の提唱するモデルにのみ注目し、それがデータにうまく適合するかどうかに注目しがちなことである。もし、想定したモデルがデータに近い適合を示すことがわかれば、多くの研究者は、データが自分の理論を証明したと直接結論づけることが多い。

しかし、同じデータに対して複数のモデルがうまく適合する可能性があるため、これは問題である。したがって、代替モデルの仮説や構造も確認する必要がある。もし、代替モデルもデータにうまくフィットすれば、我々の提案した構造が本当に「正しい」ものなのかどうかがわからなくなる。

```

<br></br>

### パス図

---

\index{Path Diagram}
\index{semPlot Package}

```{r, echo=FALSE, eval=F}
load("data/cfa2.rda")
rm(F)
```

モデルの適合後、**{metaSEM}** はそれをグラフィカルに可視化することを非常に簡単にしてくれる。パス図を描くためには、まず、**{semPlot}** パッケージ [@semplot] をインストールし、ロードする必要がある。

\vspace{2mm}

```{r,message=FALSE, warning=FALSE}
library(semPlot)
```

モデルをプロットするために、**{semPlot}** が使用できる形式に変換する必要があるので、`meta2semPlot` 関数を使用して行っておこう。

\vspace{2mm}

```{r, message=F, eval=T}
cfa.plot <- meta2semPlot(cfa2)
```

そして、グラフを生成するために、**{semPlot}** の `semPaths` 関数を使ってみよう。この関数は多くのパラメータを持っており、コンソールに `?semPaths`  と入力し、Enterキーを押すことでアクセスすることが可能である。以下がコードと結果のプロットである。

\vspace{2mm}


```{r, fig.align="center", fig.width=4, fig.height=3, out.width="60%", eval=F}
# macOS 用文字化け対策
par(family= "HiraKakuProN-W3")

# プロットラベルを作成（左から右、下から上）
labels <- c("睡眠\nの質",
            "睡眠\n潜時",
            "睡眠\n効率",
            "日中機\n能障害",
            "過眠症","不眠", 
            "倦怠感")

# プロット
semPaths(cfa.plot, 
         whatLabels = "est", 
         edge.color = "black", 
         nodeLabels = labels,
         sizeMan = 10, 
         sizeLat = 10, 
         edge.label.cex = 1)
```


```{r, fig.align="center", fig.width=4, fig.height=3, out.width="60%", echo=F}
par(bg="#FFFEFA", family= "HiraKakuProN-W3")
# Create Plot labels (left to right, bottom to top)
labels <- c("睡眠\nの質",
            "睡眠\n潜時",
            "睡眠\n効率",
            "日中機\n能障害",
            "過眠症","不眠", 
            "倦怠感")

# Plot
semPaths(cfa.plot, 
         whatLabels = "est", 
         edge.color = "black", 
         nodeLabels = labels,
         sizeMan = 10, 
         sizeLat = 10, 
         edge.label.cex = 1)
```

```{block, type='boxinfo'}
**更なる学習**

\vspace{2mm}

この章で取り上げたことは、メタアナリシス SEM の初歩的な入門として捉えていただきたい。より詳細なメタアナリシス SEM の議論は、Mike Cheung の決定的な本である **Meta-Analysis: A Structural Equation Modeling Approach** [-@cheung2015meta] に記載されている。この本は、ここでカバーしていない他のさまざまな種類のメタ分析構造方程式モデルについても記述しており、 _R_ を使用してどのように実装できるかを説明されている。

\vspace{2mm}

短めの（そして、オープンにアクセスできる）リソースを探すのであれば、**{metaSEM}** パッケージの vignette をお読みいただきたい。この vignette には、メタアナリシスSEMの理論について簡単に説明し、 _R_ を使ったいくつかの図解を掲載している。**{metaSEM}** をロードした後、コンソールで `vignette("metaSEM")` を実行することにより、インターネットからヴィネットをダウンロードすることができる。

```


$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block, type='boxquestion'}
**知識を試そう！**

\vspace{4mm}

1. 構造方程式モデリングとは何か、何のために使うのか。

\vspace{-2mm}

2. SEM の表現方法として、どのようなものがあるか？

\vspace{-2mm}

3. ランダム効果メタ分析を SEM の観点から説明しなさい。

\vspace{-2mm}

4. 多変量メタ分析とは何か、どのような場合に有用か。

\vspace{-2mm}

5. 提案したメタ分析 SEM がデータによく適合することがわかったとき、このモデルが自動的に「正しい」モデルであることを意味するのだろうか。

\vspace{4mm}


**問題の解答は、本書の巻末 [Appendix A](#qanda11) にある。**

```

<br></br>

## 要約

* 構造方程式モデリング（SEM）は、観測される（＝顕在）変数と観測されない（＝潜在）変数の間の**複雑な関係**を検証するために使用できる統計手法である。

* メタ分析はマルチレベルモデルに基づいているため、SEM の観点からも定式化することが可能である。これは、ランダム効果メタ分析を構造方程式モデルとして「複製」するために使用することが可能である。しかし、より重要なことは、観測された効果量間のより複雑な関係をモデル化したメタ分析を行うことができることである。

* メタ分析 SEM は、例えば、**多変量メタ分析**を行うために適用することができる。多変量メタ分析では、2つ以上のアウトカムを、両アウトカム間の相関を考慮しながら、共同で推定する。 

* メタ分析的 SEM のもう一つの応用は、**確証的因子分析**である。含まれるすべての研究にわたって提案された因子モデルの適合性をテストするために、2段階の手順を使用しなければならない。第一段階では、個々の研究の相関行列がプールされる。そして、このプールされた相関行列は、想定された SEM を適合させるために使用される。 


<!--chapter:end:13-sem-ja.Rmd-->

# ネットワークメタ分析 {#netwma}

---

<img src="_figs/network.jpg" />

<br></br>

<span class="firstcharacter">臨</span>
床試験や他の種類の介入研究のメタ分析を行う場合、通常、**1**個の特定の治療の真の効果の大きさを推定する。我々は、同じ種類の介入を同様の対照群、例えばプラセボと比較した研究を含める。他の条件がすべて同じであれば、これは**特定の**種類の治療が効果的かどうかを評価することを可能にする。

しかし、多くの研究分野では、「決定的な」治療法は一つだけではなく、いくつもあるのである。例えば、片頭痛はいろいろな薬物療法があるし、非薬物療法の選択肢もある。特に「成熟した」研究分野では、ある種の治療が有効であることを示すことは、あまり意味がないことが多いのである。むしろ、ある特定の適応症に対して、どの治療法が**最も**効果的であるかを調べたいのである。

これは新たな問題を引き起こす。従来のメタ分析で複数の治療の比較有効性を評価するためには、2つの治療間の十分な head-to-head 比較が利用可能であることが必要である。しかし、残念なことに、そうではないこともよくある。多くの研究分野では、「弱い」対照群の代わりに、2つの治療の効果を**直接**比較した臨床試験は、一般にあったとしても少ない。このことは、従来のメタ分析では、複数の治療法の**相対的**な有効性に関する確かな証拠を確立できないことを意味することが多い。

しかし、2つ以上の治療法を直接比較することはできなくとも、**間接的**な証拠は通常利用可能である。異なる治療法が**別々の**試験で評価されたとしても、これらの試験はすべて**同じ**対照群を用いている可能性がある。例えば、直接比較されたことはない2種類の薬があるとしても、それぞれの効果がプラセボと比較して研究されている可能性がある。

\index{Mixed-Treatment Comparison Meta-Analysis}

**ネットワークメタ分析** (network meta-analysis) では、このような間接的な比較を取り入れ、複数の介入の効果を同時に比較することがが可能である [@dias2013evidence]。ネットワークメタ分析は、**混合治療比較メタ分析** (mixed-treatment comparison meta-analysis) としても知られている [@van2012automating]。これは、複数の直接的・間接的な治療比較を1つのモデルに統合し、比較の「ネットワーク」として形式化することができるからである。

\index{Consistency}

ネットワークメタ分析は「ホット」な研究トピックである。この10年間で、バイオ分野・メディカル分野やその他の分野の応用研究者によって取り上げられることが増えてきた。しかし、この方法には、異質性やいわゆる**ネットワークの矛盾** (network inconsistency) に関する、通常のメタ分析以上に課題や落とし穴もある [@salanti2014evaluating]。

したがって、まずネットワークメタ分析モデルの中核的な構成要素と前提について議論することが重要である。ネットワークメタ分析の基礎は、少し抽象的になることがある。そこで、この手法の理解を深めるために、本質的な内容を少しずつ見ていこう。

<br></br>

## ネットワークメタ分析とは何か? {#what-is-net-ma}

---

### 直接証拠と間接証拠 {#direct-indirect-evidence}

---

まず、治療の「ネットワーク」とは何を意味するのかを理解する必要がある。ある無作為化比較試験 $i$ からデータを抽出し、治療Aの効果を他の条件B（例えば、待機リスト対照群）と比較したとする。この比較を図式化することができる。


```{r, message = F, out.width = '75%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/graph1_col_sep.png')
```

\index{Graph Theory}\index{グラフ理論}

このように治療法の比較を視覚的に表現したものを**グラフ**と呼ぶ。グラフは、異なるオブジェクトが互いにどのように関連しているかをモデル化するために使用される構造であり、このトピックに関する数学の分野として、**グラフ理論**が存在する。

このグラフには2つの主要な構成要素がある。一つは、試行 $i$ における二つの条件AとBを表す二つの円(いわゆる**ノード**)である。2つ目は、この2つのノードを結ぶ線である。この線は**エッジ**と呼ばれる。エッジは、AとBがどのように関係するかを表す。私たちの場合、この線の解釈は非常に簡単である。AとBを比較したときに観測される効果の大きさ $\theta_{i\text{,A,B}}$ でAとBの関係を表すことが可能である。この効果の大きさは、例えば、結果の指標によって標準化平均差（SMD）やオッズ比などで表現することが可能である。

さて、別の試験 $j$ からもデータを得たとする。この試験でも対照条件Bを用いたが、Aを投与する代わりに別の治療法Cを用いた。

```{r, message = F, out.width = '75%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/graph2_col_sep.png')
```

これで最初の小さなネットワークができあがる。グラフに2つの効果量推定値が含まれていることがよくわかる。AとBを比較した $\hat\theta_{i\text{,A,B}}$ と、CとBを比較した $\hat\theta_{j\text{,C,B}}$ である。これらの効果量は両方とも「実際の」試験で直接観察されているので、我々はその情報を**直接的証拠**と呼んでいる。したがって、これらの効果量を $\hat\theta^{\text{direct}}_{\text{B,A}}$ と $\hat\theta^{\text{direct}}_{\text{B,C}}$ で表記する。この表記で条件Bが最初に来るのは、**基準**グループと決めたからである。Bを参照条件としたのは、両試験で対照群として用いられていたからである。

新しいグラフでは、すべてのノード（条件）は、**直接的**か、**間接的**に接続されている。B条件（対照群）は、他のすべてのノードに直接接続されている。Bから他の2つのノードA、Cに行くには、グラフ上で1つの「ステップ」しか必要ない：B $\rightarrow$ A, B $\rightarrow$ C。 一方、AとCは1つの直接接続しかなく、両方ともBに接続する：A $\rightarrow$ B と C $\rightarrow$ B。

しかし、AとCの間には間接的なつながりがある。このつながりは、Bが2つの条件  A $\rightarrow$ B と C $\rightarrow$ B の間のリンク、すなわち**ブリッジ**として機能するために存在する。その結果、ネットワークの構造から導き出されるAとCの関係の**間接的な証拠**が存在する。


```{r, message = F, out.width = '75%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/graph3_col_sep.png')
```

直接観測されたエッジの情報を使って、**間接的に**観測されたAとCの比較の効果を計算することが可能である。この非観測、間接効果量を $\hat\theta^{\text{indirect}}_{\text{A,C}}$ と表記する。効果推定値は、次の式を用いて導出できる。 [@dias2018network, chapter 1]:

\begin{equation}
\hat\theta_{\text{A,C}}^{\text{indirect}} = \hat\theta_{\text{B,A}}^{\text{direct}} - \hat\theta_{\text{B,C}}^{\text{direct}}
(\#eq:networkes)
\end{equation}

このステップは、ネットワークメタ分析の重要な要素である。上記の式は、たとえそれが試験で直接評価されなかったとしても、比較の効果量を推定することが可能である。

ネットワークメタ分析では、1つのモデルで直接および間接的なエビデンスを組み合わせる。この情報に基づいて、含まれる各治療の（相対）効果を推定することが可能である。間接的な証拠を追加することで、その特定の比較に直接的な証拠がある場合でも、効果量推定の精度を上げることが可能である。全体として、ネットワークメタ分析にはいくつかの利点がある。

* 関連する一連の研究から入手可能なすべての情報を1つの分析にプールすることができる。従来のメタ分析で、例えばプラセボと異なる治療法を比較する試験をどのように扱うかを考えてみてみよう。それぞれの比較（例えば、治療Aとプラセボの比較、治療Bとプラセボの比較、治療Aと治療Bの比較など）を別々のメタ分析でプールしなければならないだろう。

* ネットワークメタ分析では、従来のメタ分析では不可能であった間接的なエビデンスをネットワークに取り込むことが可能である。ペアワイズメタ分析では、実際に試験に含まれた比較のうち、直接的な証拠のみをプールすることができる。

* すべての仮定が満たされ、結果が十分に決定的であれば、ネットワークメタ分析によって、研究対象集団に対してどのタイプの治療が望ましいかを推論することができる。

これらはすべて興味深いものであるが、考慮すべき重要な限界がいくつかある。まず、間接効果量の推定値の分散がどのように計算されるかを見てみよう。

\begin{equation}
\text{Var} \left(\hat\theta_{\text{A,C}}^{\text{indirect}} \right) = \text{Var} \left(\hat\theta_{\text{B,A}}^{\text{direct}} \right) + \text{Var} \left(\hat\theta_{\text{B,C}}^{\text{direct}} \right)
(\#eq:nw2)
\end{equation}

間接比較の分散を計算するために、直接比較の分散を **足し算** した。つまり、間接的な証拠から推定される効果量は、直接的な証拠に基づくものよりも常に大きな分散を持ち、したがって精度も低くなる [@dias2018network, Chapter 1]。これは極めて論理的である。数学的に推測しなければならない結果に比べ、観測データから推定された効果量には、はるかに高い信頼性を持つことができるのである。 

\index{Consistency}
\index{Transitivity Assumption}\index{推移性仮定}

さらにもう1つの問題がある。直接比較から間接的な証拠を推定することができる先ほどの式 \@ref(eq:networkes) は、重要な前提条件である**推移性 (transivity)** の仮定が満たされた場合にのみ成立するのである。統計学的な観点からは、この仮定はネットワークの**一貫性 (consistency)** と訳される [@efthimiou2016getreal]。以下では、この2つの用語の意味と、それらがなぜ重要であるかを説明する。

<br></br>

### 推移性と一貫性 {#transivity-consistency}

---

ネットワークメタ分析は、標準的なメタ分析手法の延長線上にある貴重な手法であるのは間違いない。しかし、その有効性には疑問が残る。ネットワークメタ分析に対する批判の多くは、推察される通り、間接的な証拠の利用を中心に展開されている [@edwards2009indirect; @ioannidis2006indirect]。これは特に、比較のために直接証拠が実際に利用可能である場合を含んでいる。

（ランダム化）試験の参加者は治療条件（例えばAとB）のいずれかに**偶然**割り当てられるが、私たちのネットワークでは試験条件そのものはランダムに選択されていないという点は重要である。もちろん、これはすべて論理的なことである。通常、被験者をいくつかの試験条件のうちの1つにランダムに割り当てることは問題ない。しかし、研究者がサイコロを振って治験の治療条件を決めてから研究を展開することは考えにくい。ネットワークメタ分析では、選択された試験条件の構成がランダムなパターンになることはほとんどない。

これはネットワークメタ分析モデル自体の問題ではない [@dias2018network, Chapter 1]。ネットワークメタ分析モデルが偏るのは、試験内の特定の比較の選択、または非選択が、その比較の真の効果に依存する場合のみである [@dias2013evidence]。この表現はかなり抽象的なので、少し詳しく説明しよう。

\index{Consistency}
\index{Transitivity Assumption}\index{推移性仮定}

今述べた要件は、ネットワークメタ分析の**推移性**という仮定から導かれたものである。これがネットワークメタ分析に特有の仮定なのか、それとも従来の pairwise メタ分析の仮定を単に拡張したものなのかについては、文献上でも意見が分かれているようである。また、この意見の相違は、文献における用語の一貫性のない使い方にも一部起因している可能性がある [@dias2018network; @efthimiou2016getreal; @song2009methodological; @lu2009modeling]。

推移性の仮定の核となる考え方は、以前、式 \@ref(eq:networkes) [@efthimiou2016getreal] を用いて行ったように、（例えば比較A $-$ BとC $-$ Bから）直接証拠を組み合わせて、関連する比較（例えばA $-$ C）について間接証拠を作り出せることである。

\index{Exchangeability Assumption}

推移性の仮定は**交換性**の概念と関係している。この前提条件については、ランダム効果モデルについて説明した Chapter \@ref(rem) で既に述べた。交換可能性の仮定は、ある比較 $i$ のそれぞれの真の効果量 $\theta_i$ は、真の効果量の「包括的」分布からランダムに、**独立**に引き出された結果であることを言う。

この仮定を私たちのシナリオに置き換えると、ネットワークメタ分析は、$K$ 件の臨床試験のセットと考える。ここで、このモデルの各試験は、$M$ で示されるネットワークでの**すべての**治療比較を含むと仮定する（たとえば、A $-$ B, A $-$ C, B $-$ C, など）。しかし、いくつかの臨床試験では、治療比較が**"削除"**され、**"欠落"**しているものがある。その理由は、実際には、研究はすべての可能な治療法の選択肢を評価することはできないからである [@dias2013evidence]。

重要な前提としては、ある比較、例えばA $-$ Bの効果は、試験間で**交換可能**であり、ある試験が実際にこの比較を評価したか、それが 「欠落」しているかは関係ない、ということである。ネットワークメタ分析では、ある比較 $i$ の効果 $\hat\theta_i$ が、効果量が直接または間接的な証拠によって得られたとしても、真の効果の包括的な分布からのランダムで独立した抽選に基づくとき、交換性が満たされる。

共変量や他の効果修飾因子（調査集団の年齢層や治療強度など）が、例えば、条件A対B、C対Bを評価する試験間で均等に分布していない場合、推移性の仮定が破られる可能性がある [@song2009methodological]。推移性を統計的に検証することはできませんが、母集団、方法論、対象条件ができるだけ類似している試験のみを含めることで、この仮定に違反するリスクを軽減することがが可能である [@salanti2014evaluating]。

統計的な推移性の現れ方を**整合** (consistency) と言い、その欠如を**不整合** (inconsistency) と言う [@efthimiou2016getreal; @cipriani2013conceptual]。整合とは、直接証拠に基づく比較（例：A $-$ B）と間接証拠に基づく比較の相対的効果が異ならないことを意味する [@schwarzer2015meta, chapter 8]。
 
\begin{equation}
\theta_{\text{A,B}}^{\text{indirect}} = \theta_{\text{A,B}}^{\text{direct}}
(\#eq:nw3)
\end{equation}

\vspace{4mm}

\index{Node Splitting}

ネットワークメタ分析モデルの不整合を診断する方法として、**net heat plots** [@krahn2013graphical] や **node splitting** method [@dias2010checking] など、いくつかの方法が提案されている。これらの方法については、以下のセクションで詳しく説明する。

<br></br>

### ネットワークメタ分析のモデル {#netw-which-model}

---

以上で、ネットワークメタ分析モデルの基本的な理論と前提条件についての説明を終える。以前は、3つのノードとエッジを持つ単純なネットワークを説明として使用していた。しかし、実際には、ネットワークメタ分析に含まれる治療法の数は、通常、はるかに多くなる。そのため、すぐにかなり複雑なネットワークになり、例えば次のようなネットワークになる。

\vspace{4mm}

```{r, message = F, out.width = '75%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/graph4_col_sep.png')
```

しかし、ネットワーク内の治療法 $S$ の数が増えれば、推定しなければならない（直接・間接）一対比較 $C$ の数は急増する。

\vspace{4mm}

```{r, message=F, warning=F, fig.width=4, fig.height=3, out.width="45%", fig.align="center", echo=F}
library(ggplot2)

C <- function(S){S*((S-1)/2)}


ggplot(data = data.frame(x = 0), mapping = aes(x = x)) + 
  stat_function(fun = C, cex = 1) + xlim(0,20) + theme_classic() +
  annotate("text", label = expression(C == S~frac((S-1),2)), x = 6, y = 150) +
  xlab("Number of treatments/conditions in network (S)") +
  ylab("Number of comparisons (C)") +
  theme(plot.background = element_rect(fill = "#FFFEFA", color = "#fbfbfb"),
        panel.background = element_rect(fill = "#FFFEFA"))

```

\vspace{4mm}

\index{Frequentist Statistics}\index{頻度主義統計学}
\index{Bayesian Hierarchical Model}

したがって、効率的かつ内部的に一貫性のある方法で、利用可能なすべてのネットワークデータをプールできる計算モデルが必要である。ネットワークメタ分析のために、いくつかの統計的アプローチが開発されている [@efthimiou2016getreal]。以下の章では、**頻度論的階層モデル** (frequentist hierarchical model) と**ベイズ階層モデル** (Bayesian hierarchical model) について説明し、それらがどのように _R_ に実装され得るかを説明する。

```{block, type='boxinfo'}
**どのモデル手法を使うべきか？**

\vspace{2mm}

複数のネットワークメタ分析モデルがある場合、それぞれの統計手法が異なることもありうる。良いことにサンプルサイズが十分であれば、どれも同じ結果を出すはずである [@shim2019network]。一般的に、ネットワークメタ分析の方法は、他の方法よりも有効であるとか、有効でなかったりすることはない。そのため、直感的に選ぶか、またはそれを実装している _R_ パッケージの機能に基づいて、どちらかの方法を安全に選択することがが可能である [@efthimiou2016getreal]。

\vspace{2mm}

ほとんどの分野では、ベイズ的アプローチよりも頻度論的推論に基づく手法の方が（今でも）ずっと一般的である。これは、人によっては、頻度論的モデルが生み出す結果をより簡単に理解することができるためかもしれない。頻度論的モデルのデメリットとしては、 _R_ における頻度論的ネットワークメタ分析の実装（次に取り上げる）では、ベイズモデルで可能なメタ回帰がまだサポートされていないことが挙げられる。

\vspace{2mm}

実際には、メインの分析に1つのアプローチを選択し、感度分析でもう1つのアプローチを採用するのが有効な戦略である。2つの手法が同じ結論に至れば、その知見が信頼に足るものであるという確信が得られる。

```

<br></br>

## 頻度論的ネットワークメタ分析 {#frequentist-ma}

---

\index{netmeta Package}
\index{Frequentist Statistics}\index{頻度主義統計学}

以下では、**{netmeta}** パッケージ [@nemeta]  を用いたネットワークメタ分析の実行方法を説明する。このパッケージは、**頻度論的** (frequentist) 枠組みでネットワークメタ分析モデルを推定することが可能である。**{netmeta}** で使用されている手法は、もともと電気ネットワーク用に開発されたグラフ理論的手法から派生したものである [@rucker2012network]。

```{block, type='boxinfo'}
**確率の頻度論的解釈**

\vspace{2mm}

頻度論的とは、ある事象 $E$ の確率を解釈するための一般的な理論的アプローチである。頻出論的アプローチは、あるプロセス（例えば実験）を**何度も何度も繰り返した場合に$E$が発生すると予想される頻度で $E$ の確率を定義する** [@aronow2019foundations, chapter 1.1.1]。

頻度論的な考え方は、定量的な研究者が日常的に使う多くの統計処理、例えば有意性検定、信頼区間の計算、$p$ 値の計算などの核心となるものである。
```

<br></br>

### グラフ理論モデル

---

ここで、**{netmeta}** パッケージで実装されているネットワークメタ分析モデルがどのように定式化されるかを説明しよう。いくつかの臨床試験から効果量のデータを集めたとする。そして、$K$ 件すべての試験を調べて、試験に含まれる治療比較の総数を数える。この対の比較の数を $M$ 件とする。

そして、各比較 $m$ に対する効果量 $\hat\theta_m$ を計算し、全ての効果量をベクトル $\boldsymbol{\hat\theta} = (\hat\theta_1, \hat\theta_2, \dots, \hat\theta_M)$  に集める。ネットワークメタ分析を行うには、この観測された効果量のベクトル $\boldsymbol{\hat\theta}$ がどのように生成されたかを記述するモデルが必要である。**{netmeta}**では、以下のようなモデルを用いる [@schwarzer2015meta, Chapter 8]。

\begin{equation}
\boldsymbol{\hat\theta} =\boldsymbol{X} \boldsymbol{\theta}_{\text{treat}} + \boldsymbol{\epsilon} 
(\#eq:nw4)
\end{equation}

観測された効果の大きさのベクトル $\boldsymbol{\hat\theta}$ は、式の右辺--私たちのモデル--によって生成されたと仮定する。前段の $\boldsymbol{X}$ は $m \times n$ **デザイン行列**で、列は異なる治療法 $n$、行は治療比較 $m$ を表している。この行列では、治療比較は同じ行の1と-1で定義され、列の位置は比較される治療と対応する。

式の最も重要な部分は、ベクトル $\boldsymbol{\theta}_{\text{treat}}$ である。このベクトルは、ネットワーク内の $n$ 個のユニークな治療の**真の** 効果を含みる。このベクトルは、ネットワークメタ分析モデルが推定する必要があるもので、ネットワーク内のどの治療が最も効果的であるかを決定することを可能にするからである。

パラメータ $\boldsymbol{\epsilon}$ は、すべての比較のサンプリング誤差$\epsilon_m$を含むベクトルである。各比較のサンプリング誤差は、平均0、分散$\sigma^2_m$のガウス正規分布から無作為抽出であると仮定する。

\begin{equation}
\epsilon_m \sim \mathcal{N}(0,\sigma_m^2)
(\#eq:nw4)
\end{equation}

モデル式を説明するために [@schwarzer2015meta, page 189参照]、私たちのネットワークメタ分析が $K=$ 5 件の研究から構成されていると想像する。各研究は、ユニークな治療比較を含む（すなわち、$K=M$）。これらの比較は、A $-$ B, A $-$ C, A $-$ D, B $-$ C, および B $-$ Dである。この結果、（観測された）比較のベクトルは $\boldsymbol{\hat\theta} = (\hat\theta_{1\text{,A,B}}, \hat\theta_{2\text{,A,C}}, \hat\theta_{4\text{,A,D}}, \hat\theta_{4\text{,B,C}}, \hat\theta_{5\text{,B,D}})^\top$。 私たちの目的は、ネットワークに含まれる4つの条件全ての真の効果量、$\boldsymbol{\theta}_{\text{treat}} = (\theta_{\text{A}}, \theta_{\text{B}}, \theta_{\text{C}}, \theta_{\text{D}})^\top$ を推定することである。これらのパラメータをモデルの式に代入すると、次のような式が得られる。

\begin{align}
  \boldsymbol{\hat\theta} &= \boldsymbol{X} \boldsymbol{\theta}_{\text{treat}} + \boldsymbol{\epsilon} \notag \\
 \begin{bmatrix}
 \hat\theta_{1\text{,A,B}} \\
 \hat\theta_{2\text{,A,C}} \\
 \hat\theta_{3\text{,A,D}} \\
 \hat\theta_{4\text{,B,C}} \\
 \hat\theta_{5\text{,B,D}} \\
 \end{bmatrix}
 &=
 \begin{bmatrix}
 1 & -1 & 0 & 0 \\
 1 & 0 & -1 & 0 \\
 1 & 0 & 0 & -1 \\
 0 & 1 & -1 & 0 \\
 0 & 1 & 0 & -1 \\
 \end{bmatrix}
 \begin{bmatrix}
 \theta_{\text{A}} \\
 \theta_{\text{B}} \\
 \theta_{\text{C}} \\
 \theta_{\text{D}} \\
 \end{bmatrix}
 +
 \begin{bmatrix}
 \epsilon_{1} \\
 \epsilon_{2} \\
 \epsilon_{3} \\
 \epsilon_{4} \\
 \epsilon_{5} \\
 \end{bmatrix}
 (\#eq:nw5)
\end{align}


なお、このモデル式は、現在のままでは数学的な観点から問題がある。今のところ、このモデルは**overparameterized**である。手元の情報に基づいて推定するには、私たちのモデルにはあまりにも多くのパラメータ $\boldsymbol{\theta}_{\text{treat}}$ が存在する。

これは、デザイン行列 $\boldsymbol{X}$ が**フルランク**でないことと関係がある。我々の場合、行列は、その列がすべて**独立**でないとき、フルランクを持たない。または、別の言い方をすると、**独立**列の数が列の**総数** $n$ より小さいとき、フルランクを持たない ^[行列の行数が列数より少ない場合（$m < n$）、独立した**行**の数が行の総数 $m$ より小さいと、行列はフルランクではない。] 。治療の**ネットワーク**を扱っているので、治療の組み合わせが互いに完全に独立でないことは明らかである。例えば、治療Dの列（4列目）は、最初の3列の**線形結合**として記述することができる ^[最初の3列（治療法A、B、C）に-1を掛けて足すと、4列目の値が得られる $(-\boldsymbol{x}_1) + (-\boldsymbol{x}_2) + (-\boldsymbol{x}_3) = \boldsymbol{x}_4$。] 。

全体として、たかだか $n-1$ 個の独立した治療比較が存在することになるが、私たちのモデルは常に $\boldsymbol{\theta}_{\text{treat}}$ の $n$ 個の治療の真の効果を推定しなければならない。したがって、この行列はフルランクではない。このように $\boldsymbol{X}$ がフルランクを持たないということは、**invertible**ではないということである。したがって、$\boldsymbol{\theta}_{\text{treat}}$ は（加重）最小二乗法を使って直接推定することができないのである。

\index{Graph Theory}\index{グラフ理論}

そこで、**{netmeta}** に実装されている**グラフ理論**のアプローチが解決策を提供する。このアプローチの背後にある退屈な数学的詳細については、**{netmeta}** パッケージが作業をこなしてくれるので、ここでは割愛する。この方法は、いわゆる **Moore-Penrose 擬似逆行列**を構築し、重み付き最小二乗法を用いてネットワークモデルの適合値を計算することができる、ということだけを述べておく。

この手順では、2つ以上のペアワイズ比較（つまり、2つ以上の条件が比較された研究）を行う**マルチアーム**（訳注：arm は群と同じ意味）研究についても考慮する。マルチアーム比較は、少なくとも1つの条件が2回以上比較されるため、**相関**がある (Chapter \@ref(unit-of-analysis))。このことは、このモデルで説明しない限り、マルチアーム試験の比較の精度が人為的に高くなることを意味する。

また、このモデルでは、試験間の異質性 (heterogeneity) の推定値を組み込むことができる。「従来の」ランダム効果モデル（Chapter \@ref(rem) ）と同様に、比較 $m$ の分散に推定異質性分散 $\hat\tau^2$ を追加することで実現する。すなわち $s^2_m + \hat\tau^2$ である。**{netmeta}**パッケージでは、DerSimonian-Laird estimator 法  [@jackson2013matrix, Chapter \@ref(tau-estimators) も参照] を適応して$\tau^2$値を推定している。


\index{Consistency}

$I^2$ に相当するものも計算でき、これでネットワーク内の**不整合** (inconsistency) の量を表すことができる。この $I^2$ は、Higgins and Thompson の式と同様に、$Q$ から導かれる。ただし、ネットワークメタ分析では、$Q$ は**ネットワーク**の総異質性に変換される（$Q_{\text{total}}$とも表記される）。したがって、以下の式が使われる。

\begin{equation}
I^2 = \text{max} \left(\frac{Q_{\text{total}}-\text{d.f.}} {Q_{\text{total}}}, 0 \right) 
(\#eq:nw6)
\end{equation}

ここで、ネットワークの自由度は:

\begin{equation}
\text{d.f.} = \left( \sum^K_{k=1}p_k-1 \right)- (n-1)
(\#eq:nw7)
\end{equation}

とし、$K$ を研究の総数、$p$ をある研究 $k$ における条件の数、$n$ をネットワークモデルにおける治療の総数とする。

<br></br>

###  _R_ での頻度論的ネットワークメタ分析

---

ここまでインプットしたら、いよいよ実践的な例題である。以下では、**{netmeta}** を使って、独自のネットワークメタ分析を行う。いつものように、まずパッケージをインストールし、それからライブラリからロードする。

```{r, message=F, warning=F}
library(netmeta)
```

<br></br>

#### データを準備

---

この図では、`TherapyFormats` データを使用している。このデータセットは、うつ病に対する認知行動療法の異なる提供形式の有効性を評価する実際のネットワークメタ分析 [@cuijpers2019effectiveness] をモデルとしている。含まれるすべての研究は、うつ病の症状に対する効果がテスト後に測定されたランダム化比較試験である。含まれる比較の効果量は、分析された2つの条件間の標準化平均差（SMD）として表現されている。

\index{dmetar Package}

```{block, type='boxdmetar'}
**"TherapyFormats" データセット**

\vspace{2mm}

`TherapyFormats` データセットは **{dmetar}** パッケージに含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(TherapyFormats)` を実行すると、自動的に _R_ 環境にデータセットが保存される。これでデータセットが使用できるようになる。

\vspace{2mm}

**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/TherapyFormats.rda) から _.rda_ ファイルとしてデータセットをダウンロードし、作業ディレクトリに保存してから、R Studio ウィンドウでクリックしてインポートすることが可能である。

```


データを見てみよう。

```{r, message=F, warning=F}
library(dmetar)
data(TherapyFormats)

head(TherapyFormats[1:5])
```

* 2列目の `TE` には、すべての比較の効果量、そして `seTE` にはそれぞれの標準誤差が格納される。**{netmeta}** を使用するには、データセット内の全ての効果量が既に計算されている必要がある。効果量の計算方法については、Chapter \@ref(effects) で説明したが、Chapter \@ref(es-calc) の章では、さらに詳しい計算方法を紹介している。

* このデータセットには、さらに2つの列がある。このデータセットには、さらに2つの列が含まれているが、ここでは示していない。これらの列には、単純に条件のフルネームが格納されている。

* `studlab` 列は、特定の治療比較がどの研究から抽出されたかを示す、ユニークな研究ラベルを含んでいる。この列は、マルチアーム研究（すなわち、複数の比較対象がある研究）をチェックするのに便利である。これは、 `table` と `as.matrix` 関数を使用して行うことが可能である。

```{r, eval=F}
as.matrix(table(TherapyFormats$author))
```

```
## [...]
## Bengston, 2004              1
## Blevins, 2003               1
## Bond, 1988                  1
## Bonertz, 2015               1
## Breiman, 2001               3
## [...]
```

`TherapyFormats`のデータセットには、Breiman によるマルチアーム研究1件しか含まれていない。この研究には3つの比較が含まれているが、他の研究は1つしか含まれていない。

ネットワークメタ分析のデータを作成する際には、（1）データセットに研究ラベルの列を含めること、（2）その列で個々の研究に固有の名前を付けること、（3）2つ以上の比較に貢献する研究には**正確に**同じ名前を付けることが不可欠となる。

<br></br>

#### モデルを適合

---

`netmeta` 関数を使って、最初のネットワークメタ分析モデルを適合させることが可能である。最も重要な引数は以下の通りである。

* **`TE`**. 各比較の効果量を含むデータセットの列の名前である。

* **`seTE`**. 各比較の標準誤差を格納する列の名前。

* **`treat1`**.	データセット中の **最初の** 処置の名前を格納する列。

* **`treat2`**.	データセット中の **`treat2`** の列には、**2番目の** 処置の名前が含まれている。

* **`studlab`**.	比較対象が抽出された研究。この引数はオプションであるが、常に指定することを勧める。この引数は任意であるが、常に指定することを推奨する。これは、私たちのネットワークにマルチアーム試験がある場合に、この関数に知らせる唯一の方法である。

* **`data`**. データセットの名前である。

* **`sm`**. 使用する効果量の種類。`"RD"`（リスク差）、`"RR"`（リスク比）、`"OR"`（オッズ比）、`"HR"`（ハザード比）、`"MD"`（平均差）、 `"SMD"` （標準化平均差）などとすることができる。その他の利用可能な指標については、関数ドキュメント (`?netmeta`) を参照。

* **`fixed`**.	固定効果ネットワークメタ分析を行うかどうか？`TRUE` または `FALSE` を指定する必要がある。

* **`random`**.	ランダム効果モデルを用いるか？`TRUE` または `FALSE`。

* **`reference.group`**.	他の全ての治療に対して、どの治療を参照治療とするか（例： `reference.group = "grp"` ） を指定することが可能である。

* **`tol.multiarm`**.	 マルチアーム研究の比較の効果量は、デザイン上、一貫している。しかし、原著論文では、各比較でわずかにずれた結果が報告されていることがあり、その結果、整合性が損なわれていることがある。この引数で、効果量とその標準誤差の矛盾に対する**許容閾値**（数値）を指定することで、モデルで許容される。

* **`details.chkmultiarm`**.	効果量の不一致があるマルチアーム比較の推定値を表示するかどうか (`TRUE` または `FALSE`).

* **`sep.trts`**. 比較ラベルのセパレーターとして使用する文字（例：`" vs. "`）。

最初のネットワークメタ分析の結果は、`m.netmeta`という名前で保存される。参照グループとして、"care as usual" (`"cau"`) 条件を使用する。今は、固定効果モデルが適切であると仮定しよう。この場合、次のようなコードになる。

\vspace{2mm}

```{r, eval=F}
m.netmeta <- netmeta(TE = TE,
                     seTE = seTE,
                     treat1 = treat1,
                     treat2 = treat2,
                     studlab = author,
                     data = TherapyFormats,
                     sm = "SMD",
                     fixed = TRUE,
                     random = FALSE,
                     reference.group = "cau",
                     details.chkmultiarm = TRUE,
                     sep.trts = " vs ")
summary(m.netmeta)
```

```
## Original data (with adjusted standard errors for multi-arm studies):
## 
##                    treat1 treat2    TE seTE seTE.adj narms multiarm
## [...]
## Burgan, 2012          ind    tel -0.31 0.13   0.1390     2         
## Belk, 1986            ind    tel -0.17 0.08   0.0830     2         
## Ledbetter, 1984       ind    tel -0.00 0.23   0.2310     2         
## Narum, 1986           ind    tel  0.03 0.33   0.3380     2         
## Breiman, 2001         ind    wlc -0.75 0.51   0.6267     3        *
## [...]
## 
## Number of treatment arms (by study):
##                          narms
## Ausbun, 1997                 2
## Crable, 1986                 2
## Thiede, 2011                 2
## Bonertz, 2015                2
## Joy, 2002                    2
## [...]
## 
## Results (fixed effects model):
## 
##                treat1 treat2   SMD         95%-CI      Q leverage
## Ausbun, 1997      grp    ind  0.06 [ 0.00;  0.12]   0.64     0.03
## Crable, 1986      grp    ind  0.06 [ 0.00;  0.12]   3.05     0.01
## Thiede, 2011      grp    ind  0.06 [ 0.00;  0.12]   0.05     0.03
## Bonertz, 2015     grp    ind  0.06 [ 0.00;  0.12]   0.01     0.01
## Joy, 2002         grp    ind  0.06 [ 0.00;  0.12]   0.02     0.00
## [....]
## 
## Number of studies: k = 182
## Number of treatments: n = 7
## Number of pairwise comparisons: m = 184
## Number of designs: d = 17
## 
## Fixed effects model
## 
## Treatment estimate (sm = 'SMD', comparison: other treatments vs 'cau'):
##         SMD             95%-CI      z  p-value
## cau       .                  .      .        .
## grp -0.5767 [-0.6310; -0.5224] -20.81 < 0.0001
## gsh -0.3940 [-0.4588; -0.3292] -11.92 < 0.0001
## ind -0.6403 [-0.6890; -0.5915] -25.74 < 0.0001
## tel -0.5134 [-0.6078; -0.4190] -10.65 < 0.0001
## ush -0.1294 [-0.2149; -0.0439]  -2.97   0.0030
## wlc  0.2584 [ 0.2011;  0.3157]   8.84 < 0.0001
##
## 
## Quantifying heterogeneity / inconsistency:
## tau^2 = 0.26; tau = 0.51; I^2 = 89.6% [88.3%; 90.7%]
## 
## Tests of heterogeneity (within designs) and inconsistency (between designs):
##                       Q d.f.  p-value
## Total           1696.84  177 < 0.0001
## Within designs  1595.02  165 < 0.0001
## Between designs  101.83   12 < 0.0001
```

この出力には見るべきものがたくさんあるので、順を追って見ていこう。最初に見るのは、各比較の計算された効果量である。アスタリスク記号（*）は、標準誤差が（効果量の依存性を考慮し）修正された私たちのマルチアーム研究を示している。その下には、各研究の治療群の数の概要が示されている。

次の表は、私たちの（固定効果）ネットワーク・メタ分析モデルにおける各比較の適合値を示している。この表の $Q$ 列は、どの比較がネットワーク全体の不整合に大きく寄与しているかを示しており、とても興味深い。例えば、Crable, 1986 の $Q$ 値は $Q=$ 3.05 で、かなり高いことがわかる。

そして、ネットワークメタ分析の核心である「治療推定値」にたどり着く。指定されたように、すべての治療の効果は、通常通りのケアとの比較で表示されているが、それが `cau` の効果が表示されていない理由である。その下に、このネットワークモデルにおける異質性/非整合性が非常に高く、$I^2=$ 89.6%であることを見ることができる。これは、固定効果モデルの選択がおそらく適切では**なかった**ことを示している（この点については後ほど触れる）。

\index{Consistency}
\index{Heterogeneity}\index{異質性}

出力の最後の部分（`Tests of heterogeneity`）は、ネットワークにおける総異質性を、2つのコンポーネントに分解している。すなわち、**デザイン内**の異質性、および**デザイン間**の不一致である。「デザイン」とは、例えばA $-$ B、A $-$ B $-$ Cのように、1つの試験に含まれる条件の選択と定義される。全く同じ条件を含む試験間で真の効果量の差がある場合、デザイン内異質性と呼ぶことができる。一方、デザイン間のばらつきは、私たちのネットワークの矛盾を反映している。デザイン内異質性、デザイン間不整合性ともに非常に有意である（$p$s < 0.001）。

これは、ランダム効果モデルが指示されている可能性を示すもう一つのサインである。これをさらに裏付けるために、**full design-by-treatment interaction random-effects model** [@higgins2012consistency] に基づくtotal inconsistencyを算出することが可能である。これを行うには、`m.netmeta`オブジェクトを`decomp.design`関数に差し込めばよいのである。

\vspace{2mm}

```{r, eval=F}
decomp.design(m.netmeta)
```

```
## Q statistics to assess homogeneity / consistency
##  [...]
## Design-specific decomposition of within-designs Q statistic
## 
##      Design      Q df  p-value
##  cau vs grp   82.5 20 < 0.0001
##  cau vs gsh    0.7  7   0.9982
##  cau vs ind  100.0 29 < 0.0001
##  cau vs tel   11.4  5   0.0440
##  [...]
## 
## Between-designs Q statistic after detaching of single designs
## 
##    Detached design      Q df  p-value
##  [...]
##         ind vs wlc  77.23 11 < 0.0001
##         tel vs wlc  95.45 11 < 0.0001
##         ush vs wlc  95.81 11 < 0.0001
##  gsh vs ind vs wlc 101.78 10 < 0.0001
##
## Q statistic to assess consistency under the assumption of
## a full design-by-treatment interaction random effects model
## 
##                    Q df p-value tau.within tau2.within
## Between designs 3.82 12  0.9865     0.5403      0.2919
```

\index{Cochran's \textit{Q}}

出力では、まず、このモデルにおけるデザイン内およびデザイン間の異質性/非整合性に対する各デザインの個々の寄与を示す $Q$ 値が示される。出力の重要な部分は、最後の部分（`Q statistic to assess consistency under the assumption of a full design-by-treatment interaction random effects model`）である。完全な design-by-treatment のランダム効果モデルを仮定すると、$Q$ の値がかなり減少し（以前は $Q=$ 101.83、今は $Q=$ 3.83）、デザイン間の矛盾が有意でなくなったことがわかる（$p=$ 0.9865）。 

このことは、私たちのネットワークモデルにおける矛盾や異質性を説明するために、少なくとも部分的にランダム効果モデルが示される可能性をも示唆している。


<br></br>

#### ネットワークモデルのさらなる検証

---

##### ネットワークグラフ

---

\index{Network Graph}

`netmeta` を使ってネットワークメタ分析モデルをフィットさせた後、**ネットワークグラフ** を作成することができる。これは `netgraph` 関数を用いて行うことが可能である。`netgraph` 関数には多くの引数があり、コンソールで `?netgraph` を実行すれば調べることができる。しかし、これらの引数のほとんどは、非常に賢明なデフォルト値を持っているので、あまり多くのことを指定する必要はない。

最初のステップとして、フィットしたモデル `m.netmeta` を関数に与えてみる。モデルでは短縮ラベルを使用しているので、プロットでは長いラベル（`treat1.long` と `treat2.long` に格納）に置き換える必要がある。これは、 `labels` 引数を用いて行うことができ、すべての治療法の完全な名前を指定する必要がある。治療ラベルは、 `m.netmeta$trts` に格納されているものと同じ順序である必要がある。

\vspace{4mm}

```{r, echo=F}
load("data/m.netmeta.rda")
```

```{r}
# Show treatment order (shortened labels)
m.netmeta$trts
```


```{r, message=F, warning=F, eval=F}
# Replace with full name (see treat1.long and treat2.long)
long.labels <- c("Care As Usual", "Group", 
                 "Guided Self-Help", 
                 "Individual", "Telephone", 
                 "Unguided Self-Help", 
                 "Waitlist")

netgraph(m.netmeta, 
         labels = long.labels)
```

```{r, message=F, warning=F, echo=F, fig.width=7, fig.height=7, echo=F, fig.align='center', out.width="55%"}

# Replace with full name (see treat1.long and treat2.long)
long.labels <- c("Care As Usual", "Group", "Guided \n Self-Help", 
                 "Individual", "Telephone", 
                 "Unguided \n Self-Help", "Waitlist")

par(bg="#FFFEFA")
# Produce the plot
netgraph(m.netmeta, labels = long.labels, col.multiarm = "lightgray", offset = 0.03, cex = 1.5)

long.labels <- c("Care As Usual", "Group", "Guided Self-Help", 
                 "Individual", "Telephone", 
                 "Unguided Self-Help", "Waitlist")
```

このネットワークグラフはいくつかの種類の情報を運ぶ。まず、我々はネットワークにおける比較の全体的な構造を見ることが可能である。これは、元のデータでどの治療が互いに比較されたかをよりよく理解することが可能である。

さらに、プロット中のエッジが異なる**幅**を持っていることがわかる。幅の大きさは、ネットワークで特定の比較を見つける頻度を表している。例えば、ガイド付きセルフヘルプのフォーマットは、多くの試験で待機リストと比較されていることがわかる。また、網掛けされた三角形で表現されたマルチアーム試験も見られる。これはBreimanによる研究で、ガイド付き自己啓発、個人セラピー、待機者リストの3つを比較したものである。

`netgraph`関数は、**3Dグラフ**を描くこともでき、複雑なネットワーク構造をよりよく把握するのに便利である。この関数は、**{rgl}**パッケージがインストールされ、ロードされていることが必要である。3Dグラフを作成するためには、`dim` 引数を `"3d"` に設定するだけである。

```{r, eval=F}
library(rgl)
netgraph(m.netmeta, dim = "3d")
```

<br></br>

##### 直接証拠と間接証拠の可視化

---

次のステップでは、各比較を推定するために使用される**direct**と**indirect**の証拠の比率を見よう。**{dmetar}** の `direct.evidence.plot` 関数は、この目的のために開発された関数である。

\index{dmetar Package}

```{block, type='boxdmetar'}
**"direct.evidence.plot" 関数**

\vspace{4mm}

`direct.evidence.plot` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

1. 関数のソースコードにアクセスする [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R). 
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。
3. **{ggplot2}** と **{gridExtra}** パッケージがインストールされ、ロードされていることを確認する。

```


この関数は、各推定比較に使用された直接証拠と間接証拠のパーセンテージを示すプロットを提供する。`direct.evidence.plot`関数が入力として必要とするのは、フィットしたネットワークメタ分析モデル `m.netmeta`のみである。

\vspace{2mm}

```{r, message=F, warning=F, fig.width=8, fig.height=5, fig.align='center', out.width="75%", eval=F}
library(dmetar)

d.evidence <- direct.evidence.plot(m.netmeta)
plot(d.evidence)
```


```{r, message=F, warning=F, fig.width=8, fig.height=5, fig.align='center', out.width="75%", echo=F}
library(dmetar)
# source("data/direct.evidence.plot.bw.R")

d.evidence <- dmetar::direct.evidence.plot(m.netmeta)
plot(d.evidence)
```

\index{Mean Path Length}
\index{Minimal Parallelism}

\vspace{2mm}

見てわかるように、このネットワークモデルには、間接的な証拠だけで推論しなければならない推定値がいくつかあることがわかる。また、このプロットでは、各推定比較の**最小並列度**と**平均パス長**という2つの追加指標を得ることが可能である。König, Krahn, and Binder [-@konig2013visualizing] によると、平均パス長 > 2 であるとは、比較推定が特に注意して解釈されるべきことを意味する。

<br></br>

##### 効果推計表

---

次に、すべての可能な治療比較について、私たちのネットワークの推定値を見ることができる。これを行うには、 `m.netmeta$TE.fixed` （固定効果モデルを使用した場合）または `m.netmeta$TE.random` （ランダム効果モデルを使用した場合）に保存された行列を使用することで可能である。行列を読みやすくするために、いくつかの前処理をしておこう。まず、`m.netmeta`オブジェクトからデータを抽出し、行列の数値を小数点以下2桁に丸める。

```{r}
result.matrix <- m.netmeta$TE.fixed
result.matrix <- round(result.matrix, 2)
```

行列の1つの「三角形」が冗長な情報を持つことを考慮して、このコードを使って下の三角形を空の値に置き換える。

```{r}
result.matrix[lower.tri(result.matrix, diag = FALSE)] <- NA
```

これにより、次のような結果が得られる。

```{r}
result.matrix
```

これらの結果を研究論文で報告する場合、各効果量の推定値の信頼区間を含める方がよいだろう。これは、 `m.netmeta` の `lower.fixed` と `upper.fixed` （または `lower.random` と `upper.random` ）行列を使用して、以前と同じ方法で取得することが可能である。

さらに便利な方法は、 `netleague` 関数を使用して、すべての推定効果量をエクスポートすることである。この関数は、上で作成したものと同じような表を作成する。しかし、`netleague`によって生成された行列では、上部の三角形は、私たちのネットワークで利用可能な**直接比較**のプール効果量のみを表示し、我々がそれぞれの比較について従来のメタ分析を行った場合のようなものを達成することが可能である。我々はすべての比較について直接の証拠を持っているわけではないので、上側の三角形のいくつかのフィールドは空のままである。`netleague` が生成する行列の下側の三角形には、**それぞれ**比較の推定効果量が含まれる（間接的な証拠しか得られないものも含まれる）。

`netleague` の出力は、簡単に.csv ファイルにエクスポートすることが可能である。これは、ネットワークメタ分析の包括的な結果を1つの表で報告するために使用することが可能である。この関数を使用するもう一つの大きな利点は、効果量推定値と信頼区間が各セルに一緒に表示されることである。このような治療推定表を作成して、"netleague.csv" という名前の .csv ファイルとして保存したい。これは、以下のコードを用いて実現が可能である。

```{r}
# Produce effect table
netleague <- netleague(m.netmeta, 
                       bracket = "(", # use round brackets
                       digits=2)      # round to two digits

# Save results (here: the ones of the fixed-effect model)
write.csv(netleague$fixed, "netleague.csv")
```


<br></br>

##### 治療法のランキング

---

\index{Surface Under the Cumulative Ranking (SUCRA) Score}
\index{P-Score}

ネットワークメタ分析で答えられる最も興味深い問題は、どの治療が最も高い効果を持つかということである。**{netmeta}** に実装された `netrank` 関数は、この点で役に立つ。これは、治療の**ランキング**を生成することができ、どの治療が最大の効果をもたらす可能性が高いか低いかを示す。

`netrank` 関数は、`netmeta` 自体で使われているモデルと同様に、頻度論的アプローチに基づいている。この頻度論的手法は、治療の順位付けに **P-score** を使用している。これは、ある治療が他の治療よりも優れているという確実性を、すべての競合する治療に対して平均して測定するものである。P-スコアは、ベイズネットワークメタ分析の章で説明する **SUCRA** スコア[@rucker2015ranking]と同等であることが示されている。

`netrank` 関数は入力として `m.netmeta` というモデルを必要とする。さらに、`small.values` パラメータを指定する必要がある。これは、比較において小さい（つまり、負の）効果量が有益（`"good"`）または有害（`"bad"`）の効果を示しているかを定義するものである。ここでは、`small.values = "good"`を使用する。つまり、効果量が負であるとき、ある治療法が**うつ病を減少させる**のに有効であることを意味する。

```{r}
netrank(m.netmeta, small.values = "good")
```

個人セラピー（`ind`）のPスコアが最も高く、この治療形式が特に有用であることを示している。逆に、待機者リスト（`wlc`）のPスコアはゼロである。これは、単に治療を待たせることは最良の選択肢ではないという直感と一致しているようである。

とはいえ、ランキング[@mbuagbaw2017approaches]で最高スコアだからといって、ある治療法が「最善」であると自動的に結論づけるべきでは決してないだろう。このネットワークにおける**不確実性**をよりよく可視化する方法は、ある条件を比較群として使用したフォレストプロットを作成することである。

\index{Forest Plot}\index{フォレストプロット}

**{netmeta}** では、`forest` 関数を使用してこれを実現することができる。**{netmeta}**の `forest` 関数の動作は、Chapter \@ref(forest) で説明した **{meta}** パッケージの `forest` 関数と非常によく似ている。主な違いは、forestプロットで参照グループを `reference.group` 引数で指定する必要があることである。また、care us usual (`"cau"`) を使用する。

\vspace{4mm}

```{r, fig.width=6, fig.height=4, out.width="80%", fig.align='center'}
forest(m.netmeta, 
       reference.group = "cau",
       sortvar = TE,
       xlim = c(-1.3, 0.5),
       smlab = paste("Therapy Formats vs. Care As Usual \n",
                     "(Depressive Symptoms)"),
       drop.reference.group = TRUE,
       label.left = "Favors Intervention",
       label.right = "Favors Care As Usual",
       labels = long.labels)
```

\vspace{4mm}

フォレストプロットでは、個人療法以外にも高いパフォーマンスを示す治療形式があることがわかる。また、信頼区間の一部が重なっていることもわかる。このため、明確な判断は容易ではない。個別治療が最も良い結果を出しているように見えるが、いくつかの治療法も通常のケアと比較して大きな効果を上げている。


<br></br>

#### 結果の妥当性を評価

---


##### ネットヒートプロット {#net-heat-plot}

---

**{netmeta}** パッケージは `netheat` という関数を内蔵しており、これにより **ネットヒートプロット** を作成することが可能である。ネットヒートプロットは、ネットワークモデルの不整合や、どのようなデザインが不整合に寄与しているかを評価するのに非常に有効である。

`netheat` 関数は、フィットしたネットワークメタ分析オブジェクトを必要とするだけで、プロットを生成する。

```{r, fig.width=5, fig.height=5, eval=F}
netheat(m.netmeta)
```

```{r, message = F, out.width = '60%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/heat_fixed_col_sep.png')
```

この関数は、行の各デザインが他のデザイン（列）と比較される2次ヒートマップを生成する。重要な点は、行と列が、このネットワークにおける個々の治療**比較**ではなく、特定の**デザイン**を意味することである。したがって、このプロットは、マルチアーム研究で使用されたデザイン（ガイド付き自助、個人療法、待機者リストの比較）の行と列も特徴としている。ネットヒートプロットには2つの重要な特徴がある[@schwarzer2015meta, chapter 8]。

\index{Consistency}

* **灰色のボックス**。灰色のボックスは、ある治療比較が他の治療比較の推定にどれだけ重要であるかを示すものである。ボックスが大きければ大きいほど、その比較はより重要である。これを分析する簡単な方法は、プロットの行を次々に見ていき、各行でどのボックスが最も大きいかをチェックすることである。よくある発見は、ヒートマップの対角線上にあるボックスが大きいことである。これは、直接証拠が使われたことを意味するからである。例えば、特に大きなボックスは、 "cau vs grp" 行と "cau vs grp" 列の交点で見ることが可能である。

* **色のついた背景**。色のついた背景は、**行**のデザインが**列**のデザインに起因する**不整合**の量を意味する。フィールドの色は、深い赤（強い矛盾を示す）から青（このデザインからの証拠が行の証拠をサポートすることを示す）までの範囲となる。`netheat` 関数は、アルゴリズムを使用して、行と列を矛盾が大きいクラスタと小さいクラスタにソートする。このプロットでは、いくつかの矛盾したフィールドが左上隅に表示されている。例えば、"ind vs wlc" の行では、"cau vs grp" の列のエントリーが赤く表示されていることが分かる。これは、"ind vs wlc" の推定に対して "cau vs grp" が寄与しているエビデンスが矛盾していることを意味する。一方、"gsh vs wlc" 列のフィールドは濃い青色で表示されており、これはこのデザインの証拠が行デザイン "ind vs wlc" の証拠を**サポート**していることを表している。

この結果は、固定効果モデルを用いてネットワークメタ分析モデルを適合させたため、固定効果モデルに基づいていることを再認識する必要がある。しかし、これまでの研究から、固定効果モデルの使用は適切ではないことが次第に明らかになってきた--異質性とデザインの矛盾が多すぎるのである。

そこで、ランダム効果モデルを仮定したときに、ネットヒートプロットがどのように変化するかを確認してみよう。`netheat` の `random` 引数を `TRUE` に設定することにより、これを行うことが可能である。

```{r, fig.width=5, fig.height=5, eval=F}
netheat(m.netmeta, random = TRUE)
```

```{r, message = F, out.width = '60%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/heat_random_col_sep.png')
```

この結果、ネットワーク内の不整合が大幅に減少していることがわかる。暗赤色の背景を持つフィールドはなくなった。これは、ランダム効果モデルが使用されると、私たちのモデルの全体的な一貫性がかなり改善されることを示している。

したがって、私たちのデータには、ランダム効果モデルが望ましいと結論づけることが可能である。実際には、`netmeta`を使用して `comb.random` を `TRUE` に設定しながら（そして `comb.fixed` を `FALSE` に設定して）モデルを再実行し、ランダム効果モデルに基づく分析結果のみを報告することになる。また、ランダム効果モデルに基づく分析結果のみを報告する。

<br></br>

##### ネット分割化 {#net-splitting}

---

\index{Node Splitting}

私たちのネットワークの一貫性をチェックするもう1つの方法は、**ネット分割化**である。この方法は、私たちのネットワーク推定を直接証拠と間接証拠の寄与に分割し、私たちのネットワーク内の個々の比較の推定における矛盾をコントロールすることを可能にするものである。ネット分割手法を適用するには、適合したモデルで `netsplit` 関数を提供するだけでよい。


```{r, eval=F}
netsplit(m.netmeta)
```

```
## Separate indirect from direct evidence using back-calculation method
## 
## Fixed effects model: 
## 
##  comparison  k prop     nma  direct  indir.    Diff     z  p-value
##  grp vs cau 21 0.58 -0.5767 -0.3727 -0.8628  0.4901  8.72 < 0.0001
##  gsh vs cau  8 0.22 -0.3940 -0.5684 -0.3442 -0.2243 -2.82   0.0048
##  ind vs cau 30 0.71 -0.6403 -0.7037 -0.4863 -0.2174 -3.97 < 0.0001
##  tel vs cau  6 0.35 -0.5134 -0.7471 -0.3867 -0.3604 -3.57   0.0004
##  ush vs cau  9 0.35 -0.1294 -0.1919 -0.0953 -0.0966 -1.06   0.2903
##  [...]
## 
## Legend:
##  [...]
##  Diff       - Difference between direct and indirect estimates
##  z          - z-value of test for disagreement (direct vs. indirect)
##  p-value    - p-value of test for disagreement (direct vs. indirect)
```

出力で示される最も重要な情報は、直接的証拠と間接的証拠に基づく効果推定値の差（`Diff`）と、この差が有意であるかどうか（`p-value`列で示される）である。差が$p<$ 0.05のとき、直接推定と間接推定の間に有意な不一致（不整合）があることになる。

出力では、（固定効果モデルを使用した場合）直接証拠と間接証拠の間に有意な不一致を示す比較が確かにたくさんあることがわかる。正味の分割結果を可視化する良い方法は、フォレストプロットである。

```{r, fig.width=7, fig.height=17, fig.align='center', out.width="79%"}
netsplit(m.netmeta) %>% forest()
```

<br></br>

##### 比較調整済みファネルプロット

---

\index{Funnel Plot}\index{ファンネルプロット}

ネットワークメタ分析モデルで出版バイアスを評価することは困難である。Chapter \@ref(pub-bias) で紹介した手法の多くは、従来のメタ分析からネットワークメタ分析へ移行すると、そのまま適用することはできない。しかし、ネットワークメタ分析における出版バイアスのリスクを評価するために、**比較調整ファンネルプロット**が提案されており、特定の条件下では使用することがが可能である [@salanti2014evaluating]。このファンネルプロットは、出版バイアスがネットワークモデルにどのような影響を与えたかに関する**特定の**仮説がある場合に適用される。

例えば、サンプルサイズが小さくても、「新規」の知見を持つ研究は出版される可能性が高いので、出版バイアスが生じる可能性がある。科学には、「画期的な」結果を出そうとする自然な動機がある。例えば、新しいタイプの治療法が現在の技術水準よりも優れていることを示すためである。

ということは、今回のデータには small-study effect（Chapter \@ref(small-study-effects) 参照）のようなものが存在することになる。新しい治療法と古い治療法を比較した場合の効果は、ファネルプロットにおいて**非対称**に分布していることが予想される。これは、「期待はずれ」の結果（つまり、新しい治療法が古い治療法より優れていない）が、ファイルの引き出しに入るからである。サンプルサイズが小さくなるにつれて、新しい治療法の有益性は、有意になるためにますます大きくなり、したがって、出版に値するようになる必要がある。理論的には、これは標準的なメタ分析で見られる特徴的な非対称のファンネルプロットを作成することになる。

もちろん、このようなパターンは、プロット内の効果量がある方法でコード化されている場合にのみ現れる。例えば、「新旧仮説」を検証するためには、プロットで使用される各効果量が同じように解釈できることを確認する必要がある。例えば、正の効果量は常に「新しい」治療が優れていたことを示し、負の符号はその反対を意味することを確認する必要がある。これは、古い治療法から新しい治療法への「ランキング」を定義し、このランキングを使用して各効果の符号を定義することで実現が可能である。

**{netmeta}**の `funnel` 関数は、このような比較調整されたファネルプロットを生成するために使用することが可能である。以下は最も重要な引数である。

* **`order`**.	この引数は、仮説とされる出版バイアスメカニズムの順序を指定する。我々は、単にネットワーク内のすべての治療名を提供し、私たちの仮説に従ってそれらをソートする必要がある。たとえば、出版バイアスが「新しい」治療を好むかどうかを検証したい場合、すべての治療名を挿入し、最も古い治療から始めて、最も新しいタイプの介入で終了する。

* **`pch`**. これは、ファネルプロットで使用する研究のシンボルを指定するものである。`19`に設定すると、例えば単純なドットが表示される。

* **`col`**.	この引数を使用すると、異なる比較を区別するために使用する色を指定することが可能である。ここで指定する色の数は、ファネルプロットにおける **ユニーク** な比較の数と同じでなければならない。実際には、これは多くの異なる色が必要であることを意味する。 _R_ がプロットに使用できる色の完全なリストは、[オンライン](http://www.stat.columbia.edu/~tzheng/files/Rcolor.pdf)で見ることが可能である。

* **`linreg`**.	TRUE` に設定すると、ファネルプロットの非対称性に対する Egger の検定 (Chapter \@ref(eggers-test)) が行われ、その $p$ 値がプロット内に表示される。

引数は **{meta}** の `funnel` 関数に定義されているものを追加で使用することも可能である。


```{r, fig.width=7, fig.height=5, eval=F}
funnel(m.netmeta, 
      order = c("wlc", "cau", "ind", "grp", # from old to new
                "tel", "ush", "gsh"), 
      pch = c(1:4, 5, 6, 8, 15:19, 21:24), 
      col = c("blue", "red", "purple", "forestgreen", "grey", 
              "green", "black", "brown", "orange", "pink", 
              "khaki", "plum", "aquamarine", "sandybrown", 
              "coral", "gold4"), 
      linreg = TRUE)
```

```{r, fig.width=9, fig.height=7, fig.align='center', out.width="78%", echo=F}
par(bg="#FFFEFA")
funnel(m.netmeta, 
      order = c("wlc", "cau", # from old to new
                "ind", "grp", "tel", 
                "ush", "gsh"), 
      pch = c(1:4, 5, 6, 8, 15:19, 21:24), 
      col = c("blue", "red", "purple", "forestgreen", "grey", 
              "green", "black", "brown", "orange", "pink", 
              "khaki", "plum", "aquamarine", "sandybrown", 
              "coral", "gold4"), 
      linreg = TRUE)
```

もし仮説が正しければ、サンプルサイズが小さい（つまり標準誤差が大きい）研究は、プロットのゼロ線付近に非対称に分布すると予想される。これは、新しい治療法と古い治療法を比較し、新しい治療法が優れていないことを発見した小規模の研究は、出版される可能性が低いからである。したがって、これらの研究は漏斗の片側で系統的に欠落しているのである。

しかし、このプロットは極めて対称的に見える。これは Egger の検定で確認されたが、有意ではないであった（$p=$ 0.402）。全体として、これは私たちのネットワークに小規模研究の効果があることを示すものではない。少なくとも、優れた効果を持つ「革新的な」治療法は、発表された文献の中に見つかる可能性が高いからである。

```{block, type='boxinfo'}
**Network Meta-Analysis using {netmeta}: Concluding Remarks**

\vspace{2mm}

この章は長い章であり、新しいトピックを大量にカバーしてきた。**{netmeta}** で使われている統計モデルの背後にあるコアなアイデアを示し、このアプローチでネットワークメタ分析モデルを適合させる方法、結果を可視化し解釈する方法、そして発見の妥当性を評価する方法について説明した。ネットワークメタ分析における（臨床）意思決定は、1つのテストやメトリックに基づくべきでないことは、十分に強調することができない。

その代わりに、私たちは素直な目でモデルとその結果を探求し、見つけたパターンの一貫性をチェックし、推定値に関連する大きな不確実性を考慮に入れなければならないのである。

\vspace{2mm}

次章では、ベイズの観点からネットワークメタ分析を（再び）考えてみる。このアプローチの背後にある哲学は、ここで説明したものとかなり異なるが、どちらの手法も本質的に同じことを達成しようとするものである。実際、解析の「パイプライン」も驚くほど似ている。さあ、ベイズ解析の時間だ。

```

<br></br>

## ベイズ的ネットワークメタ分析 {#bayesian-net-ma}

---

以下では、ベイズ型階層構造フレームワークに基づくネットワークメタ分析の実行方法を説明する。このために使用する _R_ パッケージは、**{gemtc}** [@van2012automating]と呼ばれるものである。しかし、その前に、一般的なベイズ推論の考え方と、ネットワークメタ分析に使用できるベイズモデルの種類を考えてみよう。


<br></br>

### ベイズ推論 {#bayesian-inference}

---

\index{Bayes' Theorem}
\index{Frequentist Statistics}\index{頻度主義統計学}
\index{Conditional Probability}

ベイズ推定は、頻度論的 (frequentist) 統計学とは別に、重要な統計学である。頻度論的統計学は、ほとんどの研究分野でより頻繁に使用されていると言ってよいでしょう。しかし、ベイズアプローチの方が実は古く、近年は研究者に取り上げられることが多くなっており [@marsman2017bayesian]、決して「無くなった」わけではない [@mcgrayne2011theory]。

ベイズ統計学の基礎となるのは、トーマス・ベイズ牧師 [1701-1761、@bellhouse2004reverend] が最初に定式化した**ベイズの定理**である。ベイズ統計学が頻出主義と異なるのは、「主観的」な**事前**知識も取り入れて推論を行う点である。ベイズの定理は、ある事象Aが発生する確率を、別の事象Bが発生したことを既に知っていると仮定して推定することを可能にする。これは、**条件付き確率**と呼ばれ、$P(\text{A}|\text{B})$ のように表現される。この定理は、この条件付き確率の計算方法を説明する公式に基づいている。

\begin{equation}
P(\text{A}|\text{B})=\frac{P(\text{B}|\text{A})\times P(\text{A})}{P(\text{B})}
(\#eq:nw8)
\end{equation}

\index{Posterior Distribution}
\index{Prior Distribution}

この式では、分数の分子にある2つの確率にそれぞれ名前がついている。$P(\text{B}|\text{A})$  の部分は、**尤度**（ゆうど）と呼ばれる。Aがある場合に事象Bが発生する確率である [@etz2018introduction]。$P(\text{A})$ は、$A$ が発生する**先行**確率である。$P(\text{A}|\text{B})$ は、**posterior** 確率で、B が与えられたときの A の確率である。

\begin{equation}
P(\text{A}|\text{B}) \propto P(\text{B}|\text{A})\times P(\text{A})
(\#eq:nw9)
\end{equation}


ここで、$\propto$ という記号は、分数の分母を捨てたので、値が変化しても、左側の確率は右側の部分と少なくとも**比例**していることを意味している。

ベイズの定理は、上の式の右辺から順に考えていくと理解しやすい。Aの確率に関する事前情報と、Aが起こる場合のBの可能性を組み合わせて、Aの事後確率（適応確率） $P(\text{A}|\text{B})$ を出すだけなのである。ここで重要なのは、前の知識を考慮すると、Aの確率の「より良い」（事後）推定値が得られるということである。この知識は、Aの確率を仮定したもの（事前確率）である。

ベイズの定理は、AやBを特定の事象に見立てて、先ほどの方法で説明されることが多いようである。しかし、AやBを2つの変数の**確率分布**と考えることもが可能である。Aを正規分布に従う確率変数とする。この分布は、パラメータの集合で特徴付けることができ、それを $\boldsymbol{\theta}$ で表す。Aは正規分布なので、 $\boldsymbol{\theta}$ にはAの真の平均 $\mu$ と分散 $\sigma^2$ の2つの要素が含まれている。

さらに、Bについて、$\boldsymbol{\theta}$ の推定に使いたい**実測データ**を集めたとする。観測されたデータをベクトル $\boldsymbol{Y}$ に格納する。また、観測データは正規分布に従うので、$P({Y})$ で表される。このことから、次のような式が成り立つ。

\begin{equation}
P(\boldsymbol{\theta} | {\boldsymbol{Y}} ) \propto P( {\boldsymbol{Y}} | \boldsymbol{\theta} )\times P( \boldsymbol{\theta})
(\#eq:bayes)
\end{equation}

\index{Credible Interval}

この式には、$P(\boldsymbol{\theta})$ という $\boldsymbol{\theta}$ の事前分布を仮定している。この事前分布は、これまでの知識に基づいて、あるいは直感的に $\boldsymbol{\theta}$ がどのようなものであるかを、私たちが _a priori_ に定義することが可能である。尤度分布 $P({\boldsymbol{Y}}|\boldsymbol{\theta})$ と、パラメータ $\boldsymbol{\theta}$ が与えられたときのデータの確率 $P(\boldsymbol{\theta}|{\boldsymbol{Y}})$ から、事後分布を推定することができる。この事後分布は、観測データと事前知識の両方を考慮した場合の $\boldsymbol{\theta}$ の推定値を表している。

\index{Credible Interval}

重要なのは、事後分布はあくまでも**分布**であって、1つの推定「真」値ではないことである。つまり、ベイズ推論の結果であっても**確率的**であることに変わりはない。また、実際のパラメータ値に対する私たちの**信念**を表すという意味で、**主観的**なものでもある。したがって、ベイズ統計学では、推定値の信頼区間を計算するのではなく、**信用（確信）区間** (Credible Interval, CrI) を計算するのである。

ここで、先ほど説明した3つの分布が、具体的な例ではどのように見えるかを可視化してみよう。

```{r, message = F, out.width = '93%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/prior_col_sep.png')
```

\index{Markov Chain Monte Carlo}
\index{Gibbs Sampler}

ベイズアプローチのもう一つの利点は、パラメータが可視化されたようなベルカーブ分布に従う必要がないことである。他の種類の（より複雑な）分布もモデル化することができる。しかし、ベイズ推定の欠点は、収集したデータから（結合）分布を生成するのに、非常に計算コストがかかることである。事後分布を生成するために、**Gibbs サンプリング法**などの特殊な**マルコフ連鎖モンテカルロ**シミュレーション手法が開発された。マルコフ連鎖モンテカルロは、ベイジアンネットワークメタ分析モデルを実行するための **{gemtc}** パッケージでも使用されている [@van2012automating]。

<br></br>

### ベイズ的ネットワークメタ分析モデル {#bayesian-net-ma-model}

---


#### ペアワイズメタ分析

---

ここでは、**{gemtc}** がネットワークメタ分析に用いるベイズ型階層モデルを定式化する。まず、従来のペアワイズメタ分析のモデルを最初に定義することから始めましょう。

\index{Bayesian Hierarchical Model}

この定義は、「標準的な」ランダム効果モデルについて説明した Chapter \@ref(rem)  の定義と同等である。以下に述べるのは、メタ分析を概念化するための「ベイズ的な方法」に過ぎない。一方、このベイズ的なペアワイズメタ分析の定義は、これ以上拡張しなくても、ネットワークメタ分析に直接適用できるので、すでに非常に有益なものとなっている [@dias2013evidence]。

このモデルをベイズ型**階層**モデルと呼んでいる [@efthimiou2016getreal、より詳細な議論は Chapter \@ref(bayes-hierarchical-model) を参照]。ここで言う「階層的」というのは、何も不思議なことではない。実際、メタ分析・モデルは階層構造、つまり「多階層」を前提としていることは、既に Chapter \@ref(multilevel-ma) で説明した。

例えば、従来のメタ分析を実施するとしよう。$K$ 件の研究が含まれ、各研究の観測された効果量 $\hat\theta_k$ を計算する。そして、固定効果モデルを次のように定義する。

\begin{equation}
\hat\theta_k \sim \mathcal{N}(\theta,\sigma_k^2)
(\#eq:nw11)
\end{equation}

この式は、効果量が正規分布に従うと仮定して、効果量の**尤度**式中の $P(\boldsymbol{Y}|\boldsymbol{\theta})$ 部分を表現したものである。各効果量は同じ分布からの抽選であり、その平均が真の効果量 $\theta$、分散が $\sigma^2_k$ であると仮定する。固定効果モデルでは、真の効果量は全ての研究で同一であると仮定するので、異なる研究 $k$ とその観測された効果量 $\hat\theta_k$ に対して、$\theta$ は変わらない。

\index{Uninformative Prior}
\index{Prior Distribution}

ベイズモデルの面白いところは、本当の効果 $\theta$ が未知でも、その事前分布を定義できることである。この事前分布は、$\theta$ がどのように見えると考えるかを近似する。例えば、平均が0の正規分布に基づく事前分布を $\theta \sim \mathcal{N}(0, \sigma^2)$ (ここで $\sigma^2$ を指定)と仮定することが可能である。

**{gemtc}** パッケージでは、デフォルトで **uninformative priors** と呼ばれる、分散が非常に大きな事前分布を使用する。これは、事前の「信念」が事後結果に大きな影響を与えないようにするためで、主に実際に観測されたデータに「語らせる」ようにする。この式は、ランダム効果モデルに簡単に拡張することができる。

\begin{equation}
\hat\theta_k \sim \mathcal{N}(\theta_k,\sigma_k^2)
(\#eq:nw12)
\end{equation}

この式は、各研究が同じ真の効果量 $\theta$ の推定量であると仮定しないことを除けば、あまり変わらない。その代わりに、各観測効果量 $\hat\theta_k$ によって推定される "試験固有"の真の効果量 $\theta_k$ が存在すると仮定する。さらに、これらの研究固有の真の効果は、真の効果量の包括的な分布の一部である。この真の効果量分布は、その平均値 $\mu$ と分散 $\tau^2$（私たちの研究間異質性）によって定義される。

\begin{equation}
\theta_k \sim \mathcal{N}(\mu,\tau^2)
(\#eq:nw13)
\end{equation}

また、ベイズモデルでは、$\mu$ と $\tau^2$ の両方に（非情報的な）事前分布を与える。

<br></br>

#### ネットワークメタ分析への拡張

---

さて、ベイズメタ分析モデルが1対比較のためにどのように定式化されるかをカバーしたので、それをネットワークメタ分析に拡張することを始めましょう。前のランダム効果モデルの2つの公式は、このために再利用することが可能である。我々は、モデル・パラメータを少し違った形で概念化するだけである。ネットワークメタ分析では、比較対象が様々な治療法からなることがあるので、ある研究 $k$ で見つかった効果量を $\hat\theta_{k \text{,A,B}}$  で表す。これは、治療Aと治療Bを比較した研究 $k$ における効果量を意味する。この新しい表記法を適用すると、以下の式が得られる。

\begin{align}
\hat\theta_{k \text{,A,B}} &\sim \mathcal{N}(\theta_{k \text{,A,B}},\sigma_k^2) \notag \\
\theta_{k \text{,A,B}} &\sim \mathcal{N}(\theta_{\text{A,B}},\tau^2) (\#eq:nw14)
\end{align}

式で表される一般的な考え方は変わらないことがわかる。ここで、A $-$ B比較の（研究固有の）真の効果、$\theta_{k \text{,A,B}}$ は、平均 $\theta_{text{A,B}}$ を持つ真の効果の包括的分布の一部であると仮定する。この平均真の効果量 $\theta_{1\text{,A,B}}$ は、$\theta_{1\text{,B}}$ から $\theta_{1\text{,A}}$ を減算した結果であり、$\theta_{1\text{,A}}$ はある定義済みの参照治療 $1$ と比べた治療Aの効果である。同様に、$\theta_{1\text{,B}}$は、同じ参照治療と比較した治療Bの効果として定義されている。ベイズモデルでは、参照群と比較したこれらの効果も事前分布を与えられる。

前章の頻度論的ネットワークメタ分析ですでに述べたように、マルチアーム研究をネットワークモデルに含めることは、効果量が相関してしまうので問題がある。ベイズネットワークメタ分析では、この問題は、マルチアーム研究の効果が**多変量**（正規）分布に由来すると仮定することによって解決することが可能である。

マルチアーム試験 $k$ が、合計 $n=$ 5 の治療法を調べたとする。E を参照治療とすると、$n$ - 1 = 4 の治療効果があることになる。ベイズ階層モデルを用いて、これらの観測された治療効果が次の形式の多変量正規分布からのドローであると仮定する^[実際には、多群試験における試験間不均一性分散は、通常それぞれの比較間で**同質** (つまり、同一)であると仮定される。これにより、行列内のすべての共分散を $\tau^2/2$ として定義することがが可能である]。

  
\begin{align}
 \begin{bmatrix}
 \hat\theta_{k\text{,A,E}} \\
 \hat\theta_{k\text{,B,E}} \\
 \hat\theta_{k\text{,C,E}} \\
 \hat\theta_{k\text{,D,E}} 
 \end{bmatrix}
 &=
 \mathcal{N}\left(
 \begin{bmatrix}
 \theta_{\text{A,E}} \\
 \theta_{\text{B,E}} \\
 \theta_{\text{C,E}} \\
 \theta_{\text{D,E}}
 \end{bmatrix}
 ,
 \begin{bmatrix}
 \tau^2 & \tau^2/2 & \tau^2/2 & \tau^2/2 \\
 \tau^2/2 & \tau^2 & \tau^2/2 & \tau^2/2 \\
 \tau^2/2 & \tau^2/2 & \tau^2 & \tau^2/2 \\
 \tau^2/2 & \tau^2/2 & \tau^2/2 & \tau^2 
 \end{bmatrix}
 \right).
 (\#eq:nw15)
\end{align}


<br></br>

### _R_ におけるベイズ的ネットワークメタ分析

---

\index{gemtc Package}

それでは、最初のベイジアンネットワークメタ分析を行うために、**{gemtc}** パッケージを使用してみよう。いつものように、まずパッケージをインストールし、ライブラリからロードする必要がある。

```{r, message=F, warning=F}
library(gemtc)
```

\index{Gibbs Sampler}
\index{JAGS}
\index{rjags Package}

**{gemtc}** パッケージは、以前説明した Gibbs サンプリング手順で使用する **{rjags}** [@rjags] に依存している（Chapter \@ref(bayesian-inference) 参照）。ただし、このパッケージをインストールして読み込む前に、まず **JAGS** (Just Another Gibbs Sampler の略) という別のソフトをインストールする必要がある。このソフトは Windows と Mac の両方に対応しており、[インターネット](https://sourceforge.net/projects/mcmc-jags/files/)から無料でダウンロード可能。これが完了したら、**{rjags}** パッケージをインストールして読み込むことができる^[技術的には、**JAGS**はコンピュータプログラムであるだけでなく、**{gemtc}**がバックグラウンドで使用しているベイズモデリングのためのプログラミング言語でもある（マニュアルは  [こちら](https://people.stat.sc.edu/hansont/stat740/jags_user_manual.pdf) から見ることがが可能である）。JAGS自体は、1980年代後半から存在する**BUGS**（「Bayesian inference Using Gibbs Sampling」の略）言語に大きく依存している [@lunn2012bugs, chapter 2.2.1]]。

\vspace{2mm}

```{r, eval=F}
install.packages("rjags")
library(rjags)
```

<br></br>

#### データを準備

---

この例では、すでに頻出ネットワークメタ分析に使用した `TherapyFormats` データセットを再び使用する。しかし、**{gemtc}** で使用できるように、データの構造を少し調整する必要がある。

元の `TherapyFormats` データセットには `TE` と `seTE` という列があり、各行が1つの比較を表す標準化平均値と標準誤差が格納されている。このような相対効果データを **{gemtc}** で使用したい場合、各行が1つの**治療群**を表すようにデータフレームの形を変更する必要がある。さらに、効果量の列に`NA`を記入して、比較でどの治療が参照群として使われたかを指定する必要がある。このように整形したデータセットを "TherapyFormatsGeMTC" という名前で保存している^[また、「より広い」**{netmeta}** 形式のネットワークメタ分析データを、**{gemtc}**の相対効果量データに必要な「Long」形式に変換する方法を説明する _R_ vignette を用意する。この vignette は、 https://www.protectlab.org/vignettes/reshape-gemtc/ で見ることが可能である]。

\index{dmetar Package}

```{block, type='boxinfo'}
**"TherapyFormatsGeMTC" データセット**

\vspace{2mm}

`TherapyFormatsGeMTC` データセットは **{dmetar}** パッケージに含まれている。**{dmetar}** をインストールし、ライブラリからロードした後、 `data(TherapyFormatsGeMTC)` を実行すると、自動的にデータセットが _R_ 環境にセーブされる。これでデータセットが利用できるようになる。もし、**{dmetar}** がインストールされていない場合は、[インターネット](https://www.protectlab.org/meta-analysis-in-r/data/TherapyFormatsGeMTC.rda) から _.rda_ ファイルとしてダウンロードし、作業ディレクトリに保存した後、R Studio のウィンドウでクリックするとインポートすることが可能である。

```


`TherapyFormatsGeMTC` データセットは、2つの要素を持つリストで、そのうちの1つは `data` と呼ばれるものである。この要素は、モデルを適合させるために必要なデータフレームである。それでは、見ていこう。

```{r, warning=F, message=F, eval=F}
library(dmetar)
data(TherapyFormatsGeMTC)

head(TherapyFormatsGeMTC$data)
```

```{r, warning=F, message=F, echo=F}
library(dmetar)
load("data/TherapyFormatsGeMTC.rda")
head(TherapyFormatsGeMTC$data)
```


**{gemtc}** パッケージを使う際は、データフレームの列名を**{gemtc}** が指定する列名にする必要がある。連続的な結果（平均差や標準化平均差など）に基づく効果量を使用する場合、以下の列名が必要である。

* **`study`**. この列には、ネットワークに含まれる各研究の（ユニークな）ラベルが含まれ、**{netmeta}**で使用されている `studlab` 列と同じである。

* **`treatment`**. この列は治療法のラベルまたは短縮コードを含む。

* **`diff`**. この列には、比較のために計算された効果量（例えば、標準化された平均差）が含まれる。`diff` 列には、比較で使用された参照治療の行は`NA`（欠損）とする必要がある。そして、参照治療が比較された治療の行には、この比較のために計算された実際の効果量が格納される。また、参照カテゴリは、**比較単位**ではなく、**試験単位**で定義されていることに留意されたい。これは、多群間試験において、他のすべての治療が比較される参照治療は1つしかないことを意味する。例えば、3群間研究では、2つの効果量を含める必要がある。1つは参照グループと比較した第一治療、もう1つは参照グループと比較した第二治療の効果量である。

* **`std.err`**. この列は、効果量の標準誤差を含む。参照群では`NA`に設定され、参照群と比較された治療法の行でのみ定義される。

２値アウトカムのデータなど、他のデータ入力フォーマットも可能である。効果量データの種類によって、データセットがどのように構成される必要があるかは、**{gemtc}** のドキュメントで詳しく説明されている。コンソールで `?mtc.model` を実行し、"Details" セクションにスクロールすることでアクセスが可能である。

<br></br>

#### ネットワークグラフ

---

さて、データの準備ができたので、これを `mtc.network` 関数に渡す。これにより、`mtc.network` クラスのオブジェクトが生成され、後のモデル作成段階で使用することが可能である。あらかじめ計算された効果量データを使用するため、`mtc.network` の `data.re` 引数でデータセットを指定する必要がある。生の効果量データ（例：平均、標準偏差、サンプルサイズ）を使用する場合は、`data.ab` 引数を使用することになる。

オプションの `treatments` 引数を使用すると、ネットワークに含まれるすべての治療の実際の名前を **{gemtc}** に提供することが可能である。この際、データフレームの列名は `id` と `description` でなければならない。ここでは事前にデータフレームを作成し、`TherapyFormatsGeMTC`に `treat.codes` として保存してある。

```{r}
TherapyFormatsGeMTC$treat.codes
```

このデータフレームと `TherapyFormatsGeMTC` の効果量データを使って、 `mtc.network` オブジェクトを作成する。それを `network` という名前で保存する。

```{r}
network <- mtc.network(data.re  = TherapyFormatsGeMTC$data,
                       treatments = TherapyFormatsGeMTC$treat.codes)
```

作成されたオブジェクトを `summary` 関数に代入すると、すでにネットワークに関する興味深い情報を得ることが可能である。

```{r, eval=F}
summary(network)
```

```
## $Description
## [1] "MTC dataset: Network"
## 
## $`Studies per treatment`
## ind grp gsh tel wlc cau ush 
##  62  52  57  11  83  74  26  
## 
## $`Number of n-arm studies`
## 2-arm 3-arm 
##   181     1 
## 
## $`Studies per treatment comparison`
##     t1  t2 nr
## 1  ind tel  4
## 2  ind wlc 18
## 3  grp ind  7
## [...]
```

\index{Network Graph}

また、`plot`関数を使用してネットワークプロットを生成することもが可能である。**{netmeta}** パッケージで生成されたネットワークと同様に、エッジの太さはその比較に含めた研究数に対応している。

\vspace{2mm}

```{r, fig.width=8, fig.height=8, fig.align="center", out.width="65%", message=F, warning=F, eval=F}
plot(network, 
     use.description = TRUE) # Use full treatment names
```


```{r, fig.width=9, fig.height=8, fig.align="center", out.width="55%", message=F, warning=F, echo=F}
par(bg="#FFFEFA")
plot(network, 
     use.description = TRUE) # Use full treatment names
```

\vspace{2mm}

別の方法として、**Fruchterman-Reingold アルゴリズム**を用いて、ネットワークのより良い視覚化を作成できるかどうかを確認することもが可能である。このアルゴリズムには固有のランダム性があるため、結果を再現できるように seed を設定する必要がある。

ネットワークプロットは **{igraph}** パッケージ [@igraph] を使って作成される。このパッケージがインストールされ、ロードされたとき、プロットの外観を変えるために他の引数も使うことが可能である。異なるスタイルオプションの詳細な説明はオンラインの **{igraph}** [manual](https://igraph.org/r/doc/plot.common.html) にある。

\vspace{2mm}

```{r, fig.width=10, fig.height=8, fig.align="center", out.width="55%", message=F, warning=F, eval=F}
library(igraph)
set.seed(12345) # set seed for reproducibility

plot(network, 
     use.description = TRUE,            # Use full treatment names
     vertex.color = "white",            # node color
     vertex.label.color = "gray10",     # treatment label color
     vertex.shape = "sphere",           # shape of the node
     vertex.label.family = "Helvetica", # label font
     vertex.size = 20,                  # size of the node
     vertex.label.dist = 2,             # distance label-node center
     vertex.label.cex = 1.5,            # node label size
     edge.curved = 0.2,                 # edge curvature
     layout = layout.fruchterman.reingold)
```

```{r, fig.width=10, fig.height=8, fig.align="center", out.width="55%", message=F, warning=F, echo=F}
library(igraph)
set.seed(12345) # set seed for reproducibility
par(bg="#FFFEFA")
plot(network, 
     use.description = TRUE,            # Use full treatment names
     vertex.color = "white",            # node color
     vertex.label.color = "gray10",     # treatment label color
     vertex.shape = "sphere",           # shape of the node
     vertex.label.family = "Helvetica", # label font
     vertex.size = 20,                  # size of the node
     vertex.label.dist = 2,             # distance label-node center
     vertex.label.cex = 1.5,            # node label size
     edge.curved = 0.2,                 # edge curvature
     layout = layout.fruchterman.reingold)
```


<br></br>

#### モデルのコンパイル

---

`mtc.network` オブジェクトを使用して、モデルの指定とコンパイルを開始することが可能である。**{gemtc}** パッケージの素晴らしいところは、ベイズ推定プロセスのほとんどの部分を自動化できることである。例えば、モデル中のすべてのパラメータに対して適切な事前分布を選択することが可能である。

\index{Markov Chain Monte Carlo}

このように、`mtc.model` 関数を用いてモデルをコンパイルする際に指定しなければならない引数はごくわずかである。まず、前に作成した `mtc.network` オブジェクトを指定する。さらに、`linearModel` 引数を用いて、ランダム効果モデルか固定効果モデルのどちらを使用するかを決定しなければならない。頻度論的分析では、かなりの異質性と不整合が見られたため (Chapter \@ref(net-heat-plot) 参照)、`linearModel = "random"` を使用する。また、使用する**マルコフ連鎖**の数を指定する必要がある。ここでは、3から4の間の値が賢明で、`n.chain = 4` とする。

さらに、オプションで `likelihood` と `link` という2つの引数を指定することが可能である。この2つの引数は、使用している効果量データの種類によって異なり、明示的に指定しない限りは **{gemtc}** によって自動的に推論される。我々は連続的な結果データ（SMDなど）に基づく効果量を扱っているので、「正規」 (normal) の尤度と 「同一」 (indetity) のリンクを仮定している。

２値アウトカム（対数オッズ比など）を使用していた場合、適切な尤度 (likelyhood) とリンク (link) はそれぞれ `"binom"` （二項）と `"logit"` であったでろう。これに関する詳細は `mtc.model` のドキュメントに記載されている。しかし、前のステップでデータが正しく準備されている場合には、通常 `mtc.model` は自動的に正しい設定を選択する。

```{r}
# We give our compiled model the name `model`.
model <- mtc.model(network,
                   likelihood = "normal",
                   link = "identity",
                   linearModel = "random",
                   n.chain = 4)
```


<br></br>

#### マルコフ連鎖モンテカルロ法サンプリング

---

\index{Markov Chain Monte Carlo}

さて、いよいよ分析の重要な部分であるマルコフ連鎖モンテカルロ法（MCMC）サンプリングに入る。MCMCシミュレーションは、パラメータの事後分布を推定し、ネットワークメタ分析の結果を生成することが可能である。この手順で達成したい重要な望みが2つある。

* マルコフ連鎖モンテカルロ法の最初の数回の実行が、シミュレーションの結果に大きな影響を与えないようにしたい。

* マルコフ連鎖モンテカルロ法は、モデルパラメータの正確な推定値を得るために十分な時間実行する必要がある（すなわち、**収束**する必要がある）。

これらの点を解決するために、マルコフ連鎖モンテカルロ法のアルゴリズムがモデル結果を推論するために反復する回数を**2つのフェーズ**に分割した：まず、**burn-in**反復回数（`n.adapt`）を定義し、その結果は破棄される。次のフェーズでは、モデルパラメータの推定に実際に使用するシミュレーションの反復回数(`n.iter`)を指定する。

通常、多くの反復計算を行うため、`thin`引数を指定することで、$i$番目の反復計算の値のみを抽出することもが可能である。これにより、必要なコンピュータのメモリを削減することが可能である。

シミュレーションは `mtc.run` 関数を用いて行うことが可能である。この例では、異なる設定で2回実行し、どちらがより効果的かを比較する。コンパイルした `model` オブジェクトを関数に与え、先ほど説明したパラメータを指定する必要がある。

まず、数回の繰り返しのシミュレーションをおこない、次に、大きな繰り返しのシミュレーションをおこないる。両方のオブジェクトをそれぞれ `mcmc1` と `mcmc2` という名前で保存する。ネットワークの大きさによっては、シミュレーションが終了するまでに時間がかかることがある。

\vspace{2mm}


```{r, eval=F}
mcmc1 <- mtc.run(model, n.adapt = 50, n.iter = 1000, thin = 10)
mcmc2 <- mtc.run(model, n.adapt = 5000, n.iter = 1e5, thin = 10)
```


<br></br>

#### モデルの収束を評価 {#bayesian-model-convergence}

---

シミュレーションの結果、アルゴリズムが収束したかどうか、また、どの設定が好ましいかを確認するために、`mcmc1` と `mcmc2` オブジェクトの出力をいくつか評価することが可能である。 `plot` 関数を使用することは、良いスタートである。これは、すべての反復における各治療比較について、一般的に**trace plot**と呼ばれる一種の 「時系列」を提供する。この例では、個人セラピー（`ind`）と待機者コントロール（`wlc`）の比較の推定値にのみ焦点を当てる。

```{r, eval=F}
plot(mcmc1)
plot(mcmc2)
```


```{r ch14-1353, echo=F, fig.width = 10, fig.height=4, fig.align="center", out.width="50%"}
load("data/mcmc1.rda")
load("data/mcmc2.rda")

library(coda)
library(purrr)

mcmc1[["samples"]] %>% 
  map(function(x) {
    x[,"d.ind.wlc"]
  }) %>% as.mcmc.list() -> mcmc1.tp

mcmc2[["samples"]] %>% 
  map(function(x) {
    x[,"d.ind.wlc"]
  }) %>% as.mcmc.list() -> mcmc2.tp



coda:::plot.mcmc.list(as.mcmc.list(mcmc1.tp),
                      density = F,
                      col = "gray50",
                      main = "Trace of d.ind.wlc (mcmc1)") # remove for color plots

coda:::plot.mcmc.list(as.mcmc.list(mcmc2.tp),
                      density = F,
                      col = "gray50",
                      main = "Trace of d.ind.wlc (mcmc2)") # remove for color plots
```


`mcmc1` の前半と後半の繰り返しを比較すると、時系列全体のトレンドに若干の不連続性があることがわかる。4種類の連鎖の推定値（4本の線）は、プロットの前半から後半に移るときに、そのコースがわずかに異なっている。一方、`mcmc2` のプロットでは、上下の変動はより急激であるが、長期的なトレンドは見られない。これは、`mcmc2` の設定がより適切であることを示す最初の兆候である^[信頼性のため、推定パラメータのマルコフ連鎖は、シミュレーションの過程で**静態性** (stationarity) に到達している必要がある。これはすべての線が共通の安定した平均値の周りにランダムに散らばることを意味する。このポイントに達すると、トレースプロットの鎖は典型的に "fat hairy caterpillar" [@lunn2012bugs, chapter 4.4.1] に類似する。]。

事後効果量推定値の密度プロットを見ることで、収束の評価を続けることが可能である。`mcmc1` の分布はまだ滑らかな正規分布から多少乖離しているが、`mcmc2` の結果は古典的なベルカーブに近づいていることがわかる。


\vspace{2mm}

```{r, echo=F, fig.width = 6, fig.height=5, out.width="50%"}
load("data/mcmc1.rda")
load("data/mcmc2.rda")

library(coda)
library(purrr)

mcmc1[["samples"]] %>% 
  map(function(x) {
    x[,"d.ind.wlc"]
  }) %>% as.mcmc.list() -> mcmc1.tp

mcmc2[["samples"]] %>% 
  map(function(x) {
    x[,"d.ind.wlc"]
  }) %>% as.mcmc.list() -> mcmc2.tp


coda:::plot.mcmc.list(as.mcmc.list(mcmc1.tp),
                      density = T,
                      trace = F,
                      col = 1,
                      main = "Density of d.ind.wlc (mcmc1)") # remove for color plots

coda:::plot.mcmc.list(as.mcmc.list(mcmc2.tp),
                      density = T,
                      trace = F,
                      col = 1,
                      main = "Density of d.ind.wlc (mcmc2)") # remove for color plots
```

\index{Potential Scale Reduction Factor}

収束を評価するのに非常に有用なもう一つの方法は、**Gelman-Rubin プロット**である。このプロットは、いわゆる**潜在的スケール削減係数** (Potential Scale Reduction Factor, PSRF) （訳注 PSRF の訳語はまだ定まっていない。） を示し、各チェーン内のばらつきとチェーン間のばらつきを比較し、両者が時間とともにどのように発展していくかを示している。収束した場合、PRSF は反復回数の増加とともに徐々にゼロまで縮小し、最終的には少なくとも 1.05 以下になるはずである。

このプロットを作成するには、`mtc.run` オブジェクトを `gelman.plot` 関数に代入するだけでよい。両方のシミュレーションの結果を示す（ここでも `ind` と `wlc` の比較のみ）。

\vspace{2mm}

```{r, eval=F}
gelman.plot(mcmc1)
gelman.plot(mcmc2)
```


```{r, echo=F, fig.width = 5, fig.height=5, out.width="50%"}
load("data/mcmc1.rda")
load("data/mcmc2.rda")

library(coda)
library(purrr)

mcmc1[["samples"]] %>% 
  map(function(x) {
    x[,"d.ind.wlc"]
  }) %>% as.mcmc.list() -> mcmc1.tp

mcmc2[["samples"]] %>% 
  map(function(x) {
    x[,"d.ind.wlc"]
  }) %>% as.mcmc.list() -> mcmc2.tp

gelman.plot(mcmc1.tp, main = "Gelman-Rubin Plot of d.ind.wlc (mcmc1)")
gelman.plot(mcmc2.tp, main = "Gelman-Rubin Plot of d.ind.wlc (mcmc2)")

```

また、このコードを使って、モデルの**全体的な** PSRF に直接アクセスすることが可能である。


```{r, eval=F}
gelman.diag(mcmc1)$mpsrf
```

```
## [1] 1.034131
```

```{r, eval=F}
gelman.diag(mcmc2)$mpsrf
```

```
## [1] 1.000351
```


両方のシミュレーションで PRSF は閾値を下回っているが、`mcmc2` の値はずっと低く、1に非常に近いことがわかる。これは、2番目のモデルを使用すべきことを示している。


<br></br>

#### 非整合性の評価: ノード分割法

---

**{netmeta}** パッケージと同様に、**{gemtc}** パッケージもネットワークモデルの整合性を評価する方法を提供している。すなわち、ノード分割 (_nodesplit_) 法である (Dias et al., 2010)。この手順の考え方は、以前説明した net splitting 法のものと似ている (Chapter \@ref(net-splitting))。ノード分割分析を行うには、`mtc.nodesplit` 関数を使用し、`mcmc2` と同じ設定を使用する。解析結果は `nodesplit` という名前で保存しよう。

_nodesplit_ モデルの計算には、ネットワークの複雑さによっては数時間かかることがある。


\index{Node Splitting}
\index{Consistency}

```{r, echo=F}
load("data/nodesplit.rda")
```


```{r, eval=F}
nodesplit <- mtc.nodesplit(network, 
                           linearModel = "random", 
                           likelihood = "normal",
                           link = "identity",
                           n.adapt = 5000, 
                           n.iter = 1e5, 
                           thin = 10)
```

`summary` 関数を使用すると、結果を表示することができる。

```{r, eval=F}
summary(nodesplit)
```

```
## Node-splitting analysis of inconsistency
## ========================================
## 
##    comparison  p.value CrI                  
## 1  d.ind.tel   0.62785                      
## 2  -> direct           0.13 (-0.39, 0.64)   
## 3  -> indirect         -0.037 (-0.46, 0.38) 
## 4  -> network          0.034 (-0.30, 0.36)  
## 5  d.ind.wlc   0.87530                      
## 6  -> direct           1.0 (0.74, 1.3)      
## 7  -> indirect         0.97 (0.71, 1.2)     
## 8  -> network          0.98 (0.80, 1.2)     
## 9  d.ind.grp   0.61380                      
## 10 -> direct           0.14 (-0.29, 0.57)   
## 11 -> indirect         0.26 (0.044, 0.48)   
## 12 -> network          0.24 (0.041, 0.43)   
## [...]
```


この関数の出力は、直接証拠のみ、間接証拠のみ、利用可能なすべての証拠を用いた場合の、異なる比較の効果についての結果を示している。直接証拠と間接証拠を用いた異なる推定値は、矛盾の存在を示唆する。ベイズの `p.value` 列を見ることによって、これをコントロールすることが可能である。$p<$ 0.05の1つ以上の比較は、このネットワークに矛盾があることを示すので、問題がある。出力から、この（ランダム効果モデルの）例では矛盾がないことがわかる。

ノード分割法によって複数の推定値に矛盾を示す場合、デザイン間の潜在的な差異について、含まれる**すべての**エビデンスを再度確認することが重要である。例えば、AとBを比較した研究では、Aを評価した他の研究とは系統的に異なる母集団が含まれている可能性がある。

もう一つのアプローチは、研究の賢明な部分集合のみがネットワークに含まれる場合に、矛盾が持続するかどうかを確認することである。最後に、後述するネットワークメタ回帰を実行することによって、矛盾の理由を評価することも可能である。

\index{Forest Plot}\index{フォレストプロット}

ノードスプリットモデルに対して、`plot` 関数を用いてフォレストプロットを生成することも可能である。しかし、先に nodesplit オブジェクトを `summary` に代入後、フォレストプロットが生成される。



```{r, eval=F}
plot(summary(nodesplit)) 
```

```{r, message = F, out.width = '90%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/nodesplit_forest_sep.png')
```

<br></br>

#### ネットワークメタ解析結果の生成

---

さて、ネットワークメタ分析モデルを適合させ、それが信頼できるものであると確信したところで、いよいよ結果を出すときが来た。

前に述べたように、ネットワークメタ分析で答えたい主な疑問は、どの治療が一番よく効くかということである。この質問に答えるために、まず `rank.probability` 関数を実行することが可能である。この関数は、ある治療法が最も良い選択である確率、2番目に良い選択である確率、3番目に良い選択である確率、などを計算する。この関数は入力として `mcmc2` オブジェクトを必要とし、さらに `preferredDirection` という引数を指定する。もし、より小さい（つまり、負の）効果量がより良い結果を示すのであれば、この引数を `-1` に設定する。それ以外の場合は `1` を使用する。

結果は `rank` という名前で保存され、いわゆる **rankogram** を用いて可視化される。

```{r, fig.height=4, fig.width=7, out.width="65%", fig.align="center", eval=F}
rank <- rank.probability(mcmc2, preferredDirection = -1)
plot(rank, beside=TRUE)
```

```{r, fig.height=4, fig.width=7, out.width="65%", fig.align="center", echo=F}
rank <- rank.probability(mcmc2, preferredDirection = -1)
par(bg="#FFFEFA")
plot(rank, beside=TRUE)
```

このプロットでは、個人セラピー（ind）はおそらく私たちのネットワークで最良の治療オプションであることがわかる。なぜなら、ind の最初の棒（1位を意味する）が最も大きいからである。この発見は、同じパターンを発見した頻度論的分析の結果と一致する。

さらに、`forest` 関数を用いて、結果のフォレストプロットを作成することもできる。これを行うには、まず results オブジェクトを `relative.effect` 関数に入れ、参照治療である `t1` を指定する必要がある。ここでも参照群として care as usual (`"cau"`) を使用する。そして、結果に対して `forest` 関数を呼び出し、プロットを生成する。

```{r, fig.width=7, fig.height=3, fig.align="center", out.width="80%", eval=F}
forest(relative.effect(mcmc2, t1 = "cau"), 
       use.description = TRUE, # Use long treatment names
       xlim = c(-1.5, 0.5))
```

```{r, fig.width=7, fig.height=3, fig.align="center", out.width="80%", echo=F}
par(bg="#FFFEFA")
forest(relative.effect(mcmc2, t1 = "cau"), 
       use.description = TRUE, # Use long treatment names
       xlim = c(-1.5, 0.5))
```

\index{SUCRA Score}

頻度論的ネットワークメタ分析の章では、ネットワーク内のどの治療が最も効果的であるかを評価するメトリックとしてP-scoreをすでに取り上げる。P-スコアに相当するのは、**Surface Under the Cumulative Ranking** (SUCRA)スコアで、これは次のように計算が可能である [@salanti2011graphical]。

\begin{equation}
\text{SUCRA}_j = \frac{\sum_{b=1}^{a-1}\text{cum}_{jb}}{a-1}
(\#eq:nw16)
\end{equation}

ここで、$j$ は何らかの治療法、$a$ は全ての競合する治療法、$b$ は $b = 1, 2, \dots, a-1$ の最良治療法、$\text{cum}$ はある治療法が $b$ 個の最良治療法の中にある**累積確率** を表す。 _R_ で SUCRA スコアを計算するには、`sucra` 関数を使用する。

\index{dmetar Package}

```{block, type='boxdmetar'}
**"sucra" 関数**

\vspace{4mm}

`sucra` 関数は **{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールしていない場合は、以下の手順でインストールできる。

\vspace{2mm}

1. 関数の [online](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/sucra.R) のソースコードにアクセスする。
2. ソースコード全体をコンソール(R Studioの左下ペイン)にコピー＆ペーストし、「Enter」キーを押して、 _R_ に関数を「学習」させる。
3. **{ggplot2}** パッケージがインストールされ、ロードされていることを確認する。


```


`sucra` 関数は入力として `rank.probability` オブジェクトだけを必要とするが、ここでは値が小さいほど良い結果を示すかことを指定する必要がある。これは `lower.is.better` という引数を用いて行うことが可能である。どのような結果が得られるか見てみよう。


```{r, message=F, warning=F, fig.height=3, fig.width=5, fig.align="center", out.width="40%", eval=F}
library(dmetar)
rank.probability <- rank.probability(mcmc2)
sucra <- dmetar::sucra(rank.probability, lower.is.better = TRUE)

sucra
```

```
##         SUCRA
## ind 0.9225292
## tel 0.8516583
## gsh 0.6451292
## [...]
```

```{r, message=F, warning=F, fig.height=3, fig.width=5, fig.align="center", out.width="40%", echo=F}
library(dmetar)
rank.probability <- rank.probability(mcmc2)
sucra <- dmetar::sucra(rank.probability, lower.is.better = TRUE)

```

```{r, message=F, warning=F, fig.height=4, fig.width=5, fig.align="center", out.width="50%"}
plot(sucra)
```

各治療の SUCRA 値を見ると、やはり個別治療 (ind) が最も良い選択肢と思われ、次いで電話による治療 (tel)、ガイド付きセルフヘルプ (gsh) が続く。

通常は、モデルに基づく各治療比較の効果量推定値を報告したい。治療効果表は、 `relative.effect.table` 関数を用いてエクスポートする。この関数の結果は `result` というオブジェクトに保存され、.csv ファイルとしてエクスポートすることも可能である。

`relative.effect.table` 関数は、推定効果と各比較の信頼区間を含む治療比較行列を自動的に作成する。

```{r, eval=F}
results <- relative.effect.table(mcmc2)
save(results, file = "results.csv")
```


<br></br>

### ネットワークメタ回帰

---

\index{Meta-Regression}\index{メタ回帰}\index{メタ回帰}
\index{gemtc Package}

**{gemtc}** パッケージの大きな特徴は、**ネットワークメタ回帰**を行うことができる点である。従来のメタ回帰と同様に、この機能を使って、特定の研究特性がネットワークで発見された効果量の大きさに影響を与えるかどうかを判断することが可能である。また、矛盾を説明する可能性のある変数をチェックするのに便利なツールである。


\index{Risk of Bias}

研究のバイアスのリスクが、ネットワークメタ分析における効果に影響を与えるかどうかを評価したいとする。たとえば、バイアス・リスクの高い研究は、一般に、対照群または代替治療と比較して、より高い効果を報告することが考えられる。モデルに予測因子として偏りのリスクを含めることで、そのような関連をコントロールし、結果への影響を評価することが可能である。

**{gemtc}** でネットワークメタ回帰を実行するには、共変量なしのベイズネットワークメタ分析モデルを適合させたときと同様のステップを踏む必要がある。まず、`mtc.network` を使用してネットワークを設定する必要がある。しかし、今回は `studies` という追加の引数を指定する。この引数には、各研究の予測変数の情報を格納したデータフレームを指定する。`TherapyFormatsGeMTC` データセットには、`study.info` という要素があり、各研究のバイアスリスクが格納されている。

それでは、データを簡単に見てみよう。

```{r, eval=F}
TherapyFormatsGeMTC$study.info
```

```
##                        study rob
## 1             Campbell, 2000   1
## 2             Reynolds, 1989   1
## 3            Carpenter, 1994   0
## 4             Shrednik, 2000   1
## [...]
```

\index{Dummy Variable}

このデータセットには2つの列が含まれている。`study` はネットワークに含まれる研究の名前、`rob` はそのバイアスリスクである。studyのラベルは、実際の効果量データセットで使用されているものと完全に同一である必要があることに注意する必要がある。`rob` 変数はダミーコードの予測変数で、`0` は低バイアスリスク、`1` は高バイアスリスクを示す。`study.info`データフレームを使用して、`mtc.network`でメタ回帰ネットワークを作成することが可能である。


```{r, eval=F}
network.mr <- mtc.network(data.re = TherapyFormatsGeMTC$data,
                          studies = TherapyFormatsGeMTC$study.info,
                          treatments = TherapyFormatsGeMTC$treat.codes)
```

ここで、ネットワークメタ分析モデルに含めたい**回帰因子**を定義する必要がある。これは、3つの要素を持つリストオブジェクトを生成することで行うことが可能である。

* **`coefficient`**: この要素は、ネットワークメタ分析に含まれるすべての治療にわたる（高）バイアスリスクの効果について、1つの共有係数を推定したいので、`"shared"` に設定する。

* **`variable`**: 予測変数として使用したい変数の名前を指定する（ここでは `"rob"` ）。

* **`control`**: 参照グループとして使用する治療法も指定しなければならない。この例では、 `"cau"`  (care as usual) を使用する。


```{r}
regressor <- list(coefficient = "shared",
                  variable = "rob",
                  control = "cau")
```


次に、モデルをコンパイルする。先ほど生成したネットワークを `mtc.model` 関数に与え、モデルのタイプを `"regression"` に設定し、先ほど生成した `regressor` オブジェクトを関数の引数に与える。出力結果は `model.mr` という名前で保存される。


```{r, eval=F}
model.mr <- mtc.model(network.mr,
                      likelihood = "normal",
                      link = "identity",
                      type = "regression",
                      regressor = regressor)
```

このステップの後、`mtc.run`関数を用いてモデルを実行することが可能である。`mcmc2` モデルのフィッティングに使用したのと同じ仕様を使用する。結果は `mcmc3` として保存される。

```{r, eval=F}
mcmc3 <- mtc.run(model.mr,
                 n.adapt = 5000,
                 n.iter = 1e5,
                 thin = 10)
```

```{r, echo=F}
load("data/mcmc3.rda")
```


では、`summary`関数を使って結果を解析してみよう。

```{r, eval=F}
summary(mcmc3)
```

```
## Results on the Mean Difference scale
## [...]
## 
## 1. Empirical mean and standard deviation for each variable,
##    plus standard error of the mean:
## 
##              Mean      SD  Naive SE Time-series SE
## d.ind.cau  0.6992 0.07970 0.0003985      0.0004201
## d.ind.grp  0.1933 0.10009 0.0005005      0.0005321
## [...]
## B         -0.3297 0.13047 0.0006523      0.0010379
## 
## 2. Quantiles for each variable:
## 
##                2.5%      25%      50%     75%    97.5%
## d.ind.cau  0.542044  0.64602  0.69967  0.7529  0.85571
## d.ind.grp -0.002622  0.12599  0.19353  0.2608  0.38962
## [...]
## B         -0.586266 -0.41790 -0.32957 -0.2417 -0.07455
## 
## [...]
## -- Regression settings:
## 
## Regression on "rob", shared coefficients, "cau" as control
## Input standardized: x' = (rob - 0.4340659) / 1
## Estimates at the centering value: rob = 0.4340659
```

予測変数の結果は、`B`の隣に報告されている。予測変数はダミー・コード化されているので、 `B` の値は、バイアスの**高い**リスクを持つ研究の効果を表す。推定値は $b=$ -0.33 で、2番目の表(`Quantiles for each variable`) を見ると、$b$の95% 信頼区間が -0.59 から -0.08 までであることがわかる。信頼区間には0が含まれないので、バイアスのリスクは確かに結果に影響すると結論づけられるであろう。バイアスのリスクが高いとき (`rob` = 1)、より高い全体効果を予測が可能である（この例では、負の効果量は「より良い」結果を示している）。

2つのフォレストプロットを生成することにより、予測変数の効果をさらに調査することができる。1つは、バイアスリスクが高いときの推定治療効果で、もう1つは、それが低いときのものである。これは `relative.effect` 関数を用いて行うことができ、ここで `covariate` 値を指定する。`covariate = 0` はバイアスリスクの低い研究を表し、`covariate = 1` はバイアスリスクの高い研究を表す。

\vspace{2mm}

```{r, fig.show='hold', fig.width=7, fig.height=3, fig.align="center", out.width="80%", eval=F}
forest(relative.effect(mcmc3, t1 = "cau", covariate = 1),
       use.description = TRUE, xlim = c(-1.5, 1))
title("High Risk of Bias")

forest(relative.effect(mcmc3, t1 = "cau", covariate = 0),
       use.description = TRUE, xlim = c(-1.5, 1))
title("Low Risk of Bias")
```

```{r, fig.show='hold', fig.width=7, fig.height=3, fig.align="center", out.width="80%", echo=F}
par(bg="#FFFEFA")
forest(relative.effect(mcmc3, t1 = "cau", covariate = 1),
       use.description = TRUE, xlim = c(-1.5, 1))
title("High Risk of Bias")
```

```{r, fig.show='hold', fig.width=7, fig.height=3, fig.align="center", out.width="80%", echo=F}
par(bg="#FFFEFA")
forest(relative.effect(mcmc3, t1 = "cau", covariate = 0),
       use.description = TRUE, xlim = c(-1.5, 1))
title("Low Risk of Bias")
```

フォレストプロットを比較すると、あるパターンが見えてくる。すなわち、バイアスリスクの高い研究に基づく治療効果は、一般に高い（よりマイナスである）。これは、予測変数の推定値と一致している。

\index{Akaike's Information Criterion}

最後に、先ほど生成したネットワークメタ回帰モデルが、先ほどの「通常の」ネットワークメタ分析モデルよりもデータにフィットしているかどうかを調べることもが可能である。これを行うには、**逸脱度情報量規準** (Deviance Information Criteria, DIC) を比較する。これは、頻度論統計学における AIC および BIC 値に相当する。以下のコードを用いて、`mcmc3` と `mcmc2` の両方の DIC にアクセスすることが可能である。

```{r}
summary(mcmc3)$DIC
summary(mcmc2)$DIC
```

メタ回帰モデルの DIC 値（261.19）は、バイアスリスクをコントロールしなかった以前のモデル（DIC = 323.6）より低いことが出力からわかる。DIC 値が低いほど、適合度が高いことを示している。この知見に基づき、私たちのネットワークメタ回帰モデルは、共変量なしのモデルよりもデータによく適合していると結論づけることが可能である。

\index{WinBUGS}

```{block, type='boxinfo'}
**更なる学習**

\vspace{2mm}

以上、 _R_ を使ったネットワークメタ分析の簡単な紹介をした。ネットワークメタ分析の背後にある一般的な考え方、それに関連する仮定といくつかの注意点、ネットワークメタ分析を行うことができる2つの異なる統計的アプローチ、およびそれらが _R_ でどのように実装されているかを説明した。 

\vspace{2mm}

ここで取り上げたことは、あくまで大まかな概要として捉えていただきたい。主な落とし穴をいくつか取り上げたが、実際にネットワークメタ分析を始めると、やはり行き詰まる可能性がある。

\vspace{2mm}

ネットワークメタ分析について、またそれをどのように実際に適用できるかを知るための優れたリソースが、Dias et al. によって書かれた _Network Meta-Analysis for Decision-Making_ である [-@dias2018network]。この本では、いくつかの実践例も紹介されており、オープンソースのソフトウェア _WinBUGS_ を使用してネットワークメタ分析モデルを実行する方法が紹介されている。ネットワークメタ分析の「最先端」の短い（そしてかなり技術的な）概要は、Efthimiou et al.  によるオープンアクセス論文[-@efthimiou2016getreal]で見ることが可能である。

```

$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block, type='boxquestion'}
**知識を試そう！**

\vspace{4mm}

1. ネットワークメタ分析はどのような場合に有用か？標準的なメタ分析と比較して、どのような利点があるか？

\vspace{-2mm}

2. 治療ネットワークにおける直接エビデンスと間接エビデンスの違いは何か？間接エビデンスの生成に直接エビデンスをどのように利用できるのか？

\vspace{-2mm}

3. ネットワークメタ分析における推移性 (transitivity) の仮定の主な考え方は何か？

\vspace{-2mm}

4. 推移性 (transivity) と一貫性 (consistency) の関係は？

\vspace{-2mm}

5. ネットワークメタ分析に使用できる2つのモデリングアプローチを挙げなさい。どちらか一方が優れているか？

\vspace{-2mm}

6. 1つの試験から複数の比較を含める場合（マルチアーム試験など）、どのような問題が発生するか？

\vspace{-2mm}

7. 異なる治療法の P-スコアまたは SUCRA スコアを解釈する際、どのような点に注意しなければならないか？

\vspace{4mm}


**問題の解答は、本書の巻末 [Appendix A](#qanda12) にある。**

```

<br></br>

## 要約

* ネットワークメタ分析は、様々な治療や介入の**相対的効果**を共同で推定するのに有用なツールである。

* 治療効果を推定するために、ネットワークメタ分析は、直接（すなわち観察）証拠と間接証拠の両方を**結合**する。ただし、これには「推移性（交差性）」という前提がある。推移性は、2つの比較の直接証拠を組み合わせて、3つ目の比較についての有効な間接証拠を導き出すことができるときに満たされる。

* 推移性の**統計的な現れ**は一貫 (consistency) であり、その反対は矛盾 (inconsistency) である。矛盾は、直接証拠に基づく比較の真の効果が、間接証拠に基づくものと一致しないときに生じるものである。

* ノードスプリッティングやネットヒートプロットなどの手法により、ネットワーク内の矛盾を**特定する**ことができる。矛盾が見つかると、結果全体の妥当性が脅かされることになる。このような場合、研究／デザイン間の系統的な差異を引き起こした可能性のある特性をネットワーク全体でチェックする必要がある。 

* ネットワークメタ分析は、**頻度論的**または**ベイズ的**アプローチのいずれかを使用して可能である。実際には、これらの方法にはそれぞれ長所があるが、通常、全体的な結果は非常に似ている。

* ベイズ型階層モデルに基づくネットワークメタ分析では、効果量の差を予測する**研究共変量**を加えることもが可能である。この結果、ネットワークメタ回帰モデルになる。

* SUCRA や P-score などの指標は、私たちのネットワークにおいて、どのタイプの治療が最も効果的であるかを調べるために使用することが可能である。しかし、意思決定プロセスに不確実性を組み込むことも重要である。異なる治療法の信頼区間は重なり合うこともよくあるので、1つの形式が他のすべての形式より本当に優れているかどうかは、あまり明確ではない。


<!--chapter:end:14-netwma-ja.Rmd-->

# ベイズメタ分析  {#bayesian-ma}

---

<img src="_figs/waves.jpg" />

<br></br>

<span class="firstcharacter">こ</span>
れまでの章では、「マルチレベル」モデル（ Chapter \@ref(multilevel-ma)  ）、メタ分析的構造方程式モデリング（ Chapter \@ref(sem)  ）、ネットワークメタ分析（ Chapter \@ref(netwma)  ）など、メタ分析のやや高度な拡張を掘り下げてきた。さて、一歩下がって、もう一度「従来の」メタ分析を見直そう。ただし、今回はこれまでとは異なる角度で**ベイズメタ分析**を扱う。 

\index{gemtc Package}
\index{Frequentist Statistics}\index{頻度主義統計学}

すでに一つ前のネットワークメタ分析に関する章でベイズモデルを取り上げた。そこでは、ベイズの定理や事前分布の考え方など、ベイズ統計の背後にある主要な考え方について議論してきた（Chapter \@ref(bayesian-inference)  参照）。本章では、この知識をもとに、メタ分析を行うための「ベイズ的な方法」をより深く理解したい。例えば、ベイジアンネットワークのメタ分析モデルを設定するとき、**{gemtc}** パッケージは自動的に優先順位を指定したが、ここでは、これを自分たちで行っていきたい。 

背景は少し複雑であるが、ベイズメタ分析も本質的に「従来の」メタ分析と同じことをしていることがわかる。しかし、ベイズモデルを使用することは、頻度論的アプローチと比較して、いくつかの実用的な利点もある。そのため、 _R_ を使用して利点のあるモデルを実装する方法を学ぶことは価値がある。 

<br></br>

## ベイズ型階層モデル  {#bayes-hierarchical-model}

---

\index{Bayesian Hierarchical Model}

ベイズメタ分析を行うために、いわゆる**ベイズ階層モデル** [@rover2017bayesian; @higgins2009re] を採用する。このタイプのモデルについては、すでにネットワークメタ分析の章（Chapter \@ref(bayesian-net-ma-model)）で簡単に取り上げた。

Chapter \@ref(multilevel-ma)  では、すべてのメタ分析モデルには固有の「マルチレベル」、つまり**階層的**な構造があることを学んだ。最初のレベルには、個々の参加者がいる。このレベルのデータは、通常、各研究 $k$ の計算された効果量 $\hat\theta_k$  という形で届く。参加者が第2レベルにネストされると、それぞれの研究の真の効果量 $\theta_k$ は、独自の分布に従うと仮定する。この真の効果の分布は、平均 $\mu$  （推定したい「真の」効果のプール値）と分散 $\tau^2$  （研究間の異質性を表す）を持っている。

これを定式化してみよう。最初のレベルでは、研究 $k$ で報告された観察された効果量 $\hat\theta_k$  が、この研究での「真の」効果 $\theta_k$ の推定値であると仮定した。観察された効果 $\hat\theta_k$  は、サンプル誤差 $\epsilon_k$ のために $\theta_k$  から乖離している。これは、$\hat\theta_k$ が $k$ の基礎となる母集団から抽出（サンプル）されたと仮定している。この母集団は、平均 $\theta_k$  、研究の「真の」効果、および分散 $\sigma^2$ を持つ分布と見なすことが可能である。 

第2ステップでは、真の効果量 $\theta_k$  自身は、真の効果量の包括的な分布のサンプルに過ぎないと仮定する。この分布の平均 $\mu$  は、推定したい効果量のプール値である。包括的な分布は分散 $\tau^2$ も持っているので、研究別の真の効果 $\theta_k$ は、$\mu$  から乖離している。この分散は、研究間の異質性を表す。まとめると、この2つの方程式が得られる。

\begin{align}
\hat\theta_k &\sim \mathcal{N}(\theta_k,\sigma_k^2) \notag \\
\theta_k &\sim \mathcal{N}(\mu,\tau^2) (\#eq:by1)
\end{align}

ここでは、$\mathcal{N}$  を使って、左側のパラメータが**正規**分布からサンプルされたことを示す。これは2番目の式に対して不必要に厳しい仮定であるという意見もあるが [@higgins2009re]、ここで示したような定式化は、ほとんどの場合に使用されているものである。前にも述べたように、固定効果モデルはこのモデルの特殊なケースで、$\tau^2 = 0$  、つまり研究間の異質性がなく、すべての研究が1つの真の効果量を共有していると仮定している（すなわち、すべての研究 $k$ に対して、 $\theta_k = \mu$）。

また、この式を簡略化するために、合わせた形式を用いることができる。

\begin{equation}
\hat\theta_k  \sim \mathcal{N}(\mu,\sigma_k^2 + \tau^2)
(\#eq:by2)
\end{equation}

これらの公式は、ランダム効果（Chapter \@ref(rem)）や３レベルメタ分析（Chapter \@ref(multilevel-nature)）モデルを議論したときに定義したものとよく似ていることに、すでに気づいただろう。実際、この定式化には特に「ベイズ的」なものはない。しかし、次の式 [@williams2018bayesian] を追加すると、この点は変わる。

\begin{align}
(\mu, \tau^2) &\sim p(.) \notag \\
\tau^2 &> 0 (\#eq:by3)
\end{align}

\index{Prior Distribution}

最初の行が特に重要で、パラメータ $\mu$  と $\tau^2$  の**先行分布**を定義している。これにより、真のプール効果量 $\mu$  と研究間異質性 $\tau^2$  がどのように見えるか、またそれについてどの程度確信が持てるかを **a priori** に指定することが可能である。2番目の式は、研究間異質性分散が0より大きくなければならないという制約を加えている。しかし、この式は、$\mu$  と $\tau^2$  で使用される事前分布の正確な**種類** を指定していない。それは、**何らかの**事前分布が仮定されていることを教えてくれるだけである。ベイズメタ分析モデルのための合理的で特別な事前分布については、後で詳しく説明する。

\index{Markov Chain Monte Carlo}
\index{Gibbs Sampler}
\index{brms Package}
\index{No-U-Turn Sampler (NUTS)}

ネットワークメタ分析の章では、ベイズアプローチがモデルパラメータを推定する方法について説明した。要約すると、**マルコフ連鎖モンテカルロ**に基づくサンプリング手続き、例えば **Gibbs サンプリング**を使用することである。本章で使用する **{brms}** パッケージでは、いわゆる **No-U-Turn** サンプリング [NUTS, @hoffman2014no] を使用する^[NUTS はいわゆる **Hamiltonian Monte Carlo** (HMC) の拡張で、後者は別のタイプの Markov Chain Monte Carlo メソッドである。他のアプローチ（例えば Gibbs サンプリング）と比較して、HMC は階層的モデル を推定するためのより効率的なソリューションを提供することができる[例えばメタ分析に使用されるもの, @betancourt2015hamiltonian]。HMC と NUTS の簡単な説明は、**Stan** <a href="https://mc-stan.org/docs/2_26/reference-manual/hamiltonian-monte-carlo.html" target="_blank">リファレンスマニュアル</a>にある（Stanは **{brms}** のベースとなっている低レベルプログラミング言語である。Chapter \@ref(bayes-ma-R) を参照）。]。

\index{meta Package}
\index{metafor Package}
\index{Posterior Distribution}

これまでの章では、主に  **{meta}**  と  **{metafor}**  パッケージを使用してきた。このパッケージは、非ベイズ的、つまり**頻度論的**なフレームワークに基づいてメタ分析を行うことが可能である。したがって、「従来の」アプローチですでにこのような強力なツールに頼ることができるのに、なぜベイズ法を使い始めなければならないのかと疑問に思うだろう。その理由は、ベイズメタ分析には明確な利点がある [@williams2018bayesian; @mcneish2016using; @chung2013nondegenerate]。

* ベイズ法は、$\tau^2$  の推定値における**不確実性**を直接モデル化することが可能である。また、特に対象研究の数が少ない場合（実際には非常に多い）、効果のプール推定に優れている場合がある。

* ベイズ法は、$\mu$  と $\tau^2$  の両方について、完全な**事後分布** (posterior distribution) を生成する。これにより、$\mu$ または $\tau^2$  がある指定された値より小さいまたは大きい正確な**確率**を計算することが可能である。これは、信頼区間だけを計算する頻度論的方法とは対照的である。しかし、（95％）信頼区間は、データサンプリングが何度も繰り返された場合、母集団のパラメータ（例えば、$\mu$  や $\tau^2$  ）の真の値が、サンプルの95％において信頼区間の範囲に収まることを述べているに過ぎないのである。真のパラメータが2つの指定された値の間にある**確率**は教えてくれない。

* ベイズ法は、メタ分析を計算する際に、**先行知識**と仮定を統合することができる。

<br></br>

## 事前分布の設定  {#priors}

---

これまで、ベイズメタ分析で効果をプールするために使用できる階層モデルを定式化した。しかし、このようなモデルを実行するためには、$\mu$ と $\tau^2$  の事前分布を指定しなければならない。特に、研究数が少ない場合、事前分布は結果にかなりの影響を与えるので、賢く選択する必要がある。 

\index{Uninformative Prior}
\index{Weakly Informative Prior}

一般的に、良いアプローチは、**弱情報**事前 (weakly informative prior) を使用することである [@williams2018bayesian]。弱情報事前分布は、**無情報**事前 (non-informative priors) 分布と対比することが可能である。無情報的事前分布は、事前分布の最も単純な形式である。これは通常、**一様**分布に基づいており、すべての値が等しく信頼できることを表現する時に使用される。 

一方、弱情報事前分布は、もう少し洗練されたものである。これは、ある値が他の値よりも信頼できるという**弱い**確信を持っていることを表す分布に依存する。しかし、データから推定されるパラメータの値については、まだ具体的な記述はしていない。 

\index{Standardized Mean Difference}

直感的には、これは非常に理にかなっている。たとえば、多くのメタ分析では、真の効果がSMD = -2.0 と 2.0 の間のどこかにあると仮定することは妥当であるが、SMD = 50 になることはまずないだろう。この理論的根拠に基づいて、私たちの $\mu$ 事前分布は、平均 0、分散 1の正規分布から出発すると良いだろう。これは、真のプールされた効果量 $\mu$ が -2.0 と 2.0 の間にあることを、約95%の事前確率で認めることを意味する。

\begin{equation}
\mu \sim \mathcal{N}(0,1)
(\#eq:by4)
\end{equation}

次に指定しなければならない事前分布は、$\tau^2$  の事前分布である。 $\tau^2$  は常に非負であるが、0（またはゼロに近い値）であってもよいことがわかっているので、これは少し難しい。この場合に推奨される分布で、$\tau^2$ のような分散によく使われるものは、 **Half-Cauchy** 事前分布である。Half-Cauchy 分布は、Cauchy 分布の特殊なケースで、分布の「半分」（もちろん、正の側）に対してのみ定義されている^[標準 Cauchy 分布自体は、$t$ の特殊ケースで、$\text{d.f.}=1$ が付いている]。 

Half-Cauchy 分布は2つのパラメータで制御される。最初のものは、分布のピークを指定する位置パラメータ $x_0$ である。もう1つは、スケーリングパラメータ $s$ である。これは、分布がどの程度**裾が重い** (heavy-tailed) か（すなわち、どの程度高い値まで「広がる」か）を制御する。Half-Cauchy 分布は $\mathcal{HC}(x_0,s)$ と表記される。

以下のグラフは、$x_0$  の値を 0 に固定し、$s$ の値を変化させた場合の Half-Cauchy 分布を可視化したものである。

\vspace{2mm}

```{r, echo=F, fig.width=5, fig.height=4, fig.align='center', out.width="55%"}
library(ggplot2)

hc_03 = function(x) {(0.3^2/(x^2+0.3^2)*(1/(pi*0.3)))}
hc_05 = function(x) {(0.5^2/(x^2+0.5^2)*(1/(pi*0.5)))}
hc_1 = function(x) {(1/(x^2+1)*(1/(pi)))}


ggplot(data = data.frame(x = 0), mapping = aes(x = x)) +
  stat_function(fun = hc_03,fill = "gray80",color = "black", alpha = 0.3, geom="area", size = 0.1) + 
  stat_function(fun = hc_05,fill = "gray50",color = "black", alpha = 0.3, geom="area", size = 0.1) + 
  stat_function(fun = hc_1, fill= "gray20", color = "black", alpha = 0.3, geom="area", size = 0.1) + 
  ylab(bquote(italic(y))) +
  xlab(bquote(italic(x))) +
  scale_x_continuous(expand = c(0, 0), limits = c(0, 1.5)) +
  scale_y_continuous(expand = c(0, 0), limits = c(0, 1.1)) +
  theme_classic() +
  annotate("text", x = 0.4, y = 0.9, 
           label = "atop(bold(HC(0,0.3)), y==(frac(0.3^2, x^2+0.3^2)) (frac(1,pi~0.3)))", 
           hjust = "left", parse = TRUE, color = "black") +
  annotate("text", x = 0.75, y = 0.6, 
           label = "atop(bold(HC(0,0.5)), y==(frac(0.5^2, x^2+0.5^2)) (frac(1,pi~0.5)))", 
           hjust = "left", parse = TRUE, color = "black") +
  annotate("text", x = 1.2, y = 0.4, 
           label = "atop(bold(HC(0,1)), y==(frac(1, x^2+1)) (frac(1,pi)))", 
           hjust = "left", parse = TRUE, color = "black") +
  annotate(geom = "curve", color = "black", x = 0.38, y = 0.85, xend = 0.2, yend = hc_03(0.2), 
            curvature = .1, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = "curve", color = "black", x = 0.73, y = 0.55, xend = 0.51, yend = hc_05(0.51), 
            curvature = .1, arrow = arrow(length = unit(2, "mm"))) +
  annotate(geom = "curve", color = "black", x = 1.18, y = 0.35, xend = 1.1, yend = hc_1(1.1), 
            curvature = .1, arrow = arrow(length = unit(2, "mm"))) +
  theme(panel.background = element_rect(fill = "#FFFEFA", size = 0),
        plot.background = element_rect(fill = "#FFFEFA", size = 0))


```

\vspace{2mm}

Half-Cauchy 分布は通常、かなり重い裾を持つので、$\tau$  の事前分布として特に有用である。この重い尾は、$\tau$ の非常に高い値を**何らかの**確率で与えることを保証すると同時に、低い値の方がより可能性が高いと想定している。 

多くのメタ分析では、$\tau$（$\tau^2$ の平方根）は 0.3 近辺にあるか、少なくとも同じような範囲にある。したがって、Half-Cauchy 事前分布を指定するために、$s=$  0.3 を使用することが可能である。これにより、$\tau=$  0.3 より小さい値は50%の確率で存在することが保証される [@williams2018bayesian]。このことは、**{extraDistr}** パッケージの `phcauchy` 関数で実装されている Half-Cauchy 分布関数を用いて確認することが可能である [@extradistr]。

\index{extraDistr Package}

```{r, message=F, warning=F}
library(extraDistr)
phcauchy(0.3, sigma = 0.3)
```

しかし、これはすでに $\tau$  の真の値に関するかなり具体的な仮定である。 より保守的なアプローチとして、この実践例では、$s$  を0.5に設定する。これは、分布をよりフラットにできる。一般的に、常に異なる事前分布を用いた感度分析を行い、それが結果に大きな影響を与えるかどうかを確認することを勧める。 $s=$  0.5 を Half-Cauchy 分布のパラメータとして使用し、$\tau$  の事前分布を次のように書くことが可能である。

\begin{equation}
\tau \sim \mathcal{HC}(0,0.5)
(\#eq:by5)
\end{equation}

これで、階層モデルの式と事前指定をまとめることが可能である。これは、ベイズ・メタ分析に使用できる完全なモデルにつながる。

\begin{align}
\hat\theta_k &\sim \mathcal{N}(\theta_k,\sigma_k^2) \notag \\
\theta_k &\sim \mathcal{N}(\mu,\tau^2) \notag \\
\mu &\sim \mathcal{N}(0,1) \notag \\
\tau &\sim \mathcal{HC}(0,0.5) (\#eq:by5)
\end{align}

<br></br>

## _R_ でのベイズメタ分析  {#bayes-ma-R}

---

\index{brms Package}
\index{STAN}
\index{Generalized Additive Model}

メタ分析のためのベイズモデルを定義したので、いよいよ _R_ で実装してみよう。ここでは、**{brms}** パッケージ [@burknerJSS; @burkner2017advanced] を使ってモデルの適合を行う。**{brms}** パッケージは、ベイズ回帰モデルを適合させるための非常に多機能で強力なツールである。マルチレベル（混合効果）モデル、一般化線形モデル、多変量モデル、一般化加法モデルなど、幅広い用途に使用することが可能である。モデルの多くは人レベルのデータを必要とするが、**{brms}** は（重み付けされた）研究レベルデータを扱うメタ分析にも使用可能である^[ **{bbrms}** パッケージは、ベイズモデリングのための低レベルプログラミング言語である **Stan** に基づいている。Stanプロジェクトでは、独自のオンラインフォーラム(https://discourse.mc-stan.org/)が活発に運営されており、**{brms}** に関する問題を議論することも可能である。また、このフォーラムには「メタ分析」タグがあり、関連する可能性のあるスレッドをフィルタリングすることが可能である]。

モデルの適合を始める前に、まず **{brms}** パッケージをインストールし、ロードする必要がある。

```{r, message=F, warning=F, eval=F}
library(brms)
```

<br></br>

### モデルの適合

---

このデータセットには、大学生における「第3の波」心理療法の効果を調査したメタ分析からの情報が含まれている（Chapter \@ref(pre-calculated-es)）。モデルを適合させる前に、まず、全体の効果量 $\mu$  と研究間の異質性 $\tau$  の事前分布を指定しよう。前に、$\mu \sim \mathcal{N}(0,1)$ と $\tau \sim \mathcal{HC}(0,0.5)$ と定義した。 

分布を指定するには、`prior`  関数を使用する。この関数は2つの引数を取る。最初の引数では、分布パラメータを含む、事前分布として想定される分布を指定する。2番目の引数では、事前分布の  `class`  を定義する必要がある。 $\mu$ の場合、母集団レベルの固定効果であるため、適切なクラスは `Intercept` である。 $\tau$  の場合は、分散（より正確には、**標準偏差**）なので、クラスは  `sd` である。両方のプライアを  `prior`  関数で定義し、それらを連結したものを  `priors`  という名前で保存する。 

```{r, eval=F}
priors <- c(prior(normal(0,1), class = Intercept),
            prior(cauchy(0,0.5), class = sd))
```

さて、次にモデルの適合を行う。これを行うには、**{brms}** の `brm` 関数を使用する。この関数には多くの引数があるが、私たちに関係するのはごく一部である。

引数 **`formula`** には、モデルの数式が指定される。**{brms}**  パッケージは回帰式の表記法を用いており、アウトカム（ここでは観測された効果量）  `y`  が一つ以上の予測変数  `x`  によって予測されることを表している。チルダ（ `~` ）は、 `y ~ x`  という予測関係があることを指定するために使用される。 

メタ分析はやや特殊で、効果量を予測する変数を持っていない（メタ回帰を実行する場合を除く）。つまり、**切片のみ**のモデルであることを示すために、`x` を `1` に置き換える必要がある。さらに、単純に各研究の効果量をそのまま `y` に使うことはできないので、`y|se(se_y)` を使う。また、精度の高い研究（すなわち、サンプルサイズ）にはより大きな重みを与える必要がある。ここで、`se(se_y)` の部分は、データセット中の各効果量 ` y` の標準誤差を表している。 

ランダム効果モデルを使用したい場合、最後のステップは、式の右側にランダム効果項  `(1|study)`  を追加することである。これは、 `y` の効果量が研究内で入れ子になっていると仮定し、その真の効果量は、真の効果量の包括的な母集団からランダムに抽出されたものであることを指定するものである。固定効果モデルを使用したい場合は、この項を省略すればよい。したがって、ランダム効果モデルの一般的な完全式は、次のようになる。`y|se(se_y) ~ 1 + (1|random)`。モデルの計算式の詳細については、コンソールで  `?brmsformula` と入力すると、ドキュメントが表示される。

他の引数はかなり単純である。`prior` には、モデルに定義したいプライヤーを指定する。この例では、以前に作成した `priors` オブジェクトを代入することが可能である。`iter` 引数は、MCMC アルゴリズムの反復回数を指定する。モデルが複雑であればあるほど、この数値は大きくなるはずである。しかし、反復回数が多ければ多いほど、関数が終了するまでに時間がかかるということでもある。最後に、 `data`  を指定する。ここでは、データセットの名前を指定する。

適合したベイズメタ分析モデルを  `m.brm`  という名前で保存する。コードは以下のようになる。

```{r, eval=F}
m.brm <- brm(TE|se(seTE) ~ 1 + (1|Author),
             data = ThirdWave,
             prior = priors,
             iter = 4000)
```

ベイズ法は、以前取り上げた標準的なメタ分析手法に比べ、計算量が非常に多いことに注意。そのため、サンプリングが完了するまで数分かかる場合がある。


<br></br>

### 収束性とモデルの妥当性の評価

---

\index{Markov Chain Monte Carlo}

結果の解析を始める前に、モデルが**収束**すること（つまり、MCMC アルゴリズムが最適解を見つること）を確認する必要がある。もし収束しなければ、パラメータは信頼できないので、解釈すべきではない。収束しないことはベイズモデルで頻繁に起こり、反復回数（`iter`）を大きくしモデルを再実行することで解決することが多い。モデルの収束と全体的な妥当性を評価するために、常に2つのことを行うべきである。まず、パラメータ推定値の $\hat{R}$ （「Rハット」と読む） 値をチェックし、次に、**後方予測チェック** を行う。

$\hat{R}$ の値は、ベイジアンネットワークメタ分析（Chapter \@ref(bayesian-model-convergence) ）を議論する際にすでに取り上げた **Potential Scale Reduction Factor** (PSRF) を表している。推定 $\hat{R}$ 値は 1.01 より小さいはずである。これを確認するために、`m.brm` オブジェクトの `summary`  を生成しよう。

```{r, eval=F}
summary(m.brm)
```

```
## Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: TE | se(seTE) ~ 1 + (1 | Author) 
##    Data: ThirdWave (Number of observations: 18) 
## Samples: 4 chains, each with iter = 4000; warmup = 2000; thin = 1;
##          total post-warmup samples = 8000
## 
## Group-Level Effects: 
## ~Author (Number of levels: 18) 
##               Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS 
## sd(Intercept)     0.29      0.10     0.11     0.51 1.00     2086   
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS 
## Intercept     0.57      0.09     0.39     0.76 1.00     3660    
## 
##
## [...]
## 
## Samples were drawn using sampling(NUTS). For each parameter, 
## Bulk_ESS and Tail_ESS are effective sample size measures, 
## and Rhat is the potential scale reduction factor on split 
## chains (at convergence, Rhat = 1).
```


見ての通り、両パラメータの `Rhat` 値は1であり、収束した。つまり、結果を解釈できることを意味する。

一方、事後予測チェックでは、事後予測分布からランダムに抽出してデータをシミュレートし、観測データと比較する。モデルが収束してデータをよく捉えていれば、再現分布の密度は観測データの密度とほぼ同じになると予想される。これは、関数 `pp_check` の出力で簡単に確認することが可能である。

\vspace{2mm}

```{r, eval=F}
pp_check(m.brm)
```


```{r, message=F, warning=F, echo=F, fig.width=5, fig.height=4, fig.align='center', out.width="50%", eval = F}
load("data/m.brm.rda")
library(bayesplot)
library(brms)
color_scheme_set(scheme = "darkgray")
set.seed(123)
pp_check(m.brm)
```

```{r, message = F, out.width = '50%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/ppcheck_sep.png')
```

\index{Potential Scale Reduction Factor}


<br></br>

### 結果の解釈

---

まず、要約出力の `Group-Level Effects` を見ることによって、結果の解釈を始めることが可能である。このセクションは、数式で定義したランダム効果のために予約されている。ランダム効果のメタ分析モデルを適用したので、個々の研究を意味する変数  `~Author` は、ランダム切片でモデル化された。前に説明したように、これはレベル2において、各研究がそれ自身の「真の」効果量を持ち、それは真の効果量の包括的な分布からサンプルされた、というの仮定を表している。また、グループレベルの効果は18あり、これは私たちのデータ中の $K=$ 18 件の研究に対応している。 

研究間異質性の推定値  `sd(Intercept)` は、$\tau=$ 0.29、したがって、prior を設定する際の最初の「最良の推測」に近いものである。`ranef` 関数を使用すると、プール効果から各研究の「真の」効果量の推定偏差を抽出することも可能である。

```{r, eval=F}
ranef(m.brm)
```

```
## $Author
## , , Intercept
##                           Estimate Est.Error         Q2.5       Q97.5
## Call et al.             0.06836636 0.1991649 -0.327463365  0.47663987
## Cavanagh et al.        -0.14151644 0.1767123 -0.510165576  0.18799272
## DanitzOrsillo           0.48091338 0.2829719 -0.003425284  1.08636421
## de Vibe et al.         -0.31923470 0.1454819 -0.612269461 -0.03795683
## Frazier et al.         -0.11388029 0.1497128 -0.417029387  0.17085917
## [...]
```

次に解釈できるのは、`Population-Level Effects` である。このセクションは、モデル化した「固定」母集団パラメータを表す。ここでは $\mu$ のことで、メタ分析の全体的な効果量である。

\index{Credible Interval}

出力では、推定値は（バイアス補正された）SMD が 0.57 であり、95％信用（確信）区間は95％CrI：0.39-0.76であることがわかる。これは、このメタ分析で研究された介入は、中程度の大きさの全体的な効果を有することを示している。

これはベイズモデルなので、$p$ -値は見当たらない。しかし、この例は、古典的な有意性検定に頼ることなく、合理的な推論を行うことができることを強調するものである。頻度論的なメタ分析になりベイズモデルの利点として、推定したいパラメータを**確率的に**モデル化することができる。ベイズモデルで、興味のあるパラメータを推定するだけでなく、$\tau^2$ と $\mu$  の事後分布全体を推定するには、`posterior_samples` 関数を使用するだけでよい。

```{r, eval=F}
post.samples <- posterior_samples(m.brm, c("^b", "^sd"))
names(post.samples)
```
```
## [1] "b_Intercept"          "sd_Author__Intercept"
```

この結果、データフレームには2つの列が含まれる。`b_Intercept` はプール効果量 $\tau$ の事後サンプルデータ、 `sd_Author_Intercept` は研究間異質性データである。列の名前をより分かりやすくするために、`smd` と `tau` に改名しよう。

```{r, eval=F}
names(post.samples) <- c("smd", "tau")
```

\vspace{2mm}

\index{Posterior Distribution}

`post.samples` のデータを用いて、事後分布の**密度プロット**を作成してみよう。プロットには、**{ggplot2}** パッケージを使用する。

```{r, eval=F}
ggplot(aes(x = smd), data = post.samples) +
  geom_density(fill = "lightblue",                # 色を指定
               color = "lightblue", alpha = 0.7) +  
  geom_point(y = 0,                               # 平均に点を追加
             x = mean(post.samples$smd)) +
  labs(x = expression(italic(SMD)),
       y = element_blank()) +
  theme_minimal()

ggplot(aes(x = tau), data = post.samples) +
  geom_density(fill = "lightgreen",               # 色を指定
               color = "lightgreen", alpha = 0.7) +  
  geom_point(y = 0, 
             x = mean(post.samples$tau)) +        # 平均に点を追加
    labs(x = expression(tau),
       y = element_blank()) +
  theme_minimal()
```


```{r, echo=F, fig.width = 4, fig.height=3, fig.align="center", out.width="30%", fig.show='hold', eval=F}
ggplot(aes(x = smd), data = post.samples) +
  geom_density(fill = "gray70",                  # 色を指定
               color = "gray70", alpha = 0.7) +  
  geom_point(y = 0,                                 # 平均に点を追加
             x = mean(post.samples$smd)) +
  labs(x = expression(italic(SMD)),
       y = element_blank()) +
  theme_minimal()

ggplot(aes(x = tau), data = post.samples) +
  geom_density(fill = "gray20",                 # 色を指定
               color = "gray20", alpha = 0.7) +  
  geom_point(y = 0, 
             x = mean(post.samples$tau)) +          # 平均に点を追加
    labs(x = expression(tau),
       y = element_blank()) +
  theme_minimal()
```

```{r, message = F, out.width = '49%', echo = F, fig.show='hold'}
library(OpenImageR)
knitr::include_graphics('images/posterior1_sep.png')
knitr::include_graphics('images/posterior2_sep.png')
```


事後分布はほぼ、一峰性の正規分布に従い、$\mu$  と $\tau$  の推定値付近でピークを示すことがわかる。 

ベイズ法は、関心のあるパラメータの実際のサンプル分布を作成するということは、$\mu$ または $\tau$  がある特定の値より大きいか小さいかという**正確な確率**を計算することができるということである。以前の文献で、介入の効果が SMD = 0.30 以下であれば、もう意味がないことがわかったと想像してみよう。そこで、私たちのメタ分析における真の全体効果が SMD = 0.30 より小さい確率を、私たちのモデルに基づいて計算してみよう

\index{Empirical Cumulative Distribution Function (ECDF)}

これは、**経験的累積分布関数** (Empirical Cumulative Distribution Function, ECDF) を見ることによって行うことが可能である。ECDF は、ある特定の値 $X$ を選択することができ、提供されたデータに基づいて、ある値 $x$ が $X$ より小さい確率を返す。この例での $\mu$ の事後分布の ECDF は、以下のようになる。

\vspace{2mm}

```{r, warning=F, message=F, fig.width=4, fig.height=3, fig.align='center', echo=F, out.width="50%", eval=F}
load("data/post.samples.rda")

library(ggplot2)
smd.ecdf = ecdf(post.samples$smd)
ecdf.dat = data.frame(smd = 1:1000/1000,
                      p = smd.ecdf(1:1000/1000))
ggplot(aes(x = smd, y = p), data = ecdf.dat) +
  geom_vline(xintercept = mean(post.samples$smd), color = "grey") +
  geom_line(size = 2, color = "black") +
  theme_minimal() +
  labs(x = "SMD", y = "Cumulative Probability") +
  ggtitle("ECDF: Posterior Distribution of the Pooled Effect Size")
```

```{r, message = F, out.width = '50%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/ecdf_sep.png')
```



`ECDF` 関数を使って、 _R_ で ECDF を定義し、プールした効果が 0.30 より小さい確率を調べることができる。コードは以下のようになる。

```{r, eval = F}
smd.ecdf <- ecdf(post.samples$smd)
smd.ecdf(0.3)
```

```
## [1] 0.002125
```


0.21%ということは、プール効果が 0.30 より小さい確率は非常に低いことがわかる。このカットオフが有効であると仮定すると、このメタ分析で見出された介入の全体的な効果は、意味のあるものである可能性が非常に高いということになる。

<br></br>

### フォレストプロットの生成

---

\index{Forest Plot}\index{フォレストプロット}
\index{tidybayes Package}

これまで見てきたように、ベイズモデルによって、そのサンプル事後分布を抽出することが可能である。これは、モデルが与えられたときの特定の値の確率を直接評価するのに非常に役立つ。また、この機能を利用して、非常に有益で見栄えのする拡張**フォレストプロット**（Chapter \@ref(forest)）を作成することも可能である^[ここで紹介するコードの一部は、Matti Vuorre [-@vuorre2016bayesian] が書いた [blog post](https://mvuorre.github.io/posts/2016-09-29-bayesian-meta-analysis/) からインスピレーションを受けたものである]。 

残念ながら、現在のところ、**{brms}** モデルから直接フォレストプロットを作成するパッケージは整備されていない。しかし、**{tidybayes}** パッケージ [@tidybayes] の関数を使用することにより、自分で作成することが可能である。そこで、まずパッケージを読み込んでから先に進もう。

```{r, message=F, warning=F, eval=F}
library(tidybayes)
library(dplyr)
library(ggplot2)
library(ggridges)
library(glue)
library(stringr)
library(forcats)
```

\vspace{2mm}

プロットを作成する前に、データを準備する必要がある。特に、**各研究の事後分布を個別に**抽出する必要がある（フォレストプロットは各研究の特定の効果量も描写しているため）。これを実現するために、**{tidybayes}** パッケージの `spread_draws` 関数を使用することが可能である。この関数は3つの引数を入力として必要とする。適合 **{brms}** モデル、結果をインデックス化するランダム効果因子、そして抽出したいパラメータ（ここでは固定項：効果量を抽出したいので `b_Intercept`）である。 

パイプ演算子を使うことで、出力を直接操作することが可能である。**{dplyr}** の `mutate`  関数を用いて、各研究の推定偏差にプール効果量 `b_Intercept`  を加算して、各研究の実際の効果量を計算する。その結果を `study.draws` として保存する。

```{r, eval=F}
study.draws <- spread_draws(m.brm, r_Author[Author,], b_Intercept) %>% 
  mutate(b_Intercept = r_Author + b_Intercept)
```

\vspace{2mm}

次に、同様の方法でプール効果の分布を生成したい（フォレストプロットでは、効果の要約は通常最後の行に表示されるため）。そこで、先ほどのコードを少しアレンジして、プール効果だけを得るために第2引数を削除する。`mutate` の呼び出しは、`"Author"` という追加の列を追加するだけである。その結果を `pooled.effect.draws` という名前で保存する。

```{r, eval=F}
pooled.effect.draws <- spread_draws(m.brm, b_Intercept) %>% 
  mutate(Author = "Pooled Effect")
```


\vspace{2mm}

次に、`study.draws` と `pooled.effect.draws` を一つのデータフレームにバインドしている。そして、パイプを再び立ち上げ、まず `ungroup`  を呼び出し、次に `mutate` を用いて、(1) 研究ラベルをきれいにし（ドットをスペースに置き換えるなど）、 (2) 研究因子レベルを効果量（高から低）で並べ替える。その結果、プロットに必要なデータができあがり、 `forest.data` として保存する。


```{r, eval=F}
forest.data <- bind_rows(study.draws, 
                         pooled.effect.draws) %>% 
   ungroup() %>%
   mutate(Author = str_replace_all(Author, "[.]", " ")) %>% 
   mutate(Author = reorder(Author, b_Intercept))
```

最後に、フォレストプロットは各研究の効果量（SMD と信用（確信）区間）も表示する必要がある。そのために、新しく作成した `forest.data` データセットを使用し、`Author` でグループ化し、`mean_qi` 関数を使用してこれらの値を計算する。出力は  `forest.data.summary` という名前で保存する。

```{r, eval = F}
forest.data.summary <- group_by(forest.data, Author) %>% 
  mean_qi(b_Intercept)
```

\vspace{2mm}

これで、**{ggplot2}** パッケージを使用してフォレストプロットを生成する準備が整った。プロットを生成するコードは次のようなものである。

```{r, message=F, warning=F, fig.width=5, fig.height=4, eval = F}
ggplot(aes(b_Intercept, 
           relevel(Author, "Pooled Effect", 
                   after = Inf)), 
       data = forest.data) +
  
  # プール効果と信頼区間に縦線を追加
  geom_vline(xintercept = fixef(m.brm)[1, 1], 
             color = "grey", size = 1) +
  geom_vline(xintercept = fixef(m.brm)[1, 3:4], 
             color = "grey", linetype = 2) +
  geom_vline(xintercept = 0, color = "black", 
             size = 1) +
  
  # 密度を追加
  geom_density_ridges(fill = "blue", 
                      rel_min_height = 0.01, 
                      col = NA, scale = 1,
                      alpha = 0.8) +
  geom_pointintervalh(data = forest.data.summary, 
                      size = 1) +
  
  # テキストとラベルを追加
  geom_text(data = mutate_if(forest.data.summary, 
                             is.numeric, round, 2),
    aes(label = glue("{b_Intercept} [{.lower}, {.upper}]"), 
        x = Inf), hjust = "inward") +
  labs(x = "Standardized Mean Difference", # 要約
       y = element_blank()) +
  theme_minimal()
```


```{r, message=F, warning=F, fig.width=5, fig.height=4, echo = F, fig.align='center', out.width="75%", eval=F}

load("data/forest.data.rda")
load("data/forest.data.summary.rda")


png("images/tidybayes.png", 4000, 3000, res = 600)
ggplot(aes(b_Intercept, 
           relevel(Author, "Pooled Effect", 
                   after = Inf)), 
       data = forest.data) +
  geom_vline(xintercept = fixef(m.brm)[1, 1], 
             color = "grey", size = 1) +
  geom_vline(xintercept = fixef(m.brm)[1, 3:4], 
             color = "grey", linetype = 2) +
  geom_vline(xintercept = 0, color = "black", 
             size = 1) +
  geom_density_ridges(fill = "gray40", 
                      rel_min_height = 0.01, 
                      col = NA, scale = 1,
                      alpha = 0.8) +
  tidybayes::geom_pointintervalh(data = forest.data.summary, 
                      size = 1) +
  geom_text(data = mutate_if(forest.data.summary, 
                             is.numeric, round, 2),
    aes(label = glue("{b_Intercept} [{.lower}, {.upper}]"), 
        x = Inf), hjust = "inward") +
  labs(x = "Standardized Mean Difference", # 要約
       y = element_blank()) +
  theme_minimal()

dev.off()
```

\vspace{4mm}

```{r, message = F, out.width = '80%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/tidybayes_sep.png')
```

```{block2, type='boximportant'}
**観測に基づく効果量とモデルに基づく効果量**

\vspace{4mm}

ここで一つ、非常に重要なことを述べておこう。フォレストプロットに表示されている効果量は、元の研究の**観測**された効果量では**なく**、ベイズモデルに基づいた研究の効果量（$\theta_k$）の推定値である。フォレストプロットで示された点は、`ranef` を用いてランダム効果を抽出した際に見た研究ごとの推定値と同等である（ただし、これらの値はプールされた効果を中心にしたもの）。

さらに、効果量が非常に大きい研究（例えば、"DanitzOrsillo" や "Shapiro et al." などの外れ値）の値を見ると、モデルベースの効果量は、最初の観測値よりも**全体効果 $\hat\mu$ に 近いことがわかる**^[例えば、"DanitzOrsillo" の観測効果は 1.79 で、モデル内の推定効果は 1.05]。

この**平均への縮小**は、メタ分析的ランダム効果モデルのような共通の包括的分布を持つ階層的モデルに典型的なものである。推定プロセスにおいて、ベイズモデルは、メタ分析におけるすべての効果量 $k$ によって共同推定される真の効果量の**全体的**分布に関する情報で、**ある**研究 $k$ の効果に関する情報を「補完」する。

このような**「強さの借用」**は、極端な効果を持つ研究の値が平均値に向かって引っ張られることを意味する [@lunn2012bugs, chapter 10.1]。この挙動は、比較的少ない情報を提供する研究（つまり、大きな標準誤差を持つ研究）においてより顕著になる。

```


$$\tag*{$\blacksquare$}$$

<br></br>

## 演習問題

```{block, type='boxinfo'}
**知識を試そう！**

\vspace{4mm}

1. 「従来の」ランダム効果モデルとベイズ型階層モデルの相違点と類似点は何か？

\vspace{-2mm}

2. ベイズメタ分析の頻度論的な利点と比較した場合の利点を3つ挙げよ。

\vspace{-2mm}

3. 弱情報的事前分布と非情報的事前分布の違いを説明しなさい。

\vspace{-2mm}

4. Half-Cauchy 分布とは何か、なぜベイズメタ分析に有用なのか。

\vspace{-2mm}

5. ECDF とは何か、ベイズメタ分析にどう使えるか？


\vspace{4mm}


**問題の解答は、本書の巻末 [Appendix A](#qanda13) にある。**

```

<br></br>

## 要約

* メタ分析は頻度論的な統計で行われることが多いが、ベイズメタ分析も可能である。

* ベイズメタ分析は、ベイズ階層モデルに基づいている。このモデルの核となる考え方は、「従来の」ランダム効果モデルと同じである。ただし、$\mu$  と $\tau^2$  、（情報量が多い、情報量が少ない、または情報量が少ない）**先行分布**を仮定している点が異なる。

* ベイズメタ分析モデルでは、通常、**弱情報**事前を仮定するのがよいだろう。弱情報的事前は、ある値が他の値よりも信頼性が高いという**弱い**信念を表すために使用される。 

* 研究間異質性分散 $\tau^2$  の事前分布を指定するために、Half-Cauchy 分布を使用することができる。Half-Cauchy 分布は、正の値に対してのみ定義され、より重いテールを持つので、このタスクに特に適している。これは、$\tau^2$  の非常に高い値の可能性は低いけれども、まだ非常に可能性があることを表現するために使うことが可能である。 

* ベイズメタ分析モデルを当てはめる際には、（1）モデルが収束するのに十分な**反復回数**を含んでいるかどうかを常に確認すること（例えば、$\hat{R}$ の値を確認するなど）、（2）異なる事前仕様を用いた**感度分析**を行って結果に対する影響を評価することが重要である。

<!--chapter:end:15-bayesianma-ja.Rmd-->

# (PART) 各種ツール  {-}

# 検出力分析  {#power}

---

<img src="_figs/power_analysis.jpg" />

<br></br>

\index{Power Analysis}

<span class="firstcharacter">メ</span>
タ分析が有用な理由の一つは、**不正確な**知見を複数組み合わせて、より**正確な**知見を得ることができるためである。ほとんどの場合、メタ分析は、含まれるどの研究よりも狭い信頼区間を持つ推定値を生成する。これは、真の効果が小さい場合に特に有効である。一次研究では小さな効果の有意性を確認できないだろうが、メタ分析による推定値は、そのような小さな効果が存在することを確認するために必要な統計的検出力を提供できることが多いのである。 

\index{Potential Scale Reduction Factor}
\index{Cochrane}

しかし、統計的検出力の不足は、メタ分析においてさえも重要な役割を果たすことがある。多くのメタ分析で含まれる研究の数は少なく、$K=$ 10 件以下であることが多い。例えば、コクランのシステマティックレビューにおける研究の数の中央値は6である [@borenstein2011introduction]。メタ分析にはサブグループ分析やメタ回帰が含まれることが多く、その場合はさらに検出力が必要となることを考慮すると、この問題はさらに深刻になる。さらに、多くのメタ分析では、研究間の異質性が高い。これもまた全体的な精度を低下させ、結果として統計的検出力を低下させる。

統計的検出力の概念については、Chapter \@ref(p-curve-es)  ですでに触れ、p-曲線法について学んだ。統計的検出力の背後にある考え方は、古典的な仮説検定に由来している。これは仮説検定で起こりうる2種類の**エラー**に直接関係している。最初のエラーは、帰無仮説 ($\mu_1 = \mu_2$) が真であるのに、対立仮説 ($\mu_1 \neq \mu_2$ ) を受け入れることである。これは、**タイプ I** または $\alpha$  エラーとしても知られている。逆に、対立仮説が真であるのに、帰無仮説を受け入れることもある。これは、**タイプ II** または $\beta$ エラーとして知られている**偽陰性** (false negative) を発生させる。

\index{Power}\index{検出力}\index{検出力} 

検定の検出力は、$\beta$  に直接依存し、検出力 = $1 - \beta$  と定義される。帰無仮説では、2群の平均の間に差がないと仮定し、対立仮説では差（すなわち「効果」）が存在すると仮定する。統計的検出力は、効果（つまり、平均値の差）が存在する場合に、検定がそれを検出する確率として定義できる。

\begin{equation}
\text{Power} = P(\text{reject H}_0~|~\mu_1 \neq \mu_2) = 1 - \beta
(\#eq:pow1)
\end{equation}

タイプ I の誤りはタイプ II の誤りよりも重大であると考えるのが一般的である。したがって、$\alpha$  レベルは慣習的に 0.05 に設定され、$\beta$ レベルは0.2に設定されている。つまり、$1-\beta$  = 1 - 0.2 = 80% という閾値をもたらし、通常、検定の統計的検出力が適切かどうかを決定するのに使われる。研究者が新しい研究を計画するとき、通常、80% の検出力が保証されるサンプルサイズを選択する。真の効果が大きければ、統計的に有意な結果を得ることは容易である。したがって、検出力が 80% に固定されている場合、必要なサンプルサイズは真の効果の大きさにのみ依存する。想定される効果が小さいほど、80% の検出力を確保するために必要なサンプルサイズは大きくなる。

一次研究を行う研究者は、発見されると予想される効果量に基づいて、**a priori** に、サンプルのサイズを計画することができる。メタ分析では公表されたものしか扱えないため、状況は異なる。しかし、メタ分析に含める研究の数や種類については、ある程度コントロールすることができる（例えば、より緩やかな、あるいは厳しい包含基準を定義する）。こうすることで、全体の検出力を調整することもできる。メタ分析における統計的検出力に影響を与える要因はいくつかある。

* 対象研究の**総数**とその**サンプルサイズ**。どれくらいの数の研究を見込んでいるのか、またその数は少ないのか多いのか。

* 見つけたい効果量。これは特に重要で、効果量がどの程度大きければ意味があるのかを仮定しなければならないことがある。例えば、あるうつ病の介入研究では、SMD = 0.24 という小さい効果でも患者にとって意味がある可能性があると計算されている [@cuijpers2014threshold] 。介入の負の効果（例えば、死亡や症状の悪化）を研究したい場合、非常に小さな効果量であっても極めて重要であり、検出されるべきものである。

* 予想される研究間の異質性。異質性が大きいとメタ分析による推定値の精度と、その結果、有意な効果を見出す可能性にも影響する。

上記以外にも、サブグループ分析など、実施したい分析について考えることも重要である。各サブグループにはどれくらいの研究があるのか？各グループでどのような効果を見出したいのか？ 

\index{Power Approach Paradox}

```{block, type='boximportant'}
**Post-Hoc 検出力検定: 「検出力の乱用」**

\vspace{2mm}

検出力分析は、必ず **a priori**、つまりメタ分析を実行する**前**に行わなければならない。

\vspace{2mm}

分析の**後**に行われる検出力分析（「post hoc 分析」）は、深い欠陥のある論理に基づいている [@hoenig2001abuse] 。まず、post hoc の検出力分析は、**一様**であり、まだ知らないことは何も教えてくれない。収集したサンプルに基づいて効果が有意でないことがわかったとき、計算された post hoc 検出力は、定義上、不十分（すなわち、50% 以下）である。あるテストの post hoc に検出力を計算するとき、単に結果の $p$ 値に直接リンクしている検出力関数で「遊んで」いるにすぎない。

post-hoc の検出力の推定値には、$p$ 値がまだ教えてくれていないことはない。すなわち、検定の効果とサンプルサイズに基づいて、検出力が統計的有意性を確認するのに不十分であることを示している。

\vspace{2mm}

post hoc に検出力を解釈すると、**power approach paradox** (PAP) にもつながる。このパラドックスは、有意な効果をもたらさない分析では、p値が**小さい**と、帰無仮説が真であるという**より多くの**証拠を示すと考えられ、真の効果を検出する力が**高く**なるために生じる。<!-- needs more explanation-->

```

<br></br>

## 固定効果モデル

---

\index{Fixed-Effect Model}

<<<<<<< HEAD
固定効果モデルの下でのメタ分析の検出力を決定するために、私たちは対立仮説が正しいことを表す分布を指定しなければならない。しかし、これを行うには、単に $\theta \neq 0$  （すなわち、**何らかの**効果が存在する）というだけでは不十分である。私たちは、十分な（80%の）検出力で検出したい**特定の**真の効果を仮定しなければならない。例えば、SMD = 0.29 である。 

効果量をその標準誤差で割ると $z$ スコアになることは、以前すでに取り上げた（ Chapter \@ref(metareg-continuous)  を参照）。$z$  スコアは、標準正規分布に従う。ここで、$|z| \geq$ 1.96 という値は、効果がゼロとは有意に異なることを意味する ($p<$  0.05)。これはまさにメタ分析で達成したいことである。つまり、結果の正確な効果量と標準誤差がどんなに大きくても、$|z|$  の値は少なくとも 1.96 でなければならず、したがって統計的に有意でなければならないのである。 
=======
固定効果モデルの下でのメタ分析の検出力を決定するために、対立仮説が正しいことを表す分布を指定しなければならない。しかし、これを行うには、単に $\theta \neq 0$  （すなわち、**何らかの**効果が存在する）というだけでは不十分である。十分な検出力（80%）で検出したい**特定の**真の効果を仮定しなければならない。例えば、SMD = 0.29 である。 

効果量をその標準誤差で割ると $z$ スコアになることは、以前すでに取り上げた（Chapter \@ref(metareg-continuous) を参照）。$z$ スコアは、標準正規分布に従う。ここで、$|z| \geq$  1.96 という値は、効果がゼロとは有意に異なることを意味する ( $p<$  0.05)。これはまさにメタ分析で達成したいことである。つまり、結果の正確な効果量と標準誤差がどんなに大きくても、$|z|$ の値は少なくとも 1.96 でなければならず、したがって統計的に有意でなければならない。 
>>>>>>> e14fe274018460cce905bfa8e57f80edbf6acb23

\begin{equation}
z  = \frac{\theta}{\sigma_{\theta}}~~~\text{where}~~~|z| \geq 1.96.
(\#eq:pow2)
\end{equation}

プール効果量の標準誤差である $\sigma_{\theta}$ （「シグマ・シータ」と読む）の値は、以下の式を用いて計算することができる。

\begin{equation}
\sigma_{\theta}=\sqrt{\frac{\left(\frac{n_1+n_2}{n_1n_2}\right)+\left(\frac{\theta^2}{2(n_1+n_2)}\right)}{K}}
(\#eq:pow3)
\end{equation}

ここで、$n_1$ と $n_2$ は、ある研究のグループ1とグループ2のサンプルサイズを表し、$\theta$は、想定される効果量（標準化平均差を表している）、$K$  は、メタ分析における研究の総数である。重要なのは、簡略化のため、この式は、両群のサンプルサイズが、含まれるすべての研究において同一であると仮定していることである。

この式は、標準化平均差の標準誤差を計算するのに使われる式と非常によく似ているが、1つだけ例外がある。ここで、標準誤差を $K$  で割る。これは、プール効果標準誤差が、メタ分析における研究の総数を表す係数 $K$  によって減少することを意味する。言い換えれば、固定効果モデルを仮定した場合、研究をプールすると、全体効果の精度が $K$-倍になる^[このステートメントは、もちろん、方程式 \@ref(eq:pow3) の簡易式を使用しているため正しいことに注意]。 

$\theta$ を定義し、$K$ を計算した結果、$z$ という値になる。この $z$ スコアは、群サイズ $n_1$ と $n_2$ を持つ $K$ 件の研究がある場合、メタ分析の検出力を得るために使用することができる。

\begin{align}
\text{Power} &= 1-\beta \notag \\
             &= 1-\Phi(c_{\alpha}-z)+\Phi(-c_{\alpha}-z) \notag \\
             &= 1-\Phi(1.96-z)+\Phi(-1.96-z). (\#eq:pow4)
\end{align}


\index{Cumulative Distribution Function (CDF)}

<<<<<<< HEAD
ここで、$c_{\alpha}$ は、指定された $\alpha$  レベルが与えられたときの、標準正規分布の臨界値である。 $\Phi$  （「ファイ」と読む）シンボルは、標準正規分布の**累積分布関数** (cumulative distribution function, CDF) である $\Phi(z)$ を表す。 _R_  では、標準正規分布の CDF は `pnorm` 関数で実装されている。

この公式は、固定効果メタ分析の検出力を計算するために使用できる。 $K=$ 10 件の研究があり、両群がそれぞれ約25人の参加者を持つと仮定しよう。SMD = 0.2 の効果を検出できるようにしたい。このようなメタ分析の検出力はどのくらいか？
=======
ここで、$c_{\alpha}$ は、指定された $\alpha$  レベルが与えられたときの、標準正規分布の臨界値である。記号 $\Phi$  （「ファイ」と読む）は、標準正規分布の**累積分布関数** (cumulative distribution function, CDF) である $\Phi(z)$ を表す。 _R_  では、標準正規分布の CDF は `pnorm` 関数で実装されている。

この公式は、固定効果メタ分析の検出力を計算するために使用できる。$K=$ 10 件の研究があり、両群がそれぞれ約25人の参加者を持つと仮定しよう。SMD = 0.2 の効果を検出できるようにしたい。このようなメタ分析にはどのような検出力があるか？
>>>>>>> e14fe274018460cce905bfa8e57f80edbf6acb23

```{r}
# 仮定条件を定義
theta <- 0.2
K <- 10
n1 <- 25
n2 <- 25

# プール効果の標準誤差を計算
sigma <- sqrt(((n1+n2)/(n1*n2)+(theta^2/(2*n1+n2)))/K)

# z を計算
z = theta/sigma

# 検出力を計算
1 - pnorm(1.96-z) + pnorm(-1.96-z)


```

このメタ分析には 10 件の研究が含まれているにもかかわらず、60.6%と**検出力不足**であることがわかる。固定効果メタ分析の検出力を計算するには、`power.analysis` 関数を使用する方が便利である。

\index{dmetar Package}

```{block, type='boxdmetar'}
**"power.analysis" 関数**

\vspace{4mm}

`power.analysis` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

\vspace{2mm}

1. 関数のソースコードにアクセスする [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R). 
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。
3. **{ggplot2}** パッケージがインストールされ、ロードされていることを確認する。

```


`power.analyze` 関数は、以下の引数を含む。

* **`d`**. 標準化平均差 (SMD) で表される仮説的な、または妥当な総合効果量。効果量は正の数値でなければならない。

* **`OR`**. 治療や介入の効果をコントロールと比較して想定したもので、オッズ比 (OR) で表される。`d` と `OR` の両方が指定された場合、結果は `d` の値に対してのみ計算される。

* **`k`**. メタ分析に含まれると予測される研究数。

* **`n1`**, **`n2`**. 対象研究の第1群、第2群における平均サンプルサイズの予測値。

* **`p`**. 使用するアルファ値。デフォルトは $\alpha$ =0.05。

* **`heterogeneity`**. 研究間の異質性のレベル。固定効果モデルで異質性がない場合は  `"fixed"`、異質性が低い場合は `"low"`、異質性が中程度の場合は `"moderate"`、異質性が高い場合は `"high"`  を指定することができる。デフォルトは `"fixed"`。


先ほどの例と同じ入力で、この関数を試してみよう。

```{r, eval=F}
library(dmetar)
power.analysis(d = 0.2, 
               k = 10, 
               n1 = 25, 
               n2 = 25, 
               p = 0.05)
```




```{r, echo=F, fig.width=4, fig.height=3, fig.align='center', out.width="55%"}
#source("data/power.analysis.bw.R")
dmetar::power.analysis(d = 0.2, 
               k = 10, 
               n1 = 25, 
               n2 = 25, 
               p = 0.05) 
```

<br></br>

## ランダム効果モデル

---

\index{Random-Effects Model}

ランダム効果モデルを仮定した検出力分析の場合、研究間の異質性分散 $\tau^2$ を考慮する必要がある。したがって、標準誤差の適合版、$\sigma^*_{\theta}$  を計算する必要がある。


\begin{equation}
\sigma^*_{\theta}=\sqrt{\frac{\left(\frac{n_1+n_2}{n_1n_2}\right)+\left(\frac{\theta^2}{2(n_1+n_2)}\right)+\tau^2}{K}}
(\#eq:pow5)
\end{equation}


問題は、$\tau^2$ の値は、通常、データを見る前にはわからないということである。しかし、Hedges and Pigott [-@hedges2001power] は、研究間異質性が低い、中程度、高い場合にモデル化するために使用することができるガイドラインを提供している。

\vspace{2mm}

**低い異質性:**

\begin{equation}
\sigma^*_{\theta} = \sqrt{1.33\times\dfrac{\sigma^2_{\theta}}{K}}
(\#eq:pow6)
\end{equation}

\vspace{2mm}

**中程度の異質性:**

\begin{equation}
\sigma^*_{\theta} = \sqrt{1.67\times\dfrac{\sigma^2_{\theta}}{K}}
(\#eq:pow7)
\end{equation}

\vspace{2mm}

**高い異質性:**

\begin{equation}
\sigma^*_{\theta} = \sqrt{2\times\dfrac{\sigma^2_{\theta}}{K}} 
(\#eq:pow8)
\end{equation}

\vspace{2mm}

また、`power.analyze` 関数はランダム効果メタ分析に使用することができる。異質性引数  `heterogeneity`  を用いて、想定される研究間の異質性の大きさを制御することができる。設定可能な値は `"low"`、`"moderate"`、`"high"`  である。前の例と同じ値を用いて、研究間の異質性が中程度の場合の期待検出力を計算してみよう。 

\vspace{2mm}

```{r, eval=F}
power.analysis(d = 0.2, 
               k = 10, 
               n1 = 25, 
               n2 = 25, 
               p = 0.05,
               heterogeneity = "moderate")
```

```
## Random-effects model used (moderate heterogeneity assumed). 
## Power: 40.76%
```

推定された検出力は 40.76% であることがわかる。これは、標準的な 80% の閾値よりも低い値である。また、固定効果モデルを仮定した場合の 60.66% よりも低くなっている。これは、研究間の異質性がプール効果の推定値の精度を低下させ、その結果、統計的検出力が低下するためである。 

Figure \@ref(fig:power) は、 真の効果量、研究数、研究間の異質性の量がメタ分析の検出力に及ぼす影響を可視化している^[様々な仮定の下でメタ分析の検出力を素早くチェックしたい場合は、この目的のために開発された**検出力計算ツール**も使用できる。このツールは、この章で取り上げるのと同じ _R_ 関数に基づくものである。https://mathiasharrer.shinyapps.io/power_calculator_meta_analysis/ にある。]。 

\vspace{2mm}

```{r power,fig.width=5,fig.height=4, fig.align='center',echo=FALSE,fig.cap="ランダム効果メタアナリシスの検出力（各研究 $n$=50）。色が濃いほど、研究間の異質性が高い。", message=FALSE, warning=F, out.width="55%"}
library(ggplot2)
library(reshape)
source("data/power.analysis.random.R")


k <- seq(0, 50, length=1000)
pow.vals01<-lapply(k,function(k) power.analysis.random(d=0.10,k=k,n1=25,n2=25,p=0.05,heterogeneity = "moderate"))
pow.vals02<-lapply(k,function(k) power.analysis.random(d=0.20,k=k,n1=25,n2=25,p=0.05,heterogeneity = "moderate"))
pow.vals03<-lapply(k,function(k) power.analysis.random(d=0.30,k=k,n1=25,n2=25,p=0.05,heterogeneity = "moderate"))
pow.vals01<-as.numeric(pow.vals01)
pow.vals02<-as.numeric(pow.vals02)
pow.vals03<-as.numeric(pow.vals03)
data1<-data.frame(k,pow.vals01,pow.vals02,pow.vals03)
k <- seq(0, 50, length=1000)
pow.vals01<-lapply(k,function(k) power.analysis.random(d=0.10,k=k,n1=25,n2=25,p=0.05,heterogeneity = "low"))
pow.vals02<-lapply(k,function(k) power.analysis.random(d=0.20,k=k,n1=25,n2=25,p=0.05,heterogeneity = "low"))
pow.vals03<-lapply(k,function(k) power.analysis.random(d=0.30,k=k,n1=25,n2=25,p=0.05,heterogeneity = "low"))
pow.vals01<-as.numeric(pow.vals01)
pow.vals02<-as.numeric(pow.vals02)
pow.vals03<-as.numeric(pow.vals03)
data2<-data.frame(k,pow.vals01,pow.vals02,pow.vals03)
k <- seq(0, 50, length=1000)
pow.vals01<-lapply(k,function(k) power.analysis.random(d=0.10,k=k,n1=25,n2=25,p=0.05,heterogeneity = "high"))
pow.vals02<-lapply(k,function(k) power.analysis.random(d=0.20,k=k,n1=25,n2=25,p=0.05,heterogeneity = "high"))
pow.vals03<-lapply(k,function(k) power.analysis.random(d=0.30,k=k,n1=25,n2=25,p=0.05,heterogeneity = "high"))
pow.vals01<-as.numeric(pow.vals01)
pow.vals02<-as.numeric(pow.vals02)
pow.vals03<-as.numeric(pow.vals03)
data3<-data.frame(k,pow.vals01,pow.vals02,pow.vals03)
ggplot()+
  geom_line(data = data1, aes(x = k, y = pow.vals01), color = "dodgerblue3",size=0.9) +
  geom_line(data = data1, aes(x = k, y = pow.vals02), color = "firebrick3",size=0.9) +
  geom_line(data = data1, aes(x = k, y = pow.vals03), color = "springgreen3",size=0.9) +
  geom_line(data = data2, aes(x = k, y = pow.vals01), color = "dodgerblue1",size=0.9) +
  geom_line(data = data2, aes(x = k, y = pow.vals02), color = "firebrick1",size=0.9) +
  geom_line(data = data2, aes(x = k, y = pow.vals03), color = "springgreen1",size=0.9) +
  geom_line(data = data3, aes(x = k, y = pow.vals01), color = "dodgerblue4",size=0.9) +
  geom_line(data = data3, aes(x = k, y = pow.vals02), color = "firebrick4",size=0.9) +
  geom_line(data = data3, aes(x = k, y = pow.vals03), color = "springgreen4",size=0.9) +
  xlab('Number of Studies') +
  ylab('Power')+
  scale_x_continuous(expand = c(0, 0), limits = c(1, 50), breaks = c(1, 10, 20, 30, 40, 50)) +
  scale_y_continuous(labels = scales::percent)+
  theme(
        axis.line= element_line(color = "black",size = 0.5,linetype = "solid"),
        legend.position = "bottom",
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.background = element_rect(fill = "#FFFEFA", size = 0),
        plot.background = element_rect(fill = "#FFFEFA", size = 0),
        legend.background = element_rect(linetype="solid",
                                         colour ="black"),
        legend.title = element_blank(),
        legend.key.size = unit(0.75,"cm"),
        legend.text=element_text(size=14))+
annotate("text", x = 6, y = 0.9, label = expression(theta==0.3),size=5, parse = T)+
  annotate("text", x = 25, y = 0.6, label = expression(theta==0.2),size=5)+
  annotate("text", x = 20, y = 0.13, label = expression(theta==0.1),size=5)+
  geom_hline(yintercept=0.8,linetype="dotted") 
```

<br></br>

## サブグループ解析  {#power-subgroup}

---

\index{Subgroup Analysis}\index{サブグループ解析}

サブグループ分析を計画する際、自由に使える研究数がある場合、2群間の差がどの程度大きければ検出できるかを知ることが重要になることがある。これは、サブグループの差のための検出力分析を適用できる条件である。 _R_ では、Hedges and Pigott [-@hedges2004power] のアプローチを実装した `power.analysis.subgroup`  関数を用いてサブグループの検出力分析を行うことができる。

```{block, type='boxdmetar'}
**`power.analysis.subgroup` 関数**

\vspace{2mm}

`power.analysis.subgroup` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

1. 関数のソースコードにアクセスする [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R). 
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。
3. **{ggplot2}** パッケージがインストールされ、ロードされていることを確認する。

```


グループ１の効果は SMD = 0.3、標準誤差は 0.13 であり、グループ２の効果は SMD = 0.66、標準誤差は 0.14 であると仮定しよう。これらの仮定条件を関数の呼び出しの入力として使用することができる。

```{r, fig.width=4, fig.height=3, fig.align='center', out.width="55%"}
power.analysis.subgroup(TE1 = 0.30, TE2 = 0.66, 
                        seTE1 = 0.13, seTE2 = 0.14)

```



この出力では、想像上のサブグループ検定の検出力 (47%) が十分でないことがわかる。出力は、他のすべてが同じで、十分な検出力に達するには、効果量の差が少なくとも 0.54 である必要があることも教えてくれる。

$$\tag*{$\blacksquare$}$$



<!--chapter:end:16-power-analysis-ja.Rmd-->

# バイアスリスクのプロット  {#risk-of-bias-plots}

**Luke A. McGuinness による**

---

<img src="_figs/traffic_light.jpg" />

```{block2, type='boxempty'}
**この章を引用する場合は**

McGuinness, L. A. (2021). Risk of Bias Plots. In Harrer, M., Cuijpers, P., Furukawa, T.A., & Ebert, D.D., _Doing Meta-Analysis with R: A Hands-On Guide_ (online version). https://bookdown.org/MathiasHarrer/Doing_Meta_Analysis_in_R/rob-plots.html.
```


<br></br>

<span class="firstcharacter">こ</span>
の章では、 **{robvis}** パッケージを使用して、 _R_ でRisk of Bias プロットを作成する方法について説明する。

<br></br>

## イントロダクション

---

システマティックレビューやメタ分析の一環として、関連する[領域別バイアスリスク評価ツール](https://handbook-5-1.cochrane.org/chapter_8/8_3_1_types_of_tools.htm)を用いて、含まれる研究の内部妥当性（バイアスリスク、Risk of Bias）を調べ、この評価結果をグラフで提示すとよいだろう。 

コクランハンドブックでは、2種類の図を推奨している。各ドメイン内で所定のバイアスリスク判定を受けた研究の割合を示す要約棒グラフと、各研究のドメインレベルの判定を提示す交通信号プロット（Traffic Light Plot、今のところ定着した日本語訳はない）である。

しかし、これらの図を作成する際に、研究者が利用できる選択肢は限られている。RevMan にはプロットを作成する機能があるが、多くの研究者はシステマティックレビューを行うために RevMan を使用していないため、関連データをシステムにコピーする解決方法は非効率的である。 

同様に、MS PowerPoint などのソフトウェアを使用して手作業でグラフを作成するのは時間がかかり、変更が必要な場合は手作業で図を更新しなければならない。さらに、ジャーナルは通常、出版品質（300-400 dpi 以上）の図を要求するが、RevMan からバイアスリスクの図をエクスポートしたり、手作業で作成したりする場合、品質を維持するのが難しい場合がある。


```{r rob-revman, fig.cap="Example RevMan output.",  out.width='75%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/robsummaryrevman.jpg')
```

このようなことを避けるために、バイアスリスク評価の要約表を要約プロットまたは交通信号プロットに変換する関数を提供する **{robvis}** パッケージ [@mcguinness2020risk; @robvis] を使用して、R Studio 内でバイアスリスク数値を自分で簡単にプロットできるようになる。


<br></br>

### **{robvis}** を読み込む

---

すでに **{dmetar}** パッケージがインストールされていると仮定して（Chapter \@ref(dmetar) 参照）、**{robvis}** パッケージを使用しロードする。

```{r, message=F}
library(robvis)
```

<br></br>

### バイアスリスクの要約表データをインポート

---

プロットを作成するために、まず、**Excel** から _R_ にバイアスリスク評価の結果をインポートする必要がある。なお、**{robvis}** はデータ作成方法について指定があり、Excel で表を設定する際には以下のガイダンスに必ず従わなければならない。

1. 最初の列名は "Study" とし、研究識別子を記述する（例：**Anthony et al, 2019**）。
2. 最後から2番目の列名は "Overall" とする。全体のリスクオブバイアス判定を記載する。
3. 最後の列名は "Weight" とし、研究の精度の指標（例えば、メタ分析で各研究に割り当てられた重み、またはメタ分析が行われなかった場合は、各研究のサンプルサイズ）を記述する。詳しくは、Chapter \@ref(fem) を参照。
4. その他の列は、特定のドメインのバイアスリスク評価結果を含む。

上記のガイダンスを詳しく説明するために、5つのドメインを持つ ROB2 ツールを例として考えてみよう。このツールで **{robvis}** が期待する結果のデータセットは8列である。

* **列 1**. 試験の識別子
* **列 2-6**. 1列につき1つの RoB2 ドメイン
* **列 7**. 総合的なリスクオブバイアス判定
* **列 8**. 重み

Excel では、このバイアスリスクの要約表は次のようになる。

```{r rob-example-data,  out.width='75%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rob_excel.png')
```

```{block, type='boximportant'}
**列の名前**

４種類あるうちの３種類のテンプレート (ROB2, ROBINS-I, QUADAS-2) では、ドメインレベル判定を含む列の名前は重要ではない。robvis 内のテンプレートが各ドメインを正しく修正する。
```

Excel で作成した表をカンマ区切りファイル（例: "robdata.csv"）として作業ディレクトリに保存し、以下のコマンドを使用してプログラム的にそのファイルを _R_ に読み込むか、Chapter \@ref(data-prep-R)  で説明したインポート機能を使用して読み込むことができる。


```{r, eval=F}
my_rob_data <- read.csv("robdata.csv", header = TRUE)
```

<br></br>

### テンプレート

---

**{robvis}** は、使用したバイアスリスク評価ツールに固有のテンプレート図を入力するために、提供されたデータを使用してバイアスリスク図を作成する。現在、**{robvis}** には、以下の3つのツールのテンプレートが含まれている。

* **ROB2**、ランダム化比較試験のための新しい Cochrane の Risk Of Bias ツール。
* **ROBINS-I** は、Risk of Bias In Non-randomized Studies of Interventions（ランダム化されていない介入研究におけるバイアスのリスク）ツール。
* **QUADAS-2** は、Quality and Applicability of Diagnostic Accuracy Studies, Version 2。

**{robvis}** には、ROB1 とラベル付けされた特別な汎用テンプレートも含まれている。ランダム化対照試験用の Cochrane risk of bias ツールで使用するために設計されているが、上記のリストに含まれていない他のドメインベースのツールで実行された評価結果を可視化するために使用することも可能である。このテンプレートを使用する際に必要な追加ステップの詳細については、Chapter \@ref(rob1-template) を参照。


<br></br>

### データセット例

---

 **{robvis}** パッケージには、上記の各テンプレートに対応したデータセット例が格納されている。これらは以下のオブジェクトに格納されている。

*  `data_rob2` :ROB2 ツールのデータ例
*  `data_robins` :ROBINS-I ツールのデータ例
*  `data_quadas` :QUADAS-2 ツール用のサンプルデータ
*  `data_rob1` :RoB-1 ツール用のサンプルデータ

データセットは `glimpse` 関数を用いて探索することができる（Chapter \@ref(class-conversion) 参照）。例えば、`library(robvis)` を用いてパッケージをロードしたら、以下のコマンドを実行して ROBINS-I のサンプルデータセットを閲覧してみよう。

```{r, message=F, eval=F}
glimpse(data_robins)
```

```{r, message=F, echo=F}
dplyr::glimpse(data_robins)
```
このサンプルデータセットを、このガイドの残りの部分で提示されるプロットを作成するために使用する。



<br></br>

## 要約プロット

---

### 基本情報

---

_R_ にバイアスリスク要約表をインポートしたら、バイアスリスク図の作成は非常に簡単である。

まず始めに、ROB2 サンプルデータセット（`data_rob2`）を用いた単純な重み付き要約棒グラフを、以下のコードを実行して作成する。

```{r, fig.width=9, fig.height=2.5, fig.align='center', out.width='90%'}
rob_summary(data = data_rob2, 
            tool = "ROB2")
```


<br></br>

### プロットを修正

---

`rob_summary` 関数には以下のパラメータがある。

*  `data`. 要約（ドメイン）レベルの risk-of-bias 評価を含むデータフレーム。最初の列は研究の詳細、2 番目の列は評価の最初のドメイン、最後の列は各研究に割り当てる重み付けを含む。この関数は、データに全体的なリスクオブバイアスの列が含まれていることを想定している。例えば、ROB2.0 のデータセットでは、8列（研究の詳細1、ドメインレベルの判定5、総合判定1、重み付け1の順）となる。
*  `tool`. 使用したバイアスリスク評価ツール。現在、RoB2.0 (`"ROB2"`)、`"ROBINS-I"`、`"QUADAS-2"` がサポートされている。
*  `overall`. 図に全体の Risk of Bias を示す追加のバーを含めるかどうかのオプション。デフォルトは `FALSE` である。
*  `weighted`. 棒グラフに重みをつけるかどうかを指定するオプション。デフォルトは  `TRUE` で、現在の Cochrane Collaboration のガイダンスに沿ったものである。
*  `colour`. プロットの配色を指定するための引数である。デフォルトは  `"cochrane"`  で、どこにでもあるコクランカラーを使用する。また、色覚異常者に優しいパレットのプリセットオプションも利用でく ( `colour = "colorblind"` ).
*  `quiet`. プロットを表示せず、静かに生成するための論理オプション。デフォルトは  `FALSE`。

各引数の機能例を以下に示す。

<br></br>

#### `tool`

---

`tool` は、使用するツールテンプレートを定義するための引数である。上の例では、ROB2テンプレートが使用されている。他の2つの主要なテンプレート、ROBINS-I と QUADAS-2 テンプレートは、以下に示されている。


```{r, fig.width=9, fig.height=3, fig.align='center', out.width='90%'}
rob_summary(data = data_robins, 
            tool = "ROBINS-I")
```

```{r, fig.width=9, fig.height=2.5, fig.align='center', out.width='90%'}
rob_summary(data = data_quadas, 
            tool = "QUADAS-2")
```

<br></br>

#### `overall`

---

デフォルトでは、全体の Risk of Bias 判定を表す追加のバーはプロットに含まれない。これを含めたい場合は、`overall = TRUE` と設定してみよう。例えば


```{r, fig.width=9, fig.height=2.5, fig.align='center', out.width='90%'}
rob_summary(data = data_rob2, 
            tool = "ROB2", 
            overall = TRUE)
```

<br></br>

#### 重み付け棒グラフと非重み付け棒グラフ

---

デフォルトでは、棒グラフは研究の精度の指標で重み付けされ、特定のバイアスのリスクがある研究の割合ではなく、情報の割合を示すようになる。このアプローチは、[Cochrane Handbook](https://training.cochrane.org/handbook/current/chapter-07#section-7-4)に沿っている。

このオプションをオフにするには、`weighted = FALSE`  と設定し、重み付けしない棒グラフを作成する。例えば、次の2つのプロットを比較してみてみよう。

```{r, fig.width=9, fig.height=2.5, fig.align='center', out.width='90%'}
rob_summary(data = data_rob2, 
            tool = "ROB2")
```


```{r, fig.width=9, fig.height=2.5, fig.align='center', out.width='90%'}
rob_summary(data = data_rob2, 
            tool = "ROB2",
            weighted = FALSE)
```

<br></br>

#### カラースキーム

---

```{block2, type='boximportant'}
**British English Spelling**

Please note the non-US English spelling of **colour**!
```

両プロット関数の `colour` 引数は、2つの定義済みカラースキーム、`"cochrane"` (デフォルト) または `"colorblind"` から選択するか、あるいは **hex code** のベクトルを与えて自分自身のパレットを定義することが可能である。例えば、定義済みの  `"colorblind"` パレットを使用するには、以下のようにした。

```{r, fig.width=9, fig.height=2.5, fig.align='center', out.width='90%'}
rob_summary(data = data_rob2, 
            tool = "ROB2", 
            colour = "colourblind")
```

自分だけのカラースキームを決めることもできる。

```{r, fig.width=9, fig.height=2.5, fig.align='center', out.width='90%'}
rob_summary(data = data_rob2, 
            tool = "ROB2", 
            colour = c("#f442c8","#bef441","#000000"))
```

独自のカラースキームを定義する場合、離散判定（例：「低」、「中」、「高」、「重要」）の数と指定する色の数が同じであることを確認する必要がある。さらに、色はバイアスのリスクの昇順（例：「Low」～「Critical」）で指定する必要があり、最初の16進数はバイアスのリスクが "Low" に対応する。


<br></br>

## 交通信号プロット

---

研究者は、評価した各研究の各領域におけるバイアスのリスクを提示したいと思うことがよくある。このプロットは一般的に交通信号プロットと呼ばれ、**{robvis}** の  `rob_traffic_light` 関数で作成することができる。

<br></br>

### 基本情報

---

まず、ROB2 サンプルデータセット( `data_rob2` )を用いた交通信号プロットを、以下のコードを実行して作成した。

```{r, fig.width=8, fig.height=10, fig.align='center', out.width='65%'}
rob_traffic_light(data = data_rob2, 
                  tool = "ROB2")
```

<br></br>

### プロットを修正

---

`rob_summary` 関数には以下のパラメータがある。

*  `data`. 要約（ドメイン）レベルの risk-of-bias 評価を含むデータフレーム。最初の列は研究の詳細、2 番目の列は評価の最初のドメイン、最後の列は各研究に割り当てる重み付けを含む。この関数は、データに全体的なリスク・オブ・バイアスの列が含まれていることを想定している。例えば、ROB2.0のデータセットでは、8列（研究の詳細1、ドメインレベルの判断5、総合判断1、重み1、この順）となる。
*  `tool`. 使用したバイアスリスク評価ツール。現在、RoB2.0 (`"ROB2"`)、`"ROBINS-I"`、`"QUADAS-2"` がサポートされている。
*  `colour`. プロットの配色を指定するための引数である。デフォルトは `"cochrane"` で、どこにでもあるコクランカラーを使用する。また、色覚異常者に優しいパレット (`"colorblind"`)のプリセットオプションも利用できる。
*  `psize`.「交通信号」ポイントの大きさを変更するためのオプション。デフォルトは `20`。
*  `quiet`. プロットを表示せず、静かに生成するための論理オプション。デフォルトは  `FALSE`。


<br></br>

#### ツール

---

使用するツールテンプレートを定義するための引数である。ROB2 テンプレートのデモと、他の2つの主要テンプレートである ROBINS-I と QUADAS-2 テンプレートを以下に表示する。


```{r, fig.width=10, fig.height=11, fig.align='center', out.width='65%'}
rob_traffic_light(data = data_robins, 
                  tool = "ROBINS-I")
```


```{r, fig.width=8, fig.height=11, fig.align='center', out.width='65%'}
rob_traffic_light(data = data_quadas, 
                  tool = "QUADAS-2")
```


<br></br>

#### カラースキーム

---


```{block2, type='boximportant'}
**イギリス英語**

「色」のスペルは、アメリカ英語ではなく **colour**  である。
```


両プロット関数の `colour` 引数は、2つの定義済み配色 `"cochrane"` (デフォルト) と `"colorblind"` から選択することができる。

例えば、定義済みの  `"colorblind"`  パレットを使用する場合。

```{r, fig.width=8, fig.height=9, fig.align='center', out.width='65%'}
rob_traffic_light(data = data_rob2, 
                  tool = "ROB2", 
                  colour = "colourblind")
```

自分だけのカラースキームを決めることもできる。

```{r, fig.width=8, fig.height=9, fig.align='center', out.width='65%'}
rob_traffic_light(data = data_rob2, 
                  tool = "ROB2", 
                  colour = c("#f442c8","#bef441","#000000"))
```


独自のカラースキームを定義する場合、離散判定（例："Low"、"Moderate"、"High"、"Critical"）の数と指定する色の数が同じであることを確認する必要がある。さらに、色はバイアスのリスクの昇順（例："Low"～"Critical"）で指定する必要があり、最初の16進数はバイアスのリスクが "Low" の色に対応する。


<br></br>

#### ポイントサイズ

---

時折、多数のバイアスリスク評価を実施した場合、結果の交通信号プロットが長すぎて役に立たないことがある。このような場合には、`rob_traffic_light` 関数の `psize`  引数を小さくすることで対応でく（デフォルトは `20`）。例えば

```{r, fig.width=5.5, fig.height=13, fig.align='center', out.width='45%'}
# Create bigger dataset (18 studies)
new_rob2_data <- rbind(data_rob2, data_rob2)
new_rob2_data$Study <- paste("Study", seq(1:length(new_rob2_data$Study))) 

# Plot bigger dataset, reducing the psize argument from 20 to 8
rob_traffic_light(data = new_rob2_data, 
                  tool = "ROB2", 
                  psize = 8)
```
<br></br>

## "ROB1 "ジェネリックテンプレート  {#rob1-template}

---

### モチベーション

---

このテンプレートは、プロットに含まれるドメインの柔軟性を高めている。任意の数のドメインを扱うことができ（ドメインの数が設定されている他のツールテンプレートを参照）、結果の図ではユーザー定義の列見出しをドメインのタイトルとして使用する。

<br></br>

### ドメイン数の違い

---

"ROB1" テンプレート ( `tool = "ROB1"` ) は、さまざまな数の列を扱うことができる。これはもともとROB1アセスメントツールで使用するために設計されたが、頻繁にドメインが追加または削除されるようになった。**このテンプレートは他のツール（ROB2、QUADAS-2、ROBINS-I）の調整版を使用して行われた評価の結果を提示すために使用できるが、これは勧めない**。他の公表されているツールを使用する著者は、ガイダンスに適合することを確実にするために、前の章で示されたより厳格なテンプレートを使用する必要がある。


<br></br>

### ドメイン名

---

前のセクションで挙げた他のツールでは、ドメインレベルのバイアスリスク判定を含む列の名称は重要ではない。例えば、 _D1_ 、 _D2_ 、 _D3_ などの名前が一般的である。しかし、 `"ROB1"` テンプレートを使用する場合は、この限りではない。

data_rob2 と data_rob1 の列見出しを比較する（ここでは比較しやすいように横向きで表示している）。


```{r, echo=F, message=FALSE}
library(kableExtra)
k<-c(colnames(robvis::data_rob2),".",".")
kk<-colnames(robvis::data_rob1)
kkk<-seq(1:10)

ms3 <- data.frame(colnum = kkk, data_rob2 = k, data_rob1 = kk)

kableExtra::kable(
  list(
    ms3[,c(1,2)],
    ms3[,c(1,3)]
  ), col.names = c("No.", "列名"),
  longtable = T,
  booktabs = T,
  caption = 'データセット `data_rob2` (左) and `data_rob1` (右) における列名の比較。'
) %>% 
  kable_styling()
```

ROB2 サンプルデータセットのドメイン列（列 2-6）には、 _D1_ ～ _D5_ という任意の名前が付けられているが、これは ROB2 ガイダンスで与えられた正しいドメインタイトルに対応するようにツールで上書きされるためである。

一方、ROB1 サンプルデータセットのドメイン列（列 2-8）は、`rob_summary` と  `rob_traffic_light` が生成する図に使用されるため、正しくラベル付けされていることがわかる。 

例として、"Random.sequence.generation" 列の名前を "これはテスト" に変更してみよう。`rob_summary` 図では、最初のバーのタイトルが変更され、`rob_traffic_light` 図では、この変更を反映してキャプションが更新されている。


```{r, fig.width=9, fig.height=2.5, fig.align='center', out.width='90%'}
# data_rob1 データセットのコピーを作成
new_rob1_data <- data_rob1

# 最初のドメインの列名を変更
colnames(new_rob1_data)[2] <- "これはテスト"

# 要約棒グラフを作成; macOS では文字化けするためフォント（ただし y 軸が追加されてしまう）
rob_summary(data = new_rob1_data, tool = "ROB1") +
  theme_classic(base_family = "Hiragino Kaku Gothic Pro W3")
```


```{r, fig.width=10, fig.height=11, fig.align='center', out.width='65%'}
# 交通信号プロットを作成
rob_traffic_light(data = new_rob1_data, 
                  tool = "ROB1")
```

<br></br>

## カスタマイズと保存

---

###  **{ggplot2}** パッケージ

---

**{robvis}** 関数（`rob_summary` と `rob_traffic_light`）は共に `ggplot` オブジェクトを生成するので、**{ggplot2}** パッケージの関数を使用してカスタマイズしたり保存したりすることができる。このパッケージを読み込むには、次のコードを使用する。

```{r, message=F}
library(ggplot2)
```

<br></br>

### プロットの修正

---

プロットには、**{ggplot2}** 関数を使ってポストプロダクションで行うことができる様々な修正がある。便利な例は、プロットにタイトルを追加することである。

```{r, fig.width=9, fig.height=2.5, fig.align='center', out.width='90%'}
# 事前に ggplot2 がインストールされ、ロードされていること
rob_summary(data_rob2, "ROB2") +
  ggtitle("Your custom title")
```

<br></br>

### プロットの保存

---

バイアスのリスクのプロットを保存するために、まず &lt;- 演算子を用いてオブジェクトに割り当て、次に **{ggplot2}** パッケージの `ggsave` 関数を用いて保存する。

要約棒グラフを保存する際は、高さと幅をデフォルト値にして、以下のコードを使用することを勧める。

```{r, eval=F}
# プロットを作成し、オブジェクトに格納
rob_barplot <- rob_summary(data_rob2, "ROB2")

# プロットを保存
ggsave(plot = rob_barplot,        # 保存するオブジェクト
       filename = "robplot2.png", # 保存先
       width = 8,                 # 画像の幅（推奨値）
       height = 2.41,             # 画像の高さ（推奨値）
       dpi = 1000)                # 画像の解像度
```

交通信号プロットも、保存する方法は同じである。しかし、`width` と `height` パラメータの最適な値は、含まれる研究の数や名前が変わると、プロットごとに異なるため、推奨値はない。

<br></br>

### 異なるフォーマットで保存

---


プロットは、ファイル名の拡張子を変えるだけで（例えば ".png" から ".pdf" に）、上記の関数を使って様々なフォーマットで保存することが可能である。使用可能なフォーマットは .png、.pdf、.tiff、.svg^[SVG は、**{svglite}** パッケージのインストールとロードを要する。`install.packages("svglite")` して  `library(svglite)` とする。] である。


例えば、上で作成した棒グラフ（`rob_barplot`）を PDF として保存するには、以下のようにする。

```{r, eval=F}
# プロットを保存
ggsave(plot = rob_barplot,                  
       filename = "robplot2.pdf", # 拡張子を ".pdf"
       width = 8,                           
       height = 2.41,                       
       dpi = 1000)
```


<br></br>

## ウェブアプリ

---

robvis の機能を手軽に体験してもらうために、**{robvis}** パッケージのグラフィカルなインターフェースを提供する Web アプリケーションを作成した。

ウェブアプリは[こちら](https://mcguinlu.shinyapps.io/robvis)で公開されている。以下に、簡単なガイド付きウォークスルーを紹介する。


<br></br>

### ランディングページ

---


```{r, out.width='90%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/robvis-app-landingpage.png')
```


このページでは、前の章で紹介したガイダンスの簡潔版、特にデータセットのセットアップについて紹介した。さらに重要なのは、各ツールのサンプルデータセットを CSV ファイルとしてダウンロードし、アプリとの対話や機能探索に利用できることである。

<br></br>

### 交通信号プロットページ

---

2番目のタブをクリックすると、以下の画面が表示される。


```{r, out.width='45%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/robvis-app-traffic-light.png')
```


このメニューは `rob_traffic_light` 関数のグラフィカルインターフェイスとして機能する。

* "Browse..." をクリックし、CSV ファイルを保存した場所に移動して、バイアスリスクの要約表をアップロードした。
* ドロップダウン・ボックスを使用して、バイアス・リスクの評価を行うために使用するツールを選択する。

基本的な交通信号のプロットがウィンドウの右側に表示されるはずである。以下のオプションを使ってプロットをカスタマイズすることができる。

* 使用する配色を選択してみよう（"Cochrane" または "Colour-blind friendly" のいずれか）
* ポイントサイズの変更（1つの交通信号プロット上に多数の研究をプロットしたい場合に有効）
* 文字サイズの変更

プロットが完成したら、必要な形式 (.png, .jpg, .tiff, .eps) を選んで "Download plot" ボタンをクリックすれば、プロットをダウンロードすることができる。最初に形式を選択しないと、ダウンロードエラーになる。


<br></br>

### 要約プロットページ

---

3番目のタブをクリックすると、以下の画面が表示される。


```{r, out.width='45%', message = F, echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/robvis-app-summary-plot.png')
```
**このメニューは `rob_summary` 関数のグラフィカルインターフェイスとして機能する。**

* "Browse..." をクリックし、CSV ファイルを保存した場所に移動して、バイアスリスクの要約表をアップロードする。
* ドロップダウン・ボックスを使用して、バイアス・リスクの評価を行うために使用するツールを選択する。

基本的な加重要約棒グラフがウィンドウの右側に表示されるはずである。

**以下のオプションを使用して、プロットをカスタマイズすることができる。**

* 図形の作成時にウェイトを使用するかどうかを選択することができる。
* バイアス判定全体のリスク分布を表す棒グラフを追加してみよう。
* 使用する配色を選択してみよう（"Cochrane" または "Colour-blind friendly" のいずれか）

交通信号プロットタブと同様に、必要なフォーマットを選択し、"Download plot" ボタンをクリックすると、プロットをダウンロードすることができる。




$$\tag*{$\blacksquare$}$$





<!--chapter:end:17-risk-of-bias-plots-ja.Rmd-->

# 報告と再現性  {#reporting-reproducibility}

---

<img src="_figs/reporting.jpg" />


<br></br>



<span class="firstcharacter">こ</span>
れまでの章では、 _R_ でメタ分析を行うために使用できる様々なテクニック、アプローチ、戦略について説明してきた。しかし、統計解析の実行は、実際にはメタ分析「プロセス」全体のごく一部の割合を占めるに過ぎない。「現場」では、以下のような「事件」が発生する。

* _R_ のコードにエラーが見つかったため、解析の一部を変更してやり直さなければならない。

* 共同研究者や査読者は、別のアプローチやモデルの使用、あるいは追加の感度分析を行うことを提案している。

* 分析作業の一部を共同研究者の一人に委任する必要があり、現在の作業状況を送らなければならない。

* プロジェクトをしばらく中断していたため、再開するころにはいろいろなことを忘れてしまっている。

* 解析結果をプロジェクトの共同研究者と共有したいが、共同研究者は _R_ を知らず、R Studio はインストールすらされていない。

これらはほんの一部のシナリオであるが、 _R_ でメタ分析を行う際の**再現可能なワークフロー**が、あなたや一緒に働く人々にとって有益であることを説明している。また、再現性を目指すことは、**オープンサイエンス**の実践の基礎でもある。完全に再現可能なメタ分析は、私たちがどのように結果に至ったかを他の人に可能な限り明らかにするものである。 

\index{Markdown, _R_}
\index{Open Science Framework (OSF)}


R Studio は、再現性のあるワークフローを作成し、協力を得るために最適なツールである。本章では、分析の再現、報告、普及のための3つのツールを紹介する _R_  Projects、**R Markdown** および **Open Science Framework** である。

<br></br>


## _R_ Project の利用

---

\index{Project, _R_}


解析を始めるには、まずR Studioで _R_ **Project** を立ち上げるのがよいだろう _R_ Projectは、コンピュータ上のフォルダーに新しい環境を作成する。このフォルダには、分析に必要なすべてのデータと _R_ コードが保存される _R_  Project で分析を行うということは、作成したすべてのオブジェクトが Project 環境に一時的に保存され、次に開いたときにアクセスできるようになることを意味する。新しい _R_ Project を作成するには、R Studio ウィンドウの右上にある **R Project** フィールドをクリックし、ドロップダウンメニューから **New Project...** を選択する。

```{r, message = F, out.width = '60%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rproj1_col.png')
```


次に、コンピュータ上に新しいフォルダである **New Directory** を作成する。これがプロジェクトの作業ディレクトリとなる。

```{r, message = F, out.width = '45%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rproj2_col.png')
```


そして、**New Project** をクリックする。

```{r, message = F, out.width = '45%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rproj3_col.png')
```


新しいプロジェクトに「Meta-Anallysis Project」という名前をつける。プロジェクトフォルダは、**~Documents/R** に格納される。

```{r, message = F, out.width = '45%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rproj4_col.png')
```

**プロジェクトの作成**をクリックすると、 _R_ Project が設定される。 _R_ Project の大きな特徴は、参照したいファイルへの**絶対パス**を使用する必要がないことである。ファイル名、またはファイルが（サブ）フォルダーにある場合は、フォルダー名とファイル名だけを使用する。例えば、データセット **data.xlsx** をサブフォルダー "data" に格納する。**{openxlsx}** パッケージ（Chapter \@ref(data-prep-R)）を使用すると、相対パスでデータセットをインポートすることができる。

```{r, eval=F}
read_excel("data/data.xlsx")
```

<br></br>


## R Markdown で再現性のあるレポートを作成

---

\index{Markdown, _R_}


**Markdown** はテキストフォーマットのためのシンプルなマークアップ言語である。**R Markdown** [@xie2018r]は Markdown の拡張機能で、プレーンテキスト、 _R_ コード、 _R_ 出力を1つのドキュメントに簡単にまとめることができるようになっている。このため、R Markdown は非常に便利なレポート作成ツールとなっている。R Markdown を使用すると、分析で使用したすべてのコード、コードによって生成された出力を含む HTML または PDF ファイルを作成でき、各分析ステップで行ったことに関する詳細な情報を追加することが可能にある。 

R Markdown ファイルを R Studio で構築するのはとても簡単である。R Studio ウィンドウの左上隅にある、緑色の「プラス」記号のついた白いシンボルをクリックすればよいのである。そして、ドロップダウンメニューから、**R Markdown...** をクリックする。

\vspace{2mm}
```{r, message = F, out.width = '35%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rmd1_col.png')
```
\vspace{2mm}


新しい R Markdown ドキュメントの名前を定義すると、R Studio ウィンドウの左上隅にポップアップ表示されるはずである。

\vspace{2mm}
```{r, message = F, out.width = '55%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rmd2_col.png')
```
\vspace{2mm}


このファイルには、すでにいくつかの例示的な内容が含まれているが、最初の6行を除いて削除することが可能である。

```
---
title: "Analysis"
author: "Author Name"
date: "10/16/2020"
output: html_document
---
```


この部分はいわゆる **YAML** ヘッダーである。これは、ドキュメントのタイトル、著者、日付、エクスポート形式を記述する。出力形式は `html_document` を選択した。これはドキュメントがレンダリングされると HTML ページとしてエクスポートされることを意味している。 

_R Markdown　ドキュメント_ はすべて、2つの部分から構成されている。 普通の Markdown テキスト、そして、グレーで示されたいわゆる **R チャンク**である。R Markdown ドキュメントのテキスト部分がどのようにフォーマットされるかについては詳しく説明しない。オンラインの [cheat sheet](https://rstudio.com/wp-content/uploads/2015/02/rmarkdown-cheatsheet.pdf) は、Markdown 構文を学び始める素晴らしいリソースである（20分程度で読むことができる）。一方、 _R_ コードのチャンクは、通常コンソールに入力するコードを含んでいるだけである。ドキュメントの右上にある **Insert** フィールドをクリックすることで、新しいコードチャンクを追加することができる。各チャンクの上にある小さな緑の三角形をクリックし、コードを実行することができる。

\vspace{2mm}
```{r, message = F, out.width = '25%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rmd3_col.png')
```
\vspace{2mm}


文書を書き終えたら、左上の**編み目**のマークをクリックして、HTML、PDF、MS Word 文書として書き出すことができる。これにより、すべてのテキスト、コード、出力を含む文書がレンダリングされ、定義されたフォーマットでエクスポートされる。最終的な文書は、自動的にプロジェクトフォルダに保存される。

\vspace{2mm}
```{r, message = F, out.width = '40%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/rmd4_col.png')
```
<br></br>


## OSF レポジトリ {#osf}

---

\index{Open Science Framework (OSF)}

**オープンサイエンス・フレームワーク**（Open Science Framework, [OSF](https://www.osf.io)）は、研究におけるコラボレーションと再現性を促進するためのオープンソースのオンラインプラットフォームである。OSF にはオンライン**リポジトリ**があり、研究者が研究資料を預けて共同研究を行い、研究プロセスのすべてのステップを（より）透明化することが可能である。OSF は、過去10年間に大きな勢いを得たオープンサイエンス運動の急先鋒である。 

すべてのメタ分析者は、収集したデータと分析に使用した _R_ コードにオープンアクセスすることで、研究と分析プロセスを一般に公開することが推奨される。OSFはこれを行うための素晴らしいツールである。自分で作成したすべてのリポジトリは、デフォルトで非公開になっており、いつ、何を公開するかは、あなた次第なのである。以下では、 _R_ で OSF リポジトリを設定する方法、ファイルのアップロードとダウンロード、共同研究者を追加する方法を紹介する。

<br></br>


### アクセス・トークン

---


OSF を使い始めるには、まず[ウェブサイト](https://osf.io/register)で個人アカウントを作成する必要がある。アカウントが作成されたら、 _R_ を使って直接リポジトリを操作できるように、**アクセストークン**を生成する必要がある。アクセストークンを取得するには、**Profile** &gt; **Settings** &gt; **Personal access tokens** に移動する必要がある。そこで、**Create token** をクリックする。

\vspace{4mm}
```{r, message = F, out.width = '60%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/osf1_col.png')
```
\vspace{4mm}


次に、**Scopes** の下にあるすべてのボックスにチェックを入れ、**Create token** を再度クリックする。すると、個人用のアクセストークンが表示されるはずである。このトークンをコピーして保存しておく。

\vspace{4mm}
```{r, message = F, out.width = '60%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/osf2_col.png')
```
<br></br>


### パッケージと認証について

---

**{OSF}** リポジトリに _R_ 経由で直接アクセスするには、**{osfr}** パッケージ [@osfr] を使用する。このパッケージの機能を使う前に、まずアクセストークンを使って認証する必要がある。これを行うには、`osf_auth` 関数を使用して、受け取ったばかりのアクセストークンを渡す (以下に表示されるトークンはデタラメ)。

```{r, eval=F}
library(osfr)
osf_auth("AtmuMZ3pSuS7tceSMz2NNSAmVDNTzpm2Ud87")
```


<br></br>


### レポジトリの設定

---

**{osfr}** を使うと、 _R_ を使った OSF リポジトリを初期化することが可能である。新しいメタ分析プロジェクトに取り組んでいて、データとR Markdown スクリプトを OSF リポジトリにアップロードしたいと想像してみよう。リポジトリの名前は "Meta-Analysis Project" とする。 

新しいリポジトリを作成するには、`osf_create_project` 関数を使用する。新しい OSF リポジトリを _R_ に  `meta_analysis_project` という名前で保存する。

\vspace{2mm}
```{r, eval=F}
meta_analysis_project <- osf_create_project("Meta-Analysis Project")
```


`osf_open` 関数を使用すると、新しく作成したリポジトリにオンラインでアクセスできるようになる。

\vspace{2mm}
```{r, eval=F}
osf_open(meta_analysis_project)
```


```{r, message = F, out.width = '60%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/osf3_col.png')
```


リポジトリが作成されたので、次に **コンポーネント**を追加していく。OSF では、コンポーネントはコンピュータのフォルダのように動作した。例えば、データセット用のコンポーネントと R Markdown スクリプト用のコンポーネントの2つを作成したいとする。これを行うには、 `osf_create_component` 関数を使用することが可能である。この関数に _R_ のリポジトリオブジェクト（ `meta_analysis_project` ）を渡し、新しいコンポーネントのタイトルを設定しなければならない。 

```{r, eval=F}
scripts <- osf_create_component(meta_analysis_project, 
                                title = "Analysis Scripts")
datasets <- osf_create_component(meta_analysis_project, 
                                 title = "Datasets")
```


リポジトリのオンラインページに行くと、2つのコンポーネントが追加されていることがわかる。

<br></br>


### アップロードとダウンロード

---


OSF リポジトリにデータをアップロードするには、  `osf_upload`  関数を使用する。この関数では、ファイルを追加するコンポーネントと、アップロードするファイルのパスを指定する必要がある。例えば、"Analysis.rmd" というR Markdownスクリプトをアップロードしたい場合、現在 _R_ プロジェクトのサブフォルダ "scripts" に保存されているものとする。アップロードするには、次のコードを使用する。

```{r, eval = F}
osf_upload(scripts, "scripts/Analysis.rmd")
```


ファイルが正常にアップロードされたかどうかを確認するには、 `osf_ls_files` 関数を使用してコンポーネントのコンテンツにアクセスする。

```{r, eval=F}
osf_ls_files(scripts)
```
```
## # A tibble: 2 x 3
##   name            id                       meta            
##   <chr>           <chr>                    <list>          
## 1 Analysis.rmd    1db74s7bfcf91f0012567572l <named list [3]>
```


アップロードが成功したことが出力で確認可能である。ファイルをダウンロードするには、 `osf_ls_files` 関数の出力から行を選択し、`osf_download` 関数でそれを使用して、ファイルをコンピュータのプロジェクトフォルダにダウンロードしなおせばよい。

```{r, eval = F}
osf_download(osf_ls_files(scripts)[1,])
```
<br></br>


### コラボレーション、オープンアクセス、事前登録  {#pre-registration}

---

\index{Preregistration}


OSF のリポジトリサイトでは、**Contributors**という項目で共同研究者を追加することも可能である。



```{r, message = F, out.width = '65%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/osf4_col.png')
```


ウェブサイト右上の **Make Public** ボタンをクリックすることで、いつでもリポジトリを **public** にすることが可能である。

```{r, message = F, out.width = '40%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/osf5.png')
```


Chapter \@ref(analysis-plan)  で、解析計画と事前登録が高品質なメタ分析に不可欠な部分であることを説明してきた。OSFでは、私たちのプロジェクトのために、オープンにアクセスできる事前登録を作成することができ、とても便利である。上部にある**登録**ボタンをクリックし、**新規登録**を作成するだけでよいのである。これにより、**OSF Registries** のウェブサイトが表示され、分析計画など、計画中の研究についての詳細情報を提供することが可能である。 

\vspace{2mm}
```{r, message = F, out.width = '57%', echo = F, fig.align='center'}
library(OpenImageR)
knitr::include_graphics('images/osf6_col.png')
```


必要な情報をすべて指定した後、試験を登録することが可能である。これにより、一意のID（例：**osf.io/q2jp7**）でアクセス可能な登録項目が作成される。登録が完了した後は、検索計画、仮説、分析戦略を変更することはできない。

$$\tag*{$\blacksquare$}$$

<!--chapter:end:18-reporting-reproducibility-ja.Rmd-->

# 効果量の計算と換算  {#es-calc}

---

<img src="_figs/effect_size_calculation.jpg" />

<br></br>

\index{meta Package}

メタ分析が頻繁に直面する問題は、適切な「生の」効果量データが、含まれるすべての研究から抽出できるとは限らないことである。`metacont` (Chapter \@ref(pooling-smd)) や `metabin` (Chapter \@ref(pooling-or-rr)) などの  **{meta}** パッケージのほとんどの関数は、生の効果量データが完全に利用可能な場合にのみ使用することができる。 

実際には、これは困難につながることも多い。出版された論文の中には、特に古いものでは、必要な（生の）効果量データを抽出できるような方法で結果を報告していないものがある。$t$-検定、one-way ANOVA、$\chi^2$-検定 の結果は報告されていても、メタ分析に必要なグループごとの平均や標準偏差、研究条件におけるイベント数が報告されていないことはよくあることである。 

\index{esc Package}

幸いなことに、報告された情報を望ましい効果量フォーマットに**変換**できる場合がある。これにより、`metagen` を用いた**事前計算**データ（Chapter \@ref(pre-calculated-es)）によるメタ分析で、影響を受けた研究を含めることができるようになる。例えば、2標本の $t$-検定 の結果を標準化平均差 (SMD) とその標準誤差に変換し、`metagen` を用いて事前に計算された SMD のメタ分析を行うことができる。 **{esc}**  パッケージ [@esc] には、このような変換を _R_ 内で直接行うことができる便利な関数がいくつか用意されている。

<br></br>

## 平均値および標準誤差

---

\index{Mean, Arithmetic}
\index{Standardized Mean Difference}\index{標準化平均差}
\index{Hedges' \textit{g}}

平均と**標準誤差**から SMD や Hedges' $g$ を計算するとき、平均の標準偏差はサンプルサイズの平方根を「割り算」して標準誤差として定義されることを利用することができる [@thalheimer2002calculate]。

\begin{equation}
\text{SD} =\text{SE}\sqrt{n}
(\#eq:esc1)
\end{equation}

SMD や Hedges' $g$ は `esc_mean_se`関数を使って計算することができる。以下はその例である。

```{r}
library(esc)

esc_mean_se(grp1m = 8.5,   # group 1 の平均
            grp1se = 1.5,  # group 1 の標準誤差
            grp1n = 50,    # group 1 のサンプル
            grp2m = 11,    # group 2 の平均
            grp2se = 1.8,  # group 2 の標準誤差
            grp2n = 60,    # group 2 のサンプル
            es.type = "d") # SMD に変換; Hedges' g を使う場合は "g"
```

<br></br>

## 回帰係数

---

標準化または非標準化回帰係数から SMD、Hedges' $g$ または相関 $r$ を計算することができる [@lipsey2001practical]。標準化されていない係数に対しては、**{esc}** の `esc_B` 関数を使用することができる。以下はその例である。

\index{Correlation}\index{相関}\index{相関}

```{r}
library(esc)

esc_B(b = 3.3,       # 標準化されていない回帰係数
      sdy = 5,       # 予測変数 y の標準偏差
      grp1n = 100,   # group 1 のサンプルサイズ
      grp2n = 150,   # group 2 のサンプルサイズ
      es.type = "d") # SMD に変換; Hedges' g を使う場合は "g"
```

\vspace{2mm}

```{r, eval=F}
esc_B(b = 2.9,       # 標準化されていない回帰係数
      sdy = 4,       # 予測変数 y の標準偏差
      grp1n = 50,    # group 1 のサンプルサイズ
      grp2n = 50,    # group 2 のサンプルサイズ
      es.type = "r") # 相関係数に変換
```

```
## Effect Size Calculation for Meta Analysis
## 
##      Conversion: un標準化されていない回帰係数 
##                  to effect size correlation
##     Effect Size:   0.3611
##  Standard Error:   0.1031
##        Variance:   0.0106
##        Lower CI:   0.1743
##        Upper CI:   0.5229
##          Weight:  94.0238
##      Fisher's z:   0.3782
##       Lower CIz:   0.1761
##       Upper CIz:   0.5803
```

\vspace{2mm}

標準化された回帰係数は `esc_beta` を用いて変換することができる。

```{r}
esc_beta(beta = 0.32,   # 標準化されていない回帰係数
         sdy = 5,       # 予測変数 y の標準偏差
         grp1n = 100,   # group 1 のサンプルサイズ
         grp2n = 150,   # group 2 のサンプルサイズ
         es.type = "d") # SMD に変換; Hedges' g を使う場合は "g"
```

```{r, eval= F}
esc_beta(beta = 0.37,   # 標準化されていない回帰係数
         sdy = 4,       # standard deviation of predicted variable y
         grp1n = 50,    # group 1 のサンプルサイズ
         grp2n = 50,    # group 2 のサンプルサイズ
         es.type = "r") # 相関係数に変換
```

```
## Effect Size Calculation for Meta Analysis
## 
##      Conversion: 標準化されていない回帰係数 
##                  to effect size correlation
##     Effect Size:   0.3668
##  Standard Error:   0.1033
##        Variance:   0.0107
##        Lower CI:   0.1803
##        Upper CI:   0.5278
##          Weight:  93.7884
##      Fisher's z:   0.3847
##       Lower CIz:   0.1823
##       Upper CIz:   0.5871
```

<br></br>

## 相関関係  {#convert-corr}

---

\index{Correlation}\index{相関}\index{相関}
\index{Correlation, Point-Biserial}

**同じ**大きさの群（$n_1=n_2$）の場合、以下の式で**点-双列**相関から SMD を導き出すことができる [@lipsey2001practical, chapter 3]。

\begin{equation}
r_{pb} = \frac{\text{SMD}}{\sqrt{\text{SMD}^2+4}} ~~~~~~~~
\text{SMD}=\frac{2r_{pb}}{\sqrt{1-r^2_{pb}}} (\#eq:esc2)
\end{equation}

**不均等**な大きさの群には、別の数式を使用する必要がある [@aaron1998equating]。

\begin{align}
r_{pb} &= \frac{\text{SMD}}{\sqrt{\text{SMD}^2+\dfrac{(N^2-2N)}{n_1n_2}}} \notag \\
\text{SMD} &= \dfrac{r_{pb}}{\sqrt{(1-r^2)\left(\frac{n_1}{N}\times\left(1-\frac{n_1}{N}\right)\right)}} (\#eq:esc3)
\end{align}

 $r_{pb}$  を SMD や Hedges' $g$ に変換するには、  `esc_rpb` 関数を使用する。

```{r}
library(esc)

esc_rpb(r = 0.25,      # 点-双列相関
        grp1n = 99,    # group 1 のサンプルサイズ
        grp2n = 120,   # group 2 のサンプルサイズ
        es.type = "d") # SMD に変換; Hedges' g を使う場合は "g"
```

<br></br>

## 一元配置分散分析

---

\index{Analysis of Variance}\index{分散分析}

また、**2群**の一元配置 ANOVA の $F$-値から SMD を導き出すこともできる。そのような ANOVA は、**自由度**を見ることで識別できる。2群の一元配置ANOVAでは、自由度は常に1から始まるはずである（例： $F_{\text{1,147}}$ =5.31）。 

変換に使う式は次のようなものである [@rosnow1996computing; @rosnow2000contrasts; @thalheimer2002calculate を参照]。

\begin{equation}
\text{SMD} = \sqrt{  F\left(\frac{n_1+n_2}{n_1 n_2}\right)\left(\frac{n_1+n_2}{n_1+n_2-2}\right)}
(\#eq:esc4)
\end{equation}

 $F$-値 から SMD や Hedges' $g$  を計算するには、  `esc_f` 関数を使用する。以下はその例である。

```{r}
esc_f(f = 5.04,      # one-way anova の F-値
      grp1n = 519,   # group 1 のサンプルサイズ 
      grp2n = 528,   # group 2 のサンプルサイズ
      es.type = "g") # Hedges' g　に変換; SMD の場合は "d"
```

<br></br>

## 2標本の $t$ 検定

---

\index{Standardized Mean Difference}\index{標準化平均差}

標準化平均差として表現される効果量は、以下の式 [@rosnow2000contrasts; @thalheimer2002calculate] を用いて、**独立**2標本 $t$ -検定値からも導き出すことができる。

\begin{equation}
\text{SMD} = \frac {t(n_1+n_2)}{\sqrt{(n_1+n_2-2)(n_1n_2)}}
(\#eq:esc5)
\end{equation}

 _R_  では、`esc_t` 関数を使って $t$-値から SMD や Hedges' `g` を計算することができる。以下はその例である。

```{r}
esc_t(t = 3.3,     # t-値
      grp1n = 100, # group 1 のサンプルサイズ
      grp2n = 150, # group 2 のサンプルサイズ
      es.type="d") # SMD に変換; Hedges' g を使う場合は "g"
```

<br></br>

## $p$ 値

---

\index{P-Value}\index{P-値}

研究では、効果の大きさ（例えば、Cohen's $d$ 値）、その効果の $p$ -値のみを報告し、それ以上のことは報告しないことがある。しかし、メタ分析で結果をプールするためには、効果量の**精度**の指標、できれば標準誤差が必要である。

そのような場合、効果量の $p$ -値から標準誤差を推定しなければならない。これは、Altman and Bland [-@altman2011obtain] による公式を用いれば、**差分**（すなわち SMD）または**比**（すなわちリスク比またはオッズ比）に基づく効果量に対して可能である。これらの公式は、 _R_ の  `se.from.p`  関数で実装されている。 

\index{dmetar Package}

```{block, type='boxdmetar'}
**"se.from.p" 関数**

\vspace{4mm}

`se.from.p` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

1. 関数のソースコードに [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R) でアクセスする。 
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。
```


$N=$ 71人の参加者を持つ研究で、$d=$ 0.71 の効果量を報告していると仮定すると、$p=$ 0.013 のように標準誤差を計算することができる。

```{r, eval=F}
library(dmetar)

se.from.p(0.71,
          p = 0.013,
          N = 71,
          effect.size.type = "difference")
```

```
##   EffectSize StandardError StandardDeviation  LLCI  ULCI
## 1       0.71         0.286             2.410 0.149 1.270
```

\vspace{2mm}

$N=$ 200人の参加者が、OR=0.91、$p=$ 0.38の効果量を報告した研究については、標準誤差はこのように計算される。

```{r, message=F, warning=F, eval=F}
library(magrittr) # pipe を使う

se.from.p(0.91, p = 0.38, N = 200,
          effect.size.type = "ratio") %>% t()
```

```
##                        [,1]
## logEffectSize        -0.094
## logStandardError      0.105
## logStandardDeviation  1.498
## logLLCI              -0.302
## logULCI               0.113
## EffectSize            0.910
## LLCI                  0.739
## ULCI                  1.120
```

また、 `effect.size.type = "ratio"` の場合、自動的に **対数変換**効果量と標準誤差も計算する。これは、`metagen` 関数（Chapter \@ref(pre-calculated-es)） を使う際に必要なものである。

<br></br>

## $\chi^2$ 検定

---

\index{Odds Ratio}\index{オッズ比}

統計量 $\chi^2$ をオッズ比に変換するには、  `esc_chisq`  関数を使用する（d.f. = 1と仮定する；例： $\chi^2_1$  = 8.7 ）。以下はその例である。

```{r}
esc_chisq(chisq = 7.9,        # カイ二乗値
          totaln = 100,       # 全体のサンプルサイズ
          es.type = "cox.or") # オッズ比へ変換
```

<br></br>

## 治療必要例数  {#nnt}

---

\index{Number Needed To Treat}\index{治療必要例数}

Cohen's $d$ や Hedges' $g$ のような効果量は、実用的な観点からは解釈が難しいことが多い。メタ分析で介入効果が $g=$  0.35 であることを発見したとする。このような効果が何を意味するのか、患者、公務員、医療関係者、その他の利害関係者にどのように伝えればよいのだろうか。 

また、他の人が結果を理解しやすいように、メタ分析ではしばしば**治療必要例数** (Number Needed to Treat, NNT) を報告している。この指標は、医学研究において最も一般的に使用されている。これは、1つの**ネガティブな事象**（例：再発）を**予防**するため、あるいは1つの**ポジティブ**な事象（例：症状の寛解、反応）を**達成**するために、研究対象の治療を何人の患者が追加で受けなければならないかを意味する。例えば、NNT = 3 の場合、研究課題に応じて、追加で1件の再発を回避するために3人が治療を受けなければならない、あるいは、確実に1件の症状寛解を達成するために3人の患者が治療を受けなければならないと言うことができる。

二値効果量データを扱う場合、NNT の算出は比較的容易である。式は次のようになる。

\begin{equation}
\text{NNT} = (p_{e_{\text{treat}}}-p_{e_{\text{control}}})^{-1}
(\#eq:esc6)
\end{equation}

この式で、$p_{e_{\text{treat}}}$  と $p_{e_{\text{control}}}$  は、それぞれ治療群と対照群でイベントを経験した参加者の割合である。これらの割合は、リスク比（Chapter \@ref(rr)  ）を計算するのに使われる「リスク」と同じで、**実験群イベント率**（experimental group event rate, EER）および**対照群イベント率**（control group event rate, CER）としても知られている。この式から、NTT は（絶対）リスク差の逆数と表現することもできる。

標準化平均差または Hedges' $g$ を NNT に変換するのはより複雑である。よく使われる方法は2つある。

\index{Area Under The Curve (AUC)}\index{曲線下面積}

* 治療群の患者が対照群の患者より好ましいアウトカムを得る確率として定義される**曲線下面積**（area under the curve, AUC）から NNT を計算する **Kraemer and Kupfer** [-@kraemer2006size] による方法である。この方法は、余分な情報がなくても SMD または $g$ から直接 NNT を計算することができる。

* **Furukawa and Leucht** の方法は、CER またはその合理的な推定値を用いて SMD から NNT 値を計算するものである。古川氏の方法は、Kraemer &amp; Kupfer 法 [@furukawa2011obtain] と比較して、真の NNT 値を推定するのに優れていることが示されている。したがって、CER を合理的に推定できるのであれば、常に Furukawa 式が優先されるべきである。 

効果量としてリスク比やオッズ比を使用する場合、NNT は `nnt` 関数を使用して **{meta}** オブジェクトから直接計算することができる。`metabin` （Chapter \@ref(pooling-or-rr)）を使ってメタ分析を行った後、その結果を `nnt` 関数に代入するだけである。以下はその例である。

```{r}
library(meta)
data(Olkin1995)

# 二値効果量データを使ってメタ分析を実行
m.b <- metabin(ev.exp, n.exp, ev.cont, n.cont, 
               data = Olkin1995,
               sm = "RR")
nnt(m.b)
```

\vspace{2mm}

`nnt` 関数は、異なる CER を仮定した場合の治療に必要な数を提供する。結果の3行は、このデータセットにおける最小、平均、最大の CER の結果を示している。CER の平均値が、通常報告される「典型的な」NNT である。 

また、要約指標 `sm` が `"RR"` または `"OR"` であれば、`nnt` を `metagen` モデルで使用することも可能である。このようなモデルでは、`nnt` の `p.c` 引数で想定される CER を指定する必要がある。以下は、Chapter \@ref(m-gen-bin)  で作成した `m.gen_bin`  メタ分析オブジェクトを使用した例である。

```{r, echo=F}
load("data/m.gen_bin.rda")
m.gen_bin$print.subgroup.name = FALSE

```


```{r}
# 固定効果も出るの結果も示す
m.gen_bin <- update.meta(m.gen_bin, 
                         fixed = TRUE)

nnt(m.gen_bin, 
    p.c = 0.1) # CER 0.1 を使用
```

\vspace{4mm}

\index{dmetar Package}

標準化平均差または Hedges' $g$  は、 **{dmetar}** の  `NNT`  関数を使用して NNT に変換することができる。

```{block, type='boxdmetar'}
**"NNT" 関数**

\vspace{4mm}

もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

\vspace{2mm}

1. 関数のソースコードに [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R) でアクセスする。
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。

```


Kraemer &amp; Kupfer 法を使うには、 `NNT` 関数に効果量（SMD または $g$  ）を与えるだけでよい。Furukawa 法は、`CER` の値が与えられるとすぐに自動的に使用される。

```{r}
NNT(d = 0.245)

NNT(d = 0.245, CER = 0.35)
```


```{block, type='boximportant'}
**注意して扱うべき数字: NNT への批判**

\vspace{2mm}

一般的ではあるが、臨床試験の結果を伝えるために NNT を使用することは議論の余地がないわけではない。批判としては、一般人がしばしば誤解すること（他の効果量の指標に代わる「直感的な」指標とされているにもかかわらず @christensen2006number）、研究者がよく NNT を不正確に計算すること [@mendes2017number] が挙げられる。

\vspace{2mm}

さらに、NNT の信頼できる標準誤差（および信頼区間）を計算することはできないので、メタアナリシスでは使用できないことになる [@hutton2010misleading]。別の効果量指標を用いてプールを行った後に初めて、結果を NNT に変換することが可能である。

```

<br></br>

## マルチアーム研究  {#pool-groups}

---

\index{Unit-of-Analysis Problem}\index{分析単位問題}

解析単位誤差（Chapter \@ref(unit-of-analysis)）を避けるために、（標準化）平均差を計算する前に、2つ以上の試験群の平均と標準偏差をプールする必要がある場合がある。2群の連続効果量データをプールするには、以下の式を用いることができる。

\begin{align}
n_{\text{pooled}} &= n_1 + n_2  \\
m_{\text{pooled}} &= \frac{n_1m_1+n_2m_2}{n_1+n_2} \\
SD_{\text{pooled}} &= \sqrt{\frac{(n_1-1)SD^{2}_{1}+ (n_2-1)SD^{2}_{2}+\frac{n_1n_2}{n_1+n_2}(m^{2}_1+m^{2}_2-2m_1m_2)} {n_1+n_2-1}}
\end{align}

この式を _R_ で適用するには、 `pool.groups` 関数を使用する。

```{block, type='boxdmetar'}
**"pool.groups" 関数**

\vspace{4mm}

`pool.groups` 関数は、**{dmetar}** パッケージに含まれている。**{dmetar}** がインストールされ、コンピュータに読み込まれると、この関数を使用できるようになる。もし、**{dmetar}** をインストールして**いない**場合は、以下の手順でインストールできる。

1. 関数のソースコードに [オンライン](https://raw.githubusercontent.com/MathiasHarrer/dmetar/master/R/power.analysis.subgroup.R) でアクセスする。
2. ソースコード全体をコンソール（R Studio の左下ペイン）にコピー＆ペーストし、Enterキーを押して、 _R_ に関数を「学習」させる。

```


以下はその一例である。

```{r}
library(dmetar)

pool.groups(n1 = 50,   # group 1 サンプルサイズ
            n2 = 50,   # group 2 サンプルサイズ
            m1 = 3.5,  # group 1 平均
            m2 = 4,    # group 2 平均
            sd1 = 3,   # group 1 標準偏差
            sd2 = 3.8) # group 2 標準偏差
```


<br></br>

## 効果量の集約  {#aggregate-es}

---

 **{metafor}** の  `aggregate`  関数を使うと、例えば、同じ研究やクラスターの一部であるという理由で、いくつかの従属する **事前に計算された効果量** を一つの推定値に集約することが可能である。これは、**unit-of-analysis error** （ Chapter \@ref(unit-of-analysis)  参照）を回避する方法であるが、研究内相関の値を仮定する必要があり、これは通常未知である。効果量依存性を扱うもう一つの（そしてしばしば望ましい）方法は、（相関）階層モデルで、これは Chapter \@ref(multilevel-ma)  で説明されている。 

この例では、 `Chernobyl` データセット（Chapter \@ref(multilevel-R)  参照）の効果量を集約し、各研究が1つの効果量のみを提供するようにする。

```{r, eval=F}
library(metafor)
library(dmetar)
data("Chernobyl")

# 'Chernobyl' データを 'escalc' オブジェクトに変換
Chernobyl <- escalc(yi = z,           # 効果量
                    sei = se.z,       # 標準誤差
                    data = Chernobyl)

# 研究レベルで効果量を集約
# 相関 rho=0.6 を仮定
Chernobyl.agg <- aggregate(Chernobyl, 
                           cluster = author,
                           rho = 0.6)

# 集約結果を表示
Chernobyl.agg[,c("author", "yi", "vi")]

```

```
##                       author     yi     vi 
## 1 Aghajanyan & Suskov (2009) 0.2415 0.0079 
## 2     Alexanin et al. (2010) 1.3659 0.0012 
## 3             Bochkov (1993) 0.2081 0.0014 
## 4      Dubrova et al. (1996) 0.3068 0.0132 
## 5      Dubrova et al. (1997) 0.4453 0.0110
## [...]
```

なお、`aggregate` は集約された効果量 `yi` とその**分散** (variance) `vi`  （標準誤差の平方根）を返す。


$$\tag*{$\blacksquare$}$$



<!--chapter:end:19-effect-size-calculation-ja.Rmd-->

# (APPENDIX) 付録  {-}

<br></br>

# Q&amp;A  {#qanda}

---


## Chapter 1: はじめに  {#qanda1}

---

**1. メタ分析はどのように定義することができるか？メタ分析と他の文献レビューの違いは何か？**

メタ分析は、**分析の分析**と定義することができる（Glassによる定義）。他のタイプの（システマティック）レビューとは対照的に、メタ分析は、定量的な方法でエビデンスを統合することを目的としている。通常、その目的は、明確に区分された研究分野**全体**を記述する数値的な推定値を導き出すことである。

**2. メタ分析の生みの親、生みの親を一人挙げることができるか？その人物はどのような功績を残したか？**

Karl Pearson：大英帝国全体の腸チフス接種データの組み合わせ; Ronald Fisher：農業調査研究のデータを統合するアプローチ; Mary Smith and Gene Glass：「メタ分析」という言葉を作り、心理療法試験の最初のメタ分析; John Hunter and Frank Schmidt：測定アーチファクトを補正したメタ分析（心理測定メタ分析）; Rebecca DerSimonian and Nan Laird：ランダム効果モデルのメタ分析計算法; Peter Elwood and Archie Cochrane：医学におけるメタ分析のパイオニア的存在である。

**3. メタ分析のよくある問題点を3つ挙げ、1～2文で説明しなさい。**

"リンゴとオレンジ"：研究が違いすぎて合成できない、"Garbage In, Garbage Out"：無効なエビデンスがメタ分析で再現されるだけ、"ファイルの引き出し"：ネガティブな結果は公表されず、メタ分析に偏った結果が出る、"研究者のアジェンダ"：研究者は証明したいことを証明するためにメタ分析をいじることができる、などである。

**4. メタ分析のための良いリサーチクエスチョンを定義する資質を挙げなさい。**

FINER：実現可能、興味深い、新規、倫理的、関連性；PICO：明確に定義された集団、介入／曝露、対照群／比較、分析されたアウトカム。

**5. 大学生の睡眠介入に関するメタ分析の適格基準をもう一度見てみよう（Chapter 1.4.1 の終わり）。この研究の適格基準、除外基準から PICO を抽出できるか。**

対象：高等教育機関学生；介入：睡眠焦点型心理学的介入；比較：受動的対照条件；アウトカム：睡眠障害、標準化症状測定による。

**6. 研究を検索するために使用できるいくつかの重要なソースを挙げなさい。**

総説、研究中の参考文献、「フォワードサーチ」（関連論文を引用した研究の検索）、関連雑誌の検索、書誌データベース検索。 

**7. 「研究の質」と「バイアスのリスク」の違いを1～2文で説明しなさい。**

研究分野において重要とされる研究品質基準をすべて満たしていても、バイアスのリスクが高い場合がある（この種の研究または研究テーマではバイアスの回避が困難なためなど）。

<br></br>

## Chapter 2: Rの発見  {#qanda2}

---

**1. 変数 `Author` を表示しなさい。**

```{r, eval=F}
data$Author
```

**2. `subgroup` を因子型 (factor) に変換しなさい。**

```{r, eval=F}
data$subgroup <- as.factor(data$subgroup)
```

**3. "Jones" と "Martin" の研究のデータをすべて選択しなさい。**

```{r, eval=F}
library(tidyverse)
data %>%
    filter(Author %in% c("Jones", "Martin"))
```

**4. 研究名 "Rose" を "Bloom" に変更しなさい。**

```{r, eval=F}
data[5,1] <- "Bloom"
```

**5. `TE` から `seTE` を引いて、新しい変数 `TE_seTE_diff` を作成し、結果を `data` に保存しなさい。**

```{r, eval=F}
TE_seTE_diff <- data$TE - data$seTE
```

**6. パイプを使用して、(1) `subgroup` が"one" または "two" に属するすべての研究をフィルタし、(2) 変数 `TE_seTE_diff` を選択し、(3) その変数の平均をとり、それに `exp` 関数を適用しなさい。**

```{r, eval=F}
data %>%
    deplyr::filter(subgroup %in% c("one", "two")) %>%
    pull(TE_seTE_diff) %>%
    mean() %>%
    exp()
```

<br></br>

## Chapter 3: 効果の大きさ  {#qanda3}

---

**1. 効果量という言葉に明確な定義はあるか？人々は、効果量という言葉で何を指すか？**

いいえ、普遍的に受け入れられる定義はない。ある人は、介入群と対照群の間の差に対して「効果量」という言葉を留保している。また、より自由な定義を使用し、「1変数」の測定値（例えば、平均値や割合）のみを除外する者もいる。 

**2. 観測された効果量が母集団の真の効果量から乖離する主な理由を挙げなさい。それはどのように定量化できるのか。**

観察された効果量は、サンプル誤差のために真の効果量から乖離することが想定されている。研究のサンプル・エラーの予想サイズは、その標準誤差で表すことができる。

**3. なぜ大規模な研究は小規模な研究よりも真の効果の推定に優れているのか？**

なぜなら、サンプリング誤差が小さく、より正確な効果推定ができると想定されることがあるからである。

**4. 効果量の指標は、どのような基準を満たせばメタ分析に使えるのか？**

比較可能で、計算可能で、信頼性があり、解釈可能である必要がある。

**5. 標準化平均差 (Standardized Mean Difference, SMD) が1であることは何を表しているのか？**

2群の平均値がプール標準偏差の1だけ異なることを表している。

**6. 比（オッズ比など）に基づく効果量をプールするためには、どのような変換が必要か。**

効果量は対数変換する必要がある（逆変量プール法を使用するため）。

**7. 効果量補正の種類を3つ挙げよ。**

標準化平均差のスモールサンプルバイアス補正（Hedges' $g$）、信頼性の低さに関する補正、範囲制限に関する補正。

**8. 分析単位の問題はどのような場合に発生するか？どうすれば回避できるか？**

データセット内の効果量に相関がある場合（例えば、同じ研究の一部であるため）。分析単位の問題は、(1)共有グループのサンプルサイズを分割する、(2)比較を取り除く、(3)グループを組み合わせる、(4)効果量の依存性を考慮したモデル（例：３レベルモデル）を使用する、などによって（一部または全部）回避することができる。

<br></br>

## Chapter 4: 効果量のプール  {#qanda4}

---

**1. 固定効果モデルとランダム効果モデルの違いは何か？**

固定効果モデルは、すべての研究が同じ真の効果量の推定者であると仮定している。ランダム効果モデルは、研究間の異質性（分散 $\tau^2$  ）によって、研究の真の効果量が変化すると仮定し、それを推定する必要がある。

**2. 固定効果モデルとランダム効果モデルの結果が同じになるケースは考えられるか。**

研究間異質性分散 $\tau^2$  がゼロの場合。

**3. $\tau^2$  とは何か？どのように推定するのか？**

研究間の異質性分散。制限付き最尤法（REML）、Paule-Mandel推定量、DerSimonian-Laird推定量など、さまざまな方法を用いて推定することができる。

**4. Knapp-Hartung の調整はどの分布に基づいているか？どのような効果があるか？**

この調整は $t$-分布に基づくものである。Knapp-Hartung の調整は、通常、より保守的な（すなわち、より広い）信頼区間をもたらす。 

**5. 「逆分散」 (inverse-variance) プーリングとはどういう意味か？この方法が最適解でないのはどのような場合か？**

この方法は、研究の分散の逆数をプーリングの重みとして使用するため、逆分散プーリングと呼ばれる。一般的な逆分散法は、二値アウトカム・データ（例えば、リスクやオッズ比）のメタ分析には好まれない。

**6. 二値アウトカムデータをメタ分析したい。試験群の観察数はほぼ同じで、観察された事象は非常にまれで、治療効果が大きくなることは期待できない。どのようなプール方法を使用するか？**

このような場合、Peto 法がうまく機能する可能性がある。

**7. GLMM はどのようなアウトカム指標に使用できるのか。**

割合(Proportions)。他の二値アウトカム指標に使用することも可能であるが、一般的には推奨されていない。 

<br></br>

## Chapter 5: 研究間異質性  {#qanda5}

---

**1. なぜメタ分析の研究間異質性を調べることが重要なのか。**

研究間の異質性が大きい場合、真の効果の大きさはかなり異なることが想定される。この場合、平均的な真の効果の点推定値は、データを全体的によく表していない可能性がある。また、研究間の異質性は、例えば、少数の外れた研究が全体の結果を歪めてしまうため、効果推定値が頑健でなくなる可能性がある。

**2. 異質性の2つのタイプを挙げられるか？メタ分析の計算にはどちらが関係するか？**

ベースライン/デザインに関連した異質性と統計的異質性。メタ分析では統計的異質性のみが定量的に評価される。

**3. Cochran's $Q$ の**有意性**が、研究間異質性の十分な指標とならないのはなぜか。**

$Q$ 検定の有意性は、メタ分析に含まれる研究数とその規模に大きく依存することがある。

**4. メタ分析で異質性の大きさを表現するために予測区間を使うメリットは何か。**

予測区間は、要約尺度と同じ尺度で、研究間の異質性が将来の研究に与える影響を表現することができる。

**5. 統計的外れ値と影響力のある研究の違いは何か？**

統計的外れ値とは、効果量が**極端**な研究のことである。研究は、全体の結果に対する影響が大きい場合、影響力がある。ある研究があまり影響力がなくても統計的外れ値として定義されることがあり、またその逆もありえる。例えば、大規模な研究は、その効果量が特に小さくもなく大きくもないのに、プール結果に大きな影響を与えることがある。

**6. GOSH のプロットは何に使えるのか。**

GOSH プロットは、データにおける異質性のパターンや、どの研究がそれに寄与しているかを調べるために使用することができる。

<br></br>

## Chapter 6: フォレストプロット  {#qanda6}

---

**1. フォレストプロットの主要な構成要素は何か？**

各研究の観察された効果量と信頼区間、観察された効果量を囲む四角の大きさで表される各研究の重み、各研究の観察された効果量と重みの数値、菱形で表されるプール効果、通常は効果なしを表す参照線などのグラフィカル表示。

**2. メタ分析でフォレストプロットを提示するメリットは何か？

これにより、含まれるすべての研究の数、効果量、精度、および観察された効果がどのようにプールされた効果に「加算」されるかを迅速に調べることができる。

**3. フォレストプロットの限界は何か、Drapery プロットはこの限界をどのように克服しているのか。**

フォレストプロットは、固定された有意閾値（通常、$\alpha$  = 0.05）を仮定した効果の信頼区間を示すことができるだけである。Drapery プロットは、$p$ -値を変化させた場合の効果量の信頼区間（したがって有意性）を表示すために使用できる。

<br></br>

## Chapter 7: サブグループ解析  {#qanda7}

---

**1. 影響度分析や異常値分析ではわからないことのうち、何がサブグループ解析ではわかることがあるか？**

サブグループ解析は、データにある異質性のパターンが存在することを教えてくれるだけでなく、なぜ存在するのかを説明できる可能性がある。

**2. サブグループ解析の背景にあるモデルが、なぜ固定効果（複数）モデルと呼ばれるのか。**

なぜなら、サブグループ内の研究はランダム効果モデルに従うが、サブグループのレベル自体は固定されていると仮定しているからである。固定サブグループ効果はいくつかある。

**3. メタ分析の一環として、ある教育研修プログラムの効果が、実施された学区によって異なるかどうかを調べたいと考えている。この問いに答えるために、固定効果（複数）モデルを用いたサブグループ解析は適切か？**

おそらく、そうではないだろう。学区は、すべての学区ではなく、より多くの学区から選ばれたものであると考える方が理にかなっている。 

**4. あなたの友人が、合計9つの研究を含むメタ分析を行った。これらの研究のうち5つが1つのサブグループに分類され、4つが他のサブグループに分類されている。彼女は、サブグループ解析を行うことに意味があるかどうかをあなたに尋ねている。あなたならどうするか？**

研究数の合計が10より少ないので、サブグループ解析を行うのは得策ではないだろう。

**5. メタ分析で、分析した治療法が男性よりも女性でより効果的であると著者が主張しているものがあった。この知見は、研究対象者に含まれる女性の割合に基づいて研究をサブグループに分けたサブグループ解析に基づいている。この知見は信頼できるか、またその理由は？**

この所見は、集計された研究データを用いて作成されたサブグループ変数に基づくものである。これは生態学的なバイアスをもたらす可能性があり、その結果には疑問が残る。

<br></br>

## Chapter 8: メタ回帰  {#qanda8}

---

**1. 一次研究で用いられる従来の回帰分析と、メタ回帰の違いは何か？**

分析の単位は（人ではなく）研究であり、その効果量はだいたい正確である。メタ回帰では、ある研究が他の研究よりも大きなウェイトを持つという事実を考慮した回帰モデルを構築しなければならない。

**2. サブグループ解析とメタ回帰は密接な関係がある。メタ回帰の公式をどのようにサブグループデータに適応させることができるか。**

ダミー／カテゴリー予測変数の使用による。

**3. メタ回帰において、個々の研究に異なる重みを与えるためにどのような方法が用いられるか？**

メタ回帰では、**加重最小二乗法**を用いて、精度の高い研究をより重要視している。

**4. データによく適合するメタ回帰モデルにはどのような特徴があるか？これを調べるには、どのような指標を用いればよいか？**

「良い」メタ回帰モデルは、説明されない研究間異質性分散の量を大きく減少させるはずである。この説明される分散の増加をカバーする指数が、$R^2$ のアナログである。

**5. メタ分析の手法でサブグループ解析を計算する場合、$\tau^2$  の値をサブグループで別々にするか、共通にするか。**

サブグループで共通の推定値 $\tau^2$ を想定している。

**6. （多重）メタ回帰の限界と落とし穴は何か。**

メタ回帰の過剰適合は偽陽性の結果につながり、多重共線性はロバストでないパラメータ推定値につながる可能性がある。

**7. （複数の）メタ回帰モデルの頑健性を向上させるために利用できる方法を2つ挙げ、それが有用である理由を述べよ。**

並べ替え検定を行うか、マルチモデル推論を利用することができる。

<br></br>

## Chapter 9：出版バイアス  {#qanda9}

---

**1. 「出版バイアス」という言葉はどのように定義できるか？なぜメタ分析で問題になるのか？**

出版バイアスは、ある研究が出版される確率がその結果に依存する場合に存在した。これは、メタ分析において偏った結果を導き出す可能性があるため、問題となる。すべてのエビデンスが考慮されているわけではないので、メタ分析では、既存のすべての情報を考慮したときには現れなかったであろう結果が得られることがある。

**2. 他にどのような報告バイアスがあるか？少なくとも3つ挙げて説明しなさい。**

引用バイアス：ネガティブな知見を持つ研究は引用されにくい、タイムラグバイアス：ネガティブな知見を持つ研究は後に出版される、多重出版バイアス：ポジティブな知見を持つ研究は複数の論文で報告されやすい、言語バイアス：英語で出版されていないため証拠が省略されることがある、結果報告バイアス：研究結果がポジティブであればネガティブよりも多く報告される傾向がある。

**3. 疑わしい研究慣行（QRP）を2つ挙げ、どのようにメタ分析の妥当性を脅かすかを説明しなさい。**

P-hacking、HARKing。どちらも、真の効果がないにもかかわらず、肯定的な知見を膨らませることにつながる。

**4. 小規模研究効果法の基本的な前提を説明しなさい。**

大規模な研究（すなわち標準誤差が小さい研究）は、その結果がどうであれ、出版される可能性が非常に高い。小規模な研究は精度が小さいので、統計的有意性を得るためには非常に高い効果量が必要となる。したがって、非常に高い効果を持つ小規模な研究だけが出版され、それ以外は「ファイルの引き出し」に入ったままになってしまうのである。

**5. データが小規模研究の効果を示すことがわかったとき、自動的に出版バイアスがあることを意味するか？**

研究間の異質性、共変量の影響（例えば、小規模な研究ほど治療の忠実度が高い）、偶然性など、小規模な研究の効果を見つける理由は他にもいくつかある。 

**6. p-曲線は、メタ分析に含まれるすべての研究の真の効果を推定するのか、それとも「有意な」効果量を持つすべての研究の真の効果だけを推定するのか、どちらか？**

P曲線は、すべての有意な効果量の真の効果を推定するだけである。これは、研究間の異質性がある場合にうまく機能しない理由の一つである。

**7. どの出版バイアス法が一番性能が良いか。**

出版バイアス方法は、一貫して他のすべての方法より優れているものはない。したがって、いくつかの方法を適用して、その結果が一致するかどうかを確認することは有用である。

<br></br>

## Chapter 10:「マルチレベルメタ分析  {#qanda10}

---

**1. なぜ「マルチレベル」モデルではなく「３レベル」モデルと言う方が正確なのか？**

なぜなら、「従来の」ランダム効果モデルは、すでにマルチレベルモデルであることがある。参加者が研究内にネストされており、研究自体が真の効果量の母集団から引き出されていることを仮定している。 

**2. ３レベルメタ分析モデルはいつ有用か？**

相関のあるデータやネストされたデータを扱う場合。３レベルモデルは、研究が複数の効果量に寄与している場合や、研究自体がより大きなクラスターに分類されると信じるに足る理由がある場合に特に有用である。

**3. 効果量依存性の一般的な原因を2つ挙げなさい。**

一次研究に携わった研究者が引き起こした依存、メタ分析者自身が作り出した依存。

**4. マルチレベル $I^2$ の統計量はどのように解釈すればよいか。**

これは、サンプル誤差に起因しない分散の量を示し、クラスタ内の異質性分散とクラスタ間の異質性分散を区別するものである。

**5. モデレータ変数の効果を取り入れるために、どのように３レベルモデルを拡張することができるのか？**

モデル式に固定効果項を積算することで

<br></br>

## Chapter 11: 構造方程式モデリングメタ分析  {#qanda11}

---

**1. 構造方程式モデリングとは何か、何のために使うのか。**

構造方程式モデリングは、顕在変数と潜在変数の間に想定される関係を検証するために用いることができる統計手法である。

**2. SEM の表現方法として、どのようなものがあるか？**

SEM はグラフやマトリックスで表現することができる。 

**3. ランダム効果メタ分析を SEM の観点から説明しなさい。**

SEMの観点からは、ランダム効果メタ分析における真の全体効果量は、潜在変数と見なすことができる。それは、レベル1のサンプル誤差とレベル2の真の効果量の異質性分散という2つのアームによって "影響 "される。

**4. 多変量メタ分析とは何か、どのような場合に有用か。**

多変量メタ分析では、2つ（またはそれ以上）の研究のアウトカムを同時にプールすることができる。2つのアウトカム変数を共同で推定することの利点は、アウトカム間の相関を考慮することができることである。 

**5. 提案したメタ分析 SEM がデータによく適合することがわかったとき、このモデルが自動的に「正しい」モデルであることを意味するのだろうか。**

いいえ、データによく合うモデルは1つだけではないことが多い。 

<br></br>

## Chapter 12: ネットワークメタ分析  {#qanda12}

---

**1. ネットワークメタ分析はどんな時に有用か？標準的なメタ分析と比較して、どのような利点があるか？**

ネットワークメタ分析は、ある問題領域に対して複数の競合する治療法があり、どの治療法が最も効果が大きいかを推定したい場合に有効である。従来のメタ分析とは対照的に、ネットワーク・メタ分析モデルは、直接および間接のエビデンスを統合することができる。

**2. 治療ネットワークにおける直接エビデンスと間接エビデンスの違いは何か？間接エビデンスの生成に直接エビデンスをどのように利用できるのか？**

直接エビデンスとは、対象となる研究で実際に調査された比較によって提供される情報である。間接エビデンスは、ある（直接観察された）比較の効果を、関連する比較（例えば、同じ対照群を用いた比較）の効果から差し引くことによって、直接エビデンスから導き出されるものである。 

**3. ネットワークメタ分析における推移性 (transitivity) の仮定の主な考え方は何か？**

推移性の仮定は、直接証拠が観察されない間接証拠を推論するために使用できること、および直接証拠と間接証拠は一致することを規定している。

**4. 推移性 (transivity) と一貫性 (consistency) の関係は？**

推移性は、ネットワークメタ分析を行うための前提条件であり、直接的に検証することはできない。推移性統計的な現れ方は一貫性であり、直接エビデンスに基づく効果量の推定値が間接エビデンスに基づく推定値と同一または類似している場合に満たされる。

**5. ネットワークメタ分析に使用できる2つのモデリングアプローチを挙げなさい。どちらか一方が優れているか？**

ネットワークメタ分析は、頻度論的モデルまたはベイズモデルを用いて実施することができる。どちらのモデルも同等で、サンプルサイズが大きくなるにつれて収束する結果が得られる。

**6. 1つの試験から複数の比較を含める場合（マルチアーム試験など）、どのような問題が発生するか？**

つまり、効果推定値に相関があり、解析単位に誤差が生じる。

**7. 異なる治療法の P-スコアまたは SUCRA スコアを解釈する際、どのような点に注意しなければならないか？**

異なる治療法の効果推定値が重なることが多いこと。つまり、P-/SUCRAスコアは常に慎重に解釈されるべきものである。 

<br></br>

## Chapter 13: ベイズメタ分析  {#qanda13}

---

**1. 「従来の」ランダム効果モデルとベイズ型階層モデルの相違点と類似点は何か？**

頻度論的メタ分析の基礎となるランダム効果モデルは、概念的にはベイズ階層モデルと同じである。主な違いは、ベイズ型階層モデルは、全体の真の効果量 $\mu$  と研究間の異質性 $\tau$  に対する（弱い情報量の）事前分布を含むということである。

**2. ベイズメタ分析の頻度論的な利点と比較した場合の利点を3つ挙げよ。**

 $\tau^2$  の推定値の不確実性を直接モデル化する。$\mu$ の事後分布を作成し、$\mu$  がある値以下になる確率を計算するために使用できる。事前知識や信念をモデルに統合することができる。

**3. 弱情報的事前分布と非情報的事前分布の違いを説明しなさい。**

非情報的プライヤは、すべて、あるいはある範囲の可能な値が等しくあり得ると仮定する。弱情報的プライヤは、ある値が他の値よりも確率が高いという**弱い**信念を表している。 

**4. Half-Cauchy 分布とは何か、なぜベイズメタ分析に有用なのか。**

Half-Cauchy 分布は、正の値に対してのみ定義されるコーシー分布である。これは、位置とスケーリング・パラメータによって制御され、後者は分布の尾がどの程度重いかを決定する。Half-Cauchy 分布は、$\tau$  の事前分布として使うことができる。

**5. ECDF とは何か、ベイズメタ分析にどう使えるか？**

ECDF とは、**経験的累積分布関数**の略である。$\mu$（または $\tau$）の事後分布に基づく ECDF は、推定されたパラメータがある指定された閾値より下または上にある（累積）確率を決定するために使用されることができる。 



<br></br>

# 効果量の計算式  {#formula}

---



\renewcommand{\arraystretch}{2}
```{r esformula, echo=F, message=F, fig.align='center'}
library(kableExtra)
library(openxlsx)

dat = read.xlsx("data/estable2.xlsx")

colnames(dat) = c(" ", "Effect Size ($\\hat\\theta$)",
                  "Standard Error (SE)", "Function")
dat[1][is.na(dat[1])] = " "
dat[2][is.na(dat[2])] = " "
dat[3][is.na(dat[3])] = " "
dat[4][is.na(dat[4])] = " "
dat[1][dat[1] == "XXX"] = " "

#dat[5,2] = cell_spec(dat[5,2], "latex", font_size = 6, escape = FALSE) # cor2
dat[6,2] = cell_spec(dat[6,2], "latex", font_size = 4, escape = FALSE)    # pb
dat[7,3] = cell_spec(dat[7,3], "latex", font_size = 6, escape = FALSE) # between md
dat[8,3] = cell_spec(dat[8,3], "latex", font_size = 6, escape = FALSE) # between smd
dat[9,3] = cell_spec(dat[9,3], "latex", font_size = 6, escape = FALSE) # within md
dat[10,2] = cell_spec(dat[10,2], "latex", font_size = 6, escape = FALSE) # within smd
dat[10,3] = cell_spec(dat[10,3], "latex", font_size = 6, escape = FALSE) # within smd
dat[11,3] = cell_spec(dat[11,3], "latex", font_size = 6, escape = FALSE) # rr 1
dat[26,2] = cell_spec(dat[26,2], "latex", font_size = 6, escape = FALSE) # range 2
dat[27,2] = cell_spec(dat[27,2], "latex", font_size = 6, escape = FALSE) # range 3

dat[1,1] = "Arithmetic Mean (\\@ref(means))"
dat[c(2,3),1] = "Proportion (\\@ref(props))"
dat[4:5,1] = "Product-Moment Correlation (\\@ref(pearson-cors))"
dat[6,1] = "Point-Biserial Correlation<sup>1</sup> (\\@ref(pb-cors))"
dat[7,1] = "Between-Group Mean Difference (\\@ref(b-group-md))"
dat[8,1] = "Between-Group Standardized Mean Difference (\\@ref(b-group-smd))"
dat[9,1] = "Within-Group Mean Difference (\\@ref(w-group-smd))"
dat[10,1] = "Within-Group Standardized Mean Difference (\\@ref(w-group-smd))"
dat[11:14,1] = "Risk Ratio (\\@ref(rr))"
dat[15:18,1] = "Odds Ratio (\\@ref(or))"
dat[19:20,1] = "Incidence Rate Ratio (\\@ref(irr))"
dat[21,1] = "Small Sample Bias (\\@ref(hedges-g))"
dat[22:24,1] = "Unreliability (\\@ref(unrealiable))"
dat[25:27,1] = "Range Restriction (\\@ref(range))"

kableExtra::kable(dat, "html",
                  #longtable = TRUE,
                  escape = FALSE,
                  #booktabs = TRUE,
                  align = "lccl",
                  linesep = "") %>% 
  kable_classic(font_size = 12,
                html_font = "Roboto") %>% 
  #column_spec(1, width = "2cm") %>% 
  #column_spec(2, width = "3cm") %>% 
  #column_spec(3, width = "4cm") %>% 
  column_spec(4, monospace = T) %>% 
  collapse_rows(columns = 1, latex_hline = "none", valign = "top") %>% 
  pack_rows(" ", 1, 1, indent = FALSE) %>% 
  pack_rows(" ", 2, 3, indent = FALSE) %>% 
  pack_rows(" ", 4, 6, indent = FALSE) %>% 
  pack_rows(" ", 6, 6, indent = FALSE) %>% 
  pack_rows(" ", 8, 8, indent = FALSE) %>% 
  pack_rows(" ", 9, 9, indent = FALSE) %>% 
  pack_rows(" ", 10, 10, indent = FALSE) %>% 
  pack_rows(" ", 11, 15, indent = FALSE) %>% 
  pack_rows(" ", 15, 18, indent = FALSE) %>% 
  pack_rows(" ", 19, 20, indent = FALSE) %>% 
  pack_rows(" ", 21, 21, indent = FALSE) %>% 
  pack_rows(" ", 22, 24, indent = FALSE) %>% 
  pack_rows(" ", 25, 27, indent = FALSE) %>% 
  pack_rows("Correlation", 4, 6, indent = FALSE, 
            label_row_css = "background-color: #277DB0; color: #fff;") %>% 
  pack_rows("(Standardized) Mean Difference", 7, 10, hline_after = FALSE, indent = FALSE,
            label_row_css = "background-color: #277DB0; color: #fff;") %>% 
  pack_rows("Binary Outcome Effect Size", 11, 20, hline_after = FALSE, indent = FALSE,
            label_row_css = "background-color: #277DB0; color: #fff;") %>% 
  pack_rows("Effect Size Correction", 21, 27, hline_after = FALSE, indent = FALSE,
            label_row_css = "background-color: #277DB0; color: #fff;") %>% 
  footnote(number = c("Point-biserial correlations may be converted to SMDs for meta-analysis (see Chapter \\@ref(pb-cors))."),
           symbol = "The pooled standard deviation is defined as $s_{\\text{pooled}} = \\sqrt{\\dfrac{(n_1-1)s^2_1+(n_2-1)s^2_2}{(n_1-1)+(n_2-1)}}$.", 
           escape=FALSE) %>% 
  row_spec(0, background = "#277DB0", color = "#f5f5f5") %>% 
  row_spec(1, extra_css = "border-bottom: 1px solid") %>% 
  row_spec(2:3, background = "#f5f5f5") %>% 
  row_spec(6, extra_css = "border-top: 1px solid", background = "#f5f5f5") %>% 
  #row_spec(6, background = "#f5f5f5") %>% 
  row_spec(7, extra_css = "border-bottom: 1px solid") %>% 
  row_spec(8, background = "#f5f5f5", extra_css = "border-bottom: 1px solid") %>% 
  row_spec(9, extra_css = "border-bottom: 1px solid") %>% 
  row_spec(10, background = "#f5f5f5") %>% 
  row_spec(14, extra_css = "border-bottom: 1px solid") %>% 
  row_spec(15:18, background = "#f5f5f5") %>% 
  row_spec(19, extra_css = "border-top: 1px solid") %>% 
  row_spec(21, extra_css = "border-bottom: 1px solid") %>% 
  row_spec(22:24, background = "#f5f5f5") %>% 
  row_spec(25, extra_css = "border-top: 1px solid")

```



\renewcommand{arraystretch}{1}

<br></br>

# シンボルマーク一覧  {#symbollist}

---

```{r symbol, echo=F, message=F, fig.align='center', warning = F}
library(kableExtra)
library(openxlsx)

# dat = read.xlsx("data/symbols.xlsx")
dat = read.csv("data/symbols.csv")
dat = dat[2:5]

dat[14,4] = "Risk ratio, odds ratio, incidence rate ratio."

dat[2,3] = "$\\mathcal{HC}(x_0,s)$"
dat[11,3] = "$\\mathcal{N}(\\mu, \\sigma^2)$"

rbind(c("$~$", "$~$", "$~$", "$~$"), dat) -> dat

below = function(data, i){rbind(data[i,], c(" ", " ", " ", "$~$"))}
l = list()
for (i in 1:nrow(dat)){l[[i]] = below(dat, i)}
do.call(rbind, l) %>% as.data.frame() -> dat

rownames(dat) = 1:nrow(dat)

kableExtra::kable(dat, "html", 
                  col.names = NULL, booktabs = TRUE,
                  longtable = T,
                  escape = FALSE, 
                  linesep = "") %>% 
  kable_classic(font_size = 14,
                html_font = "Roboto", 
                bootstrap_options = c("striped")) %>% 
  column_spec(1, width = "1cm") %>% 
  column_spec(2, width = "4cm") %>% 
  column_spec(3, width = "1cm") %>% 
  column_spec(4, width = "4cm") 

```


**注記**: ベクトルや行列は**太字**で表記される。例えば、メタ分析で観測された全ての効果量をベクトルで表すと $\boldsymbol{\hat\theta} = (\hat\theta_1, \hat\theta_2, \dots, \hat\theta_K)^\top$ となる。ここで $K$ はそ総研究数である。$\top$ 記号はベクトルが **transposed** であることを表している。これは、ベクトルの要素が水平方向ではなく、垂直方向に配置されていることを意味する。これは、ベクトルと別の行列を掛け合わせるなどの操作を行う際に必要な場合がある。


<br></br>

#  _R_  &amp; パッケージ情報  {#attr}

---

<br></br>

本書は、macOS Catalina 10.15.4 (Apple Darwin 17.0 64-bit x86-64) で動作する  _R_  バージョン 4.0.3 ("Bunny-Wunnies Freak Out", 2020-10-10) を使ってコンパイルされている。本書では、以下のパッケージバージョンを使用している。（訳注: 翻訳は、macOS および Windows の _R_ 3.6 から 4.3 で検証した。）

\vspace{4mm}

```
brms 2.13.0                 clubSandwich 0.5.5
dmetar 0.0.9000             dplyr 1.0.1                 
esc 0.5.1                   extraDistr 1.9.1            
forcats 0.5.0               gemtc 0.8-6                 
ggplot2 3.3.2               ggridges 0.5.2              
glue 1.4.1                  igraph 1.2.5                
meta 5.0-0                  metafor 2.5-62              
metaSEM 1.2.5               metasens 0.5-0              
netmeta 2.0-0               openxlsx 4.1.5              
osfr 0.2.8                  PerformanceAnalytics 2.0.4  
rjags 4-10                  robvis 0.3.0                
semPlot 1.1.2               stringr 1.4.0               
tidybayes 2.1.1             tidyverse 1.3.0
wildmeta 0.1.0
```

\vspace{4mm}

付属のベースパッケージ

```
base 4.0.3        datasets 4.0.3    graphics 4.0.3      
grDevices 4.0.3   methods 4.0.3     stats 4.0.3
utils 4.0.3
```

\vspace{4mm}

ロケール:  `en_US.UTF-8` （訳注: 日本語は `ja_JP.UTF-8`）

\vspace{8mm}

<br></br>

** 属性**

Figure \@ref(fig:eysenck) :Sirswindon at [英語版ウィキペディア](https://commons.wikimedia.org/wiki/File:Hans.Eysenck.jpg), [CC BY-SA 3.0](https://creativecommons.org/licenses/by-sa/3.0)。Wikimedia Commons 経由。オリジナルから脱色している。 


<br></br>

# 訂正・備考  {#corrections}

---


```{block2, type='boxinfo'}
初版の印刷版に関する正誤表や備考を記載する。
```

最終更新日 `r format(Sys.time(), '%d %B, %Y')` である（訳注: 翻訳の更新日）。


## Chapter 4.2  {-}

最近、**{meta}** の新しいバージョン(バージョン5.0-0)がリリースされた。この章では、非推奨のメッセージを避けるために、それに応じてコードを適応させた。

- 引数 `comb.fixed` と `comb.random` は、それぞれ `fixed` と `random` と呼ばれるようになった。

- すべての研究を表示すには、 **{meta}** メタ分析オブジェクトの `summary`  メソッドを使用する必要がある。

## Chapter 7.3  {-}

最近、**{meta}** の新しいバージョン(バージョン5.0-0)がリリースされた。この章では、非推奨のメッセージを避けるために、それに応じてコードを適応させることとした。

- 引数 `byvar` は `subgroup` と呼ばれるようになった。

- すべての研究を表示すには、**{meta}** メタ分析オブジェクトの `summary` メソッドを使用する必要がある。

## Chapter 12.2.1  {-}

印刷版には、非正方形（長方形）行列におけるフルランクの定義に関する事実誤認がある。行がすべて独立でない行列はフルランクではない」と記載されている。しかし、これは正方行列と、行数が列数より少ない ($m < n$) 非正方行列にのみ適用される。この例では、行数が列数よりも多いので、$\boldsymbol{X}$ はフルランクではない。これは、その**列**がすべて独立していないためである（$m > n$ の行列では、行は常に線形従属）。この誤りはオンライン版で修正された。 

## Chapter 12.2.2  {-}

最近、**{netmeta}** の新しいバージョン(バージョン2.0-0)がリリースされた。この章では、エラーメッセージを避けるために、それに応じてコードを適応させた。

- 最新版の **{netmeta}** では、`rma.mv` に実装されている Fisher scoring algorithm が収束しない問題が発生していた。この問題は、2021年10月24日以前にインストールされたすべてのバージョンの **{dmetar}** に関連した。この問題を回避するには、最新バージョンの  **{dmetar}** を再インストールしよう (https://dmetar.protectlab.org/#installation)。




<br></br>








<!--chapter:end:90-appendix-ja.Rmd-->

# 本書の引用 {-}

---

<br></br>

本書を引用する際は、:

```{block, type='boxempty'}
**Harrer, M., Cuijpers, P., Furukawa, T.A., & Ebert, D.D.** (2021). _Doing Meta-Analysis with R: A Hands-On Guide_. Boca Raton, FL and London: Chapmann & Hall/CRC Press. ISBN 978-0-367-61007-4.
```

としていただきたい。参照情報は、 [BibTeX](https://www.protectlab.org/meta-analysis-in-r/data/citation.bib) または [.ris](https://www.protectlab.org/meta-analysis-in-r/data/citation.ris) でダウンロード可能。


<br></br>

<!--chapter:end:98-cite.Rmd-->

`r if (knitr:::is_html_output()) '
# References {-}
'`

---

<style>
p { margin-top: 0; margin-bottom: 20px; }
</style>

<br></br>

<!--chapter:end:99-references.Rmd-->

